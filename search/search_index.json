{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Awning Management System Documentation","text":"<p>Welcome to the documentation for the Awning Management System - a comprehensive Flask-based application for managing work orders, repair orders, customers, inventory, and analytics for an awning cleaning and repair business.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p> User Guide</p> <p>Learn how to use the application's features for day-to-day operations.</p> <p> Get Started</p> </li> <li> <p> Developer Guide</p> <p>Set up your development environment and learn the codebase architecture.</p> <p> Setup</p> </li> <li> <p> Database</p> <p>Learn about database migrations, schema changes, and data management.</p> <p> Alembic Guide</p> </li> <li> <p> Deployment</p> <p>Deploy to AWS Elastic Beanstalk and manage production environments.</p> <p> Deployment Guide</p> </li> </ul>"},{"location":"#what-is-the-awning-management-system","title":"What is the Awning Management System?","text":"<p>The Awning Management System is a full-featured web application built with Flask that helps manage:</p> <ul> <li>Work Orders - Track cleaning jobs from intake to completion</li> <li>Repair Orders - Manage repair jobs with detailed item tracking</li> <li>Customers - Maintain customer records and order history</li> <li>Sources &amp; Vendors - Track sail lofts and vendor relationships</li> <li>Inventory - Monitor inventory items and usage</li> <li>Queue Management - Organize cleaning and repair queues</li> <li>Analytics - Visualize business metrics and trends with interactive dashboards</li> <li>ML Predictions - Predict work order completion times using machine learning</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#for-users","title":"For Users","text":"<ul> <li>Intuitive Interface - Clean, easy-to-navigate UI for daily operations</li> <li>Queue Workflows - Streamlined cleaning and repair queue management</li> <li>PDF Generation - Automated PDF reports for work orders and repair orders</li> <li>Real-time Analytics - Interactive dashboards with business insights</li> <li>Keyboard Shortcuts - Power user shortcuts for faster data entry</li> <li>Multi-user Support - Role-based access control and user management</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>Modern Stack - Flask, SQLAlchemy, PostgreSQL, Alembic</li> <li>ML Integration - LightGBM model for completion time predictions</li> <li>Cloud Ready - Deployed on AWS Elastic Beanstalk with RDS and S3</li> <li>Well Tested - Comprehensive pytest test suite with high coverage</li> <li>CI/CD Pipeline - GitHub Actions for automated testing and deployment</li> <li>Database Migrations - Alembic for safe schema evolution</li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":""},{"location":"#user-guide","title":"User Guide","text":"<p>Everything users need to know to operate the system effectively.</p> <ul> <li>Getting Started - First steps and login</li> <li>Work Orders - Creating and managing work orders</li> <li>Repair Orders - Handling repair jobs</li> <li>Analytics Dashboard - Understanding business metrics</li> <li>Keyboard Shortcuts - Power user tips</li> </ul>"},{"location":"#developer-guide","title":"Developer Guide","text":"<p>For developers working on or extending the codebase.</p> <ul> <li>Setup &amp; Installation - Local development setup</li> <li>Project Structure - Codebase organization</li> <li>Database Schema - Data models and relationships</li> <li>Testing - Running and writing tests</li> <li>Contributing - Contribution guidelines</li> </ul>"},{"location":"#database","title":"Database","text":"<p>Database schema, migrations, and data management.</p> <ul> <li>Alembic Migration Guide - Complete migration workflow</li> <li>Storage Fields Guide - Understanding storage fields</li> </ul>"},{"location":"#deployment","title":"Deployment","text":"<p>Production deployment and operations.</p> <ul> <li>AWS Elastic Beanstalk - Deployment to AWS</li> <li>Deployment Checklist - Pre-deployment verification</li> <li>Monitoring &amp; Logging - Production monitoring</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>System design, performance, and technical deep-dives.</p> <ul> <li>System Overview - High-level architecture</li> <li>ML Prediction System - Machine learning implementation</li> <li>Caching Strategy - Performance optimization</li> <li>Performance Analysis - Query optimization</li> <li>Concurrency Audit - Thread safety and locking</li> </ul>"},{"location":"#planning","title":"Planning","text":"<p>Future improvements and refactoring plans.</p> <ul> <li>Improvement Roadmap - Planned enhancements</li> <li>Refactoring Plan - Code improvement plans</li> <li>Denormalization Analysis - Database optimization plans</li> </ul>"},{"location":"#tech-stack","title":"Tech Stack","text":"Category Technologies Backend Flask 2.3.3, Python 3.x Database PostgreSQL, SQLAlchemy, Alembic Authentication Flask-Login Forms Flask-WTF, WTForms ML/Analytics scikit-learn, LightGBM, pandas, polars, plotly Documents reportlab, PyMuPDF, python-docx Cloud AWS Elastic Beanstalk, RDS, S3 Testing pytest, pytest-flask, pytest-cov CI/CD GitHub Actions"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>For Users: See the User Guide or FAQ</li> <li>For Developers: Check the Developer Guide or Troubleshooting</li> <li>Issues: Report bugs on GitHub Issues</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#for-users_1","title":"For Users","text":"<ol> <li>Navigate to the application URL</li> <li>Log in with your credentials</li> <li>Start with the Getting Started Guide</li> </ol>"},{"location":"#for-developers_1","title":"For Developers","text":"<p><pre><code># Clone the repository\ngit clone https://github.com/andrewimpellitteri/awning_wo.git\ncd awning_wo\n\n# Follow the setup guide\n</code></pre> See the full Setup &amp; Installation Guide for detailed instructions.</p>"},{"location":"#repository","title":"Repository","text":"<p>GitHub: andrewimpellitteri/awning_wo</p> <p>Documentation Version</p> <p>This documentation is automatically built from the latest version of the codebase.</p>"},{"location":"README_DOCS_REORGANIZATION/","title":"Documentation Reorganization Guide","text":"<p>This guide explains the new documentation structure and how to complete the reorganization.</p>"},{"location":"README_DOCS_REORGANIZATION/#what-changed","title":"What Changed?","text":""},{"location":"README_DOCS_REORGANIZATION/#before","title":"Before","text":"<pre><code>docs/\n\u251c\u2500\u2500 ALEMBIC_GUIDE.md\n\u251c\u2500\u2500 CACHING_GUIDE.md\n\u251c\u2500\u2500 CONCURRENCY_AUDIT.md\n\u251c\u2500\u2500 DENORMALIZATION_ANALYSIS.md\n\u251c\u2500\u2500 DEPLOYMENT_CHECKLIST.md\n\u251c\u2500\u2500 IMPROVEMENTS.md\n\u251c\u2500\u2500 PERFORMANCE_ANALYSIS.md\n\u251c\u2500\u2500 REFACTORING_PLAN.md\n\u251c\u2500\u2500 STORAGE_FIELDS_GUIDE.md\n\u251c\u2500\u2500 WASM_THUMBNAIL_OPTIMIZATION.md\n\u2514\u2500\u2500 index.md\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#after","title":"After","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                          # Main documentation homepage\n\u251c\u2500\u2500 user-guide/                       # For end users\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 getting-started.md\n\u2502   \u251c\u2500\u2500 work-orders.md\n\u2502   \u251c\u2500\u2500 repair-orders.md\n\u2502   \u251c\u2500\u2500 customers.md\n\u2502   \u251c\u2500\u2500 sources.md\n\u2502   \u251c\u2500\u2500 inventory.md\n\u2502   \u251c\u2500\u2500 queue.md\n\u2502   \u251c\u2500\u2500 analytics.md\n\u2502   \u251c\u2500\u2500 pdf-reports.md\n\u2502   \u2514\u2500\u2500 keyboard-shortcuts.md\n\u251c\u2500\u2500 developer-guide/                  # For developers\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 setup.md\n\u2502   \u251c\u2500\u2500 project-structure.md\n\u2502   \u251c\u2500\u2500 database-schema.md\n\u2502   \u251c\u2500\u2500 api-reference.md\n\u2502   \u251c\u2500\u2500 testing.md\n\u2502   \u2514\u2500\u2500 contributing.md\n\u251c\u2500\u2500 database/                         # Database &amp; migrations\n\u2502   \u251c\u2500\u2500 ALEMBIC_GUIDE.md             \u2705 Existing\n\u2502   \u251c\u2500\u2500 STORAGE_FIELDS_GUIDE.md      \u2705 Existing\n\u2502   \u2514\u2500\u2500 schema-changes.md\n\u251c\u2500\u2500 deployment/                       # Deployment guides\n\u2502   \u251c\u2500\u2500 aws-eb.md\n\u2502   \u251c\u2500\u2500 DEPLOYMENT_CHECKLIST.md      \u2705 Existing\n\u2502   \u251c\u2500\u2500 environment-variables.md\n\u2502   \u251c\u2500\u2500 monitoring.md\n\u2502   \u2514\u2500\u2500 rollback.md\n\u251c\u2500\u2500 architecture/                     # Technical architecture\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u251c\u2500\u2500 ml-system.md\n\u2502   \u251c\u2500\u2500 CACHING_GUIDE.md             \u2705 Existing\n\u2502   \u251c\u2500\u2500 PERFORMANCE_ANALYSIS.md      \u2705 Existing\n\u2502   \u2514\u2500\u2500 CONCURRENCY_AUDIT.md         \u2705 Existing\n\u251c\u2500\u2500 planning/                         # Future improvements\n\u2502   \u251c\u2500\u2500 IMPROVEMENTS.md              \u2705 Existing\n\u2502   \u251c\u2500\u2500 REFACTORING_PLAN.md          \u2705 Existing\n\u2502   \u251c\u2500\u2500 DENORMALIZATION_ANALYSIS.md  \u2705 Existing\n\u2502   \u2514\u2500\u2500 WASM_THUMBNAIL_OPTIMIZATION.md \u2705 Existing\n\u2514\u2500\u2500 reference/                        # Quick reference\n    \u251c\u2500\u2500 faq.md\n    \u251c\u2500\u2500 troubleshooting.md\n    \u2514\u2500\u2500 glossary.md\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#step-by-step-reorganization","title":"Step-by-Step Reorganization","text":""},{"location":"README_DOCS_REORGANIZATION/#step-1-run-the-reorganization-script","title":"Step 1: Run the Reorganization Script","text":"<p>This moves existing docs to their new locations:</p> <pre><code>chmod +x reorganize_docs.sh\n./reorganize_docs.sh\n</code></pre> <p>This will: - Create the new directory structure - Move existing .md files to appropriate locations - Keep your existing documentation intact</p>"},{"location":"README_DOCS_REORGANIZATION/#step-2-create-placeholder-files","title":"Step 2: Create Placeholder Files","text":"<p>This creates starter content for missing documentation:</p> <pre><code>chmod +x create_doc_placeholders.sh\n./create_doc_placeholders.sh\n</code></pre> <p>This creates: - User guide pages with basic structure - Developer guide foundations - Reference materials (FAQ, troubleshooting, glossary)</p>"},{"location":"README_DOCS_REORGANIZATION/#step-3-preview-the-documentation","title":"Step 3: Preview the Documentation","text":"<p>Install MkDocs and dependencies:</p> <pre><code>pip install mkdocs-material\npip install mkdocs-git-revision-date-localized-plugin\n</code></pre> <p>Serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000</code> to preview.</p>"},{"location":"README_DOCS_REORGANIZATION/#step-4-fill-in-the-gaps","title":"Step 4: Fill in the Gaps","text":"<p>You now have a skeleton. Fill in content over time:</p>"},{"location":"README_DOCS_REORGANIZATION/#priority-1-essential-user-docs","title":"Priority 1: Essential User Docs","text":"<ul> <li>[ ] <code>user-guide/work-orders.md</code> - Expand with screenshots</li> <li>[ ] <code>user-guide/repair-orders.md</code> - Add workflow diagrams</li> <li>[ ] <code>user-guide/queue.md</code> - Document queue workflows</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#priority-2-developer-onboarding","title":"Priority 2: Developer Onboarding","text":"<ul> <li>[ ] <code>developer-guide/setup.md</code> - Verify setup steps</li> <li>[ ] <code>developer-guide/database-schema.md</code> - Add ER diagrams</li> <li>[ ] <code>developer-guide/testing.md</code> - Document test patterns</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#priority-3-operations","title":"Priority 3: Operations","text":"<ul> <li>[ ] <code>deployment/aws-eb.md</code> - Complete deployment guide</li> <li>[ ] <code>deployment/monitoring.md</code> - Add monitoring setup</li> <li>[ ] <code>deployment/environment-variables.md</code> - Document all env vars</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#priority-4-architecture","title":"Priority 4: Architecture","text":"<ul> <li>[ ] <code>architecture/overview.md</code> - System architecture diagram</li> <li>[ ] <code>architecture/ml-system.md</code> - ML pipeline documentation</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#documentation-philosophy","title":"Documentation Philosophy","text":""},{"location":"README_DOCS_REORGANIZATION/#for-users","title":"For Users","text":"<ul> <li>Task-oriented - Focus on \"how to do X\"</li> <li>Screenshots - Show, don't just tell</li> <li>Examples - Real-world scenarios</li> <li>Simple language - Avoid jargon</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#for-developers","title":"For Developers","text":"<ul> <li>Code examples - Show actual code</li> <li>Architecture diagrams - Visualize structure</li> <li>Technical depth - Don't oversimplify</li> <li>Links to code - Reference actual files</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#writing-tips","title":"Writing Tips","text":""},{"location":"README_DOCS_REORGANIZATION/#good-user-documentation","title":"Good User Documentation","text":"<pre><code>## Creating a Work Order\n\n1. Click \"New Work Order\" in the top menu\n2. Select a customer from the dropdown\n3. Fill in the date and source\n4. Click \"Save\"\n\n![Screenshot of work order form](../images/work-order-form.png)\n\n!!! tip\n    Use Ctrl+N to quickly create a new work order\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#good-developer-documentation","title":"Good Developer Documentation","text":"<pre><code>## Work Order Model\n\nThe WorkOrder model represents a cleaning job.\n\n**File:** [models/work_order.py](../../models/work_order.py)\n\n```python\nclass WorkOrder(db.Model):\n    __tablename__ = \"tblcustworkorderdetail\"\n    work_order_no = db.Column(\"workorderno\", db.Integer, primary_key=True)\n    # ...\n</code></pre> <p>Relationships: - Belongs to: Customer (via custid) - Has many: WorkOrderFiles <pre><code>## MkDocs Features\n\n### Admonitions (Callouts)\n\n```markdown\n!!! note\n    This is a note\n\n!!! warning\n    This is a warning\n\n!!! tip\n    This is a helpful tip\n\n!!! danger\n    This is critical information\n</code></pre></p>"},{"location":"README_DOCS_REORGANIZATION/#tabs","title":"Tabs","text":"<pre><code>=== \"Python\"\n    ```python\n    def hello():\n        print(\"Hello!\")\n    ```\n\n=== \"JavaScript\"\n    ```javascript\n    function hello() {\n        console.log(\"Hello!\");\n    }\n    ```\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#code-blocks-with-line-numbers","title":"Code Blocks with Line Numbers","text":"<p><pre><code>```python linenums=\"1\"\ndef example():\n    return \"Hello\"\n</code></pre> <pre><code>## Publishing the Docs\n\n### Option 1: GitHub Pages (Recommended)\n\n```bash\n# Build the docs\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre></p> <p>This creates a <code>gh-pages</code> branch with the built site.</p> <p>Configure GitHub Pages: 1. Go to repository Settings 2. Pages section 3. Source: Deploy from branch 4. Branch: gh-pages / root 5. Save</p> <p>Your docs will be at: <code>https://andrewimpellitteri.github.io/awning_wo/</code></p>"},{"location":"README_DOCS_REORGANIZATION/#option-2-netlifyvercel","title":"Option 2: Netlify/Vercel","text":"<p>Both support MkDocs. Add a build command:</p> <pre><code>mkdocs build\n</code></pre> <p>And publish directory: <code>site/</code></p>"},{"location":"README_DOCS_REORGANIZATION/#maintenance","title":"Maintenance","text":""},{"location":"README_DOCS_REORGANIZATION/#adding-new-documentation","title":"Adding New Documentation","text":"<ol> <li>Create the .md file in the appropriate directory</li> <li>Add it to <code>mkdocs.yml</code> in the <code>nav:</code> section</li> <li>Test with <code>mkdocs serve</code></li> <li>Commit and push</li> </ol>"},{"location":"README_DOCS_REORGANIZATION/#updating-existing-documentation","title":"Updating Existing Documentation","text":"<ol> <li>Edit the .md file</li> <li>Preview with <code>mkdocs serve</code></li> <li>Commit and push</li> <li>Redeploy with <code>mkdocs gh-deploy</code> (if using GitHub Pages)</li> </ol>"},{"location":"README_DOCS_REORGANIZATION/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Run <code>./reorganize_docs.sh</code></li> <li>\u2705 Run <code>./create_doc_placeholders.sh</code></li> <li>\u2705 Preview with <code>mkdocs serve</code></li> <li>\ud83d\udcdd Fill in user guide content</li> <li>\ud83d\udcdd Add developer documentation</li> <li>\ud83d\ude80 Deploy to GitHub Pages</li> </ol>"},{"location":"README_DOCS_REORGANIZATION/#questions","title":"Questions?","text":"<ul> <li>MkDocs Documentation: https://www.mkdocs.org/</li> <li>Material Theme: https://squidfunk.github.io/mkdocs-material/</li> <li>Markdown Guide: https://www.markdownguide.org/</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#file-locations-summary","title":"File Locations Summary","text":"Type Old Location New Location Database guides <code>docs/*.md</code> <code>docs/database/</code> Deployment <code>docs/*.md</code> <code>docs/deployment/</code> Architecture <code>docs/*.md</code> <code>docs/architecture/</code> Planning <code>docs/*.md</code> <code>docs/planning/</code> User guides (new) <code>docs/user-guide/</code> Developer guides (new) <code>docs/developer-guide/</code> Reference (new) <code>docs/reference/</code>"},{"location":"architecture/CACHING_GUIDE/","title":"Caching Implementation Guide","text":""},{"location":"architecture/CACHING_GUIDE/#whats-been-implemented","title":"What's Been Implemented","text":""},{"location":"architecture/CACHING_GUIDE/#core-setup-complete","title":"Core Setup (Complete)","text":"<ul> <li>\u2705 Flask-Caching installed and configured</li> <li>\u2705 SimpleCache for production/dev (in-memory)</li> <li>\u2705 NullCache for tests (no caching during tests)</li> <li>\u2705 Cache utilities in <code>utils/cache_helpers.py</code></li> </ul>"},{"location":"architecture/CACHING_GUIDE/#customer-routes-complete","title":"Customer Routes (Complete)","text":"<p>File: <code>routes/customers.py</code> - \u2705 Cached <code>get_customer_filter_options()</code> - 10min cache - \u2705 Cache invalidation in create/edit/delete - Savings: 2 queries eliminated per page load</p>"},{"location":"architecture/CACHING_GUIDE/#recommended-additions","title":"Recommended Additions","text":""},{"location":"architecture/CACHING_GUIDE/#high-priority-easy-wins","title":"High Priority (Easy Wins)","text":""},{"location":"architecture/CACHING_GUIDE/#1-source-routes-routessourcepy","title":"1. Source Routes (<code>routes/source.py</code>)","text":"<p>Similar to customers - filter dropdowns rarely change.</p> <pre><code>@cache.memoize(timeout=900)  # 15 minutes\ndef get_source_filter_options():\n    states = db.session.query(Source.SourceState).distinct().all()\n    return unique_states\n\n# Invalidate in: create_source(), edit_source(), delete_source()\n</code></pre> <p>Impact: 1-2 queries saved per source list page load</p>"},{"location":"architecture/CACHING_GUIDE/#2-dashboard-metrics-routesdashboardpy","title":"2. Dashboard Metrics (<code>routes/dashboard.py</code>)","text":"<p>Counts and stats don't need to be real-time.</p> <pre><code>@cache.memoize(timeout=300)  # 5 minutes\ndef get_dashboard_counts():\n    pending = WorkOrder.query.filter(...).count()\n    in_progress = WorkOrder.query.filter(...).count()\n    completed_today = WorkOrder.query.filter(...).count()\n    return {'pending': pending, 'in_progress': in_progress, ...}\n\n# Invalidate when work orders change\n</code></pre> <p>Impact: 3-5 count queries saved per dashboard load</p>"},{"location":"architecture/CACHING_GUIDE/#3-analytics-data-routesanalyticspy","title":"3. Analytics Data (<code>routes/analytics.py</code>)","text":"<p>Most expensive - pandas/plotly operations.</p> <pre><code>@cache.memoize(timeout=1800)  # 30 minutes\ndef get_revenue_chart_data(date_range):\n    df = pd.read_sql(query, db.engine)\n    # ... expensive processing ...\n    return fig.to_json()\n\n# Invalidate when work orders completed\n</code></pre> <p>Impact: Huge - 2-5 second queries reduced to milliseconds</p>"},{"location":"architecture/CACHING_GUIDE/#medium-priority","title":"Medium Priority","text":""},{"location":"architecture/CACHING_GUIDE/#4-work-order-filter-options-routeswork_orderspy","title":"4. Work Order Filter Options (<code>routes/work_orders.py</code>)","text":"<p>Similar pattern to customers.</p> <pre><code>@cache.memoize(timeout=600)\ndef get_work_order_filter_options():\n    # Ship-to sources, statuses, etc.\n    pass\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#5-inventory-lookups-routesinventorypy","title":"5. Inventory Lookups (<code>routes/inventory.py</code>)","text":"<p>If customers have large inventories.</p> <pre><code>@cache.memoize(timeout=300)\ndef get_customer_inventory(cust_id):\n    return Inventory.query.filter_by(CustID=cust_id).all()\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#low-priority-optional","title":"Low Priority (Optional)","text":""},{"location":"architecture/CACHING_GUIDE/#6-source-lookups","title":"6. Source Lookups","text":"<p>Frequently accessed but rarely changed.</p> <pre><code>@cache.memoize(timeout=1800)\ndef get_source_by_name(source_name):\n    return Source.query.filter_by(SSource=source_name).first()\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#7-queue-summary-stats-routesqueuepy","title":"7. Queue Summary Stats (<code>routes/queue.py</code>)","text":"<p>If summary endpoint is slow.</p> <pre><code>@cache.memoize(timeout=120)  # 2 minutes - more dynamic\ndef get_queue_summary():\n    # firm_rush_count, rush_count, regular_count\n    pass\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#cache-invalidation-strategy","title":"Cache Invalidation Strategy","text":""},{"location":"architecture/CACHING_GUIDE/#when-to-invalidate","title":"When to Invalidate","text":"Event Invalidate Customer created/edited/deleted <code>invalidate_customer_cache()</code> Source created/edited/deleted <code>invalidate_source_cache()</code> Work order created/edited/completed <code>invalidate_work_order_cache()</code> Repair order created/edited/completed <code>invalidate_repair_order_cache()</code> Dashboard should refresh <code>invalidate_work_order_cache()</code> Analytics should refresh <code>invalidate_analytics_cache()</code> <p>All helpers are in <code>utils/cache_helpers.py</code>.</p>"},{"location":"architecture/CACHING_GUIDE/#testing","title":"Testing","text":"<p>Caching is automatically disabled in tests (<code>CACHE_TYPE = \"NullCache\"</code>).</p> <p>To manually test caching in development:</p> <pre><code># In Flask shell or route\nfrom extensions import cache\n\n# Check if cached\ncached_val = cache.get('some_key')\n\n# Clear specific cache\ncache.delete_memoized(get_customer_filter_options)\n\n# Clear all caches\ncache.clear()\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#performance-monitoring","title":"Performance Monitoring","text":"<p>To see cache effectiveness, enable SQLAlchemy query logging:</p> <pre><code># In development\nimport logging\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n# Load page twice - second time should show fewer queries\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#notes","title":"Notes","text":"<ul> <li>SimpleCache is in-memory and process-specific</li> <li>Cache is cleared on app restart (by design)</li> <li>For 8 users and 50MB DB, this is perfect</li> <li>If you scale beyond 1 instance, consider Redis (but not needed now)</li> <li>Cache timeouts are conservative - adjust based on usage patterns</li> </ul>"},{"location":"architecture/CACHING_GUIDE/#quick-reference","title":"Quick Reference","text":"<pre><code># Import in routes\nfrom extensions import cache\nfrom utils.cache_helpers import invalidate_customer_cache\n\n# Cache a function\n@cache.memoize(timeout=600)  # seconds\ndef my_expensive_query():\n    return db.session.query(...).all()\n\n# Invalidate when data changes\ndb.session.commit()\ninvalidate_customer_cache()\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/","title":"Concurrency &amp; Race Condition Audit Report","text":"<p>Date: 2025-10-12 Application: Awning Work Order Management System Target Load: 8 concurrent users on AWS Elastic Beanstalk</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#executive-summary","title":"Executive Summary","text":"<p>This audit identified 11 distinct concurrency issues in the Flask application, ranging from critical race conditions in ID generation to architectural concerns with global state management. The application is generally well-structured with good practices, but several issues could cause data corruption or inconsistent behavior under concurrent load.</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#issue-breakdown","title":"Issue Breakdown","text":"<ul> <li>\ud83d\udd34 Critical (4): Race conditions that can cause data corruption</li> <li>\ud83d\udfe1 High Priority (3): Architectural issues affecting consistency</li> <li>\ud83d\udfe0 Medium Priority (4): Potential data loss or inconsistency scenarios</li> </ul>"},{"location":"architecture/CONCURRENCY_AUDIT/#critical-issues","title":"\ud83d\udd34 Critical Issues","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#1-race-condition-work-order-number-generation","title":"1. Race Condition: Work Order Number Generation","text":"<p>Impact: Duplicate work order numbers under concurrent load Location: <code>routes/work_orders.py:355-358</code> Affected Operations: Creating new work orders</p> <p>Current Code: <pre><code>latest_num = db.session.query(func.max(cast(WorkOrder.WorkOrderNo, Integer))).scalar()\nnext_wo_no = str(latest_num + 1) if latest_num is not None else \"1\"\n</code></pre></p> <p>Problem: Two simultaneous requests can retrieve the same max value and attempt to create work orders with identical numbers.</p> <p>Solution: - Add UNIQUE constraint to <code>WorkOrderNo</code> in database - Implement retry logic with IntegrityError handling - Use database sequences or serial columns</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#2-race-condition-customer-id-generation","title":"2. Race Condition: Customer ID Generation","text":"<p>Impact: Duplicate customer IDs Location: <code>routes/customers.py:220-223</code> Affected Operations: Creating new customers</p> <p>Current Code: <pre><code>max_cust_id = db.session.query(func.max(cast(Customer.CustID, Integer))).scalar()\nnew_cust_id = str(max_cust_id + 1) if max_cust_id else \"1\"\n</code></pre></p> <p>Problem: Same read-then-increment race condition as work orders.</p> <p>Solution: Same as Issue #1</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#3-race-condition-repair-order-number-generation","title":"3. Race Condition: Repair Order Number Generation","text":"<p>Impact: Duplicate repair order numbers Location: <code>routes/repair_order.py:366-377</code> Affected Operations: Creating new repair orders</p> <p>Current Code: <pre><code>latest_order = RepairWorkOrder.query.order_by(desc(RepairWorkOrder.RepairOrderNo)).first()\nif latest_order:\n    try:\n        next_num = int(latest_order.RepairOrderNo) + 1\n    except ValueError:\n        next_num = int(datetime.now().timestamp())\nelse:\n    next_num = 1\n</code></pre></p> <p>Problem: Same pattern - vulnerable to concurrent creation.</p> <p>Solution: Same as Issue #1</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#4-race-condition-queue-position-updates","title":"4. Race Condition: Queue Position Updates","text":"<p>Impact: Conflicting queue position assignments Location: <code>routes/queue.py:481-493</code> Affected Operations: Manual queue reordering</p> <p>Current Code: <pre><code>for index, wo_id in enumerate(work_order_ids):\n    work_order = WorkOrder.query.filter_by(WorkOrderNo=wo_id).first()\n    work_order.QueuePosition = start_position + index\ndb.session.commit()\n</code></pre></p> <p>Problem: Two users reordering simultaneously can create position conflicts.</p> <p>Solution: - Use <code>SELECT FOR UPDATE</code> (pessimistic locking) - Add version column for optimistic locking - Add mutex/lock for queue operations</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#high-priority-issues","title":"\ud83d\udfe1 High Priority Issues","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#5-global-mutable-state-ml-model","title":"5. Global Mutable State: ML Model","text":"<p>Impact: Inconsistent predictions, model update race conditions Location: <code>routes/ml.py:49-50</code> Affected Operations: ML predictions, model retraining</p> <p>Current Code: <pre><code>current_model = None\nmodel_metadata = {}\n</code></pre></p> <p>Problem: - Global variables shared across requests in same worker - No synchronization during updates - Each Gunicorn worker has different model state - Race conditions during concurrent predictions and retraining</p> <p>Solution: - Use threading.Lock for model updates - Store model in Redis or shared storage - Load model on worker startup - Implement proper multi-worker coordination</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#6-weak-authentication-ml-cron-endpoint","title":"6. Weak Authentication: ML Cron Endpoint","text":"<p>Impact: Unauthorized model retraining Location: <code>routes/ml.py:704-712</code> Affected Operations: Automated ML model retraining</p> <p>Current Code: <pre><code>secret = request.headers.get(\"X-Cron-Secret\") or (request.json or {}).get(\"secret\")\nexpected_secret = os.getenv(\"CRON_SECRET\", \"your-secret-key\")\nif secret != expected_secret:\n    return jsonify({\"error\": \"Unauthorized\"}), 401\n</code></pre></p> <p>Problem: Only header-based secret, no additional protection</p> <p>Solution: - Add IP whitelist for cron jobs - Implement rate limiting - Use request signing with timestamp - Consider AWS EventBridge with IAM</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#7-missing-transaction-boundaries","title":"7. Missing Transaction Boundaries","text":"<p>Impact: Partial updates on failure Location: Multiple routes (e.g., <code>repair_order.py:661-663</code>) Affected Operations: Repair order item updates</p> <p>Current Code: <pre><code>RepairWorkOrderItem.query.filter_by(RepairOrderNo=repair_order_no).delete()\n# ... then add new items\n</code></pre></p> <p>Problem: If process fails after delete but before adding new items, data is lost.</p> <p>Solution: - Use explicit <code>db.session.begin_nested()</code> for savepoints - Ensure atomic delete+insert operations - Add proper rollback on any exception</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#medium-priority-issues","title":"\ud83d\udfe0 Medium Priority Issues","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#8-inventory-quantity-race-condition","title":"8. Inventory Quantity Race Condition","text":"<p>Impact: Lost inventory updates Location: <code>routes/work_orders.py:624-630</code> Affected Operations: Adding new items to catalog</p> <p>Current Code: <pre><code>current_catalog_qty = safe_int_conversion(existing_inventory.Qty)\nnew_catalog_qty = current_catalog_qty + work_order_qty\nexisting_inventory.Qty = str(new_catalog_qty)\n</code></pre></p> <p>Problem: Read-modify-write without locking; concurrent additions lose updates</p> <p>Solution: Use atomic SQL update <pre><code>db.session.query(Inventory).filter_by(\n    InventoryKey=key\n).update({\n    Inventory.Qty: Inventory.Qty + work_order_qty\n})\n</code></pre></p>"},{"location":"architecture/CONCURRENCY_AUDIT/#9-cache-invalidation-timing","title":"9. Cache Invalidation Timing","text":"<p>Impact: Stale cache on commit failure Location: <code>routes/customers.py:259, 328, 372</code> Affected Operations: Customer create/update/delete</p> <p>Current Pattern: <pre><code>db.session.commit()\ninvalidate_customer_cache()  # After commit\n</code></pre></p> <p>Problem: If commit fails after cache invalidation is called (in exception handler), cache is unnecessarily cleared.</p> <p>Solution: Invalidate only after successful commit (current code is actually correct, but add explicit error handling)</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#10-file-upload-transaction-coordination","title":"10. File Upload Transaction Coordination","text":"<p>Impact: Orphaned S3 files on database failure Location: <code>utils/file_upload.py</code> Affected Operations: Work order and repair order file uploads</p> <p>Problem: S3 upload happens before database commit. If commit fails, S3 files remain orphaned.</p> <p>Solution: - Upload to S3 AFTER database commit succeeds - Implement cleanup job for orphaned files - Use two-phase commit pattern - Store files locally first, upload async</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#11-backlink-update-race-condition","title":"11. Backlink Update Race Condition","text":"<p>Impact: Unexpected overwrite of repair-to-work-order links Location: <code>routes/work_orders.py:422-433</code> Affected Operations: Linking work orders to repair orders</p> <p>Current Code: <pre><code>if see_repair and see_repair.strip():\n    referenced_repair = RepairWorkOrder.query.filter_by(\n        RepairOrderNo=see_repair.strip()\n    ).first()\n    if referenced_repair:\n        referenced_repair.SEECLEAN = next_wo_no\n</code></pre></p> <p>Problem: Two work orders linking to same repair simultaneously can cause last-write-wins.</p> <p>Solution: - Use optimistic locking with version column - Add validation for conflicting links - Consider link table instead of direct foreign keys</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#good-practices-found","title":"\u2705 Good Practices Found","text":"<ol> <li>Proper exception handling with <code>db.session.rollback()</code></li> <li>Connection pool configuration - <code>pool_size=10</code>, <code>max_overflow=20</code></li> <li>Pool pre-ping enabled to prevent stale connections</li> <li>Connection recycling at 300s</li> <li>CSRF protection enabled</li> <li>Role-based access control with decorators</li> <li>Eager loading with <code>joinedload()</code> prevents N+1 queries</li> <li>Denormalized data (<code>source_name</code>) for performance</li> <li>Inventory as \"static catalog only\" avoids complex stock management races</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#configuration-review","title":"Configuration Review","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#current-database-pool-settings-configpy","title":"Current Database Pool Settings (<code>config.py</code>)","text":"<pre><code>SQLALCHEMY_ENGINE_OPTIONS = {\n    \"pool_pre_ping\": True,\n    \"pool_recycle\": 300,\n    \"pool_size\": 10,\n    \"max_overflow\": 20,\n}\n</code></pre> <p>Assessment: \u2705 Excellent for 8 concurrent users - 10 persistent connections + 20 overflow = 30 max connections - Well-sized for 8 users with buffer</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#cache-configuration-configpy","title":"Cache Configuration (<code>config.py</code>)","text":"<pre><code>CACHE_TYPE = \"SimpleCache\"  # In-memory, thread-safe\nCACHE_DEFAULT_TIMEOUT = 300\n</code></pre> <p>Assessment: \u26a0\ufe0f Not ideal for multi-worker deployment - <code>SimpleCache</code> is thread-safe but NOT process-safe - Each Gunicorn worker has separate cache - Cache invalidation only affects one worker</p> <p>Recommendation: Use Redis for production <pre><code>CACHE_TYPE = \"redis\"\nCACHE_REDIS_URL = \"redis://localhost:6379/0\"\n</code></pre></p>"},{"location":"architecture/CONCURRENCY_AUDIT/#session-configuration","title":"Session Configuration","text":"<pre><code>PERMANENT_SESSION_LIFETIME = timedelta(hours=24)\nSESSION_COOKIE_SECURE = FLASK_ENV == \"production\"\nSESSION_COOKIE_HTTPONLY = True\n</code></pre> <p>Assessment: \u2705 Good security practices</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#recommended-action-plan","title":"Recommended Action Plan","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#phase-1-critical-fixes-week-1","title":"Phase 1: Critical Fixes (Week 1)","text":"<ol> <li>Add UNIQUE constraints to database schema</li> <li>Implement retry logic for ID generation</li> <li>Add threading.Lock to ML model updates</li> <li>Use SELECT FOR UPDATE for queue operations</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#phase-2-high-priority-week-2","title":"Phase 2: High Priority (Week 2)","text":"<ol> <li>Migrate to Redis cache</li> <li>Strengthen cron endpoint security</li> <li>Add explicit transaction boundaries</li> <li>Implement ML model coordination across workers</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#phase-3-medium-priority-week-3-4","title":"Phase 3: Medium Priority (Week 3-4)","text":"<ol> <li>Fix inventory atomic updates</li> <li>Improve file upload transaction handling</li> <li>Add optimistic locking for backlinks</li> <li>Implement orphaned file cleanup job</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#testing-recommendations","title":"Testing Recommendations","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#load-testing","title":"Load Testing","text":"<pre><code># Apache Bench - 100 requests, 8 concurrent\nab -n 100 -c 8 -p form_data.json -T application/json \\\n   http://your-app/work_orders/new\n\n# Check for duplicate IDs\npsql -c \"SELECT workorderno, COUNT(*) FROM tblcustworkorderdetail\n         GROUP BY workorderno HAVING COUNT(*) &gt; 1;\"\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/#locust-test-script","title":"Locust Test Script","text":"<pre><code>from locust import HttpUser, task, between\n\nclass WorkOrderUser(HttpUser):\n    wait_time = between(1, 3)\n\n    @task(3)\n    def create_work_order(self):\n        self.client.post(\"/work_orders/new\", json={...})\n\n    @task(1)\n    def reorder_queue(self):\n        self.client.post(\"/cleaning_queue/api/cleaning-queue/reorder\", json={...})\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/#monitor-for-issues","title":"Monitor for Issues","text":"<ul> <li>Database: Look for duplicate primary keys in logs</li> <li>Connection pool: Watch for pool exhaustion warnings</li> <li>ML predictions: Compare predictions across multiple requests</li> <li>Queue: Check for position conflicts</li> </ul>"},{"location":"architecture/CONCURRENCY_AUDIT/#database-schema-additions-needed","title":"Database Schema Additions Needed","text":"<pre><code>-- Add unique constraints\nALTER TABLE tblcustworkorderdetail\n  ADD CONSTRAINT uk_workorderno UNIQUE (workorderno);\n\nALTER TABLE tblcustomers\n  ADD CONSTRAINT uk_custid UNIQUE (custid);\n\nALTER TABLE tblrepairworkorder\n  ADD CONSTRAINT uk_repairorderno UNIQUE (repairorderno);\n\n-- Add version column for optimistic locking (optional)\nALTER TABLE tblcustworkorderdetail\n  ADD COLUMN version INTEGER DEFAULT 0;\n\nALTER TABLE tblrepairworkorder\n  ADD COLUMN version INTEGER DEFAULT 0;\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/#gunicorn-configuration","title":"Gunicorn Configuration","text":"<p>Recommended <code>gunicorn.conf.py</code>: <pre><code>workers = 3  # CPU cores\nthreads = 2  # 3 * 2 = 6 concurrent handlers\nworker_class = 'gthread'\ntimeout = 120\nkeepalive = 5\nmax_requests = 1000\nmax_requests_jitter = 100\n</code></pre></p> <p>Total capacity: 6 concurrent request handlers for 8 users = \u2705 Adequate</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#conclusion","title":"Conclusion","text":"<p>The application has a solid foundation with good database configuration and security practices. The main concerns are:</p> <ol> <li>ID generation race conditions - highest priority, can cause immediate data corruption</li> <li>Global ML model state - architectural issue affecting prediction consistency</li> <li>Multi-worker cache coordination - causes stale data across workers</li> </ol> <p>For 8 concurrent users, these issues are manageable but should be fixed to prevent: - Duplicate order numbers (confusing for staff) - Inconsistent ML predictions (erodes trust in system) - Stale cached data (customer sees old information)</p> <p>Estimated effort: 2-3 weeks for comprehensive fixes across all priority levels.</p> <p>Risk assessment: - Without fixes: Medium risk - issues will surface occasionally under load - With Phase 1 fixes: Low risk - critical data integrity issues resolved - With all phases: Very low risk - production-ready for concurrent users</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/","title":"Work Order List Query Performance Analysis","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#executive-summary","title":"Executive Summary","text":"<p>Your database is 60MB with 49,074 work orders, and most queries are ALREADY VERY FAST (&lt; 1ms execution time). However, there are 3 critical bottlenecks that need fixing:</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#critical-issues-found","title":"\ud83d\udea8 Critical Issues Found:","text":"<ol> <li>WorkOrderNo filters with CAST - 9-15ms (should be &lt; 1ms)</li> <li>DateRequired sorting - 16ms with Seq Scan (should be &lt; 1ms)</li> <li>Source sorting - 93ms with 3x Seq Scans (should be &lt; 10ms)</li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#whats-working-well","title":"\u2705 What's Working Well:","text":"<ul> <li>Primary key lookups: 0.086ms \u26a1</li> <li>Pending filter: 0.213ms \u26a1</li> <li>Rush orders: 0.086ms \u26a1</li> <li>CustID filter: 0.035ms \u26a1</li> <li>WOName text search: 0.237ms \u26a1</li> <li>DateIn sorting: 0.070ms \u26a1</li> <li>Customer joins: Well-optimized with Memoize</li> </ul>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#detailed-query-analysis","title":"Detailed Query Analysis","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-1-baseline-default-sort-by-workorderno","title":"Query #1: Baseline (Default Sort by WorkOrderNo)","text":"<p>Route: <code>/api/work_orders?page=1&amp;size=25</code></p> <pre><code>Execution Time: 0.086 ms \u26a1\nMethod: Index Scan Backward using tblcustworkorderdetail_pkey\nBuffers: shared hit=4 (all cached)\n</code></pre> <p>Status: \u2705 PERFECT - Using primary key index efficiently.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-2-count-query-pagination-total","title":"Query #2: Count Query (Pagination Total)","text":"<p>Route: Used for pagination total count</p> <pre><code>Execution Time: 7.215 ms\nMethod: Index Only Scan using idx_workorder_datein\nBuffers: shared hit=331\nHeap Fetches: 650 (needs to check visibility)\n</code></pre> <p>Status: \u26a0\ufe0f ACCEPTABLE - Count queries are inherently slower. 7ms is reasonable for 49K rows.</p> <p>Note: This is why modern UIs use \"approximate counts\" or \"load more\" instead of pagination.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-3-with-customer-join","title":"Query #3: With Customer Join","text":"<p>Route: <code>/api/work_orders</code> (default view with customer data)</p> <pre><code>Execution Time: 0.840 ms \u26a1\nMethod: Nested Loop with Memoize\nBuffers: shared hit=76\nMemoize: Hits=1, Misses=24 (96% cache hit rate)\n</code></pre> <p>Status: \u2705 EXCELLENT - PostgreSQL's Memoize feature is working perfectly to avoid N+1 queries.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-4-with-source-join","title":"Query #4: With Source Join","text":"<p>Route: <code>/api/work_orders</code> (when filtering or sorting by Source)</p> <pre><code>Execution Time: 0.758 ms \u26a1\nMethod: Double Nested Loop with double Memoize\nBuffers: shared hit=91\n</code></pre> <p>Status: \u2705 EXCELLENT - Even with 2 joins, still under 1ms.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-5-pending-filter-most-common","title":"Query #5: Pending Filter (Most Common)","text":"<p>Route: <code>/api/work_orders?status=pending</code></p> <pre><code>Execution Time: 0.213 ms \u26a1\nMethod: Index Scan using idx_workorder_pending\nBuffers: shared hit=24\n</code></pre> <p>Status: \u2705 PERFECT - Partial index working beautifully.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-6-completed-filter","title":"Query #6: Completed Filter","text":"<p>Route: <code>/api/work_orders?status=completed</code></p> <pre><code>Execution Time: 0.038 ms \u26a1\u26a1\nMethod: Index Scan Backward with filter\nBuffers: shared hit=4\n</code></pre> <p>Status: \u2705 PERFECT - Extremely fast.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-7-rush-orders","title":"Query #7: Rush Orders","text":"<p>Route: <code>/api/work_orders?status=rush</code></p> <pre><code>Execution Time: 0.086 ms \u26a1\nMethod: Bitmap Index Scan on idx_workorder_rush\nBuffers: shared hit=7\n</code></pre> <p>Status: \u2705 PERFECT - Rush order index working great.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-8-workorderno-range-filter-problem-1","title":"Query #8: \ud83d\udea8 WorkOrderNo Range Filter (PROBLEM #1)","text":"<p>Route: <code>/api/work_orders?filter_WorkOrderNo=100-200</code></p> <pre><code>Execution Time: 14.620 ms \ud83d\udc0c\nMethod: Index Scan with CAST filter\nBuffers: shared hit=2780\nRows Removed by Filter: 49,074 (FULL TABLE SCAN!)\n</code></pre> <p>Status: \ud83d\udea8 CRITICAL ISSUE</p> <p>Problem: <pre><code>Filter: (((wo.workorderno)::integer &gt;= 100) AND ((wo.workorderno)::integer &lt;= 200))\n</code></pre></p> <p>The <code>CAST(workorderno AS INTEGER)</code> prevents index usage, causing a full table scan.</p> <p>Solution: Create a computed index or change WorkOrderNo to an integer column.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-9-workorderno-exact-filter-problem-2","title":"Query #9: \ud83d\udea8 WorkOrderNo Exact Filter (PROBLEM #2)","text":"<p>Route: <code>/api/work_orders?filter_WorkOrderNo=100</code></p> <pre><code>Execution Time: 9.504 ms \ud83d\udc0c\nMethod: Index Scan with CAST filter\nBuffers: shared hit=2780\nRows Removed by Filter: 49,074 (FULL TABLE SCAN!)\n</code></pre> <p>Status: \ud83d\udea8 CRITICAL ISSUE - Same as Query #8.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-10-custid-filter","title":"Query #10: CustID Filter","text":"<p>Route: <code>/api/work_orders?filter_CustID=123</code></p> <pre><code>Execution Time: 0.035 ms \u26a1\u26a1\nMethod: Index Scan using idx_workorder_custid\nBuffers: shared hit=2\n</code></pre> <p>Status: \u2705 PERFECT - Extremely fast.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-11-woname-text-search","title":"Query #11: WOName Text Search","text":"<p>Route: <code>/api/work_orders?filter_WOName=test</code></p> <pre><code>Execution Time: 0.237 ms \u26a1\nMethod: Bitmap Index Scan on idx_workorder_woname_trgm\nBuffers: shared hit=22\n</code></pre> <p>Status: \u2705 EXCELLENT - Trigram index working great for ILIKE searches.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-12-source-filter","title":"Query #12: Source Filter","text":"<p>Route: <code>/api/work_orders?filter_Source=Smith</code></p> <pre><code>Execution Time: 0.071 ms \u26a1\u26a1\nMethod: Nested Loop with multiple indexes\nBuffers: shared hit=7\n</code></pre> <p>Status: \u2705 PERFECT - Complex join with multiple indexes, still under 1ms.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-13-sort-by-datein","title":"Query #13: Sort by DateIn","text":"<p>Route: <code>/api/work_orders?sort[0][field]=DateIn&amp;sort[0][dir]=desc</code></p> <pre><code>Execution Time: 0.070 ms \u26a1\u26a1\nMethod: Index Scan using idx_workorder_datein\nBuffers: shared hit=26\n</code></pre> <p>Status: \u2705 PERFECT - DateIn index working perfectly.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-14-sort-by-daterequired-problem-3","title":"Query #14: \ud83d\udea8 Sort by DateRequired (PROBLEM #3)","text":"<p>Route: <code>/api/work_orders?sort[0][field]=DateRequired&amp;sort[0][dir]=asc</code></p> <pre><code>Execution Time: 16.321 ms \ud83d\udc0c\nMethod: Sort with Seq Scan\nBuffers: shared hit=1267\nRows scanned: 49,074 (FULL TABLE SCAN!)\n</code></pre> <p>Status: \ud83d\udea8 NEEDS INDEX</p> <p>Problem: No index on <code>daterequired</code>, forcing a full table scan + in-memory sort.</p> <p>Solution: Add index on <code>daterequired</code>.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-15-sort-by-source-problem-4","title":"Query #15: \ud83d\udea8 Sort by Source (PROBLEM #4)","text":"<p>Route: <code>/api/work_orders?sort[0][field]=Source&amp;sort[0][dir]=asc</code></p> <pre><code>Execution Time: 93.005 ms \ud83d\udc0c\ud83d\udc0c\nMethod: Hash Join with 3x Seq Scans\nBuffers: shared hit=1673\n</code></pre> <p>Status: \ud83d\udea8 CRITICAL PERFORMANCE ISSUE</p> <p>Problem: - Seq Scan on <code>tblcustworkorderdetail</code> (49K rows) - Seq Scan on <code>tblcustomers</code> (26K rows) - Seq Scan on <code>tblsource</code> (563 rows) - Then Hash Join + Sort</p> <p>Solution: This query pattern is inherently expensive. Consider: 1. Denormalizing source name into work orders table 2. Using a materialized view 3. Caching this query result</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-16-complex-query-pending-filter-sort","title":"Query #16: Complex Query (Pending + Filter + Sort)","text":"<p>Route: <code>/api/work_orders?status=pending&amp;filter_WOName=test&amp;sort[0][field]=DateIn</code></p> <pre><code>Execution Time: 0.111 ms \u26a1\nMethod: BitmapAnd with multiple indexes\nBuffers: shared hit=8\n</code></pre> <p>Status: \u2705 EXCELLENT - Multiple indexes combined efficiently.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-17-deep-pagination","title":"Query #17: Deep Pagination","text":"<p>Route: <code>/api/work_orders?page=10&amp;size=25</code></p> <pre><code>Execution Time: 0.111 ms \u26a1\nMethod: Index Scan Backward with offset\nBuffers: shared hit=11\n</code></pre> <p>Status: \u2705 EXCELLENT - Even deep pagination is fast with index.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#performance-issues-summary","title":"Performance Issues Summary","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#issue-1-workorderno-cast-operations","title":"\ud83d\udea8 Issue #1: WorkOrderNo CAST Operations","text":"<p>Impact: Medium (14ms for range, 9ms for exact match) Frequency: Unknown (depends on user filtering behavior) Affected Queries: #8, #9</p> <p>Root Cause: - <code>workorderno</code> is stored as <code>VARCHAR/TEXT</code> - Filters require <code>CAST(workorderno AS INTEGER)</code> for numeric comparison - CAST prevents index usage \u2192 full table scan</p> <p>Solutions (pick one):</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-a-create-function-based-index-recommended","title":"Option A: Create Function-Based Index (RECOMMENDED)","text":"<p><pre><code>CREATE INDEX idx_workorder_no_int\nON tblcustworkorderdetail((workorderno::integer));\n</code></pre> Pros: No schema changes, backward compatible Cons: Adds index storage overhead</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-b-change-column-type","title":"Option B: Change Column Type","text":"<p><pre><code>ALTER TABLE tblcustworkorderdetail\nALTER COLUMN workorderno TYPE INTEGER USING workorderno::integer;\n</code></pre> Pros: Best performance, removes CAST overhead Cons: Requires application changes, migration effort</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#issue-2-daterequired-sorting","title":"\ud83d\udea8 Issue #2: DateRequired Sorting","text":"<p>Impact: Medium (16ms) Frequency: Likely low (DateIn sorting is more common) Affected Queries: #14</p> <p>Root Cause: No index on <code>daterequired ASC NULLS LAST</code></p> <p>Solution: <pre><code>CREATE INDEX idx_workorder_daterequired_asc\nON tblcustworkorderdetail(daterequired ASC NULLS LAST);\n</code></pre></p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#issue-3-source-sorting","title":"\ud83d\udea8 Issue #3: Source Sorting","text":"<p>Impact: CRITICAL (93ms - 100x slower than other sorts) Frequency: Unknown Affected Queries: #15</p> <p>Root Cause: - Requires joining 3 tables: work_orders \u2192 customers \u2192 sources - No way to avoid scanning all 49K work orders + 26K customers - Hash join is expensive</p> <p>Solutions (ranked):</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-a-denormalize-source-into-work-orders-best","title":"Option A: Denormalize Source into Work Orders (BEST)","text":"<p><pre><code>ALTER TABLE tblcustworkorderdetail ADD COLUMN source_name TEXT;\nCREATE INDEX idx_workorder_source_name ON tblcustworkorderdetail(source_name);\n\n-- Populate\nUPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nJOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n\n-- Maintain with trigger or application logic\n</code></pre> Pros: 100x faster (will be ~1ms), simple queries Cons: Data duplication, need to maintain consistency</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-b-materialized-view","title":"Option B: Materialized View","text":"<p><pre><code>CREATE MATERIALIZED VIEW work_orders_with_source AS\nSELECT wo.*, s.ssource as source_name\nFROM tblcustworkorderdetail wo\nLEFT JOIN tblcustomers c ON wo.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource;\n\nCREATE INDEX ON work_orders_with_source(source_name);\nREFRESH MATERIALIZED VIEW CONCURRENTLY work_orders_with_source;\n</code></pre> Pros: No schema changes, can be refreshed periodically Cons: Stale data, requires refresh strategy</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-c-cache-the-query-result","title":"Option C: Cache the Query Result","text":"<p>Use application-level caching (Redis, Memcached) with TTL.</p> <p>Pros: No database changes Cons: Cache invalidation complexity</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-d-accept-the-performance","title":"Option D: Accept the Performance","text":"<p>93ms is still under 100ms, which is generally acceptable for user interfaces. If this sort is rarely used, it may not be worth optimizing.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#database-statistics","title":"Database Statistics","text":"<pre><code>Table: tblcustworkorderdetail\n- Size: 17 MB (10 MB table + 7.5 MB indexes)\n- Rows: 49,074\n- Indexes: 9 (well-indexed!)\n\nTable: tblcustomers\n- Size: 7.6 MB (3.2 MB table + 4.4 MB indexes)\n- Rows: 26,841\n\nTable: tblsource\n- Size: 280 KB (56 KB table + 224 KB indexes)\n- Rows: 563\n</code></pre> <p>Analysis: Your database is small and well-indexed. Most slow queries are due to algorithmic issues (CAST, missing indexes) rather than data volume.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#index-usage-summary","title":"Index Usage Summary","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#existing-indexes-all-working-well","title":"Existing Indexes (All Working Well)","text":"<p>\u2705 <code>tblcustworkorderdetail_pkey</code> - Primary key \u2705 <code>idx_workorder_pending</code> - Partial index for incomplete orders \u2705 <code>idx_workorder_completed</code> - Partial index for completed orders \u2705 <code>idx_workorder_custid</code> - Foreign key lookups \u2705 <code>idx_workorder_datein</code> - Date sorting (most common) \u2705 <code>idx_workorder_rush</code> - Rush orders \u2705 <code>idx_workorder_processing</code> - In-progress orders \u2705 <code>idx_workorder_queue</code> - Queue management \u2705 <code>idx_workorder_woname_trgm</code> - Text search (trigram)</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#missing-indexes","title":"Missing Indexes","text":"<p>\u274c <code>(workorderno::integer)</code> - For numeric filters \u274c <code>(daterequired ASC NULLS LAST)</code> - For date sorting \u274c <code>(source_name)</code> - If you denormalize (recommended)</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#recommendations","title":"Recommendations","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#priority-1-do-now","title":"\ud83c\udfaf Priority 1 (Do Now)","text":"<ol> <li> <p>Add WorkOrderNo integer index:    <pre><code>CREATE INDEX CONCURRENTLY idx_workorder_no_int\nON tblcustworkorderdetail((workorderno::integer));\n</code></pre> Impact: Fixes 9-15ms slowdown \u2192 &lt; 1ms</p> </li> <li> <p>Add DateRequired index:    <pre><code>CREATE INDEX CONCURRENTLY idx_workorder_daterequired\nON tblcustworkorderdetail(daterequired ASC NULLS LAST);\n</code></pre> Impact: 16ms \u2192 &lt; 1ms</p> </li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#priority-2-evaluate-costbenefit","title":"\ud83c\udfaf Priority 2 (Evaluate Cost/Benefit)","text":"<ol> <li>Denormalize source name (if Source sorting is frequently used):    <pre><code>ALTER TABLE tblcustworkorderdetail ADD COLUMN source_name TEXT;\nCREATE INDEX idx_workorder_source_name ON tblcustworkorderdetail(source_name);\n</code></pre> Impact: 93ms \u2192 ~1ms    Cost: Schema change, data maintenance</li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#priority-3-optional-optimizations","title":"\ud83c\udfaf Priority 3 (Optional Optimizations)","text":"<ol> <li>Optimize count query (if pagination is slow):</li> <li>Use approximate counts: <code>SELECT reltuples FROM pg_class WHERE relname = 'tblcustworkorderdetail'</code></li> <li> <p>Or implement \"Load More\" UI instead of pagination</p> </li> <li> <p>Monitor query performance with <code>pg_stat_statements</code>:    <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre></p> </li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#application-level-recommendations","title":"Application-Level Recommendations","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#1-use-eager-loading-already-doing-well","title":"1. Use Eager Loading (Already Doing Well \u2705)","text":"<p>Your code already uses <code>joinedload</code>: <pre><code>query = query.options(joinedload(WorkOrder.customer))\n</code></pre> This is correct and prevents N+1 queries.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#2-avoid-cast-in-filters","title":"2. Avoid CAST in Filters","text":"<p>Consider changing the application code to avoid casting:</p> <p>Current (routes/work_orders.py:978): <pre><code>query = query.filter(\n    cast(WorkOrder.WorkOrderNo, Integer) &gt;= start,\n    cast(WorkOrder.WorkOrderNo, Integer) &lt;= end,\n)\n</code></pre></p> <p>Better (after adding index): <pre><code># Index will now work!\nquery = query.filter(\n    cast(WorkOrder.WorkOrderNo, Integer) &gt;= start,\n    cast(WorkOrder.WorkOrderNo, Integer) &lt;= end,\n)\n</code></pre></p> <p>Or even better, change WorkOrderNo to INTEGER type and remove casts entirely.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#3-add-database-connection-pooling","title":"3. Add Database Connection Pooling","text":"<p>Ensure you're using SQLAlchemy connection pooling: <pre><code># In config.py\nSQLALCHEMY_ENGINE_OPTIONS = {\n    'pool_size': 10,\n    'max_overflow': 20,\n    'pool_pre_ping': True,  # Verify connections before use\n    'pool_recycle': 3600,   # Recycle connections after 1 hour\n}\n</code></pre></p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#4-consider-caching-for-expensive-queries","title":"4. Consider Caching for Expensive Queries","text":"<p>For the Source sorting query, consider caching: <pre><code>from flask_caching import Cache\n\ncache = Cache(config={'CACHE_TYPE': 'redis'})\n\n@cache.memoize(timeout=300)  # Cache for 5 minutes\ndef get_work_orders_by_source(page, size):\n    # ... expensive query ...\n</code></pre></p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#testing-the-fixes","title":"Testing the Fixes","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#step-1-apply-priority-1-indexes","title":"Step 1: Apply Priority 1 Indexes","text":"<pre><code>psql \"postgresql://...\" &lt;&lt;EOF\nCREATE INDEX CONCURRENTLY idx_workorder_no_int\nON tblcustworkorderdetail((workorderno::integer));\n\nCREATE INDEX CONCURRENTLY idx_workorder_daterequired\nON tblcustworkorderdetail(daterequired ASC NULLS LAST);\n\nANALYZE tblcustworkorderdetail;\nEOF\n</code></pre>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#step-2-re-run-analysis","title":"Step 2: Re-run Analysis","text":"<pre><code>psql \"postgresql://...\" -f query_optimization/analyze_work_orders.sql\n</code></pre>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#step-3-verify-improvements","title":"Step 3: Verify Improvements","text":"<p>Expected results: - Query #8 (WorkOrderNo range): 14ms \u2192 &lt; 1ms \u26a1 - Query #9 (WorkOrderNo exact): 9ms \u2192 &lt; 1ms \u26a1 - Query #14 (DateRequired sort): 16ms \u2192 &lt; 1ms \u26a1</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#conclusion","title":"Conclusion","text":"<p>Your database is well-architected and well-indexed. Most queries are extremely fast (&lt; 1ms). The issues you're experiencing are likely due to:</p> <ol> <li>Network latency - Even with 1ms queries, network round-trips add overhead</li> <li>Application rendering - React/browser rendering time</li> <li>The 3 specific slow queries identified above</li> </ol> <p>Quick wins: Add the 2 missing indexes (Priority 1). This will take 5 minutes and fix 90% of your slow queries.</p> <p>Bigger optimization: Denormalize source name if Source sorting is critical.</p> <p>Reality check: For a 60MB database with 50K rows, you should expect: - Simple queries: &lt; 5ms \u2705 (you're already there!) - Complex joins: &lt; 50ms \u2705 (you're already there!) - The slowest query (Source sort): &lt; 100ms \u26a0\ufe0f (93ms is acceptable, but fixable)</p> <p>Your queries are close to instantaneous. If the UI feels slow, the bottleneck is likely: - Frontend rendering (check React DevTools) - Network latency (check browser Network tab) - Database connection overhead (use connection pooling)</p>"},{"location":"database/ALEMBIC_GUIDE/","title":"Alembic Database Migration Guide","text":""},{"location":"database/ALEMBIC_GUIDE/#overview","title":"Overview","text":"<p>This project uses Alembic for database schema migrations. Alembic provides version control for your database schema, making it safe and easy to evolve your database structure over time.</p>"},{"location":"database/ALEMBIC_GUIDE/#quick-start","title":"Quick Start","text":""},{"location":"database/ALEMBIC_GUIDE/#basic-commands","title":"Basic Commands","text":"<pre><code># Check current migration status\n./alembic_db.sh prod current      # Production database\n./alembic_db.sh test current      # Test database\n\n# View migration history\n./alembic_db.sh prod history\n\n# Create a new migration (after modifying models)\n./alembic_db.sh test revision --autogenerate -m \"add_new_column\"\n\n# Apply migrations\n./alembic_db.sh test upgrade head    # Test first!\n./alembic_db.sh prod upgrade head    # Then production\n\n# Rollback one migration\n./alembic_db.sh prod downgrade -1\n\n# Show SQL without executing\n./alembic_db.sh prod upgrade head --sql\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#workflow-adding-a-new-field","title":"Workflow: Adding a New Field","text":"<p>Let's say you want to add a new field to the WorkOrder model. Here's the complete workflow:</p>"},{"location":"database/ALEMBIC_GUIDE/#1-update-your-model","title":"1. Update Your Model","text":"<p>Edit <code>models/work_order.py</code>:</p> <pre><code>class WorkOrder(db.Model):\n    __tablename__ = \"tblcustworkorderdetail\"\n\n    # ... existing fields ...\n\n    # New field\n    cleaning_notes = db.Column(\"cleaning_notes\", db.Text, nullable=True)\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#2-create-a-migration","title":"2. Create a Migration","text":"<pre><code># Generate migration automatically by comparing models to database\n./alembic_db.sh test revision --autogenerate -m \"add_cleaning_notes_to_work_orders\"\n</code></pre> <p>This creates a new file in <code>alembic/versions/</code> like: <code>20251013_1930-abc123def456_add_cleaning_notes_to_work_orders.py</code></p>"},{"location":"database/ALEMBIC_GUIDE/#3-review-the-migration","title":"3. Review the Migration","text":"<p>IMPORTANT: Always review auto-generated migrations!</p> <pre><code># Open the generated migration file\ncode alembic/versions/20251013_1930-abc123def456_add_cleaning_notes_to_work_orders.py\n</code></pre> <p>Check that: - The <code>upgrade()</code> function adds the column correctly - The <code>downgrade()</code> function removes it correctly - No unexpected changes were detected</p> <p>Example migration:</p> <pre><code>def upgrade() -&gt; None:\n    op.add_column('tblcustworkorderdetail',\n                  sa.Column('cleaning_notes', sa.Text(), nullable=True))\n\ndef downgrade() -&gt; None:\n    op.drop_column('tblcustworkorderdetail', 'cleaning_notes')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#4-test-on-test-database-first","title":"4. Test on Test Database First","text":"<pre><code># Apply migration to test database\n./alembic_db.sh test upgrade head\n\n# Verify the change worked\npsql \"postgresql://postgres:PASSWORD@HOST:5432/clean_repair_test\" -c \"\\d tblcustworkorderdetail\"\n</code></pre> <p>Test your application with the test database to make sure everything works.</p>"},{"location":"database/ALEMBIC_GUIDE/#5-apply-to-production","title":"5. Apply to Production","text":"<pre><code># Apply to production database\n./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#6-deploy-code","title":"6. Deploy Code","text":"<pre><code># Commit your changes (model + migration file)\ngit add models/work_order.py alembic/versions/20251013_1930-*.py\ngit commit -m \"Add cleaning_notes field to WorkOrder\"\ngit push\n\n# Deploy to Elastic Beanstalk\neb deploy\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#database-switching","title":"Database Switching","text":"<p>The <code>alembic_db.sh</code> helper script manages database switching:</p> <pre><code>./alembic_db.sh prod &lt;command&gt;    # Uses clean_repair\n./alembic_db.sh test &lt;command&gt;    # Uses clean_repair_test\n</code></pre> <p>You can also use raw alembic commands with environment variables:</p> <pre><code>POSTGRES_DB=clean_repair_test alembic current\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#common-scenarios","title":"Common Scenarios","text":""},{"location":"database/ALEMBIC_GUIDE/#scenario-1-add-a-column","title":"Scenario 1: Add a Column","text":"<p>Model change: <pre><code>new_field = db.Column(\"new_field\", db.String(100), nullable=True)\n</code></pre></p> <p>Migration (auto-generated): <pre><code>def upgrade():\n    op.add_column('table_name', sa.Column('new_field', sa.String(100), nullable=True))\n\ndef downgrade():\n    op.drop_column('table_name', 'new_field')\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#scenario-2-rename-a-column-issue-82-storage-rack","title":"Scenario 2: Rename a Column (Issue #82 - Storage + Rack)","text":"<p>For issue #82, you need to combine <code>storage</code> and <code>rack_number</code> into one field.</p> <p>Step 1: Add migration with data transformation:</p> <pre><code>def upgrade():\n    # Add temporary column\n    op.add_column('tblcustworkorderdetail',\n                  sa.Column('storage_combined', sa.String(), nullable=True))\n\n    # Migrate data: Combine storage + rack_number\n    op.execute(\"\"\"\n        UPDATE tblcustworkorderdetail\n        SET storage_combined = CONCAT(\n            COALESCE(storage, ''),\n            CASE\n                WHEN rack_number IS NOT NULL AND rack_number != ''\n                THEN ' - Rack: ' || rack_number\n                ELSE ''\n            END\n        )\n        WHERE storage IS NOT NULL OR rack_number IS NOT NULL\n    \"\"\")\n\n    # Drop old columns (optional - keep for historical data)\n    # op.drop_column('tblcustworkorderdetail', 'rack_number')\n\ndef downgrade():\n    # Reverse the migration\n    op.drop_column('tblcustworkorderdetail', 'storage_combined')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#scenario-3-change-column-type","title":"Scenario 3: Change Column Type","text":"<p>Model change: <pre><code># Change from String to Text\nfield = db.Column(\"field\", db.Text)  # was db.String(100)\n</code></pre></p> <p>Migration: <pre><code>def upgrade():\n    op.alter_column('table_name', 'field',\n                    existing_type=sa.String(100),\n                    type_=sa.Text())\n\ndef downgrade():\n    op.alter_column('table_name', 'field',\n                    existing_type=sa.Text(),\n                    type_=sa.String(100))\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#scenario-4-add-an-index","title":"Scenario 4: Add an Index","text":"<pre><code>def upgrade():\n    op.create_index('idx_workorder_cleaning_notes',\n                    'tblcustworkorderdetail',\n                    ['cleaning_notes'])\n\ndef downgrade():\n    op.drop_index('idx_workorder_cleaning_notes',\n                  'tblcustworkorderdetail')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#scenario-5-add-optimistic-locking-issue-92","title":"Scenario 5: Add Optimistic Locking (Issue #92)","text":"<pre><code>def upgrade():\n    # Add version column for optimistic locking\n    op.add_column('tblcustworkorderdetail',\n                  sa.Column('version', sa.Integer(), nullable=False, server_default='1'))\n\n    # Create index for faster version checks\n    op.create_index('idx_workorder_version', 'tblcustworkorderdetail', ['version'])\n\ndef downgrade():\n    op.drop_index('idx_workorder_version', 'tblcustworkorderdetail')\n    op.drop_column('tblcustworkorderdetail', 'version')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#safety-best-practices","title":"Safety Best Practices","text":""},{"location":"database/ALEMBIC_GUIDE/#1-always-test-first","title":"1. Always Test First","text":"<pre><code># Test database first\n./alembic_db.sh test upgrade head\n\n# Run application tests\npytest\n\n# If all good, apply to production\n./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#2-backup-before-production-migrations","title":"2. Backup Before Production Migrations","text":"<pre><code># Backup production database before major migrations\npg_dump \"postgresql://user:pass@host:5432/clean_repair\" &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n\n# Or via RDS snapshot (recommended)\naws rds create-db-snapshot \\\n    --db-instance-identifier database-1 \\\n    --db-snapshot-identifier pre-migration-$(date +%Y%m%d)\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#3-review-auto-generated-migrations","title":"3. Review Auto-Generated Migrations","text":"<p>Alembic's autogenerate is smart but not perfect. Always review: - Check for unexpected table/column drops - Verify data type changes are correct - Add data migrations if needed (see Scenario 2)</p>"},{"location":"database/ALEMBIC_GUIDE/#4-test-rollbacks","title":"4. Test Rollbacks","text":"<pre><code># Apply migration\n./alembic_db.sh test upgrade head\n\n# Test rollback\n./alembic_db.sh test downgrade -1\n\n# Re-apply\n./alembic_db.sh test upgrade head\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#5-keep-migrations-small","title":"5. Keep Migrations Small","text":"<p>Create focused migrations: - \u2705 Good: \"add_cleaning_notes_field\" - \u2705 Good: \"add_index_to_customer_name\" - \u274c Bad: \"update_all_tables_for_issue_67_82_92\"</p>"},{"location":"database/ALEMBIC_GUIDE/#migration-file-structure","title":"Migration File Structure","text":"<pre><code>\"\"\"descriptive_message\n\nRevision ID: abc123def456          # Unique ID for this migration\nRevises: previous_revision_id      # Previous migration (creates chain)\nCreate Date: 2025-10-13 19:30:00\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\nrevision = 'abc123def456'\ndown_revision = 'previous_id'      # Forms migration chain\n\ndef upgrade() -&gt; None:\n    \"\"\"Apply the migration\"\"\"\n    op.add_column(...)\n\ndef downgrade() -&gt; None:\n    \"\"\"Reverse the migration\"\"\"\n    op.drop_column(...)\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"database/ALEMBIC_GUIDE/#problem-cant-locate-revision-identified-by-head","title":"Problem: \"Can't locate revision identified by 'head'\"","text":"<p>Solution: Database not stamped. Stamp it: <pre><code>./alembic_db.sh prod stamp head\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#problem-target-database-is-not-up-to-date","title":"Problem: \"Target database is not up to date\"","text":"<p>Solution: Check status and upgrade: <pre><code>./alembic_db.sh prod current\n./alembic_db.sh prod upgrade head\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#problem-migration-detects-changes-you-didnt-make","title":"Problem: Migration detects changes you didn't make","text":"<p>Solution: Your model doesn't match the database. Options: 1. If database is correct: Update your model to match 2. If model is correct: Create migration to update database 3. If both are correct: Check for server_default, type differences</p>"},{"location":"database/ALEMBIC_GUIDE/#problem-cant-drop-column-because-its-referenced","title":"Problem: \"Can't drop column because it's referenced\"","text":"<p>Solution: Drop foreign key constraints first: <pre><code>def upgrade():\n    op.drop_constraint('fk_name', 'table_name', type_='foreignkey')\n    op.drop_column('table_name', 'column_name')\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#advanced-manual-migrations","title":"Advanced: Manual Migrations","text":"<p>Sometimes you need to write migrations by hand:</p> <pre><code># Create empty migration\n./alembic_db.sh prod revision -m \"custom_data_migration\"\n</code></pre> <p>Example - Migrate data between tables:</p> <pre><code>def upgrade():\n    # Use Alembic's connection\n    connection = op.get_bind()\n\n    # Execute raw SQL for complex data migrations\n    connection.execute(\"\"\"\n        INSERT INTO new_table (field1, field2)\n        SELECT old_field1, old_field2 FROM old_table\n        WHERE condition = true\n    \"\"\")\n\n    # Or use SQLAlchemy Core for type safety\n    from sqlalchemy import table, column, select\n    old_table = table('old_table',\n                      column('old_field1'),\n                      column('old_field2'))\n    new_table = table('new_table',\n                      column('field1'),\n                      column('field2'))\n\n    # Select and insert\n    connection.execute(\n        new_table.insert().from_select(\n            ['field1', 'field2'],\n            select(old_table.c.old_field1, old_table.c.old_field2)\n        )\n    )\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#elastic-beanstalk-deployment","title":"Elastic Beanstalk Deployment","text":""},{"location":"database/ALEMBIC_GUIDE/#option-1-automatic-migrations-recommended-for-small-teams","title":"Option 1: Automatic Migrations (Recommended for Small Teams)","text":"<p>Add to <code>.ebextensions/02_migrations.config</code>:</p> <pre><code>container_commands:\n  01_migrate:\n    command: \"source /var/app/venv/*/bin/activate &amp;&amp; alembic upgrade head\"\n    leader_only: true\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#option-2-manual-migrations-recommended-for-production","title":"Option 2: Manual Migrations (Recommended for Production)","text":"<pre><code># 1. SSH into EB instance\neb ssh\n\n# 2. Activate virtual environment\nsource /var/app/venv/*/bin/activate\ncd /var/app/current\n\n# 3. Run migration\nalembic upgrade head\n\n# 4. Verify\nalembic current\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#migration-history","title":"Migration History","text":"<p>View all migrations:</p> <pre><code>./alembic_db.sh prod history --verbose\n</code></pre> <p>View current version:</p> <pre><code>./alembic_db.sh prod current\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#relationship-with-old-migration-tool","title":"Relationship with Old Migration Tool","text":"<p>Your <code>migration_tool/</code> directory is kept for historical reference: - \u2705 Use for: Re-migrating from Access DB if needed - \u274c Don't use for: Schema changes going forward</p> <p>Going forward: - Old way: Modify <code>run_migration.py</code> \u2192 Drop all tables \u2192 Re-import - New way: Modify model \u2192 Create Alembic migration \u2192 Apply safely</p>"},{"location":"database/ALEMBIC_GUIDE/#summary-cheat-sheet","title":"Summary Cheat Sheet","text":"<pre><code># Day-to-day workflow\n./alembic_db.sh test revision --autogenerate -m \"description\"  # Create\n./alembic_db.sh test upgrade head                               # Test\n./alembic_db.sh prod upgrade head                               # Deploy\n\n# Checking status\n./alembic_db.sh prod current    # What version am I on?\n./alembic_db.sh prod history    # Show all migrations\n\n# Undoing mistakes\n./alembic_db.sh test downgrade -1        # Undo last migration\n./alembic_db.sh test downgrade &lt;revision_id&gt;  # Go to specific version\n\n# Previewing changes\n./alembic_db.sh prod upgrade head --sql  # Show SQL without running\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#next-steps","title":"Next Steps","text":"<ol> <li>Read through this guide</li> <li>Practice creating a test migration</li> <li>Review your GitHub issues (#67, #82, #92, #98) and plan migrations</li> <li>Test migrations on <code>clean_repair_test</code> first</li> <li>Apply to <code>clean_repair</code> production</li> </ol>"},{"location":"database/ALEMBIC_GUIDE/#additional-resources","title":"Additional Resources","text":"<ul> <li>Alembic Documentation</li> <li>Alembic Tutorial</li> <li>SQLAlchemy Column Types</li> </ul>"},{"location":"database/ALEMBIC_GUIDE/#questions","title":"Questions?","text":"<p>If you're unsure about a migration: 1. Test on <code>clean_repair_test</code> first 2. Review the auto-generated SQL 3. Create a database backup 4. Ask for review if making destructive changes</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/","title":"Storage Fields Guide (Issue #82)","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#tldr","title":"TL;DR","text":"<p>Work Orders: - \u2705 Use <code>RackNo</code> (db: <code>rack_number</code>) for physical location - \u2705 Use <code>StorageTime</code> (db: <code>storagetime</code>) for \"Seasonal\" / \"Temporary\" - \u274c Do NOT use <code>Storage</code> (deprecated, empty)</p> <p>Repair Orders: - \u2705 Use <code>RackNo</code> (db: <code>RACK#</code>) for physical location - \u2705 Use <code>STORAGE</code> (db: <code>storage</code>) for \"TEMPORARY\" / \"SEASONAL\" - \u26a0\ufe0f <code>LOCATION</code> exists but <code>RackNo</code> is primary location field</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#the-confusion-explained","title":"The Confusion Explained","text":"<p>There was confusion between storage time type (how long something is stored) and physical location (where it is stored). This guide clarifies which fields to use for what purpose.</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#field-naming-issues","title":"Field Naming Issues","text":"What You Want Work Order Field Repair Order Field Why It's Confusing Physical Location(e.g., \"5 B\", \"bin 4 top\") <code>RackNo</code>(db: <code>rack_number</code>) <code>RackNo</code>(db: <code>RACK#</code>) \u2705 Clear - named after racks Storage Duration Type(\"Seasonal\" / \"Temporary\") <code>StorageTime</code>(db: <code>storagetime</code>) <code>STORAGE</code>(db: <code>storage</code>) \u26a0\ufe0f Confusing - RO field is named \"STORAGE\" not \"StorageTime\" Deprecated/Unused <code>Storage</code>(db: <code>storage</code>) N/A \u274c Empty, don't use"},{"location":"database/STORAGE_FIELDS_GUIDE/#work-orders-field-usage","title":"Work Orders - Field Usage","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#model-workorder-table-tblcustworkorderdetail","title":"Model: <code>WorkOrder</code> (Table: <code>tblcustworkorderdetail</code>)","text":"<pre><code># \u2705 CORRECT - Use these fields:\n\n# For physical location (where the item is)\nwork_order.RackNo = \"5 B\"  # Maps to rack_number column\nwork_order.RackNo = \"bin 4 top\"\nwork_order.RackNo = \"cleaning room\"\n\n# For storage time type (how long it's stored)\nwork_order.StorageTime = \"Seasonal\"  # Maps to storagetime column\nwork_order.StorageTime = \"Temporary\"\n\n# For post-cleaning location\nwork_order.final_location = \"Customer pickup area\"\n\n# \u274c WRONG - Don't use this:\nwork_order.Storage = \"...\"  # DEPRECATED - column is empty/unused\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#database-columns","title":"Database Columns","text":"Python Attribute DB Column Purpose Values <code>RackNo</code> <code>rack_number</code> Physical location \"5 B\", \"bin 4 top\", etc. <code>StorageTime</code> <code>storagetime</code> Storage duration type \"Seasonal\", \"Temporary\" <code>final_location</code> <code>finallocation</code> Post-service location Any string <code>Storage</code> <code>storage</code> \u274c DEPRECATED Empty/unused"},{"location":"database/STORAGE_FIELDS_GUIDE/#repair-orders-field-usage","title":"Repair Orders - Field Usage","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#model-repairworkorder-table-tblrepairworkorderdetail","title":"Model: <code>RepairWorkOrder</code> (Table: <code>tblrepairworkorderdetail</code>)","text":"<pre><code># \u2705 CORRECT - Use these fields:\n\n# For physical location (where the item is)\nrepair_order.RackNo = \"hang 4\"  # Maps to RACK# column\nrepair_order.RackNo = \"6D\"\nrepair_order.RackNo = \"1 D\"\n\n# For storage time type (how long it's stored)\n# NOTE: Field is named STORAGE but it's actually storage TIME type!\nrepair_order.STORAGE = \"TEMPORARY\"  # Maps to storage column\nrepair_order.STORAGE = \"SEASONAL\"\n\n# For additional location details (legacy)\nrepair_order.LOCATION = \"Back room\"  # Maps to location column\n\n# For post-repair location\nrepair_order.final_location = \"Ship to customer\"\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#database-columns_1","title":"Database Columns","text":"Python Attribute DB Column Purpose Values <code>RackNo</code> <code>RACK#</code> Physical location (PRIMARY) \"hang 4\", \"6D\", \"1 D\", etc. <code>STORAGE</code> <code>storage</code> Storage duration type \u26a0\ufe0f \"TEMPORARY\", \"SEASONAL\" <code>LOCATION</code> <code>location</code> Additional location details Any string <code>final_location</code> <code>finallocation</code> Post-service location Any string <p>\u26a0\ufe0f Important: Despite being named <code>STORAGE</code>, this field stores the storage TIME type (Seasonal/Temporary), not a physical location!</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#template-labels","title":"Template Labels","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#current-labels-confusing","title":"Current Labels (Confusing)","text":"<p>Work Order Edit: - Label says: \"Storage\" - Actually saves to: <code>RackNo</code> (rack_number) - Problem: Misleading label</p> <p>Repair Order Edit: - Label says: \"Storage\" - Actually saves to: <code>STORAGE</code> (storage type dropdown) - Label says: \"Location\" - Actually saves to: <code>LOCATION</code> but pre-fills from <code>RackNo</code> - Problem: Multiple fields for same purpose</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#recommended-labels-clear","title":"Recommended Labels (Clear)","text":"<p>Work Orders: <pre><code>&lt;!-- For physical location --&gt;\n&lt;label&gt;Location / Rack #&lt;/label&gt;\n&lt;input name=\"RackNo\" value=\"{{ work_order.RackNo }}\"&gt;\n\n&lt;!-- For storage duration --&gt;\n&lt;label&gt;Storage Time&lt;/label&gt;\n&lt;select name=\"StorageTime\"&gt;\n    &lt;option value=\"Seasonal\"&gt;Seasonal&lt;/option&gt;\n    &lt;option value=\"Temporary\"&gt;Temporary&lt;/option&gt;\n&lt;/select&gt;\n\n&lt;!-- For post-cleaning location --&gt;\n&lt;label&gt;Final Location (after cleaning)&lt;/label&gt;\n&lt;input name=\"final_location\" value=\"{{ work_order.final_location }}\"&gt;\n</code></pre></p> <p>Repair Orders: <pre><code>&lt;!-- For physical location --&gt;\n&lt;label&gt;Location / Rack #&lt;/label&gt;\n&lt;input name=\"RackNo\" value=\"{{ repair_order.RackNo }}\"&gt;\n\n&lt;!-- For storage duration (note: field name is STORAGE!) --&gt;\n&lt;label&gt;Storage Time&lt;/label&gt;\n&lt;select name=\"STORAGE\"&gt;\n    &lt;option value=\"TEMPORARY\"&gt;Temporary&lt;/option&gt;\n    &lt;option value=\"SEASONAL\"&gt;Seasonal&lt;/option&gt;\n&lt;/select&gt;\n\n&lt;!-- For post-repair location --&gt;\n&lt;label&gt;Final Location (after repair)&lt;/label&gt;\n&lt;input name=\"final_location\" value=\"{{ repair_order.final_location }}\"&gt;\n</code></pre></p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#routes-readingwriting","title":"Routes - Reading/Writing","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#work-orders-routes","title":"Work Orders Routes","text":"<pre><code># \u2705 CORRECT\nfrom routes.work_orders import work_orders_bp\n\n@work_orders_bp.route('/edit/&lt;work_order_no&gt;', methods=['POST'])\ndef edit_work_order(work_order_no):\n    work_order = WorkOrder.query.get_or_404(work_order_no)\n\n    # Physical location\n    work_order.RackNo = request.form.get(\"RackNo\")  # \"5 B\", \"bin 4 top\"\n\n    # Storage duration type\n    work_order.StorageTime = request.form.get(\"StorageTime\")  # \"Seasonal\"/\"Temporary\"\n\n    # Post-service location\n    work_order.final_location = request.form.get(\"final_location\")\n\n    # \u274c WRONG - Don't use Storage field\n    # work_order.Storage = request.form.get(\"Storage\")  # DEPRECATED!\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#repair-orders-routes","title":"Repair Orders Routes","text":"<pre><code># \u2705 CORRECT\nfrom routes.repair_order import repair_order_bp\n\n@repair_order_bp.route('/edit/&lt;repair_order_no&gt;', methods=['POST'])\ndef edit_repair_order(repair_order_no):\n    repair_order = RepairWorkOrder.query.get_or_404(repair_order_no)\n\n    # Physical location\n    repair_order.RackNo = request.form.get(\"RackNo\")  # \"hang 4\", \"6D\"\n\n    # Storage duration type (note field name!)\n    repair_order.STORAGE = request.form.get(\"STORAGE\")  # \"TEMPORARY\"/\"SEASONAL\"\n\n    # Additional location (optional, legacy)\n    repair_order.LOCATION = request.form.get(\"LOCATION\")\n\n    # Post-service location\n    repair_order.final_location = request.form.get(\"final_location\")\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#mistake-1-using-workorderstorage","title":"\u274c Mistake 1: Using WorkOrder.Storage","text":"<pre><code># WRONG - Storage field is deprecated and empty\nwork_order.Storage = \"5 B\"  # This goes nowhere useful!\n\n# CORRECT - Use RackNo\nwork_order.RackNo = \"5 B\"\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#mistake-2-confusing-storage-with-location-in-repair-orders","title":"\u274c Mistake 2: Confusing STORAGE with location in Repair Orders","text":"<pre><code># WRONG - STORAGE is for time type, not location\nrepair_order.STORAGE = \"hang 4\"  # This is a location, not a time type!\n\n# CORRECT - Use RackNo for location, STORAGE for time\nrepair_order.RackNo = \"hang 4\"      # Physical location\nrepair_order.STORAGE = \"TEMPORARY\"   # How long it's stored\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#mistake-3-inconsistent-field-names-between-wo-and-ro","title":"\u274c Mistake 3: Inconsistent field names between WO and RO","text":"<pre><code># WRONG - Field names are different!\nwork_order.STORAGE = \"Seasonal\"      # Field doesn't exist in WO\nrepair_order.StorageTime = \"SEASONAL\"  # Field doesn't exist in RO\n\n# CORRECT - Use the right field for each model\nwork_order.StorageTime = \"Seasonal\"     # WO uses StorageTime\nrepair_order.STORAGE = \"SEASONAL\"       # RO uses STORAGE (unfortunately)\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#data-migration-notes","title":"Data Migration Notes","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#work-order-storage-field","title":"Work Order Storage Field","text":"<ul> <li>The <code>storage</code> column in <code>tblcustworkorderdetail</code> is empty</li> <li>All location data is in <code>rack_number</code> column</li> <li>No data migration needed - just don't use <code>Storage</code> attribute</li> </ul>"},{"location":"database/STORAGE_FIELDS_GUIDE/#repair-order-storage-field","title":"Repair Order Storage Field","text":"<ul> <li>The <code>storage</code> column in <code>tblrepairworkorderdetail</code> contains data</li> <li>Data is storage time type: \"TEMPORARY\", \"SEASONAL\"</li> <li>This is why we can't rename it easily - it's actively used!</li> </ul>"},{"location":"database/STORAGE_FIELDS_GUIDE/#why-not-fix-this-with-a-migration","title":"Why Not Fix This With a Migration?","text":"<p>You might ask: \"Why not just rename STORAGE \u2192 StorageTime in repair orders?\"</p> <p>Answer: We decided not to change the schema because: 1. Schema changes require coordination across dev/test/prod databases 2. Risk of data loss or application downtime 3. The app works correctly - it's just confusing field names 4. Clear documentation and comments solve the problem without risk</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#quick-reference-card","title":"Quick Reference Card","text":"<p>Need to store WHERE something is located? - Work Orders: Use <code>RackNo</code> (db: <code>rack_number</code>) - Repair Orders: Use <code>RackNo</code> (db: <code>RACK#</code>)</p> <p>Need to store HOW LONG it's stored? - Work Orders: Use <code>StorageTime</code> (db: <code>storagetime</code>) \u2192 \"Seasonal\"/\"Temporary\" - Repair Orders: Use <code>STORAGE</code> (db: <code>storage</code>) \u2192 \"TEMPORARY\"/\"SEASONAL\"</p> <p>Need to store WHERE it goes after service? - Both: Use <code>final_location</code> (db: <code>finallocation</code>)</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#related-issues","title":"Related Issues","text":"<ul> <li>Issue #82: Combine Storage + Rack # into one field on detail page</li> <li>Issue #67: Add cleaning storage information to all work order edits (final_location)</li> </ul>"},{"location":"database/STORAGE_FIELDS_GUIDE/#see-also","title":"See Also","text":"<ul> <li>models/work_order.py - Lines 17-27 (Storage field definitions)</li> <li>models/repair_order.py - Lines 48-64 (Storage field definitions)</li> <li>CLAUDE.md - Project documentation</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/","title":"Source Name Denormalization - Deployment Checklist","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#pre-deployment-checklist","title":"Pre-Deployment Checklist","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#1-code-review","title":"1. Code Review","text":"<ul> <li>[ ] Review all code changes in Git</li> <li>[ ] Verify all tests pass locally</li> <li>[ ] Review migration script for syntax errors</li> <li>[ ] Confirm backup/rollback plan is understood</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#2-staging-environment","title":"2. Staging Environment","text":"<ul> <li>[ ] Backup staging database</li> <li>[ ] Apply migration to staging:   <pre><code>psql \"$STAGING_DATABASE_URL\" -f query_optimization/add_source_name_denormalization.sql\n</code></pre></li> <li>[ ] Verify migration success:   <pre><code>SELECT COUNT(*) as total, COUNT(source_name) as with_source\nFROM tblcustworkorderdetail;\n</code></pre></li> <li>[ ] Deploy code to staging</li> <li>[ ] Test all work order operations:</li> <li>[ ] Create work order</li> <li>[ ] Edit work order (change customer)</li> <li>[ ] List work orders</li> <li>[ ] Filter by source</li> <li>[ ] Sort by source</li> <li>[ ] Create repair order</li> <li>[ ] Edit repair order</li> <li>[ ] Filter repair orders by source</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#3-performance-verification-staging","title":"3. Performance Verification (Staging)","text":"<ul> <li>[ ] Run EXPLAIN ANALYZE on source filter query (before/after comparison)</li> <li>[ ] Check query execution times in logs</li> <li>[ ] Verify indexes are being used:   <pre><code>SELECT schemaname, tablename, indexname, idx_scan\nFROM pg_stat_user_indexes\nWHERE indexname LIKE '%source_name%';\n</code></pre></li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#4-data-consistency-check-staging","title":"4. Data Consistency Check (Staging)","text":"<ul> <li>[ ] Run verification query:   <pre><code>SELECT\n    COUNT(*) as total,\n    COUNT(wo.source_name) as has_source_name,\n    SUM(CASE WHEN wo.source_name = s.ssource THEN 1 ELSE 0 END) as correct,\n    SUM(CASE WHEN wo.source_name != s.ssource THEN 1 ELSE 0 END) as incorrect\nFROM tblcustworkorderdetail wo\nLEFT JOIN tblcustomers c ON wo.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource;\n</code></pre></li> <li>[ ] Verify incorrect count is 0</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#production-deployment-checklist","title":"Production Deployment Checklist","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#1-pre-deployment","title":"1. Pre-Deployment","text":"<ul> <li>[ ] Schedule maintenance window (recommend off-peak hours)</li> <li>[ ] Notify team of deployment</li> <li>[ ] Ensure backup retention is enabled</li> <li>[ ] Take manual snapshot of RDS (if using AWS)</li> <li>[ ] Document current performance baseline</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#2-database-migration","title":"2. Database Migration","text":"<ul> <li>[ ] Backup production database:   <pre><code># AWS RDS\naws rds create-db-snapshot --db-instance-identifier your-instance --db-snapshot-identifier pre-denorm-$(date +%Y%m%d)\n\n# Or manual\npg_dump \"$DATABASE_URL\" &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n</code></pre></li> <li>[ ] Apply migration to production:   <pre><code>psql \"$DATABASE_URL\" -f query_optimization/add_source_name_denormalization.sql\n</code></pre></li> <li>[ ] Verify migration completed successfully</li> <li>[ ] Check for errors in migration output</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#3-verification","title":"3. Verification","text":"<ul> <li>[ ] Run data consistency check:   <pre><code>-- Work Orders\nSELECT 'Work Orders' as table_name,\n       COUNT(*) as total,\n       COUNT(source_name) as with_source_name,\n       SUM(CASE WHEN source_name = s.ssource THEN 1 ELSE 0 END) as correct,\n       SUM(CASE WHEN source_name != s.ssource THEN 1 ELSE 0 END) as incorrect\nFROM tblcustworkorderdetail wo\nLEFT JOIN tblcustomers c ON wo.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource\n\nUNION ALL\n\n-- Repair Orders\nSELECT 'Repair Orders' as table_name,\n       COUNT(*) as total,\n       COUNT(source_name) as with_source_name,\n       SUM(CASE WHEN source_name = s.ssource THEN 1 ELSE 0 END) as correct,\n       SUM(CASE WHEN source_name != s.ssource THEN 1 ELSE 0 END) as incorrect\nFROM tblrepairworkorderdetail ro\nLEFT JOIN tblcustomers c ON ro.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource;\n</code></pre></li> <li>[ ] Verify indexes were created:   <pre><code>SELECT schemaname, tablename, indexname, indexdef\nFROM pg_indexes\nWHERE indexname IN ('idx_workorder_source_name', 'idx_repairorder_source_name');\n</code></pre></li> <li>[ ] Verify triggers were created:   <pre><code>SELECT trigger_name, event_manipulation, event_object_table\nFROM information_schema.triggers\nWHERE trigger_name LIKE '%source_name%';\n</code></pre></li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#4-application-deployment","title":"4. Application Deployment","text":"<ul> <li>[ ] Commit all code changes:   <pre><code>git add .\ngit commit -m \"Add source_name denormalization for 100x query performance\"\ngit push origin main\n</code></pre></li> <li>[ ] Deploy application (AWS EB example):   <pre><code>eb deploy\n</code></pre></li> <li>[ ] Wait for deployment to complete</li> <li>[ ] Check deployment status:   <pre><code>eb status\n</code></pre></li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#5-smoke-testing","title":"5. Smoke Testing","text":"<ul> <li>[ ] Open application in browser</li> <li>[ ] Test work order list page loads</li> <li>[ ] Test source filter works</li> <li>[ ] Test source sorting works</li> <li>[ ] Test creating new work order</li> <li>[ ] Test editing existing work order</li> <li>[ ] Test repair order list page</li> <li>[ ] Test creating new repair order</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#6-performance-monitoring","title":"6. Performance Monitoring","text":"<ul> <li>[ ] Monitor application logs for errors:   <pre><code>eb logs --stream\n# or\ntail -f /var/log/application.log\n</code></pre></li> <li>[ ] Check query execution times in database logs</li> <li>[ ] Monitor application response times</li> <li>[ ] Check error rates in monitoring tools</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#7-post-deployment-verification","title":"7. Post-Deployment Verification","text":"<ul> <li>[ ] Test source filter API:   <pre><code>curl \"https://your-app.com/api/work_orders?filter_Source=Boat\"\n</code></pre></li> <li>[ ] Test source sorting API:   <pre><code>curl \"https://your-app.com/api/work_orders?sort[0][field]=Source&amp;sort[0][dir]=asc\"\n</code></pre></li> <li>[ ] Verify API returns correct data</li> <li>[ ] Check response times are faster</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#post-deployment-monitoring-first-24-hours","title":"Post-Deployment Monitoring (First 24 Hours)","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#immediate-first-hour","title":"Immediate (First Hour)","text":"<ul> <li>[ ] Monitor error logs continuously</li> <li>[ ] Check application metrics dashboard</li> <li>[ ] Watch for any null pointer exceptions</li> <li>[ ] Monitor database CPU and memory usage</li> <li>[ ] Check query execution times</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#first-4-hours","title":"First 4 Hours","text":"<ul> <li>[ ] Review error logs every hour</li> <li>[ ] Check data consistency</li> <li>[ ] Monitor user-reported issues</li> <li>[ ] Verify backup completed successfully</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#first-24-hours","title":"First 24 Hours","text":"<ul> <li>[ ] Review error logs 3-4 times</li> <li>[ ] Check data consistency once</li> <li>[ ] Monitor query performance trends</li> <li>[ ] Document any issues encountered</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#rollback-plan-if-needed","title":"Rollback Plan (If Needed)","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#when-to-rollback","title":"When to Rollback","text":"<ul> <li>[ ] Critical errors in application</li> <li>[ ] Data inconsistency detected</li> <li>[ ] Performance degradation</li> <li>[ ] User-facing bugs</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#rollback-steps","title":"Rollback Steps","text":"<ol> <li> <p>[ ] Revert application code:    <pre><code>git revert HEAD\ngit push origin main\neb deploy\n</code></pre></p> </li> <li> <p>[ ] Revert database changes:    <pre><code>psql \"$DATABASE_URL\" -f query_optimization/rollback_source_name_denormalization.sql\n</code></pre></p> </li> </ol> <p>Or manually:    <pre><code>BEGIN;\n\n-- Drop triggers\nDROP TRIGGER IF EXISTS trg_sync_work_order_source_name ON tblcustworkorderdetail;\nDROP TRIGGER IF EXISTS trg_sync_repair_order_source_name ON tblrepairworkorderdetail;\nDROP TRIGGER IF EXISTS trg_sync_orders_on_customer_source_change ON tblcustomers;\n\n-- Drop functions\nDROP FUNCTION IF EXISTS sync_work_order_source_name();\nDROP FUNCTION IF EXISTS sync_repair_order_source_name();\nDROP FUNCTION IF EXISTS sync_orders_on_customer_source_change();\n\n-- Drop indexes\nDROP INDEX IF EXISTS idx_workorder_source_name;\nDROP INDEX IF EXISTS idx_repairorder_source_name;\n\n-- Drop columns (optional - can leave for future retry)\n-- ALTER TABLE tblcustworkorderdetail DROP COLUMN IF EXISTS source_name;\n-- ALTER TABLE tblrepairworkorderdetail DROP COLUMN IF EXISTS source_name;\n\nCOMMIT;\n</code></pre></p> <ol> <li>[ ] Verify rollback successful</li> <li>[ ] Monitor for stability</li> <li>[ ] Document rollback reason</li> </ol>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#success-criteria","title":"Success Criteria","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#migration-success","title":"Migration Success","text":"<ul> <li>[x] All SQL statements executed without errors</li> <li>[x] All existing records have <code>source_name</code> populated</li> <li>[x] Indexes created successfully</li> <li>[x] Triggers created successfully</li> <li>[x] Data consistency checks pass</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#application-success","title":"Application Success","text":"<ul> <li>[x] All tests pass (40/40)</li> <li>[x] No errors in application logs</li> <li>[x] Work order operations work correctly</li> <li>[x] Repair order operations work correctly</li> <li>[x] Source filtering works</li> <li>[x] Source sorting works</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#performance-success","title":"Performance Success","text":"<ul> <li>[ ] Source sorting &lt; 5ms (target: ~1ms)</li> <li>[ ] Source filtering &lt; 1ms (target: ~0.1ms)</li> <li>[ ] Default list load &lt; 1ms (target: ~0.04ms)</li> <li>[ ] Index usage confirmed in query plans</li> <li>[ ] No sequential scans on source_name queries</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#data-integrity-success","title":"Data Integrity Success","text":"<ul> <li>[ ] No data inconsistencies detected</li> <li>[ ] All triggers firing correctly</li> <li>[ ] Application sync methods working</li> <li>[ ] Customer source changes propagate correctly</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#contact-information","title":"Contact Information","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#in-case-of-issues","title":"In Case of Issues","text":"<ul> <li>Database Admin: [Your DBA Contact]</li> <li>DevOps Lead: [Your DevOps Contact]</li> <li>On-Call Engineer: [Your On-Call Contact]</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#useful-commands","title":"Useful Commands","text":"<pre><code># Check current git commit\ngit log -1\n\n# Check deployed version\neb printenv | grep GIT_COMMIT\n\n# View real-time logs\neb logs --stream\n\n# Check database connections\npsql \"$DATABASE_URL\" -c \"SELECT count(*) FROM pg_stat_activity;\"\n\n# Check table size\npsql \"$DATABASE_URL\" -c \"\n  SELECT\n    pg_size_pretty(pg_total_relation_size('tblcustworkorderdetail')) as work_orders_size,\n    pg_size_pretty(pg_total_relation_size('tblrepairworkorderdetail')) as repair_orders_size;\n\"\n</code></pre>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#notes","title":"Notes","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#duration-estimates","title":"Duration Estimates","text":"<ul> <li>Migration execution: 1-5 minutes (depends on table size)</li> <li>Application deployment: 5-10 minutes</li> <li>Smoke testing: 10-15 minutes</li> <li>Total: 20-30 minutes</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#risks","title":"Risks","text":"<ul> <li>Low risk: Migration is backward compatible</li> <li>Low risk: All relationships maintained</li> <li>Low risk: Comprehensive testing completed</li> <li>Low risk: Rollback plan available</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#known-issues","title":"Known Issues","text":"<ul> <li>None at this time</li> </ul> <p>Last Updated: October 12, 2025 Version: 1.0 Status: Ready for Production Deployment</p>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>Welcome to the Awning Management System Developer Guide!</p>"},{"location":"developer-guide/#for-new-developers","title":"For New Developers","text":"<p>Start here to get your development environment set up:</p> <ol> <li>Setup &amp; Installation - Get the app running locally</li> <li>Project Structure - Understand the codebase organization</li> <li>Database Schema - Learn the data model</li> </ol>"},{"location":"developer-guide/#development-workflow","title":"Development Workflow","text":"<ul> <li>Testing - Running and writing tests</li> <li>Contributing - Contribution guidelines</li> <li>API Reference - API endpoints and usage</li> </ul>"},{"location":"developer-guide/#architecture-documentation","title":"Architecture Documentation","text":"<p>For deeper technical understanding:</p> <ul> <li>System Overview - High-level architecture</li> <li>ML Prediction System - Machine learning details</li> <li>Performance Analysis - Optimization strategies</li> </ul>"},{"location":"developer-guide/#deployment","title":"Deployment","text":"<p>Learn about deploying to production:</p> <ul> <li>AWS Elastic Beanstalk - Deployment guide</li> <li>Environment Variables - Configuration</li> <li>Monitoring - Production monitoring</li> </ul>"},{"location":"developer-guide/api-reference/","title":"API Reference","text":"<p>This document provides a reference for all API endpoints and routes in the Awning Management System.</p>"},{"location":"developer-guide/api-reference/#authentication","title":"Authentication","text":"<p>All routes require authentication via Flask-Login unless otherwise noted.</p> <ul> <li>Login: <code>POST /auth/login</code></li> <li>Logout: <code>GET /auth/logout</code></li> <li>Register: <code>POST /auth/register</code> (requires invite token)</li> </ul>"},{"location":"developer-guide/api-reference/#work-orders","title":"Work Orders","text":"<p>Base URL: <code>/work_orders</code></p>"},{"location":"developer-guide/api-reference/#list-view","title":"List &amp; View","text":"Endpoint Method Description <code>/work_orders/</code> GET List all work orders (HTML view) <code>/work_orders/&lt;work_order_no&gt;</code> GET View work order detail <code>/work_orders/pending</code> GET View pending work orders <code>/work_orders/completed</code> GET View completed work orders <code>/work_orders/rush</code> GET View rush orders <code>/work_orders/status/&lt;status&gt;</code> GET Filter by status"},{"location":"developer-guide/api-reference/#create-edit","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/work_orders/new</code> GET, POST Create new work order <code>/work_orders/new/&lt;prefill_cust_id&gt;</code> GET, POST Create work order with customer pre-filled <code>/work_orders/edit/&lt;work_order_no&gt;</code> GET, POST Edit work order <code>/work_orders/cleaning-room/edit/&lt;work_order_no&gt;</code> GET, POST Simplified cleaning room edit <code>/work_orders/delete/&lt;work_order_no&gt;</code> POST Delete work order"},{"location":"developer-guide/api-reference/#api-endpoints","title":"API Endpoints","text":"Endpoint Method Description <code>/work_orders/api/work_orders</code> GET JSON API for work orders (supports filtering, sorting, pagination) <code>/work_orders/api/next_wo_number</code> GET Get next available work order number <code>/work_orders/api/customer_inventory/&lt;cust_id&gt;</code> GET Get inventory for customer <code>/work_orders/api/open_repair_orders/&lt;cust_id&gt;</code> GET Get open repair orders for customer"},{"location":"developer-guide/api-reference/#file-management","title":"File Management","text":"Endpoint Method Description <code>/work_orders/&lt;work_order_no&gt;/files</code> GET List files for work order <code>/work_orders/&lt;work_order_no&gt;/files/upload</code> POST Upload file <code>/work_orders/&lt;work_order_no&gt;/files/&lt;file_id&gt;/download</code> GET Download file <code>/work_orders/thumbnail/&lt;file_id&gt;</code> GET Get PDF thumbnail"},{"location":"developer-guide/api-reference/#pdf-generation","title":"PDF Generation","text":"Endpoint Method Description <code>/work_orders/&lt;work_order_no&gt;/pdf/download</code> GET Generate and download PDF"},{"location":"developer-guide/api-reference/#repair-orders","title":"Repair Orders","text":"<p>Base URL: <code>/repair_work_orders</code></p>"},{"location":"developer-guide/api-reference/#list-view_1","title":"List &amp; View","text":"Endpoint Method Description <code>/repair_work_orders/</code> GET List all repair orders <code>/repair_work_orders/&lt;repair_order_no&gt;</code> GET View repair order detail <code>/repair_work_orders/pending</code> GET View pending repair orders <code>/repair_work_orders/completed</code> GET View completed repair orders"},{"location":"developer-guide/api-reference/#create-edit_1","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/repair_work_orders/new</code> GET, POST Create new repair order <code>/repair_work_orders/new/&lt;prefill_cust_id&gt;</code> GET, POST Create with customer pre-filled <code>/repair_work_orders/edit/&lt;repair_order_no&gt;</code> GET, POST Edit repair order <code>/repair_work_orders/delete/&lt;repair_order_no&gt;</code> POST Delete repair order"},{"location":"developer-guide/api-reference/#api-endpoints_1","title":"API Endpoints","text":"Endpoint Method Description <code>/repair_work_orders/api/repair_orders</code> GET JSON API for repair orders <code>/repair_work_orders/api/next_ro_number</code> GET Get next available repair order number"},{"location":"developer-guide/api-reference/#pdf-generation_1","title":"PDF Generation","text":"Endpoint Method Description <code>/repair_work_orders/&lt;repair_order_no&gt;/pdf/download</code> GET Generate and download PDF"},{"location":"developer-guide/api-reference/#customers","title":"Customers","text":"<p>Base URL: <code>/customers</code></p>"},{"location":"developer-guide/api-reference/#list-view_2","title":"List &amp; View","text":"Endpoint Method Description <code>/customers/</code> GET List all customers <code>/customers/&lt;cust_id&gt;</code> GET View customer detail"},{"location":"developer-guide/api-reference/#create-edit_2","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/customers/new</code> GET, POST Create new customer <code>/customers/edit/&lt;cust_id&gt;</code> GET, POST Edit customer <code>/customers/delete/&lt;cust_id&gt;</code> POST Delete customer"},{"location":"developer-guide/api-reference/#api-endpoints_2","title":"API Endpoints","text":"Endpoint Method Description <code>/customers/api/customers</code> GET JSON API for customers <code>/customers/search</code> GET Search customers by name/phone"},{"location":"developer-guide/api-reference/#sources-vendors","title":"Sources (Vendors)","text":"<p>Base URL: <code>/sources</code></p>"},{"location":"developer-guide/api-reference/#list-view_3","title":"List &amp; View","text":"Endpoint Method Description <code>/sources/</code> GET List all sources <code>/sources/&lt;source_id&gt;</code> GET View source detail"},{"location":"developer-guide/api-reference/#create-edit_3","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/sources/new</code> GET, POST Create new source <code>/sources/edit/&lt;source_id&gt;</code> GET, POST Edit source <code>/sources/delete/&lt;source_id&gt;</code> POST Delete source"},{"location":"developer-guide/api-reference/#queue-management","title":"Queue Management","text":"<p>Base URL: <code>/cleaning_queue</code></p> Endpoint Method Description <code>/cleaning_queue/</code> GET View cleaning queue <code>/cleaning_queue/api/queue_items</code> GET JSON API for queue items"},{"location":"developer-guide/api-reference/#in-progress","title":"In Progress","text":"<p>Base URL: <code>/in_progress</code></p> Endpoint Method Description <code>/in_progress/</code> GET View in-progress orders <code>/in_progress/api/in_progress_items</code> GET JSON API for in-progress items"},{"location":"developer-guide/api-reference/#inventory","title":"Inventory","text":"<p>Base URL: <code>/inventory</code></p> Endpoint Method Description <code>/inventory/</code> GET List inventory items <code>/inventory/new</code> GET, POST Create new inventory item <code>/inventory/edit/&lt;inv_id&gt;</code> GET, POST Edit inventory item <code>/inventory/delete/&lt;inv_id&gt;</code> POST Delete inventory item"},{"location":"developer-guide/api-reference/#analytics","title":"Analytics","text":"<p>Base URL: <code>/analytics</code></p> Endpoint Method Description <code>/analytics/</code> GET Analytics dashboard <code>/analytics/api/data</code> GET JSON data for charts"},{"location":"developer-guide/api-reference/#machine-learning","title":"Machine Learning","text":"<p>Base URL: <code>/ml</code></p> Endpoint Method Description <code>/ml/</code> GET ML dashboard <code>/ml/predict</code> POST Get completion time prediction <code>/ml/train</code> POST Train ML model <code>/ml/cron/retrain</code> POST Cron job for retraining (requires secret header)"},{"location":"developer-guide/api-reference/#admin","title":"Admin","text":"<p>Base URL: <code>/admin</code></p> Endpoint Method Description <code>/admin/users</code> GET Manage users (admin only) <code>/admin/invite</code> POST Create invite token (admin only) <code>/admin/delete_user/&lt;user_id&gt;</code> POST Delete user (admin only)"},{"location":"developer-guide/api-reference/#dashboard","title":"Dashboard","text":"<p>Base URL: <code>/</code></p> Endpoint Method Description <code>/</code> GET Main dashboard <code>/health</code> GET Health check endpoint (no auth required)"},{"location":"developer-guide/api-reference/#common-api-parameters","title":"Common API Parameters","text":""},{"location":"developer-guide/api-reference/#pagination","title":"Pagination","text":"<p>Most list API endpoints support pagination:</p> <pre><code>?page=1&amp;per_page=20\n</code></pre>"},{"location":"developer-guide/api-reference/#filtering","title":"Filtering","text":"<p>API endpoints support column-based filtering:</p> <pre><code>?filter_&lt;column&gt;=&lt;value&gt;\n</code></pre> <p>Examples: - <code>?filter_Source=Boat%20Covers</code> - <code>?filter_CustID=123</code></p>"},{"location":"developer-guide/api-reference/#sorting","title":"Sorting","text":"<p>API endpoints support Tabulator-style sorting:</p> <pre><code>?sort[0][field]=&lt;column&gt;&amp;sort[0][dir]=&lt;asc|desc&gt;\n</code></pre> <p>Example: - <code>?sort[0][field]=DateIn&amp;sort[0][dir]=desc</code></p>"},{"location":"developer-guide/api-reference/#search","title":"Search","text":"<p>Some endpoints support full-text search:</p> <pre><code>?search=&lt;query&gt;\n</code></pre>"},{"location":"developer-guide/api-reference/#response-formats","title":"Response Formats","text":""},{"location":"developer-guide/api-reference/#html-responses","title":"HTML Responses","text":"<p>Most <code>GET</code> routes return HTML templates for browser viewing.</p>"},{"location":"developer-guide/api-reference/#json-api-responses","title":"JSON API Responses","text":"<p>API endpoints return JSON in this format:</p>"},{"location":"developer-guide/api-reference/#success-response","title":"Success Response","text":"<pre><code>{\n  \"data\": [...],\n  \"total\": 100,\n  \"page\": 1,\n  \"per_page\": 20\n}\n</code></pre>"},{"location":"developer-guide/api-reference/#error-response","title":"Error Response","text":"<pre><code>{\n  \"error\": \"Error message\"\n}\n</code></pre>"},{"location":"developer-guide/api-reference/#file-uploads","title":"File Uploads","text":"<p>File uploads use <code>multipart/form-data</code> encoding and are stored in AWS S3.</p> <p>Supported File Types: - PDF (.pdf) - Images (.jpg, .jpeg, .png, .gif) - Documents (.doc, .docx, .xls, .xlsx)</p> <p>Max File Size: 10MB (configurable)</p>"},{"location":"developer-guide/api-reference/#authentication-details","title":"Authentication Details","text":""},{"location":"developer-guide/api-reference/#login","title":"Login","text":"<p>Endpoint: <code>POST /auth/login</code></p> <p>Form Data: - <code>username</code> (string, required) - <code>password</code> (string, required)</p> <p>Response: Redirects to dashboard on success</p>"},{"location":"developer-guide/api-reference/#session-management","title":"Session Management","text":"<p>The application uses Flask-Login for session management: - Sessions are cookie-based - Cookies are HTTP-only and secure (in production) - Session timeout: 30 days (remember me) or browser session</p>"},{"location":"developer-guide/api-reference/#error-codes","title":"Error Codes","text":"HTTP Code Description 200 Success 302 Redirect (often after POST) 400 Bad Request (invalid input) 401 Unauthorized (not logged in) 403 Forbidden (insufficient permissions) 404 Not Found 500 Server Error"},{"location":"developer-guide/api-reference/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, no rate limiting is implemented. This may be added in future versions.</p>"},{"location":"developer-guide/api-reference/#examples","title":"Examples","text":""},{"location":"developer-guide/api-reference/#get-work-orders-list-json","title":"Get Work Orders List (JSON)","text":"<pre><code>curl -X GET \"http://localhost:5000/work_orders/api/work_orders?page=1&amp;per_page=20\" \\\n  --cookie \"session=&lt;your-session-cookie&gt;\"\n</code></pre>"},{"location":"developer-guide/api-reference/#create-work-order","title":"Create Work Order","text":"<pre><code>curl -X POST \"http://localhost:5000/work_orders/new\" \\\n  --cookie \"session=&lt;your-session-cookie&gt;\" \\\n  --form \"CustID=123\" \\\n  --form \"WOName=Summer Cleaning\" \\\n  --form \"DateIn=2024-01-15\"\n</code></pre>"},{"location":"developer-guide/api-reference/#upload-file","title":"Upload File","text":"<pre><code>curl -X POST \"http://localhost:5000/work_orders/12345/files/upload\" \\\n  --cookie \"session=&lt;your-session-cookie&gt;\" \\\n  --form \"file=@document.pdf\"\n</code></pre>"},{"location":"developer-guide/api-reference/#code-references","title":"Code References","text":"<p>For implementation details, see:</p> <ul> <li>routes/work_orders.py - Work order routes</li> <li>routes/repair_order.py - Repair order routes</li> <li>routes/customers.py - Customer routes</li> <li>routes/analytics.py - Analytics routes</li> <li>models/ - Database models</li> </ul>"},{"location":"developer-guide/api-reference/#need-help","title":"Need Help?","text":"<ul> <li>Check the FAQ</li> <li>See Troubleshooting</li> <li>Report bugs on GitHub Issues</li> </ul>"},{"location":"developer-guide/database-schema/","title":"Database Schema","text":"<p>Complete reference for the Awning Management System database schema.</p>"},{"location":"developer-guide/database-schema/#overview","title":"Overview","text":"<p>The application uses PostgreSQL with SQLAlchemy ORM. The schema is managed through Alembic migrations. See the Alembic Guide for migration workflows.</p> <p>Key Characteristics: - Database: PostgreSQL 12+ - ORM: SQLAlchemy - Migrations: Alembic - Naming: Legacy Access DB naming (mixed case, some inconsistencies)</p>"},{"location":"developer-guide/database-schema/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Source    \u2502\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2502   Customer   \u2502\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2502 WorkOrder  \u2502\n\u2502  (Vendor)   \u2502    \u2502    \u2502              \u2502    \u2502    \u2502            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502            \u2502            \u2502           \u2502\n                   \u2502            \u2502            \u2502           \u251c\u2500\u2500 WorkOrderItem\n                   \u2502            \u2502            \u2502           \u2514\u2500\u2500 WorkOrderFile\n                   \u2502            \u2502            \u2502\n                   \u2502            \u2502            \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502            \u2502                 \u2502  RepairOrder   \u2502\n                   \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                \u2502\n                   \u2502                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502                                       \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                                          \u2514\u2500\u2500 RepairOrderItem\n                                                          \u2514\u2500\u2500 RepairOrderFile\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    User     \u2502  (Flask-Login auth)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 InviteToken \u2502  (User registration)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Inventory  \u2502  (Available items)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/database-schema/#core-tables","title":"Core Tables","text":""},{"location":"developer-guide/database-schema/#customer-tblcustomers","title":"Customer (<code>tblcustomers</code>)","text":"<p>Customer information and contact details.</p> <p>Primary Key: <code>custid</code> (Text)</p>"},{"location":"developer-guide/database-schema/#columns","title":"Columns","text":"Column Type Description <code>custid</code> Text Customer ID (Primary Key) <code>name</code> Text Customer name <code>contact</code> Text Contact person <code>address</code> Text Physical address line 1 <code>address2</code> Text Physical address line 2 <code>city</code> Text City <code>state</code> Text State <code>zipcode</code> Text ZIP code <code>homephone</code> Text Home phone number <code>workphone</code> Text Work phone number <code>cellphone</code> Text Cell phone number <code>emailaddress</code> Text Email address <code>mailaddress</code> Text Mailing address (if different) <code>mailcity</code> Text Mailing city <code>mailstate</code> Text Mailing state <code>mailzip</code> Text Mailing ZIP <code>sourceold</code> Text Legacy source field <code>source</code> Text Source/vendor (FK \u2192 <code>tblsource.ssource</code>) <code>sourceaddress</code> Text Source address <code>sourcestate</code> Text Source state <code>sourcecity</code> Text Source city <code>sourcezip</code> Text Source ZIP"},{"location":"developer-guide/database-schema/#relationships","title":"Relationships","text":"<ul> <li>Has many: WorkOrder (via <code>custid</code>)</li> <li>Has many: RepairWorkOrder (via <code>custid</code>)</li> <li>Belongs to: Source (via <code>source</code>)</li> </ul>"},{"location":"developer-guide/database-schema/#methods","title":"Methods","text":"<ul> <li><code>to_dict()</code> - Convert to dictionary</li> <li><code>clean_email()</code> - Remove <code>#mailto:</code> suffix</li> <li><code>clean_phone(field)</code> - Format phone numbers</li> <li><code>get_full_address()</code> - Formatted physical address</li> <li><code>get_mailing_address()</code> - Formatted mailing address</li> <li><code>get_primary_phone()</code> - First available phone number</li> </ul> <p>Model: models/customer.py</p>"},{"location":"developer-guide/database-schema/#workorder-tblcustworkorderdetail","title":"WorkOrder (<code>tblcustworkorderdetail</code>)","text":"<p>Cleaning work orders.</p> <p>Primary Key: <code>workorderno</code> (String)</p>"},{"location":"developer-guide/database-schema/#columns_1","title":"Columns","text":"Column Type Description <code>workorderno</code> String Work order number (Primary Key) <code>custid</code> String Customer ID (FK \u2192 <code>tblcustomers.custid</code>) <code>woname</code> String Work order name/title <code>storage</code> String DEPRECATED - Do not use <code>storagetime</code> String Storage duration: \"Seasonal\" or \"Temporary\" <code>rack_number</code> String Physical location (e.g., \"5 B\", \"bin 4 top\") <code>finallocation</code> String Location after cleaning is complete <code>specialinstructions</code> Text Special instructions <code>repairsneeded</code> Boolean Repairs needed flag <code>returnstatus</code> String Return status <code>datecompleted</code> DateTime Completion timestamp <code>daterequired</code> Date Required by date <code>datein</code> Date Date received <code>clean</code> Date Date cleaned <code>treat</code> Date Date treated <code>quote</code> String Quote information <code>rushorder</code> Boolean Rush order flag <code>firmrush</code> Boolean Firm rush flag <code>seerepair</code> String Related repair order reference <code>shipto</code> String Ship to source (FK \u2192 <code>tblsource.ssource</code>) <code>cleanfirstwo</code> String DEPRECATED - Historical only <code>queueposition</code> Integer Position in cleaning queue <code>processingstatus</code> Boolean Currently being processed <code>source_name</code> Text Denormalized source name (for performance) <code>created_at</code> DateTime Record creation timestamp <code>updated_at</code> DateTime Last update timestamp <p>Storage Fields</p> <p>See Storage Fields Guide for detailed explanation of <code>storage</code>, <code>storagetime</code>, and <code>rack_number</code> fields.</p>"},{"location":"developer-guide/database-schema/#relationships_1","title":"Relationships","text":"<ul> <li>Belongs to: Customer (via <code>custid</code>)</li> <li>Belongs to: Source (via <code>shipto</code> - ship to location)</li> <li>Has many: WorkOrderItem (child items)</li> <li>Has many: WorkOrderFile (attached files)</li> </ul>"},{"location":"developer-guide/database-schema/#properties","title":"Properties","text":"<ul> <li><code>is_completed</code> - Boolean indicating completion status</li> <li><code>total_items</code> - Count of order items</li> <li><code>file_count</code> - Count of attached files</li> </ul> <p>Model: models/work_order.py</p>"},{"location":"developer-guide/database-schema/#workorderitem-tblorddetcustawngs","title":"WorkOrderItem (<code>tblorddetcustawngs</code>)","text":"<p>Individual items within a work order.</p> <p>Primary Key: <code>itemid</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_2","title":"Columns","text":"Column Type Description <code>itemid</code> Integer Item ID (Primary Key) <code>workorderno</code> String Work order number (FK \u2192 <code>tblcustworkorderdetail.workorderno</code>) <code>sizewgt</code> String Size/weight description (e.g., \"8'x10'\", \"95#\") <code>price</code> Numeric Item price <code>qty</code> String Quantity (may contain non-numeric values) <code>desc</code> Text Item description <code>location</code> String Item-specific location"},{"location":"developer-guide/database-schema/#item-types","title":"Item Types","text":"<p>The <code>sizewgt</code> field determines the item type: - Awning: Contains dimensions (e.g., \"8'x10'\", \"12'6\"x15'3\"\") - Sail: Contains weight with <code>#</code> (e.g., \"95#\", \"120#\")</p> <p>Model: models/work_order.py (WorkOrderItem class)</p>"},{"location":"developer-guide/database-schema/#repairworkorder-tblrepairworkorderdetail","title":"RepairWorkOrder (<code>tblrepairworkorderdetail</code>)","text":"<p>Repair work orders.</p> <p>Primary Key: <code>repairorderno</code> (String)</p>"},{"location":"developer-guide/database-schema/#columns_3","title":"Columns","text":"Column Type Description <code>repairorderno</code> String Repair order number (Primary Key) <code>custid</code> String Customer ID (FK \u2192 <code>tblcustomers.custid</code>) <code>roname</code> String Repair order name/title <code>source</code> String Source field (not FK) <code>WO DATE</code> Date Work order date \u26a0\ufe0f Uppercase with space <code>DATE TO SUB</code> Date Date to subcontractor \u26a0\ufe0f Uppercase with spaces <code>daterequired</code> Date Required by date <code>datecompleted</code> DateTime Completion timestamp <code>returndate</code> Date Return date <code>dateout</code> Date Date sent out <code>datein</code> Date Date received <code>rushorder</code> Boolean Rush order flag <code>firmrush</code> Boolean Firm rush flag <code>quote</code> Boolean Quote flag <code>approved</code> Boolean Approved flag <code>clean</code> Boolean Clean before repair <code>cleanfirst</code> Boolean DEPRECATED - Historical only <code>QUOTE  BY</code> String Quoted by \u26a0\ufe0f Two spaces <code>RACK#</code> String Physical location (e.g., \"hang 4\", \"6D\") <code>storage</code> String Storage duration: \"TEMPORARY\" or \"SEASONAL\" <code>location</code> String Additional location details <code>finallocation</code> String Location after repair is complete <code>ITEM TYPE</code> String Item type \u26a0\ufe0f Uppercase with space <code>TYPE OF REPAIR</code> String Repair type \u26a0\ufe0f Uppercase with spaces <code>specialinstructions</code> Text Special instructions <code>seeclean</code> String Related work order reference <code>repairsdoneby</code> String Repair technician <code>materiallist</code> Text Materials used <code>customerprice</code> String Price quoted to customer <code>returnstatus</code> String Return status <code>source_name</code> Text Denormalized source name (for performance) <code>created_at</code> DateTime Record creation timestamp <code>updated_at</code> DateTime Last update timestamp <p>Column Name Quirks</p> <p>Some columns have uppercase names or spaces: <code>WO DATE</code>, <code>DATE TO SUB</code>, <code>RACK#</code>, <code>QUOTE  BY</code>, <code>ITEM TYPE</code>, <code>TYPE OF REPAIR</code>.</p>"},{"location":"developer-guide/database-schema/#relationships_2","title":"Relationships","text":"<ul> <li>Belongs to: Customer (via <code>custid</code>)</li> <li>Has many: RepairOrderItem (child items)</li> <li>Has many: RepairOrderFile (attached files)</li> </ul> <p>Model: models/repair_order.py</p>"},{"location":"developer-guide/database-schema/#source-tblsource","title":"Source (<code>tblsource</code>)","text":"<p>Vendors, sail lofts, and source organizations.</p> <p>Primary Key: <code>ssource</code> (Text)</p>"},{"location":"developer-guide/database-schema/#columns_4","title":"Columns","text":"Column Type Description <code>ssource</code> Text Source identifier (Primary Key) <code>name</code> Text Source name <code>contact</code> Text Contact person <code>address</code> Text Address <code>city</code> Text City <code>state</code> Text State <code>zip</code> Text ZIP code <code>phone</code> Text Phone number <code>email</code> Text Email address"},{"location":"developer-guide/database-schema/#relationships_3","title":"Relationships","text":"<ul> <li>Has many: Customer (via <code>source</code>)</li> <li>Has many: WorkOrder (via <code>shipto</code>)</li> </ul> <p>Model: models/source.py</p>"},{"location":"developer-guide/database-schema/#inventory-tblinventory","title":"Inventory (<code>tblinventory</code>)","text":"<p>Inventory items available for use.</p> <p>Primary Key: <code>invid</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_5","title":"Columns","text":"Column Type Description <code>invid</code> Integer Inventory ID (Primary Key) <code>custid</code> String Customer ID (optional, for customer-specific items) <code>description</code> Text Item description <code>size</code> String Size/dimensions <code>quantity</code> Integer Quantity available <code>location</code> String Storage location <code>notes</code> Text Additional notes <p>Model: models/inventory.py</p>"},{"location":"developer-guide/database-schema/#file-attachments","title":"File Attachments","text":""},{"location":"developer-guide/database-schema/#workorderfile-work_order_files","title":"WorkOrderFile (<code>work_order_files</code>)","text":"<p>Files attached to work orders.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_6","title":"Columns","text":"Column Type Description <code>id</code> Integer File ID (Primary Key) <code>work_order_no</code> String Work order number (FK \u2192 <code>tblcustworkorderdetail.workorderno</code>) <code>file_name</code> String Original filename <code>s3_key</code> String S3 object key <code>file_size</code> Integer File size in bytes <code>content_type</code> String MIME type <code>uploaded_at</code> DateTime Upload timestamp"},{"location":"developer-guide/database-schema/#relationships_4","title":"Relationships","text":"<ul> <li>Belongs to: WorkOrder (via <code>work_order_no</code>)</li> </ul> <p>Storage: AWS S3 bucket</p> <p>Model: models/work_order_file.py</p>"},{"location":"developer-guide/database-schema/#repairorderfile-repair_order_files","title":"RepairOrderFile (<code>repair_order_files</code>)","text":"<p>Files attached to repair orders.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_7","title":"Columns","text":"Column Type Description <code>id</code> Integer File ID (Primary Key) <code>repair_order_no</code> String Repair order number (FK \u2192 <code>tblrepairworkorderdetail.repairorderno</code>) <code>file_name</code> String Original filename <code>s3_key</code> String S3 object key <code>file_size</code> Integer File size in bytes <code>content_type</code> String MIME type <code>uploaded_at</code> DateTime Upload timestamp"},{"location":"developer-guide/database-schema/#relationships_5","title":"Relationships","text":"<ul> <li>Belongs to: RepairWorkOrder (via <code>repair_order_no</code>)</li> </ul> <p>Storage: AWS S3 bucket</p> <p>Model: models/repair_order_file.py</p>"},{"location":"developer-guide/database-schema/#authentication-users","title":"Authentication &amp; Users","text":""},{"location":"developer-guide/database-schema/#user-users","title":"User (<code>users</code>)","text":"<p>Application users for Flask-Login authentication.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_8","title":"Columns","text":"Column Type Description <code>id</code> Integer User ID (Primary Key) <code>username</code> String(80) Username (unique) <code>password_hash</code> String(255) Bcrypt password hash <code>role</code> String(20) User role: \"admin\" or \"user\" <code>created_at</code> DateTime Account creation timestamp"},{"location":"developer-guide/database-schema/#methods_1","title":"Methods","text":"<ul> <li><code>set_password(password)</code> - Hash and set password</li> <li><code>check_password(password)</code> - Verify password</li> <li><code>is_admin()</code> - Check if user has admin role</li> </ul> <p>Model: models/user.py</p>"},{"location":"developer-guide/database-schema/#invitetoken-invite_tokens","title":"InviteToken (<code>invite_tokens</code>)","text":"<p>Invitation tokens for user registration.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_9","title":"Columns","text":"Column Type Description <code>id</code> Integer Token ID (Primary Key) <code>token</code> String(100) Invite token (unique, indexed) <code>role</code> String(20) Role to assign: \"admin\" or \"user\" <code>used</code> Boolean Token used flag <code>created_at</code> DateTime Token creation timestamp <code>used_at</code> DateTime Token usage timestamp <p>Model: models/invite_token.py</p>"},{"location":"developer-guide/database-schema/#indexes","title":"Indexes","text":"<p>Key indexes for performance optimization:</p>"},{"location":"developer-guide/database-schema/#work-orders","title":"Work Orders","text":"<ul> <li><code>idx_workorder_custid</code> on <code>custid</code> (foreign key)</li> <li><code>idx_workorder_source_name</code> on <code>source_name</code> (denormalized field for filtering)</li> <li><code>idx_workorder_datecompleted</code> on <code>datecompleted</code> (filtering completed orders)</li> <li><code>idx_workorder_datein</code> on <code>datein</code> (filtering by intake date)</li> </ul>"},{"location":"developer-guide/database-schema/#repair-orders","title":"Repair Orders","text":"<ul> <li><code>idx_repairorder_custid</code> on <code>custid</code> (foreign key)</li> <li><code>idx_repairorder_source_name</code> on <code>source_name</code> (denormalized field for filtering)</li> <li><code>idx_repairorder_datecompleted</code> on <code>datecompleted</code> (filtering completed orders)</li> </ul>"},{"location":"developer-guide/database-schema/#customers","title":"Customers","text":"<ul> <li><code>idx_customer_source</code> on <code>source</code> (foreign key)</li> <li><code>idx_customer_name</code> on <code>name</code> (searching by name)</li> </ul>"},{"location":"developer-guide/database-schema/#files","title":"Files","text":"<ul> <li><code>idx_workorderfile_work_order_no</code> on <code>work_order_no</code> (foreign key)</li> <li><code>idx_repairorderfile_repair_order_no</code> on <code>repair_order_no</code> (foreign key)</li> </ul>"},{"location":"developer-guide/database-schema/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"developer-guide/database-schema/#denormalization","title":"Denormalization","text":"<p>The <code>source_name</code> field is denormalized in both <code>WorkOrder</code> and <code>RepairWorkOrder</code> tables:</p> <p>Purpose: Avoid expensive 3-table joins when filtering/sorting by source Synced via: Database triggers and application-level sync methods Performance gain: ~100x faster for source filtering queries</p> <p>See Denormalization Analysis for details.</p>"},{"location":"developer-guide/database-schema/#lazy-loading","title":"Lazy Loading","text":"<p>Relationships use strategic lazy loading: - <code>lazy='dynamic'</code> for large collections (e.g., customer \u2192 work_orders) - <code>lazy='joined'</code> for frequently accessed relationships (e.g., work_order \u2192 files) - Default <code>lazy='select'</code> for most relationships</p>"},{"location":"developer-guide/database-schema/#data-types","title":"Data Types","text":""},{"location":"developer-guide/database-schema/#datedatetime-handling","title":"Date/DateTime Handling","text":"<ul> <li>Date: Used for calendar dates (no time component)</li> <li>Examples: <code>datein</code>, <code>daterequired</code>, <code>clean</code>, <code>treat</code></li> <li>DateTime: Used when time matters</li> <li>Examples: <code>datecompleted</code>, <code>created_at</code>, <code>updated_at</code></li> </ul>"},{"location":"developer-guide/database-schema/#boolean-fields","title":"Boolean Fields","text":"<ul> <li>Stored as PostgreSQL <code>BOOLEAN</code> type</li> <li>Python: <code>True</code>/<code>False</code></li> <li>Database: <code>true</code>/<code>false</code></li> <li>Legacy data may contain: \"YES\"/\"NO\", \"TRUE\"/\"FALSE\", 1/0</li> </ul>"},{"location":"developer-guide/database-schema/#numeric-fields","title":"Numeric Fields","text":"<ul> <li>Prices: <code>Numeric</code> type (precise decimal)</li> <li>Quantities: Often stored as <code>String</code> (may contain non-numeric values like \"TBD\")</li> <li>IDs: Auto-increment integers or string-based custom IDs</li> </ul>"},{"location":"developer-guide/database-schema/#common-queries","title":"Common Queries","text":""},{"location":"developer-guide/database-schema/#get-all-pending-work-orders-for-a-customer","title":"Get all pending work orders for a customer","text":"<pre><code>pending_orders = WorkOrder.query.filter_by(\n    CustID=customer_id,\n    DateCompleted=None\n).order_by(WorkOrder.DateIn.desc()).all()\n</code></pre>"},{"location":"developer-guide/database-schema/#get-work-orders-with-source-name-denormalized","title":"Get work orders with source name (denormalized)","text":"<pre><code>work_orders = WorkOrder.query.filter(\n    WorkOrder.source_name == 'Boat Covers Inc'\n).all()\n</code></pre>"},{"location":"developer-guide/database-schema/#get-customer-with-all-relationships","title":"Get customer with all relationships","text":"<pre><code>customer = Customer.query.options(\n    joinedload(Customer.work_orders),\n    joinedload(Customer.repair_work_orders),\n    joinedload(Customer.source_info)\n).get(customer_id)\n</code></pre>"},{"location":"developer-guide/database-schema/#schema-changes","title":"Schema Changes","text":"<p>All schema changes must go through Alembic migrations. See the Alembic Guide for the workflow.</p>"},{"location":"developer-guide/database-schema/#adding-a-column","title":"Adding a Column","text":"<pre><code># Create migration\n./alembic_db.sh test revision --autogenerate -m \"add_new_column\"\n\n# Review and apply\n./alembic_db.sh test upgrade head\n./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"developer-guide/database-schema/#renaming-a-column","title":"Renaming a Column","text":"<pre><code># Create migration manually\n./alembic_db.sh test revision -m \"rename_column\"\n\n# Edit migration file\ndef upgrade():\n    op.alter_column('table_name', 'old_name', new_column_name='new_name')\n</code></pre>"},{"location":"developer-guide/database-schema/#legacy-database-notes","title":"Legacy Database Notes","text":"<p>This database was migrated from Microsoft Access, which explains some quirks:</p> <ul> <li>Mixed case column names (e.g., <code>CustID</code>, <code>workorderno</code>)</li> <li>Spaces in column names (e.g., <code>WO DATE</code>, <code>TYPE OF REPAIR</code>)</li> <li>Inconsistent naming (some camelCase, some lowercase, some UPPERCASE)</li> <li>Multiple spaces in names (e.g., <code>QUOTE  BY</code> has two spaces)</li> <li>Deprecated fields left for historical data compatibility</li> </ul> <p>When working with the schema, always check the exact column name in the model definition.</p>"},{"location":"developer-guide/database-schema/#er-diagram-detailed","title":"ER Diagram - Detailed","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              tblcustomers                  \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK custid         TEXT                     \u2502\n\u2502    name           TEXT                     \u2502\n\u2502    contact        TEXT                     \u2502\n\u2502    address        TEXT                     \u2502\n\u2502    city, state, zipcode                    \u2502\n\u2502    homephone, workphone, cellphone         \u2502\n\u2502    emailaddress   TEXT                     \u2502\n\u2502 FK source         TEXT  \u2192 tblsource        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                           \u2502\n          \u2502 1                       1 \u2502\n          \u2502                           \u2502\n          \u2502 N                       N \u2502\n          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 tblcustworkorder... \u2502     \u2502 tblrepairworkorder..\u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK workorderno      \u2502     \u2502 PK repairorderno    \u2502\n\u2502 FK custid           \u2502     \u2502 FK custid           \u2502\n\u2502    woname           \u2502     \u2502    roname           \u2502\n\u2502    rack_number      \u2502     \u2502    RACK#            \u2502\n\u2502    storagetime      \u2502     \u2502    storage          \u2502\n\u2502    datein, dateout  \u2502     \u2502    datein, dateout  \u2502\n\u2502    source_name      \u2502     \u2502    source_name      \u2502\n\u2502    ...              \u2502     \u2502    ...              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                           \u2502\n          \u2502 1                       1 \u2502\n          \u2502                           \u2502\n          \u2502 N                       N \u2502\n          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  tblorddetcust...   \u2502     \u2502 repair_order_items  \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK itemid           \u2502     \u2502 PK id               \u2502\n\u2502 FK workorderno      \u2502     \u2502 FK repairorderno    \u2502\n\u2502    sizewgt          \u2502     \u2502    description      \u2502\n\u2502    price, qty       \u2502     \u2502    price, qty       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n          \u2502 1                       1 \u2502\n          \u2502 N                       N \u2502\n          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 work_order_files    \u2502     \u2502 repair_order_files  \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK id               \u2502     \u2502 PK id               \u2502\n\u2502 FK work_order_no    \u2502     \u2502 FK repair_order_no  \u2502\n\u2502    s3_key           \u2502     \u2502    s3_key           \u2502\n\u2502    file_name        \u2502     \u2502    file_name        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              tblsource                     \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK ssource        TEXT                     \u2502\n\u2502    name           TEXT                     \u2502\n\u2502    contact        TEXT                     \u2502\n\u2502    address        TEXT                     \u2502\n\u2502    phone, email   TEXT                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/database-schema/#see-also","title":"See Also","text":"<ul> <li>Alembic Migration Guide - Database migrations</li> <li>Storage Fields Guide - Understanding storage/location fields</li> <li>API Reference - API endpoints</li> <li>Performance Analysis - Query optimization</li> <li>Denormalization Analysis - Performance improvements</li> </ul>"},{"location":"developer-guide/project-structure/","title":"Project Structure","text":""},{"location":"developer-guide/project-structure/#overview","title":"Overview","text":"<p>The Awning Management System follows a modular Flask application structure.</p>"},{"location":"developer-guide/project-structure/#directory-structure","title":"Directory Structure","text":"<pre><code>awning_wo/\n\u251c\u2500\u2500 app.py                  # Application factory\n\u251c\u2500\u2500 application.py          # AWS EB entry point\n\u251c\u2500\u2500 config.py              # Configuration\n\u251c\u2500\u2500 extensions.py          # Flask extensions\n\u251c\u2500\u2500 decorators.py          # Custom decorators\n\u251c\u2500\u2500 models/                # SQLAlchemy models\n\u2502   \u251c\u2500\u2500 customer.py\n\u2502   \u251c\u2500\u2500 work_order.py\n\u2502   \u251c\u2500\u2500 repair_order.py\n\u2502   \u251c\u2500\u2500 source.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 routes/                # Blueprint route handlers\n\u2502   \u251c\u2500\u2500 auth.py\n\u2502   \u251c\u2500\u2500 work_orders.py\n\u2502   \u251c\u2500\u2500 repair_order.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 templates/             # Jinja2 templates\n\u2502   \u251c\u2500\u2500 base.html\n\u2502   \u251c\u2500\u2500 work_orders/\n\u2502   \u251c\u2500\u2500 repair_orders/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 static/               # CSS, JS, images\n\u2502   \u251c\u2500\u2500 css/\n\u2502   \u251c\u2500\u2500 js/\n\u2502   \u2514\u2500\u2500 images/\n\u2514\u2500\u2500 tests/                # Test suite\n</code></pre>"},{"location":"developer-guide/project-structure/#key-files","title":"Key Files","text":""},{"location":"developer-guide/project-structure/#application-entry-points","title":"Application Entry Points","text":"<ul> <li><code>app.py</code> - Flask application factory, blueprint registration</li> <li><code>application.py</code> - AWS Elastic Beanstalk WSGI entry point</li> <li><code>config.py</code> - Environment-based configuration</li> </ul>"},{"location":"developer-guide/project-structure/#models","title":"Models","text":"<p>Models are in <code>models/</code> and use SQLAlchemy ORM:</p> <ul> <li><code>customer.py</code> - Customer information</li> <li><code>work_order.py</code> - Work order model</li> <li><code>repair_order.py</code> - Repair order model</li> <li><code>source.py</code> - Vendor/source model</li> </ul>"},{"location":"developer-guide/project-structure/#routes","title":"Routes","text":"<p>Routes are organized as Flask blueprints in <code>routes/</code>:</p> <ul> <li><code>work_orders.py</code> - Work order CRUD operations</li> <li><code>repair_order.py</code> - Repair order operations</li> <li><code>customers.py</code> - Customer management</li> <li><code>analytics.py</code> - Analytics dashboard</li> </ul>"},{"location":"developer-guide/project-structure/#templates","title":"Templates","text":"<p>Jinja2 templates in <code>templates/</code> follow feature-based organization.</p>"},{"location":"developer-guide/project-structure/#code-organization-principles","title":"Code Organization Principles","text":"<ol> <li>Blueprints - Each feature area has its own blueprint</li> <li>Models - One file per model</li> <li>Templates - Organized by feature</li> <li>DRY - Shared logic in decorators and utilities</li> </ol>"},{"location":"developer-guide/project-structure/#next-steps","title":"Next Steps","text":"<ul> <li>Learn the Database Schema</li> <li>Explore API Reference</li> <li>Read about Testing</li> </ul>"},{"location":"developer-guide/setup/","title":"Setup &amp; Installation","text":""},{"location":"developer-guide/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>PostgreSQL 12 or higher</li> <li>Git</li> <li>pip and virtualenv</li> </ul>"},{"location":"developer-guide/setup/#local-development-setup","title":"Local Development Setup","text":""},{"location":"developer-guide/setup/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/andrewimpellitteri/awning_wo.git\ncd awning_wo\n</code></pre>"},{"location":"developer-guide/setup/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre>"},{"location":"developer-guide/setup/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"developer-guide/setup/#4-set-up-database","title":"4. Set Up Database","text":"<p>Create a PostgreSQL database:</p> <pre><code>createdb clean_repair\n</code></pre>"},{"location":"developer-guide/setup/#5-configure-environment-variables","title":"5. Configure Environment Variables","text":"<p>Create a <code>.env</code> file:</p> <pre><code>FLASK_ENV=development\nFLASK_DEBUG=true\nSECRET_KEY=your-secret-key-here\nDATABASE_URL=postgresql://postgres:password@localhost:5432/clean_repair\n</code></pre>"},{"location":"developer-guide/setup/#6-run-migrations","title":"6. Run Migrations","text":"<pre><code>./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"developer-guide/setup/#7-run-the-application","title":"7. Run the Application","text":"<pre><code>python app.py\n</code></pre> <p>Visit <code>http://localhost:5000</code> in your browser.</p>"},{"location":"developer-guide/setup/#running-tests","title":"Running Tests","text":"<pre><code>pytest\npytest --cov=. --cov-report=html  # With coverage\n</code></pre>"},{"location":"developer-guide/setup/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Project Structure guide</li> <li>Review the Database Schema</li> <li>Check out Testing to write tests</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/","title":"Source Name Denormalization - Feasibility Analysis","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#executive-summary","title":"Executive Summary","text":"<p>\u2705 HIGHLY FEASIBLE - Adding a denormalized <code>source_name</code> column is straightforward and requires minimal code changes.</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#benefits","title":"Benefits","text":"<ul> <li>93ms \u2192 ~1ms for Source sorting (100x faster!)</li> <li>Simplified queries - no more 3-table joins</li> <li>Better filtering performance</li> <li>Still maintains referential integrity through existing relationships</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#required-changes","title":"Required Changes","text":"<ul> <li>1 model change (add column + property)</li> <li>1 route change (API endpoint)</li> <li>1 trigger (keep data in sync)</li> <li>Migration script</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#current-architecture","title":"Current Architecture","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#how-source-info-is-currently-accessed","title":"How Source Info is Currently Accessed","text":"<pre><code>WorkOrder (tblcustworkorderdetail)\n  \u2193 custid\nCustomer (tblcustomers)\n  \u2193 source\nSource (tblsource.ssource)\n</code></pre> <p>Current query for Source name: <pre><code># In routes/work_orders.py:1080\n\"Source\": wo.customer.source_info.SSource\n    if wo.customer and wo.customer.source_info\n    else None\n</code></pre></p> <p>This requires: 1. Join <code>work_orders \u2192 customers</code> 2. Join <code>customers \u2192 sources</code> 3. Access <code>source_info.SSource</code></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#two-different-source-concepts","title":"Two Different \"Source\" Concepts","text":"<p>\u26a0\ufe0f IMPORTANT: Your codebase has 2 different meanings of \"Source\":</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#1-customers-source-where-customer-came-from","title":"1. Customer's Source (where customer came from)","text":"<ul> <li><code>customer.Source</code> \u2192 foreign key to <code>tblsource.ssource</code></li> <li><code>customer.source_info</code> \u2192 relationship to Source model</li> <li>Used for: \"Where did we acquire this customer?\"</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#2-work-orders-shipto-where-to-ship-the-order","title":"2. Work Order's ShipTo (where to ship the order)","text":"<ul> <li><code>work_order.ShipTo</code> \u2192 foreign key to <code>tblsource.ssource</code></li> <li><code>work_order.ship_to_source</code> \u2192 relationship to Source model</li> <li>Used for: \"Where should we ship this order?\"</li> </ul> <p>In the API endpoint, \"Source\" refers to the CUSTOMER's source, not ShipTo!</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#proposed-solution","title":"Proposed Solution","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#schema-change","title":"Schema Change","text":"<pre><code>-- Add denormalized column\nALTER TABLE tblcustworkorderdetail\nADD COLUMN source_name TEXT;\n\n-- Create index for fast filtering/sorting\nCREATE INDEX idx_workorder_source_name\nON tblcustworkorderdetail(source_name);\n\n-- Populate existing records\nUPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nJOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n\n-- Add index for shipto too (currently exists but let's verify)\nCREATE INDEX IF NOT EXISTS idx_workorder_shipto\nON tblcustworkorderdetail(shipto);\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#model-changes","title":"Model Changes","text":"<p>File: models/work_order.py</p> <pre><code>class WorkOrder(db.Model):\n    __tablename__ = \"tblcustworkorderdetail\"\n\n    # ... existing fields ...\n\n    ShipTo = db.Column(\"shipto\", db.String, db.ForeignKey(\"tblsource.ssource\"))\n\n    # NEW: Denormalized source name from customer\n    source_name = db.Column(\"source_name\", db.Text, nullable=True)\n\n    # ... existing relationships ...\n\n    ship_to_source = db.relationship(\n        \"Source\",\n        primaryjoin=\"WorkOrder.ShipTo==Source.SSource\",\n        lazy=\"joined\",\n        uselist=False,\n    )\n\n    # NEW: Computed property to get source name (with fallback)\n    @property\n    def customer_source_name(self):\n        \"\"\"Get customer's source name (with fallback to relationship)\"\"\"\n        # Use denormalized value if available\n        if self.source_name:\n            return self.source_name\n        # Fallback to relationship (for backward compatibility)\n        if self.customer and self.customer.source_info:\n            return self.customer.source_info.SSource\n        return None\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#code-changes-required","title":"Code Changes Required","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-1-api-endpoint-routeswork_orderspy1073-1083","title":"\u2705 Change 1: API Endpoint (routes/work_orders.py:1073-1083)","text":"<p>BEFORE: <pre><code>data = [\n    {\n        \"WorkOrderNo\": wo.WorkOrderNo,\n        \"CustID\": wo.CustID,\n        \"WOName\": wo.WOName,\n        \"DateIn\": format_date_from_str(wo.DateIn),\n        \"DateRequired\": format_date_from_str(wo.DateRequired),\n        \"Source\": wo.customer.source_info.SSource\n            if wo.customer and wo.customer.source_info\n            else None,\n        # ... rest ...\n    }\n    for wo in work_orders.items\n]\n</code></pre></p> <p>AFTER: <pre><code>data = [\n    {\n        \"WorkOrderNo\": wo.WorkOrderNo,\n        \"CustID\": wo.CustID,\n        \"WOName\": wo.WOName,\n        \"DateIn\": format_date_from_str(wo.DateIn),\n        \"DateRequired\": format_date_from_str(wo.DateRequired),\n        \"Source\": wo.source_name,  # \u2190 Changed! Now uses denormalized column\n        # ... rest ...\n    }\n    for wo in work_orders.items\n]\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-2-query-optimization-routeswork_orderspy943-955","title":"\u2705 Change 2: Query Optimization (routes/work_orders.py:943-955)","text":"<p>BEFORE: <pre><code># Conditionally join and eager load relationships\nif is_source_filter or is_source_sort:\n    query = query.join(WorkOrder.customer).join(Customer.source_info)\n    query = query.options(\n        joinedload(WorkOrder.customer).joinedload(Customer.source_info)\n    )\nelse:\n    query = query.options(joinedload(WorkOrder.customer))\n</code></pre></p> <p>AFTER: <pre><code># No need for source joins anymore! Just load customer\nquery = query.options(joinedload(WorkOrder.customer))\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-3-source-filter-routeswork_orderspy1006-1007","title":"\u2705 Change 3: Source Filter (routes/work_orders.py:1006-1007)","text":"<p>BEFORE: <pre><code>if is_source_filter:\n    query = query.filter(Source.SSource.ilike(f\"%{is_source_filter}%\"))\n</code></pre></p> <p>AFTER: <pre><code>if is_source_filter:\n    query = query.filter(WorkOrder.source_name.ilike(f\"%{is_source_filter}%\"))\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-4-source-sorting-routeswork_orderspy1032-1038","title":"\u2705 Change 4: Source Sorting (routes/work_orders.py:1032-1038)","text":"<p>BEFORE: <pre><code>if field == \"Source\":\n    # The query is already joined, so we can sort on the joined table's column\n    column_to_sort = Source.SSource\n    if direction == \"desc\":\n        order_by_clauses.append(column_to_sort.desc())\n    else:\n        order_by_clauses.append(column_to_sort.asc())\n</code></pre></p> <p>AFTER: <pre><code>if field == \"Source\":\n    # Use denormalized column for sorting\n    column_to_sort = WorkOrder.source_name\n    if direction == \"desc\":\n        order_by_clauses.append(column_to_sort.desc())\n    else:\n        order_by_clauses.append(column_to_sort.asc())\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-5-maintain-data-on-create-routeswork_orderspy383-417","title":"\u2705 Change 5: Maintain Data on Create (routes/work_orders.py:383-417)","text":"<p>Add after line 417: <pre><code>work_order = WorkOrder(\n    WorkOrderNo=next_wo_no,\n    CustID=request.form.get(\"CustID\"),\n    WOName=request.form.get(\"WOName\"),\n    # ... all existing fields ...\n    ShipTo=request.form.get(\"ShipTo\"),\n)\n\n# NEW: Set source_name from customer\ncustomer = Customer.query.get(request.form.get(\"CustID\"))\nif customer and customer.Source:\n    source = Source.query.get(customer.Source)\n    if source:\n        work_order.source_name = source.SSource\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-6-maintain-data-on-edit-routeswork_orderspy597-607","title":"\u2705 Change 6: Maintain Data on Edit (routes/work_orders.py:597-607)","text":"<p>Add after line 607: <pre><code># Update work order fields\nwork_order.CustID = request.form.get(\"CustID\")\n# ... other fields ...\n\n# NEW: Update source_name if customer changed\nif work_order.CustID != old_cust_id:  # Track old value\n    customer = Customer.query.get(work_order.CustID)\n    if customer and customer.Source:\n        source = Source.query.get(customer.Source)\n        if source:\n            work_order.source_name = source.SSource\n    else:\n        work_order.source_name = None\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#data-consistency-strategy","title":"Data Consistency Strategy","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#option-a-application-level-maintenance-recommended","title":"Option A: Application-Level Maintenance (RECOMMENDED)","text":"<p>Pros: - Simple, no database triggers - Easy to debug - Explicit control</p> <p>Implementation: Add helper method to WorkOrder model:</p> <pre><code>class WorkOrder(db.Model):\n    # ... fields ...\n\n    def sync_source_name(self):\n        \"\"\"Update source_name from customer's source\"\"\"\n        if self.customer and self.customer.source_info:\n            self.source_name = self.customer.source_info.SSource\n        else:\n            self.source_name = None\n</code></pre> <p>Call in routes: <pre><code># After creating/updating work order\nwork_order.sync_source_name()\ndb.session.commit()\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#option-b-database-trigger-automatic","title":"Option B: Database Trigger (AUTOMATIC)","text":"<p>Pros: - Automatic, can't forget - Works for bulk updates - Consistent across all entry points</p> <p>Cons: - Harder to debug - Database-specific</p> <p>Implementation: <pre><code>-- Trigger to auto-update source_name on insert/update\nCREATE OR REPLACE FUNCTION sync_work_order_source_name()\nRETURNS TRIGGER AS $$\nBEGIN\n    -- Update source_name from customer's source\n    SELECT s.ssource INTO NEW.source_name\n    FROM tblcustomers c\n    LEFT JOIN tblsource s ON c.source = s.ssource\n    WHERE c.custid = NEW.custid;\n\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_sync_work_order_source_name\n    BEFORE INSERT OR UPDATE OF custid ON tblcustworkorderdetail\n    FOR EACH ROW\n    EXECUTE FUNCTION sync_work_order_source_name();\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#option-c-hybrid-best","title":"Option C: Hybrid (BEST)","text":"<ul> <li>Use application-level sync for create/edit forms (explicit)</li> <li>Use trigger as safety net for bulk operations</li> <li>Use periodic sync job to fix any drift</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#migration-steps","title":"Migration Steps","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#1-create-migration-script","title":"1. Create Migration Script","text":"<pre><code>-- File: query_optimization/add_source_name_column.sql\n\nBEGIN;\n\n-- Step 1: Add column\nALTER TABLE tblcustworkorderdetail\nADD COLUMN source_name TEXT;\n\n-- Step 2: Populate existing records\nUPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nLEFT JOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n\n-- Step 3: Create index\nCREATE INDEX idx_workorder_source_name\nON tblcustworkorderdetail(source_name);\n\n-- Step 4: Create trigger (optional, for automatic sync)\nCREATE OR REPLACE FUNCTION sync_work_order_source_name()\nRETURNS TRIGGER AS $$\nBEGIN\n    SELECT s.ssource INTO NEW.source_name\n    FROM tblcustomers c\n    LEFT JOIN tblsource s ON c.source = s.ssource\n    WHERE c.custid = NEW.custid;\n\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_sync_work_order_source_name\n    BEFORE INSERT OR UPDATE OF custid ON tblcustworkorderdetail\n    FOR EACH ROW\n    EXECUTE FUNCTION sync_work_order_source_name();\n\n-- Step 5: Analyze table\nANALYZE tblcustworkorderdetail;\n\nCOMMIT;\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#2-apply-code-changes","title":"2. Apply Code Changes","text":"<pre><code># File: routes/work_orders.py\n\n# Remove conditional joins (lines 943-955)\nquery = query.options(joinedload(WorkOrder.customer))\n\n# Update Source filter (line 1006)\nif is_source_filter:\n    query = query.filter(WorkOrder.source_name.ilike(f\"%{is_source_filter}%\"))\n\n# Update Source sorting (lines 1032-1038)\nif field == \"Source\":\n    column_to_sort = WorkOrder.source_name\n    if direction == \"desc\":\n        order_by_clauses.append(column_to_sort.desc())\n    else:\n        order_by_clauses.append(column_to_sort.asc())\n\n# Update API response (line 1080)\n\"Source\": wo.source_name,\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#3-test","title":"3. Test","text":"<pre><code># Run migration\npsql \"postgresql://...\" -f query_optimization/add_source_name_column.sql\n\n# Run tests\npytest test/test_work_orders_routes.py -v\n\n# Test API endpoint\ncurl http://localhost:5000/api/work_orders?sort[0][field]=Source&amp;sort[0][dir]=asc\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#4-verify-performance","title":"4. Verify Performance","text":"<pre><code># Re-run performance analysis\npsql \"postgresql://...\" -f query_optimization/analyze_work_orders.sql\n</code></pre> <p>Expected result for Source sorting: - BEFORE: 93ms with Hash Join + 3 Seq Scans - AFTER: ~1ms with Index Scan on <code>idx_workorder_source_name</code></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#edge-cases-to-handle","title":"Edge Cases to Handle","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#1-work-order-with-no-customer","title":"1. Work Order with No Customer","text":"<pre><code>if wo.source_name:\n    source = wo.source_name\nelse:\n    source = None\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#2-customer-with-no-source","title":"2. Customer with No Source","text":"<pre><code>customer = Customer.query.get(custid)\nif customer and customer.Source:\n    work_order.source_name = customer.source_info.SSource\nelse:\n    work_order.source_name = None\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#3-customer-source-changes","title":"3. Customer Source Changes","text":"<ul> <li>If using trigger: Automatic update</li> <li>If application-level: Add to customer edit route <pre><code># In routes/customers.py after updating customer.Source\naffected_work_orders = WorkOrder.query.filter_by(CustID=customer.CustID).all()\nfor wo in affected_work_orders:\n    wo.sync_source_name()\n</code></pre></li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#4-source-name-changes","title":"4. Source Name Changes","text":"<ul> <li>Rare: Source names don't typically change</li> <li>If it happens: Run bulk update script <pre><code>UPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nJOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n</code></pre></li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#backward-compatibility","title":"Backward Compatibility","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#keep-old-relationships-working","title":"Keep Old Relationships Working","text":"<pre><code>class WorkOrder(db.Model):\n    # ... fields ...\n\n    # NEW: Denormalized column\n    source_name = db.Column(\"source_name\", db.Text, nullable=True)\n\n    # OLD: Relationships still work!\n    customer = db.relationship(\"Customer\", back_populates=\"work_orders\")\n    ship_to_source = db.relationship(\n        \"Source\",\n        primaryjoin=\"WorkOrder.ShipTo==Source.SSource\",\n        lazy=\"joined\",\n        uselist=False,\n    )\n\n    @property\n    def customer_source_name(self):\n        \"\"\"Get customer's source name (with fallback)\"\"\"\n        # Prefer denormalized value\n        if self.source_name:\n            return self.source_name\n        # Fallback to relationship (for backward compatibility)\n        if self.customer and self.customer.source_info:\n            return self.customer.source_info.SSource\n        return None\n</code></pre> <p>This means: - Old code using <code>wo.customer.source_info.SSource</code> still works - New code using <code>wo.source_name</code> is faster - Gradual migration is possible</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#testing-checklist","title":"Testing Checklist","text":"<ul> <li>[ ] Work order list loads with Source column</li> <li>[ ] Source column sorting works (asc/desc)</li> <li>[ ] Source filtering works</li> <li>[ ] Creating work order sets source_name correctly</li> <li>[ ] Editing work order updates source_name if customer changes</li> <li>[ ] Work orders without customers show None for source</li> <li>[ ] Customers without sources show None for work order source</li> <li>[ ] PDF generation still works (uses relationships)</li> <li>[ ] All existing tests pass</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#performance-impact-summary","title":"Performance Impact Summary","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#before-denormalization","title":"Before Denormalization","text":"Query Time Method Source sort 93ms Hash Join + 3 Seq Scans Source filter ~1ms Nested joins (but complex) Default list (no joins) 0.8ms Index scan"},{"location":"planning/DENORMALIZATION_ANALYSIS/#after-denormalization","title":"After Denormalization","text":"Query Time Method Source sort ~1ms \u26a1 Index Scan on source_name Source filter ~0.1ms \u26a1 Index Scan on source_name Default list 0.04ms \u26a1\u26a1 Index scan (no joins!) <p>Overall improvement: - Source sorting: 93x faster - Eliminates all 3-table joins - Simpler, more maintainable code</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#risks-mitigation","title":"Risks &amp; Mitigation","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#risk-1-data-drift","title":"Risk 1: Data Drift","text":"<p>Problem: source_name gets out of sync with customer.Source</p> <p>Mitigation: - Database trigger (automatic sync) - Periodic sync job (cron) - Validation in tests</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#risk-2-storage-overhead","title":"Risk 2: Storage Overhead","text":"<p>Problem: Denormalization uses more disk space</p> <p>Impact: - ~18 bytes per row average source name - 49,074 rows \u00d7 18 bytes = ~880 KB - Negligible for a 17 MB table</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#risk-3-breaking-existing-code","title":"Risk 3: Breaking Existing Code","text":"<p>Problem: Code expecting relationships breaks</p> <p>Mitigation: - Keep all relationships intact - Add <code>customer_source_name</code> property with fallback - Gradual migration</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#recommendation","title":"Recommendation","text":"<p>\u2705 PROCEED WITH DENORMALIZATION</p> <p>Rationale: 1. Minimal code changes (5 small edits) 2. 100x performance improvement for Source sorting 3. Maintains all existing relationships (backward compatible) 4. Easy to implement (1-2 hours) 5. Low risk (can roll back easily)</p> <p>Implementation order: 1. Test database: Apply migration + code changes 2. Test thoroughly: Run all tests, manual testing 3. Production database: Apply migration during low-traffic period 4. Monitor: Check logs, query performance 5. Optimize: Remove old conditional joins after confirming</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#next-steps","title":"Next Steps","text":"<ol> <li>Review this analysis</li> <li>Decide on trigger vs. application-level sync</li> <li>Create migration script</li> <li>Apply to test database</li> <li>Update code</li> <li>Test</li> <li>Deploy to production</li> </ol> <p>Would you like me to: - Create the migration script? - Update the model and routes? - Write tests for the new functionality?</p>"},{"location":"planning/IMPROVEMENTS/","title":"Analytics Dashboard Improvement Plan","text":"<p>This document outlines a roadmap for enhancing the analytics dashboard. The goal is to provide deeper insights into the business performance, moving beyond the current order-centric view.</p>"},{"location":"planning/IMPROVEMENTS/#eda-findings","title":"EDA Findings","text":"<p>Based on an analysis of the database, here are some key findings that should inform the analytics improvements:</p> <ul> <li>Revenue Calculation: The <code>quote</code> column in the <code>tblcustworkorderdetail</code> table is not a reliable source for revenue figures, as it often contains non-numeric values like \"Approved\". The <code>price</code> column in the <code>tblorddetcustawngs</code> table, which represents the price of individual order items, is a much more accurate source for revenue calculation. The existing \"Total Revenue\" KPI should be updated to sum the <code>price</code> of all items in completed work orders.</li> <li>Product Types: The <code>sizewgt</code> column in <code>tblorddetcustawngs</code> contains complex strings that describe the size and weight of order items. The existing logic to differentiate between \"awnings\" and \"sails\" (based on the presence of a \"#\" symbol) appears to be correct. This provides a good foundation for product-level analysis.</li> <li>Rush Orders: The <code>rushorder</code> and <code>firmrush</code> boolean columns in <code>tblcustworkorderdetail</code> are well-populated and can be used to analyze the frequency and impact of rush orders.</li> </ul>"},{"location":"planning/IMPROVEMENTS/#review-of-square-footage-parsing-code","title":"Review of Square Footage Parsing Code","text":"<p>The <code>clean_square_footage</code> and <code>clean_sail_weight</code> functions, along with their usage in <code>load_work_orders</code>, have been reviewed for accuracy and robustness.</p> <p>Findings:</p> <ul> <li><code>clean_square_footage</code>: This function is highly robust and accurate. It effectively handles a wide variety of complex input formats for awning sizes, including dimensions with feet and inches (e.g., <code>8'9\"x10'2\"</code>), simple <code>XxY</code> dimensions, and values with an <code>=</code> sign indicating a pre-calculated area. It also correctly strips currency and unit markers. Error handling for malformed strings is graceful, returning <code>0.0</code>.</li> <li><code>clean_sail_weight</code>: This function accurately parses sail weights in the format <code>95#</code>. It correctly extracts the numeric value and handles potential conversion errors.</li> <li><code>load_work_orders</code> Integration: The logic within <code>load_work_orders</code> to determine <code>product_type</code> (Awning vs. Sail based on <code>#</code> in <code>sizewgt</code>) and then apply the appropriate cleaning function (<code>clean_square_footage</code> or <code>clean_sail_weight</code>) is correct and efficient.</li> </ul> <p>Conclusion:</p> <p>The existing square footage parsing code is accurate, robust, and well-implemented for the identified data patterns. No major improvements are immediately necessary for its core functionality. The current implementation is well-suited for the task of calculating square footage from diverse input strings.</p>"},{"location":"planning/IMPROVEMENTS/#review-of-cleaning-throughput-calculation-code","title":"Review of Cleaning Throughput Calculation Code","text":"<p>The code responsible for calculating cleaning throughput, primarily within <code>load_work_orders</code> and <code>get_daily_throughput</code>, has been reviewed for correctness.</p> <p>Findings:</p> <ul> <li><code>load_work_orders</code>: This function accurately calculates the <code>sqft</code> for individual items by multiplying <code>qty_numeric</code> with the results from <code>clean_sail_weight</code> or <code>clean_square_footage</code> (which were previously reviewed and found to be robust). It then correctly aggregates these <code>sqft</code> values to derive <code>totalsize</code> for each work order.</li> <li><code>get_daily_throughput</code>: This function correctly filters for completed work orders using <code>datecompleted</code>. It then accurately groups these completed orders by their completion date and sums their <code>totalsize</code> to determine the <code>daily_sqft</code>. The rolling average calculation is also correctly implemented, providing a smoothed trend of throughput.</li> </ul> <p>Conclusion:</p> <p>The cleaning throughput calculation code is correct and accurate. It effectively processes raw data into meaningful daily and rolling average metrics. The recent change to remove the <code>.tail(90)</code> limit will ensure that the dashboard now displays the full historical data for daily cleaning throughput, providing a comprehensive view over time.</p>"},{"location":"planning/IMPROVEMENTS/#outlier-analysis-in-daily-throughput","title":"Outlier Analysis in Daily Throughput","text":"<p>An initial outlier detection using the IQR method on daily throughput data revealed several dates with extremely high square footage values. These outliers are highly suggestive of data entry errors rather than legitimate production spikes. For example, some single work orders are recorded with millions of square feet, which is physically improbable.</p> <p>Examples of extreme outliers: *   <code>2011-04-27</code>: 1.679114e+07 sq ft *   <code>2010-08-12</code>: 7.204018e+06 sq ft *   <code>2011-02-18</code>: 6.003085e+06 sq ft</p> <p>Recommendations for Outlier Handling: 1.  Data Validation: Investigate the raw <code>sizewgt</code> entries for the work orders contributing to these extreme outliers. This will help confirm if they are indeed data entry errors. 2.  Data Cleaning Strategy: Implement a strategy to handle such outliers. This could involve:     *   Correction: If possible, correct the erroneous entries in the source data.     *   Exclusion: Exclude extreme outliers from calculations, perhaps by setting a reasonable upper bound for <code>totalsize</code> per work order or per day.     *   Transformation: Apply data transformation techniques (e.g., winsorization) to cap extreme values. 3.  Robustness of Parsing: While <code>clean_square_footage</code> is robust, review if specific malformed patterns in <code>sizewgt</code> are consistently leading to these extreme values, and if so, enhance the parsing logic to better handle or flag them.</p>"},{"location":"planning/IMPROVEMENTS/#1-customer-centric-kpis","title":"1. Customer-Centric KPIs","text":"<p>The current dashboard focuses heavily on work orders. To better understand customer behavior and value, we should add the following KPIs:</p> <ul> <li>New vs. Returning Customers: Track the number of new customers acquired over time versus the number of returning customers. This will help measure customer loyalty and business growth.</li> <li>Customer Lifetime Value (CLV): Calculate the total revenue generated per customer. This will help identify high-value customers.</li> <li>Top Customers: A list of top customers by revenue or number of orders.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Modify the <code>load_work_orders</code> function to also return customer data.</li> <li>Create a new function <code>calculate_customer_kpis</code> to compute the new metrics.</li> <li>Add new KPI cards to the <code>dashboard.html</code> template.</li> <li>Add a new chart to visualize new vs. returning customers over time.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#2-productservice-analysis","title":"2. Product/Service Analysis","text":"<p>The current <code>sizewgt</code> column processing differentiates between \"awnings\" and \"sails\". We can leverage this to provide a more granular analysis of the business.</p> <ul> <li>Revenue by Product Type: Break down total revenue by \"awning\" and \"sail\".</li> <li>Throughput by Product Type: Analyze the square footage cleaned for each product type.</li> <li>Order Volume by Product Type: Show the number of orders for each product type.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Modify the <code>load_work_orders</code> function to categorize each order item as \"awning\" or \"sail\".</li> <li>Update the KPI calculation functions to aggregate by product type.</li> <li>Add new charts or update existing ones to show the product type breakdown. A stacked bar chart for monthly trends could work well.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#3-rush-order-analysis","title":"3. Rush Order Analysis","text":"<p>The <code>rushorder</code> and <code>firmrush</code> columns indicate the urgency of an order. We should analyze the impact of these orders.</p> <ul> <li>Rush Order Frequency: What percentage of orders are rush orders?</li> <li>Rush Order Revenue: Do rush orders generate more revenue on average?</li> <li>Impact on Lead Time: Do rush orders get completed faster?</li> </ul> <p>Implementation Steps:</p> <ol> <li>Incorporate the <code>rushorder</code> and <code>firmrush</code> columns into the <code>load_work_orders</code> function.</li> <li>Calculate KPIs related to rush orders.</li> <li>Add a section to the dashboard to display these insights.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#4-lead-time-analysis","title":"4. Lead Time Analysis","text":"<p>Understanding how long it takes to complete an order is a crucial operational metric.</p> <ul> <li>Average Lead Time: Calculate the average time between <code>datein</code> and <code>datecompleted</code>.</li> <li>Lead Time Distribution: Show a histogram of lead times to identify outliers.</li> <li>Lead Time by Product Type: Analyze if certain products take longer to complete.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Calculate the lead time for each completed order in the <code>load_work_orders</code> function.</li> <li>Create a new function to calculate lead time metrics.</li> <li>Add a new chart to the dashboard to visualize the lead time distribution.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#5-interactive-filtering","title":"5. Interactive Filtering","text":"<p>To make the dashboard more useful, we should add interactive filtering capabilities.</p> <ul> <li>Date Range Filter: Allow users to select a date range to view analytics for a specific period.</li> <li>Product Type Filter: Allow users to filter the data for \"awnings\" or \"sails\".</li> <li>Customer Filter: Allow users to search for a specific customer and see their history.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Add filter controls to the <code>dashboard.html</code> template.</li> <li>Modify the <code>/api/data</code> endpoint to accept filter parameters.</li> <li>Update the backend functions to apply the filters to the data.</li> </ol>"},{"location":"planning/REFACTORING_PLAN/","title":"Route Refactoring Plan","text":""},{"location":"planning/REFACTORING_PLAN/#priority-1-query-helpers-biggest-impact-low-risk","title":"Priority 1: Query Helpers (Biggest Impact, Low Risk)","text":"<p>Impact: Reduces ~300 lines across all route files Complexity: Low - Pure utility functions Files affected: <code>work_orders.py</code>, <code>repair_order.py</code>, <code>customers.py</code>, <code>queue.py</code></p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsquery_helperspy","title":"Create <code>utils/query_helpers.py</code>","text":"<pre><code>def apply_search_filter(query, model, search_term, searchable_fields):\n    \"\"\"\n    Apply OR-based search across multiple model fields.\n\n    Args:\n        query: SQLAlchemy query object\n        model: SQLAlchemy model class (WorkOrder, RepairWorkOrder, etc.)\n        search_term: Search string from request.args\n        searchable_fields: List of field names to search\n\n    Returns:\n        Modified query with search filters applied\n\n    Example:\n        query = apply_search_filter(\n            query,\n            WorkOrder,\n            \"ABC123\",\n            [\"WorkOrderNo\", \"CustID\", \"WOName\", \"ShipTo\"]\n        )\n    \"\"\"\n\ndef apply_column_filters(query, model, request_args, filter_config):\n    \"\"\"\n    Apply individual column filters from Tabulator.\n\n    Args:\n        filter_config: Dict mapping filter names to columns\n            {\n                \"filter_CustID\": {\"column\": Customer.CustID, \"type\": \"exact\"},\n                \"filter_Name\": {\"column\": Customer.Name, \"type\": \"like\"}\n            }\n    \"\"\"\n\ndef apply_tabulator_sorting(query, model, request_args, type_config=None):\n    \"\"\"\n    Parse and apply Tabulator multi-column sorting.\n\n    Args:\n        type_config: Dict of field types for casting\n            {\n                \"WorkOrderNo\": \"integer\",\n                \"DateIn\": \"date\",\n                \"CustID\": \"integer\"\n            }\n\n    Handles: sort[0][field], sort[0][dir], etc.\n    Auto-casts numeric/date fields with nulls_last()\n    \"\"\"\n\ndef optimize_relationship_loading(query, model, request_args, relationship_map):\n    \"\"\"\n    Conditionally eager-load relationships based on filters/sorts.\n\n    Args:\n        relationship_map: Dict of relationships to check for\n            {\n                \"Source\": {\n                    \"join_path\": [WorkOrder.customer, Customer.source_info],\n                    \"load_path\": [WorkOrder.customer, Customer.source_info]\n                }\n            }\n\n    Checks if Source is in filter_* or sort[*][field] params.\n    Only joins/loads if needed (avoids N+1 and unnecessary joins).\n    \"\"\"\n</code></pre>"},{"location":"planning/REFACTORING_PLAN/#refactor-examples","title":"Refactor Examples","text":"<p>Before (work_orders.py lines 909-1043): <pre><code># 135 lines of complex filtering and sorting\n</code></pre></p> <p>After: <pre><code>@work_orders_bp.route(\"/api/work_orders\")\n@login_required\ndef api_work_orders():\n    page = request.args.get(\"page\", 1, type=int)\n    size = request.args.get(\"size\", 25, type=int)\n    status = request.args.get(\"status\", \"\").lower()\n\n    query = WorkOrder.query\n\n    # Optimize relationship loading\n    query = optimize_relationship_loading(\n        query, WorkOrder, request.args,\n        {\"Source\": {\n            \"join_path\": [WorkOrder.customer, Customer.source_info],\n            \"load_path\": [WorkOrder.customer, Customer.source_info]\n        }}\n    )\n\n    # Apply filters\n    if status == \"pending\":\n        query = query.filter(WorkOrder.DateCompleted.is_(None))\n    elif status == \"completed\":\n        query = query.filter(WorkOrder.DateCompleted.isnot(None))\n    elif status == \"rush\":\n        query = query.filter(\n            or_(WorkOrder.RushOrder == True, WorkOrder.FirmRush == True),\n            WorkOrder.DateCompleted.is_(None)\n        )\n\n    # Column-specific filters\n    query = apply_column_filters(query, WorkOrder, request.args, {\n        \"filter_WorkOrderNo\": {\"column\": WorkOrder.WorkOrderNo, \"type\": \"range_or_exact\"},\n        \"filter_CustID\": {\"column\": WorkOrder.CustID, \"type\": \"exact\"},\n        \"filter_WOName\": {\"column\": WorkOrder.WOName, \"type\": \"like\"},\n        \"filter_DateIn\": {\"column\": WorkOrder.DateIn, \"type\": \"like\"},\n        \"filter_DateRequired\": {\"column\": WorkOrder.DateRequired, \"type\": \"like\"},\n        \"filter_Source\": {\"column\": Source.SSource, \"type\": \"like\"}\n    })\n\n    # Sorting\n    query = apply_tabulator_sorting(query, WorkOrder, request.args, {\n        \"WorkOrderNo\": \"integer\",\n        \"CustID\": \"integer\",\n        \"DateIn\": \"date\",\n        \"DateRequired\": \"date\",\n        \"Source\": Source.SSource\n    })\n\n    total = query.count()\n    items = query.paginate(page=page, per_page=size, error_out=False)\n\n    return build_tabulator_response(\n        items.items,\n        total,\n        page,\n        items.pages,\n        row_builder=build_work_order_row\n    )\n</code></pre></p> <p>Lines saved: ~100 lines per API route \u00d7 4 routes = 400 lines</p>"},{"location":"planning/REFACTORING_PLAN/#priority-2-date-helpers-high-impact-zero-risk","title":"Priority 2: Date Helpers (High Impact, Zero Risk)","text":"<p>Impact: Reduces ~150 lines, eliminates bugs Complexity: Trivial Files affected: All route files</p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsdate_helperspy","title":"Create <code>utils/date_helpers.py</code>","text":"<pre><code>def parse_form_date(form, field_name, required=False, default=None):\n    \"\"\"\n    Parse date from form with consistent error handling.\n\n    Returns: date object or None\n    Raises: ValueError if required and missing\n    \"\"\"\n    value = form.get(field_name)\n    if not value:\n        if required:\n            raise ValueError(f\"{field_name} is required\")\n        return default\n\n    try:\n        return datetime.strptime(value, \"%Y-%m-%d\").date()\n    except ValueError:\n        raise ValueError(f\"Invalid date format for {field_name}\")\n\ndef format_date_for_api(date_value):\n    \"\"\"Convert date/datetime to YYYY-MM-DD string for JSON.\"\"\"\n    if not date_value:\n        return None\n    if isinstance(date_value, str):\n        return date_value\n    return date_value.strftime(\"%Y-%m-%d\")\n</code></pre>"},{"location":"planning/REFACTORING_PLAN/#refactor-examples_1","title":"Refactor Examples","text":"<p>Before (work_orders.py lines 397-410): <pre><code>DateIn=datetime.strptime(request.form.get(\"DateIn\"), \"%Y-%m-%d\").date()\nif request.form.get(\"DateIn\")\nelse date.today(),\nDateRequired=datetime.strptime(\n    request.form.get(\"DateRequired\"), \"%Y-%m-%d\"\n).date()\nif request.form.get(\"DateRequired\")\nelse None,\nClean=datetime.strptime(request.form.get(\"Clean\"), \"%Y-%m-%d\").date()\nif request.form.get(\"Clean\")\nelse None,\n# ... repeated 5 more times\n</code></pre></p> <p>After: <pre><code>from utils.date_helpers import parse_form_date\n\nDateIn=parse_form_date(request.form, \"DateIn\", default=date.today()),\nDateRequired=parse_form_date(request.form, \"DateRequired\"),\nClean=parse_form_date(request.form, \"Clean\"),\nTreat=parse_form_date(request.form, \"Treat\"),\n</code></pre></p> <p>Lines saved: ~10 lines per route \u00d7 15 routes = 150 lines</p>"},{"location":"planning/REFACTORING_PLAN/#priority-3-api-response-builders-medium-impact-low-risk","title":"Priority 3: API Response Builders (Medium Impact, Low Risk)","text":"<p>Impact: Reduces ~100 lines, standardizes responses Complexity: Low Files affected: All API routes</p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsapi_helperspy","title":"Create <code>utils/api_helpers.py</code>","text":"<pre><code>def build_tabulator_response(items, total, page, pages, row_builder=None):\n    \"\"\"\n    Standard Tabulator pagination response.\n\n    Args:\n        row_builder: Function to convert model instance to dict\n    \"\"\"\n    if row_builder:\n        data = [row_builder(item) for item in items]\n    else:\n        data = [item.__dict__ for item in items]\n\n    return jsonify({\n        \"data\": data,\n        \"total\": total,\n        \"page\": page,\n        \"last_page\": pages\n    })\n\ndef build_work_order_row(work_order, include_source=True):\n    \"\"\"Convert WorkOrder model to API dict.\"\"\"\n    row = {\n        \"WorkOrderNo\": work_order.WorkOrderNo,\n        \"CustID\": work_order.CustID,\n        \"WOName\": work_order.WOName,\n        \"DateIn\": format_date_for_api(work_order.DateIn),\n        \"DateRequired\": format_date_for_api(work_order.DateRequired),\n        \"detail_url\": url_for(\"work_orders.view_work_order\", work_order_no=work_order.WorkOrderNo),\n        \"edit_url\": url_for(\"work_orders.edit_work_order\", work_order_no=work_order.WorkOrderNo),\n        \"delete_url\": url_for(\"work_orders.delete_work_order\", work_order_no=work_order.WorkOrderNo),\n    }\n\n    if include_source and work_order.customer and work_order.customer.source_info:\n        row[\"Source\"] = work_order.customer.source_info.SSource\n\n    if work_order.customer:\n        row[\"customer_url\"] = url_for(\"customers.customer_detail\", customer_id=work_order.CustID)\n\n    return row\n</code></pre>"},{"location":"planning/REFACTORING_PLAN/#priority-4-form-data-extraction-high-impact-medium-risk","title":"Priority 4: Form Data Extraction (High Impact, Medium Risk)","text":"<p>Impact: Reduces ~200 lines, makes validation easier Complexity: Medium - requires careful testing Files affected: <code>work_orders.py</code>, <code>repair_order.py</code></p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsform_helperspy","title":"Create <code>utils/form_helpers.py</code>","text":"<pre><code>def extract_work_order_fields(form):\n    \"\"\"\n    Extract all work order fields from form into dict.\n\n    Returns: Dict ready to pass to WorkOrder(**data)\n    Raises: ValueError for validation errors\n    \"\"\"\n    from utils.date_helpers import parse_form_date\n\n    if not form.get(\"CustID\"):\n        raise ValueError(\"Customer is required\")\n    if not form.get(\"WOName\"):\n        raise ValueError(\"Name is required\")\n\n    return {\n        \"CustID\": form.get(\"CustID\"),\n        \"WOName\": form.get(\"WOName\"),\n        \"StorageTime\": form.get(\"StorageTime\"),\n        \"RackNo\": form.get(\"RackNo\"),\n        \"SpecialInstructions\": form.get(\"SpecialInstructions\"),\n        \"RepairsNeeded\": \"RepairsNeeded\" in form,\n        \"SeeRepair\": form.get(\"SeeRepair\"),\n        \"Quote\": form.get(\"Quote\"),\n        \"RushOrder\": \"RushOrder\" in form,\n        \"FirmRush\": \"FirmRush\" in form,\n        \"DateIn\": parse_form_date(form, \"DateIn\", default=date.today()),\n        \"DateRequired\": parse_form_date(form, \"DateRequired\"),\n        \"Clean\": parse_form_date(form, \"Clean\"),\n        \"Treat\": parse_form_date(form, \"Treat\"),\n        \"ReturnStatus\": form.get(\"ReturnStatus\"),\n        \"ShipTo\": form.get(\"ShipTo\"),\n    }\n</code></pre> <p>Before (work_orders.py lines 383-414): 31 lines After: 2 lines <pre><code>wo_data = extract_work_order_fields(request.form)\nwork_order = WorkOrder(WorkOrderNo=next_wo_no, **wo_data)\n</code></pre></p>"},{"location":"planning/REFACTORING_PLAN/#priority-5-order-item-processing-highest-complexity-high-impact","title":"Priority 5: Order Item Processing (Highest Complexity, High Impact)","text":"<p>Impact: Reduces ~400 lines, biggest code smell Complexity: High - complex business logic Files affected: <code>work_orders.py</code>, <code>repair_order.py</code></p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsorder_item_helperspy","title":"Create <code>utils/order_item_helpers.py</code>","text":"<pre><code>def process_selected_inventory_items(form, order_no, cust_id, item_class):\n    \"\"\"\n    Process items selected from customer inventory.\n\n    Args:\n        item_class: WorkOrderItem or RepairWorkOrderItem\n\n    Returns: List of item instances (not yet added to session)\n    \"\"\"\n    items = []\n    selected_ids = form.getlist(\"selected_items[]\")\n\n    for inv_key in selected_ids:\n        inventory_item = Inventory.query.get(inv_key)\n        if not inventory_item:\n            continue\n\n        qty_key = f\"item_qty_{inv_key}\"\n        qty = safe_int_conversion(form.get(qty_key, 1))\n\n        item = item_class(\n            WorkOrderNo=order_no,\n            CustID=cust_id,\n            Description=inventory_item.Description,\n            Material=inventory_item.Material,\n            Qty=str(qty),\n            Condition=inventory_item.Condition,\n            Color=inventory_item.Color,\n            SizeWgt=inventory_item.SizeWgt,\n            Price=inventory_item.Price,\n        )\n        items.append(item)\n\n    return items\n\ndef process_new_items(form, order_no, cust_id, item_class, update_catalog=True):\n    \"\"\"\n    Process manually added new items.\n\n    Returns: (items, catalog_updates)\n        items: List of item instances\n        catalog_updates: List of inventory updates if update_catalog=True\n    \"\"\"\n    items = []\n    catalog_updates = []\n\n    descriptions = form.getlist(\"new_item_description[]\")\n    materials = form.getlist(\"new_item_material[]\")\n    quantities = form.getlist(\"new_item_qty[]\")\n    # ... etc\n\n    for i, description in enumerate(descriptions):\n        if not description:\n            continue\n\n        # Create order item\n        item = item_class(...)\n        items.append(item)\n\n        # Catalog update logic\n        if update_catalog:\n            catalog_update = add_or_update_catalog(cust_id, item_data)\n            if catalog_update:\n                catalog_updates.append(catalog_update)\n\n    return items, catalog_updates\n</code></pre> <p>Before (work_orders.py create_work_order): 225 lines After: ~60 lines</p>"},{"location":"planning/REFACTORING_PLAN/#implementation-order","title":"Implementation Order","text":""},{"location":"planning/REFACTORING_PLAN/#week-1-foundation-low-risk","title":"Week 1: Foundation (Low Risk)","text":"<ol> <li>\u2705 Create <code>utils/date_helpers.py</code></li> <li>\u2705 Refactor all date parsing (test thoroughly)</li> <li>\u2705 Create <code>utils/query_helpers.py</code></li> <li>\u2705 Refactor one API route as proof of concept</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#week-2-api-layer-medium-risk","title":"Week 2: API Layer (Medium Risk)","text":"<ol> <li>\u2705 Create <code>utils/api_helpers.py</code></li> <li>\u2705 Refactor all API routes</li> <li>\u2705 Test Tabulator functionality</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#week-3-forms-higher-risk","title":"Week 3: Forms (Higher Risk)","text":"<ol> <li>\u2705 Create <code>utils/form_helpers.py</code></li> <li>\u2705 Refactor work_orders create/edit</li> <li>\u2705 Refactor repair_orders create/edit</li> <li>\u2705 Extensive testing</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#week-4-items-highest-risk","title":"Week 4: Items (Highest Risk)","text":"<ol> <li>\u2705 Create <code>utils/order_item_helpers.py</code></li> <li>\u2705 Refactor item processing</li> <li>\u2705 Test inventory catalog updates</li> <li>\u2705 Regression testing</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#testing-strategy","title":"Testing Strategy","text":""},{"location":"planning/REFACTORING_PLAN/#unit-tests-new","title":"Unit Tests (New)","text":"<ul> <li>Test each helper function in isolation</li> <li>Mock database calls</li> <li>Test edge cases (None, empty, invalid dates)</li> </ul>"},{"location":"planning/REFACTORING_PLAN/#integration-tests-existing","title":"Integration Tests (Existing)","text":"<ul> <li>Run full test suite after each refactor</li> <li>Pay special attention to:</li> <li>Date parsing edge cases</li> <li>Inventory quantity tracking</li> <li>API response formats</li> </ul>"},{"location":"planning/REFACTORING_PLAN/#manual-testing-checklist","title":"Manual Testing Checklist","text":"<ul> <li>[ ] Create work order with selected items</li> <li>[ ] Create work order with new items</li> <li>[ ] Edit work order and remove items</li> <li>[ ] API filtering works (all columns)</li> <li>[ ] API sorting works (all columns)</li> <li>[ ] Date fields handle None correctly</li> <li>[ ] Rush orders filter correctly</li> <li>[ ] Pagination works on all views</li> </ul>"},{"location":"planning/REFACTORING_PLAN/#metrics","title":"Metrics","text":"Metric Before After Change Total route LOC 3,685 2,150 -42% Longest function 225 lines 60 lines -73% Code duplication High Low \u2705 Test coverage 60% 85% +25% Helper functions 5 25 +400%"},{"location":"planning/REFACTORING_PLAN/#risk-mitigation","title":"Risk Mitigation","text":""},{"location":"planning/REFACTORING_PLAN/#high-risk-areas","title":"High-Risk Areas","text":"<ol> <li>Inventory catalog updates - Complex business logic, easy to break</li> <li>Solution: Unit test helpers thoroughly</li> <li> <p>Solution: Compare before/after catalog state in tests</p> </li> <li> <p>Date parsing - Used everywhere, silent failures possible</p> </li> <li>Solution: Explicit error handling in helpers</li> <li> <p>Solution: Return None vs raise exception (document clearly)</p> </li> <li> <p>Query optimization - Could break N+1 or add unnecessary joins</p> </li> <li>Solution: Log SQL queries in dev</li> <li>Solution: Benchmark before/after</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#rollback-plan","title":"Rollback Plan","text":"<ul> <li>Keep old code commented out for 1 sprint</li> <li>Feature flag for new helpers (if needed)</li> <li>Git tags for each refactor phase</li> </ul>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/","title":"Optimizing Thumbnail Generation with WebAssembly (WASM)","text":"<p>This guide details how to refactor the file upload process to generate thumbnails on the client-side using WebAssembly, significantly reducing server load and improving user experience.</p> <p>The current workflow executes all thumbnail generation (a CPU-intensive task) on the server. The new workflow offloads this to the user's browser.</p>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#step-1-update-backend-to-receive-pre-processed-thumbnails","title":"Step 1: Update Backend to Receive Pre-Processed Thumbnails","text":"<p>First, we'll simplify the backend. It will no longer generate thumbnails; it will only receive and save the original file and the thumbnail file created by the client.</p>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#11-simplify-utilsfile_uploadpy","title":"1.1. Simplify <code>utils/file_upload.py</code>","text":"<p>The <code>save_work_order_file</code> function will be simplified to just save two files. The complex <code>generate_thumbnail</code> logic is no longer needed here.</p> <p>Replace the contents of <code>utils/file_upload.py</code> with the following. We are keeping the S3 logic but removing all thumbnail generation calls.</p> <pre><code>import os\nfrom werkzeug.utils import secure_filename\nfrom models.work_order_file import WorkOrderFile\nfrom extensions import db\nimport boto3\nfrom io import BytesIO\nfrom datetime import datetime\n\n# --- S3 Configuration ---\nUPLOAD_FOLDER = \"uploads/work_orders\"  # local fallback\nALLOWED_EXTENSIONS = {\"pdf\", \"jpg\", \"jpeg\", \"png\", \"docx\", \"xlsx\", \"txt\", \"csv\"}\n\nAWS_S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\")\nAWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n\nif not AWS_S3_BUCKET:\n    raise ValueError(\"AWS_S3_BUCKET environment variable is required\")\n\ndef is_running_on_aws():\n    return any([\n        os.getenv(\"AWS_EXECUTION_ENV\"),\n        os.getenv(\"AWS_LAMBDA_FUNCTION_NAME\"),\n        os.getenv(\"AWS_REGION\"),\n    ])\n\nis_aws_environment = is_running_on_aws()\n\nif is_aws_environment:\n    print(\"Detected AWS environment - using IAM role for S3 access\")\n    s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\nelse:\n    print(\"Detected local environment - using explicit AWS credentials\")\n    AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n        raise ValueError(\"Local dev requires AWS credentials\")\n    s3_client = boto3.client(\n        \"s3\",\n        aws_access_key_id=AWS_ACCESS_KEY_ID,\n        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n        region_name=AWS_REGION,\n    )\n\ndef save_uploaded_files(work_order_no, original_file, thumbnail_file, to_s3=True):\n    \"\"\"\n    Saves an original file and its pre-generated thumbnail.\n    This function no longer generates thumbnails.\n    \"\"\"\n    original_filename = secure_filename(original_file.filename)\n    thumbnail_filename = secure_filename(thumbnail_file.filename)\n\n    if to_s3:\n        # Save Original File\n        original_s3_key = f\"work_orders/{work_order_no}/{original_filename}\"\n        s3_client.upload_fileobj(original_file, AWS_S3_BUCKET, original_s3_key)\n        file_path = f\"s3://{AWS_S3_BUCKET}/{original_s3_key}\"\n\n        # Save Thumbnail File\n        thumbnail_s3_key = f\"work_orders/{work_order_no}/{thumbnail_filename}\"\n        s3_client.upload_fileobj(thumbnail_file, AWS_S3_BUCKET, thumbnail_s3_key)\n        thumbnail_path = f\"s3://{AWS_S3_BUCKET}/{thumbnail_s3_key}\"\n    else:\n        # Save locally (fallback)\n        wo_folder = os.path.join(UPLOAD_FOLDER, str(work_order_no))\n        os.makedirs(wo_folder, exist_ok=True)\n\n        file_path = os.path.join(wo_folder, original_filename)\n        original_file.save(file_path)\n\n        thumbnail_path = os.path.join(wo_folder, thumbnail_filename)\n        thumbnail_file.save(thumbnail_path)\n\n    # Create WorkOrderFile object to be committed later\n    wo_file = WorkOrderFile(\n        WorkOrderNo=work_order_no,\n        filename=original_filename,\n        file_path=file_path,\n        thumbnail_path=thumbnail_path,\n    )\n    return wo_file\n\n# Other utility functions like generate_presigned_url can remain unchanged.\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#12-update-routeswork_orderspy","title":"1.2. Update <code>routes/work_orders.py</code>","text":"<p>Modify the <code>create_work_order</code> route (and any other upload routes) to handle the two incoming files (<code>original</code> and <code>thumbnail</code>).</p> <pre><code># Inside routes/work_orders.py\n\n# IMPORTANT: Change the import from `save_work_order_file` to `save_uploaded_files`\nfrom utils.file_upload import save_uploaded_files\n\n# ... inside the create_work_order function, find the file handling block ...\n\n# --- This block replaces the old file handling logic ---\nif 'original_files[]' in request.files:\n    original_files = request.files.getlist('original_files[]')\n    thumbnail_files = request.files.getlist('thumbnail_files[]')\n\n    if len(original_files) != len(thumbnail_files):\n        raise Exception(\"Mismatch between original files and thumbnails.\")\n\n    for i, original_file in enumerate(original_files):\n        if original_file and original_file.filename:\n            thumbnail_file = thumbnail_files[i]\n\n            wo_file = save_uploaded_files(\n                work_order_no=next_wo_no,\n                original_file=original_file,\n                thumbnail_file=thumbnail_file,\n                to_s3=True \n            )\n\n            if not wo_file:\n                raise Exception(f\"Failed to save file: {original_file.filename}\")\n\n            db.session.add(wo_file)\n            print(f\"Saved {wo_file.filename} and its thumbnail {thumbnail_file.filename}\")\n# --- End of replacement block ---\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#step-2-implement-client-side-thumbnail-generation","title":"Step 2: Implement Client-Side Thumbnail Generation","text":"<p>This involves adding JavaScript to your frontend templates. We will use <code>pdf.js</code> for PDFs and <code>libsquoosh</code> for images, as they are robust, well-supported libraries that use WebAssembly.</p>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#21-update-your-html-template","title":"2.1. Update Your HTML Template","text":"<p>In your <code>work_orders/create.html</code> and <code>work_orders/edit.html</code> (or any template with a file upload), add a file input and a preview area.</p> <pre><code>&lt;!-- Add a unique ID to your file input --&gt;\n&lt;input type=\"file\" id=\"file-uploader\" name=\"files[]\" multiple&gt;\n\n&lt;!-- Add a container to display thumbnail previews --&gt;\n&lt;div id=\"thumbnail-preview-area\" style=\"display:flex; flex-wrap:wrap; gap:10px; margin-top:15px;\"&gt;&lt;/div&gt;\n\n&lt;!-- Include pdf.js and libsquosh from a CDN --&gt;\n&lt;!-- Place these in your base.html or at the bottom of the page --&gt;\n&lt;script src=\"https://unpkg.com/pdfjs-dist@3.4.120/build/pdf.min.js\"&gt;&lt;/script&gt;\n&lt;script&gt;\n    // Required for pdf.js\n    pdfjsLib.GlobalWorkerOptions.workerSrc = `https://unpkg.com/pdfjs-dist@3.4.120/build/pdf.worker.min.js`;\n&lt;/script&gt;\n&lt;script type=\"module\" src=\"https://unpkg.com/@jsquash/jpeg@1.3.0/meta.js\"&gt;&lt;/script&gt;\n&lt;script type=\"module\" src=\"https://unpkg.com/@jsquash/resize@1.2.1/meta.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#22-add-the-client-side-processing-javascript","title":"2.2. Add the Client-Side Processing JavaScript","text":"<p>Add this script to your page. It will listen for file selections, process them, and prepare them for upload.</p> <pre><code>document.addEventListener('DOMContentLoaded', () =&gt; {\n    const fileUploader = document.getElementById('file-uploader');\n    const previewArea = document.getElementById('thumbnail-preview-area');\n\n    // This will store our processed files, ready for upload\n    const processedFiles = {\n        originals: [],\n        thumbnails: []\n    };\n\n    fileUploader.addEventListener('change', async (event) =&gt; {\n        const files = event.target.files;\n        if (!files.length) return;\n\n        // Clear previous previews and stored files\n        previewArea.innerHTML = '';\n        processedFiles.originals = [];\n        processedFiles.thumbnails = [];\n\n        for (const file of files) {\n            let thumbnailBlob;\n            const originalFileName = file.name;\n\n            // Show a placeholder\n            const placeholder = document.createElement('div');\n            placeholder.textContent = `Processing ${originalFileName}...`;\n            previewArea.appendChild(placeholder);\n\n            try {\n                if (file.type.startsWith('image/')) {\n                    thumbnailBlob = await processImage(file);\n                } else if (file.type === 'application/pdf') {\n                    thumbnailBlob = await processPdf(file);\n                } else {\n                    // For other files, you might create a default icon or skip a thumbnail\n                    console.log(`Skipping thumbnail for ${originalFileName}`);\n                    placeholder.textContent = `No preview for ${originalFileName}`;\n                    continue; // Or create a default thumbnail\n                }\n\n                const thumbnailFile = new File([thumbnailBlob], `thumb_${originalFileName.split('.')[0]}.jpeg`, { type: 'image/jpeg' });\n\n                // Store the files\n                processedFiles.originals.push(file);\n                processedFiles.thumbnails.push(thumbnailFile);\n\n                // Create and display the thumbnail preview\n                const reader = new FileReader();\n                reader.onload = (e) =&gt; {\n                    const img = document.createElement('img');\n                    img.src = e.target.result;\n                    img.style.width = '150px';\n                    img.style.height = '150px';\n                    img.style.objectFit = 'cover';\n                    img.title = `Thumbnail for ${originalFileName}`;\n                    placeholder.replaceWith(img); // Replace placeholder with the actual thumbnail\n                };\n                reader.readAsDataURL(thumbnailBlob);\n\n            } catch (error) {\n                console.error(`Failed to process ${originalFileName}:`, error);\n                placeholder.textContent = `Error processing ${originalFileName}`;\n            }\n        }\n    });\n\n    // --- Image Processing Function (uses libsquosh) ---\n    async function processImage(file) {\n        const imageBuffer = await file.arrayBuffer();\n\n        // Resize the image\n        const resizeOptions = {\n            width: 200,\n            height: 200,\n            method: 'lanczos3',\n        };\n        const resizedImage = await resize(imageBuffer, resizeOptions);\n\n        // Encode the resized image to JPEG\n        const jpegBlob = await encode(resizedImage, { quality: 85 });\n        return jpegBlob;\n    }\n\n    // --- PDF Processing Function (uses pdf.js) ---\n    async function processPdf(file) {\n        const fileBuffer = await file.arrayBuffer();\n        const pdf = await pdfjsLib.getDocument({ data: fileBuffer }).promise;\n        const page = await pdf.getPage(1); // Get the first page\n\n        const viewport = page.getViewport({ scale: 1 });\n        const canvas = document.createElement('canvas');\n        const context = canvas.getContext('2d');\n\n        // Set canvas dimensions to match PDF page aspect ratio\n        const scale = 200 / viewport.height;\n        const scaledViewport = page.getViewport({ scale });\n        canvas.height = scaledViewport.height;\n        canvas.width = scaledViewport.width;\n\n        // Render PDF page to canvas\n        await page.render({ canvasContext: context, viewport: scaledViewport }).promise;\n\n        // Convert canvas to JPEG blob\n        return new Promise(resolve =&gt; {\n            canvas.toBlob(resolve, 'image/jpeg', 0.85);\n        });\n    }\n\n    // --- Modify Form Submission ---\n    // You need to intercept the form submission to append the processed files.\n    const form = fileUploader.closest('form');\n    form.addEventListener('submit', function(event) {\n        event.preventDefault(); // Stop the default submission\n\n        const formData = new FormData(form);\n\n        // Remove the original placeholder file list\n        formData.delete('files[]');\n\n        // Append the processed files\n        processedFiles.originals.forEach(file =&gt; {\n            formData.append('original_files[]', file);\n        });\n        processedFiles.thumbnails.forEach(file =&gt; {\n            formData.append('thumbnail_files[]', file);\n        });\n\n        // Submit the form with the new FormData\n        fetch(form.action, {\n            method: 'POST',\n            body: formData,\n            // headers: { 'X-CSRF-TOKEN': 'your_csrf_token' } // If you use CSRF tokens\n        })\n        .then(response =&gt; {\n            if (response.ok) {\n                // Redirect on success, e.g., to the work order detail page\n                window.location.href = response.url; \n            } else {\n                // Handle errors\n                console.error('Upload failed');\n                alert('Upload failed!');\n            }\n        })\n        .catch(error =&gt; {\n            console.error('Error submitting form:', error);\n            alert('An error occurred.');\n        });\n    });\n});\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#step-3-clean-up-old-code","title":"Step 3: Clean Up Old Code","text":"<p>Once the new implementation is verified and working, you can safely remove the old server-side generation code.</p> <ol> <li>Delete <code>utils/thumbnail_generator.py</code>: This file is no longer needed.</li> <li>Clean up <code>utils/file_upload.py</code>: Ensure the old <code>save_work_order_file</code> and any related helper functions for generation are removed, as shown in Step 1.1.</li> <li>Remove old libraries: If <code>Pillow</code>, <code>PyMuPDF</code>, <code>python-docx</code>, etc., were only used for thumbnailing, you can remove them from your <code>requirements.txt</code> to slim down your application dependencies.</li> </ol> <p>This refactoring moves the performance-critical task of thumbnail generation to the client, resulting in a faster, more scalable, and more responsive application.</p>"},{"location":"reference/faq/","title":"Frequently Asked Questions","text":""},{"location":"reference/faq/#general","title":"General","text":""},{"location":"reference/faq/#how-do-i-reset-my-password","title":"How do I reset my password?","text":"<p>Contact your system administrator to reset your password.</p>"},{"location":"reference/faq/#can-i-use-the-app-on-mobile","title":"Can I use the app on mobile?","text":"<p>The application is responsive and works on mobile devices, though some features work best on desktop.</p>"},{"location":"reference/faq/#work-orders","title":"Work Orders","text":""},{"location":"reference/faq/#how-do-i-add-multiple-items-to-a-work-order","title":"How do I add multiple items to a work order?","text":"<p>On the work order edit page, use the \"Add Item\" button to add additional awnings or sails.</p>"},{"location":"reference/faq/#can-i-edit-a-completed-work-order","title":"Can I edit a completed work order?","text":"<p>Yes, but be cautious. Editing completed work orders may affect historical data and analytics.</p>"},{"location":"reference/faq/#technical","title":"Technical","text":""},{"location":"reference/faq/#what-browsers-are-supported","title":"What browsers are supported?","text":"<p>Modern versions of Chrome, Firefox, Safari, and Edge are supported.</p>"},{"location":"reference/faq/#where-is-my-data-stored","title":"Where is my data stored?","text":"<p>Data is stored in a PostgreSQL database hosted on AWS RDS.</p>"},{"location":"reference/faq/#more-help","title":"More Help","text":"<p>Check the Troubleshooting Guide or contact support.</p>"},{"location":"reference/glossary/","title":"Glossary","text":""},{"location":"reference/glossary/#terms","title":"Terms","text":"<p>Awning : A fabric covering used for shade or weather protection.</p> <p>Cleaning Queue : The queue of work orders awaiting cleaning.</p> <p>Customer : A client who owns awnings or sails that need cleaning or repair.</p> <p>Final Location : Where an item is stored after service is complete.</p> <p>Rack Number : The physical storage location identifier (e.g., \"5B\", \"Hang 4\").</p> <p>Repair Order : A job to repair damaged awnings or sails.</p> <p>Sail : A large fabric structure, typically for boats.</p> <p>Source : The sail loft or vendor associated with a customer.</p> <p>Storage Time : Whether storage is Seasonal or Temporary.</p> <p>Work Order : A job to clean awnings or sails.</p>"},{"location":"reference/glossary/#abbreviations","title":"Abbreviations","text":"<p>RO: Repair Order</p> <p>WO: Work Order</p> <p>SQL: Structured Query Language</p> <p>ORM: Object-Relational Mapping</p> <p>PDF: Portable Document Format</p>"},{"location":"reference/troubleshooting/","title":"Troubleshooting","text":"<p>Common issues and solutions.</p>"},{"location":"reference/troubleshooting/#login-issues","title":"Login Issues","text":""},{"location":"reference/troubleshooting/#invalid-username-or-password","title":"\"Invalid username or password\"","text":"<ul> <li>Verify your credentials are correct</li> <li>Check Caps Lock is off</li> <li>Contact admin if you've forgotten your password</li> </ul>"},{"location":"reference/troubleshooting/#work-order-issues","title":"Work Order Issues","text":""},{"location":"reference/troubleshooting/#cannot-save-work-order","title":"\"Cannot save work order\"","text":"<ul> <li>Check all required fields are filled</li> <li>Verify customer exists</li> <li>Check database connection</li> </ul>"},{"location":"reference/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting/#page-loads-slowly","title":"Page loads slowly","text":"<ul> <li>Clear browser cache</li> <li>Check internet connection</li> <li>Contact admin if issue persists</li> </ul>"},{"location":"reference/troubleshooting/#pdf-generation-issues","title":"PDF Generation Issues","text":""},{"location":"reference/troubleshooting/#pdf-doesnt-generate","title":"PDF doesn't generate","text":"<ul> <li>Verify work order has all required data</li> <li>Check browser allows downloads</li> <li>Try a different browser</li> </ul>"},{"location":"reference/troubleshooting/#need-more-help","title":"Need More Help?","text":"<p>Contact your system administrator or check the developer documentation.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the Awning Management System User Guide! This section contains everything you need to know to use the application effectively.</p>"},{"location":"user-guide/#getting-started","title":"Getting Started","text":"<p>If you're new to the system, start here:</p> <ul> <li>Getting Started - Login, navigation, and basic concepts</li> <li>Keyboard Shortcuts - Speed up your workflow</li> </ul>"},{"location":"user-guide/#core-features","title":"Core Features","text":"<p>Learn about the main features of the application:</p> <ul> <li>Work Orders - Creating and managing cleaning work orders</li> <li>Repair Orders - Handling repair jobs</li> <li>Customers - Managing customer information</li> <li>Sources &amp; Vendors - Working with sail lofts and vendors</li> <li>Inventory - Tracking inventory items</li> </ul>"},{"location":"user-guide/#workflows","title":"Workflows","text":"<p>Specialized workflows for daily operations:</p> <ul> <li>Queue Management - Managing the cleaning and repair queues</li> <li>Analytics Dashboard - Understanding business metrics</li> <li>PDF Reports - Generating and using PDF reports</li> </ul>"},{"location":"user-guide/#need-help","title":"Need Help?","text":"<ul> <li>Check the FAQ for common questions</li> <li>See Troubleshooting for common issues</li> </ul>"},{"location":"user-guide/getting-started/","title":"Getting Started","text":""},{"location":"user-guide/getting-started/#logging-in","title":"Logging In","text":"<ol> <li>Navigate to the application URL</li> <li>Enter your username and password</li> <li>Click \"Log In\"</li> </ol> <p>If you don't have credentials, contact your administrator.</p>"},{"location":"user-guide/getting-started/#dashboard-overview","title":"Dashboard Overview","text":"<p>After logging in, you'll see the main dashboard with:</p> <ul> <li>Quick Stats - Key metrics at a glance</li> <li>Recent Activity - Latest work orders and updates</li> <li>Navigation Menu - Access to all features</li> </ul>"},{"location":"user-guide/getting-started/#basic-navigation","title":"Basic Navigation","text":"<p>Use the top navigation bar to access:</p> <ul> <li>Dashboard - Main overview</li> <li>Work Orders - Cleaning work orders</li> <li>Repair Orders - Repair jobs</li> <li>Customers - Customer database</li> <li>Sources - Vendor management</li> <li>Queue - Work queue</li> <li>Analytics - Reports and insights</li> </ul>"},{"location":"user-guide/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Work Orders</li> <li>Set up Keyboard Shortcuts</li> <li>Explore the Analytics Dashboard</li> </ul> <p>Pro Tip</p> <p>Use keyboard shortcuts to speed up data entry. Press <code>?</code> to see available shortcuts.</p>"},{"location":"user-guide/work-orders/","title":"Work Orders","text":"<p>Work orders track cleaning jobs from intake to completion.</p>"},{"location":"user-guide/work-orders/#creating-a-work-order","title":"Creating a Work Order","text":"<ol> <li>Click \"New Work Order\" in the navigation menu</li> <li>Select or create a customer</li> <li>Fill in work order details</li> <li>Add items to be cleaned</li> <li>Click \"Save\"</li> </ol>"},{"location":"user-guide/work-orders/#work-order-fields","title":"Work Order Fields","text":"<ul> <li>Customer - The customer for this order</li> <li>Date In - When the items were received</li> <li>Source - The sail loft or vendor</li> <li>Storage Location - Where items are stored</li> <li>Storage Time - Seasonal or Temporary</li> <li>Items - Individual awnings or sails to clean</li> </ul>"},{"location":"user-guide/work-orders/#editing-a-work-order","title":"Editing a Work Order","text":"<ol> <li>Navigate to the work order detail page</li> <li>Click \"Edit\"</li> <li>Update fields as needed</li> <li>Click \"Save Changes\"</li> </ol>"},{"location":"user-guide/work-orders/#completing-a-work-order","title":"Completing a Work Order","text":"<ol> <li>Open the work order</li> <li>Set the \"Date Completed\" field</li> <li>Add final location if needed</li> <li>Click \"Mark Complete\"</li> </ol>"},{"location":"user-guide/work-orders/#generating-pdfs","title":"Generating PDFs","text":"<p>Click the \"Generate PDF\" button on any work order to create a printable report.</p> <p>Important</p> <p>Always verify customer information before completing an order.</p>"}]}