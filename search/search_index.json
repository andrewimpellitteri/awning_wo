{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Awning Management System Documentation","text":"<p>Welcome to the documentation for the Awning Management System - a comprehensive Flask-based application for managing work orders, repair orders, customers, inventory, and analytics for an awning cleaning and repair business.</p>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p> User Guide</p> <p>Learn how to use the application's features for day-to-day operations.</p> <p> Get Started</p> </li> <li> <p> Developer Guide</p> <p>Set up your development environment and learn the codebase architecture.</p> <p> Setup</p> </li> <li> <p> Database</p> <p>Learn about database migrations, schema changes, and data management.</p> <p> Alembic Guide</p> </li> <li> <p> Deployment</p> <p>Deploy to AWS Elastic Beanstalk and manage production environments.</p> <p> Deployment Guide</p> </li> </ul>"},{"location":"#what-is-the-awning-management-system","title":"What is the Awning Management System?","text":"<p>The Awning Management System is a full-featured web application built with Flask that helps manage:</p> <ul> <li>Work Orders - Track cleaning jobs from intake to completion</li> <li>Repair Orders - Manage repair jobs with detailed item tracking</li> <li>Customers - Maintain customer records and order history</li> <li>Sources &amp; Vendors - Track sail lofts and vendor relationships</li> <li>Inventory - Monitor inventory items and usage</li> <li>Queue Management - Organize cleaning and repair queues</li> <li>Analytics - Visualize business metrics and trends with interactive dashboards</li> <li>ML Predictions - Predict work order completion times using machine learning</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#for-users","title":"For Users","text":"<ul> <li>Intuitive Interface - Clean, easy-to-navigate UI for daily operations</li> <li>Queue Workflows - Streamlined cleaning and repair queue management</li> <li>PDF Generation - Automated PDF reports for work orders and repair orders</li> <li>Real-time Analytics - Interactive dashboards with business insights</li> <li>Keyboard Shortcuts - Power user shortcuts for faster data entry</li> <li>Multi-user Support - Role-based access control and user management</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>Modern Stack - Flask, SQLAlchemy, PostgreSQL, Alembic</li> <li>ML Integration - LightGBM model for completion time predictions</li> <li>Cloud Ready - Deployed on AWS Elastic Beanstalk with RDS and S3</li> <li>Well Tested - Comprehensive pytest test suite with high coverage</li> <li>CI/CD Pipeline - GitHub Actions for automated testing and deployment</li> <li>Database Migrations - Alembic for safe schema evolution</li> </ul>"},{"location":"#documentation-structure","title":"Documentation Structure","text":""},{"location":"#user-guide","title":"User Guide","text":"<p>Everything users need to know to operate the system effectively.</p> <ul> <li>Getting Started - First steps and login</li> <li>Work Orders - Creating and managing work orders</li> <li>Repair Orders - Handling repair jobs</li> <li>Analytics Dashboard - Understanding business metrics</li> <li>Keyboard Shortcuts - Power user tips</li> </ul>"},{"location":"#developer-guide","title":"Developer Guide","text":"<p>For developers working on or extending the codebase.</p> <ul> <li>Setup &amp; Installation - Local development setup</li> <li>Project Structure - Codebase organization</li> <li>Database Schema - Data models and relationships</li> <li>Testing - Running and writing tests</li> <li>Contributing - Contribution guidelines</li> </ul>"},{"location":"#database","title":"Database","text":"<p>Database schema, migrations, and data management.</p> <ul> <li>Alembic Migration Guide - Complete migration workflow</li> <li>Storage Fields Guide - Understanding storage fields</li> </ul>"},{"location":"#deployment","title":"Deployment","text":"<p>Production deployment and operations.</p> <ul> <li>AWS Elastic Beanstalk - Deployment to AWS</li> <li>Deployment Checklist - Pre-deployment verification</li> <li>Monitoring &amp; Logging - Production monitoring</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>System design, performance, and technical deep-dives.</p> <ul> <li>System Overview - High-level architecture</li> <li>ML Prediction System - Machine learning implementation</li> <li>Caching Strategy - Performance optimization</li> <li>Performance Analysis - Query optimization</li> <li>Concurrency Audit - Thread safety and locking</li> </ul>"},{"location":"#planning","title":"Planning","text":"<p>Future improvements and refactoring plans.</p> <ul> <li>Improvement Roadmap - Planned enhancements</li> <li>Refactoring Plan - Code improvement plans</li> <li>Denormalization Analysis - Database optimization plans</li> </ul>"},{"location":"#tech-stack","title":"Tech Stack","text":"Category Technologies Backend Flask 2.3.3, Python 3.x Database PostgreSQL, SQLAlchemy, Alembic Authentication Flask-Login Forms Flask-WTF, WTForms ML/Analytics scikit-learn, LightGBM, pandas, polars, plotly Documents reportlab, PyMuPDF, python-docx Cloud AWS Elastic Beanstalk, RDS, S3 Testing pytest, pytest-flask, pytest-cov CI/CD GitHub Actions"},{"location":"#getting-help","title":"Getting Help","text":"<ul> <li>For Users: See the User Guide or FAQ</li> <li>For Developers: Check the Developer Guide or Troubleshooting</li> <li>Issues: Report bugs on GitHub Issues</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#for-users_1","title":"For Users","text":"<ol> <li>Navigate to the application URL</li> <li>Log in with your credentials</li> <li>Start with the Getting Started Guide</li> </ol>"},{"location":"#for-developers_1","title":"For Developers","text":"<p><pre><code># Clone the repository\ngit clone https://github.com/andrewimpellitteri/awning_wo.git\ncd awning_wo\n\n# Follow the setup guide\n</code></pre> See the full Setup &amp; Installation Guide for detailed instructions.</p>"},{"location":"#repository","title":"Repository","text":"<p>GitHub: andrewimpellitteri/awning_wo</p> <p>Documentation Version</p> <p>This documentation is automatically built from the latest version of the codebase.</p>"},{"location":"CHECKIN_FEATURE_TODO/","title":"Check-In Feature - Todo List &amp; Code Review","text":"<p>Created: 2025-11-09 Status: Feature Partially Complete - Critical Items Remaining Related Files: <code>routes/checkins.py</code>, <code>models/checkin.py</code>, <code>templates/checkins/</code></p>"},{"location":"CHECKIN_FEATURE_TODO/#executive-summary","title":"Executive Summary","text":"<p>The check-in feature allows staff (managers/admins) to record customer items as they arrive for cleaning/repair. Admins can later convert pending check-ins into work orders. The feature is 80% complete but has critical missing functionality and several bugs that need addressing.</p>"},{"location":"CHECKIN_FEATURE_TODO/#what-works","title":"What Works \u2705","text":"<ul> <li>\u2705 Check-in creation with customer search (Selectize.js)</li> <li>\u2705 Item entry with full metadata (Description, Material, Color, Qty, Size, Price, Condition)</li> <li>\u2705 Additional fields matching work order (SpecialInstructions, StorageTime, RackNo, ReturnTo, DateRequired, RepairsNeeded, RushOrder)</li> <li>\u2705 Pending check-ins list view</li> <li>\u2705 Check-in detail view with all fields displayed</li> <li>\u2705 Admin-only conversion to work order</li> <li>\u2705 Pre-filling work order form from check-in data</li> <li>\u2705 Status tracking (pending \u2192 processed)</li> <li>\u2705 Check-in deletion (pending only)</li> <li>\u2705 Source information display</li> <li>\u2705 Comprehensive test coverage (7 tests, all passing)</li> </ul>"},{"location":"CHECKIN_FEATURE_TODO/#whats-missing","title":"What's Missing \u274c","text":"<ul> <li>\u274c CRITICAL: Customer item history not shown on check-in form</li> <li>\u274c CRITICAL: File upload UI not implemented (database ready, but no routes/templates)</li> <li>\u274c Item pre-selection from customer catalog (major UX issue)</li> <li>\u274c Edit check-in functionality</li> <li>\u274c Badge count in navigation for pending check-ins</li> <li>\u274c Check-in search/filter functionality</li> <li>\u274c Mobile responsiveness testing</li> <li>\u274c File attachment viewing on detail page</li> </ul>"},{"location":"CHECKIN_FEATURE_TODO/#priority-1-critical-issues-must-fix","title":"Priority 1 - Critical Issues (Must Fix)","text":""},{"location":"CHECKIN_FEATURE_TODO/#p11-add-customer-item-history-to-check-in-form","title":"\ud83d\udea8 P1.1: Add Customer Item History to Check-In Form","text":"<p>Status: Not Started Impact: High - Staff must manually re-enter all item details instead of selecting from history Effort: Medium (2-3 hours)</p> <p>Problem: The check-in creation form (<code>templates/checkins/new.html</code>) does NOT show customer item history like the work order form does. This forces staff to manually type every item detail from scratch, which: - Increases data entry time by 5-10x - Introduces typos and inconsistencies (e.g., \"Sunbrela\" vs \"Sunbrella\") - Defeats the purpose of having an inventory catalog system</p> <p>Expected Behavior: When a customer is selected in the check-in form, it should: 1. Load their previous items from <code>Inventory</code> table via AJAX 2. Display items in a selectable card UI (same as work order form) 3. Allow staff to check items to add them to the check-in 4. Show item details: Description, Material, Color, Size, Last Price, Last Condition 5. Auto-populate item fields when selected (editable)</p> <p>Implementation Steps: 1. Import the <code>customer_inventory_section()</code> macro from <code>_order_macros.html</code> into <code>templates/checkins/new.html</code> 2. Add the macro call after the \"Check-In Information\" card (line 88) 3. Include <code>order-form-shared.js</code> script in the template's <code>{% block scripts %}</code> 4. Update Selectize.js <code>onChange</code> handler to call <code>loadCustomerInventory(value)</code> 5. Ensure the existing <code>/work_orders/api/customer_inventory/&lt;cust_id&gt;</code> endpoint works for check-ins 6. Test with a customer who has previous work order items</p> <p>Files to Modify: - <code>templates/checkins/new.html</code> (lines 88-89, 205-210) - May need to create a check-in-specific JS file or modify <code>order-form-shared.js</code></p> <p>Testing: - Create a new check-in for a customer with previous work orders - Verify item history loads via AJAX - Verify items can be selected and added to check-in - Verify selected items appear in the items section with pre-filled data</p> <p>Related Code: - Work order implementation: <code>templates/work_orders/edit.html:2-4</code> (macro import) - Inventory API: <code>routes/work_orders.py:611-633</code> - Shared JS: <code>static/js/order-form-shared.js:91-150</code></p>"},{"location":"CHECKIN_FEATURE_TODO/#p12-implement-file-upload-for-check-ins","title":"\ud83d\udea8 P1.2: Implement File Upload for Check-Ins","text":"<p>Status: Not Started (Database Ready, Routes/UI Missing) Impact: High - Staff cannot attach photos/documents to check-ins Effort: Medium (3-4 hours)</p> <p>Problem: The <code>CheckInFile</code> model and database table (<code>tblcheckinfiles</code>) exist, but: - No file upload UI in <code>templates/checkins/new.html</code> - No routes in <code>routes/checkins.py</code> for handling file uploads - No display of uploaded files in <code>templates/checkins/detail.html</code> - Files cannot be transferred to work orders during conversion</p> <p>Expected Behavior: 1. Check-in creation form shows file upload dropzone (like work orders) 2. Files are uploaded to S3 during check-in creation 3. Detail page displays uploaded files with download links 4. Files are COPIED to work order when converting check-in</p> <p>Implementation Steps: 1. Add file upload section to <code>templates/checkins/new.html</code>    - Import <code>file_upload_section()</code> macro from <code>_order_macros.html</code>    - Add dropzone UI after \"Additional Details\" card 2. Update <code>routes/checkins.py</code> POST handler:    - Add <code>from utils.file_upload import handle_file_uploads</code>    - Process uploaded files after check-in creation    - Create <code>CheckInFile</code> records for each uploaded file 3. Update <code>templates/checkins/detail.html</code>:    - Add \"Files\" card section to display <code>checkin.files</code>    - Show file name, size, upload date, download link 4. Update <code>routes/work_orders.py</code> conversion logic:    - Copy files from check-in to work order during conversion    - Create corresponding <code>WorkOrderFile</code> records</p> <p>Files to Modify: - <code>templates/checkins/new.html</code> (add file upload section) - <code>routes/checkins.py:52-117</code> (POST handler for create_checkin) - <code>templates/checkins/detail.html:186-233</code> (add files display section) - <code>routes/work_orders.py:693-750</code> (work order POST handler for conversion)</p> <p>Testing: - Upload files during check-in creation - Verify files saved to S3 and database records created - View check-in detail page and verify files displayed - Convert check-in to work order and verify files copied</p> <p>Security Considerations: - Reuse existing file validation from <code>utils/file_upload.py</code> - Enforce file size limits (10MB) - Validate file types (PDF, JPG, PNG, DOCX, XLSX, TXT, CSV) - Sanitize file names to prevent path traversal attacks</p>"},{"location":"CHECKIN_FEATURE_TODO/#priority-2-important-features-should-have","title":"Priority 2 - Important Features (Should Have)","text":""},{"location":"CHECKIN_FEATURE_TODO/#p21-add-edit-check-in-functionality","title":"P2.1: Add Edit Check-In Functionality","text":"<p>Status: Not Implemented Impact: Medium - Staff cannot correct mistakes without deleting and recreating Effort: Medium (2-3 hours)</p> <p>Problem: There is no way to edit a check-in after creation. Staff must delete and recreate to fix: - Wrong customer selected - Missing items - Incorrect item details - Wrong dates or special instructions</p> <p>Expected Behavior: - \"Edit\" button on check-in detail page (pending only) - Edit form pre-filled with all current data - Item updates use same pattern as work orders (delete-then-insert) - Cannot edit processed check-ins</p> <p>Implementation Steps: 1. Create <code>templates/checkins/edit.html</code> (similar to <code>new.html</code>) 2. Add GET route: <code>@checkins_bp.route(\"/&lt;int:checkin_id&gt;/edit\")</code> 3. Add POST route to handle updates 4. Use delete-then-insert pattern for items (same as repair orders) 5. Add \"Edit\" button to detail page (line 148-150, next to \"Edit as Work Order\")</p> <p>Files to Create/Modify: - <code>templates/checkins/edit.html</code> (new file) - <code>routes/checkins.py</code> (add edit routes) - <code>templates/checkins/detail.html</code> (add edit button)</p>"},{"location":"CHECKIN_FEATURE_TODO/#p22-add-pending-check-in-badge-to-navigation","title":"P2.2: Add Pending Check-In Badge to Navigation","text":"<p>Status: Not Implemented Impact: Medium - Staff cannot see at-a-glance if check-ins need processing Effort: Small (30 minutes)</p> <p>Problem: The navigation has no visual indicator of pending check-ins count, unlike other features (e.g., cleaning queue shows count).</p> <p>Expected Behavior: - Navigation link shows \"Check-Ins\" with badge count (e.g., \"Check-Ins (3)\") - Badge updates in real-time when check-ins are created/processed - Badge color: warning (yellow/orange) for pending items</p> <p>Implementation Steps: 1. Update <code>templates/base.html</code> navigation to include badge 2. Use existing API endpoint: <code>GET /checkins/api/pending_count</code> (already exists at line 213) 3. Add JavaScript to poll endpoint every 30 seconds 4. Update badge count dynamically</p> <p>Files to Modify: - <code>templates/base.html</code> (navigation section) - Add JavaScript in <code>static/js/</code> or inline in base.html</p> <p>Existing API: <pre><code>@checkins_bp.route(\"/api/pending_count\")\n@login_required\ndef get_pending_count():\n    \"\"\"Get count of pending check-ins for navigation badge\"\"\"\n    count = CheckIn.query.filter_by(Status=\"pending\").count()\n    return jsonify({\"count\": count})\n</code></pre></p>"},{"location":"CHECKIN_FEATURE_TODO/#p23-add-searchfilter-to-pending-check-ins-list","title":"P2.3: Add Search/Filter to Pending Check-Ins List","text":"<p>Status: Not Implemented Impact: Medium - Hard to find specific check-ins as list grows Effort: Medium (2 hours)</p> <p>Problem: <code>templates/checkins/pending.html</code> shows all pending check-ins in date order with no search or filter capabilities.</p> <p>Expected Behavior: - Search by customer name, CustID, or check-in ID - Filter by date range (DateIn, DateRequired) - Filter by flags (RepairsNeeded, RushOrder) - Sort by date, customer name, or created date</p> <p>Implementation Steps: 1. Add search input and filter controls to <code>templates/checkins/pending.html</code> 2. Implement client-side filtering with JavaScript (simple, fast) 3. OR implement server-side filtering with query params 4. Add \"Clear Filters\" button</p> <p>Files to Modify: - <code>templates/checkins/pending.html</code> - Possibly <code>routes/checkins.py:128-139</code> (if server-side)</p>"},{"location":"CHECKIN_FEATURE_TODO/#priority-3-nice-to-have-future-enhancements","title":"Priority 3 - Nice to Have (Future Enhancements)","text":""},{"location":"CHECKIN_FEATURE_TODO/#p31-mobile-responsiveness-testing","title":"P3.1: Mobile Responsiveness Testing","text":"<p>Status: Unknown Impact: Low-Medium - Depends on mobile usage Effort: Small (1 hour testing + fixes)</p> <p>Action Items: - Test all check-in pages on mobile viewport (375px, 768px) - Verify Selectize.js works on touch devices - Ensure item cards stack properly - Test file upload on mobile - Fix any layout issues</p>"},{"location":"CHECKIN_FEATURE_TODO/#p32-check-in-analytics-dashboard","title":"P3.2: Check-In Analytics Dashboard","text":"<p>Status: Not Implemented Impact: Low - Nice for business insights Effort: Medium (3 hours)</p> <p>Potential Metrics: - Average time from check-in to work order conversion - Most common items by customer/source - Rush order frequency - Check-ins by day/week/month</p>"},{"location":"CHECKIN_FEATURE_TODO/#p33-bulk-actions-for-pending-check-ins","title":"P3.3: Bulk Actions for Pending Check-Ins","text":"<p>Status: Not Implemented Impact: Low - Would speed up admin workflow Effort: Medium (2-3 hours)</p> <p>Features: - Select multiple check-ins with checkboxes - Bulk convert to work orders - Bulk delete (with confirmation) - Assign to specific staff member</p>"},{"location":"CHECKIN_FEATURE_TODO/#code-review-findings","title":"Code Review Findings","text":""},{"location":"CHECKIN_FEATURE_TODO/#bug-1-boolean-field-handling-in-check-in-creation","title":"\ud83d\udc1b Bug #1: Boolean Field Handling in Check-In Creation","text":"<p>Location: <code>routes/checkins.py:76-77</code> Severity: Low Status: Existing (Works but could be better)</p> <p>Current Code: <pre><code>RepairsNeeded=bool(request.form.get(\"RepairsNeeded\")),\nRushOrder=bool(request.form.get(\"RushOrder\"))\n</code></pre></p> <p>Issue: Using <code>bool(request.form.get(...))</code> will evaluate to <code>True</code> even if the checkbox is unchecked but the field exists in the form. In HTML forms, unchecked checkboxes don't send any value, but if the field is present with any value (even empty string), <code>bool(\"\")</code> returns <code>False</code>, which is correct. However, this is fragile.</p> <p>Better Approach: <pre><code>RepairsNeeded=request.form.get(\"RepairsNeeded\") == \"1\",\nRushOrder=request.form.get(\"RushOrder\") == \"1\"\n</code></pre></p> <p>This explicitly checks for the value \"1\" (which is what the checkbox sends when checked).</p> <p>Fix Priority: Low (current code works, but explicit is better)</p>"},{"location":"CHECKIN_FEATURE_TODO/#bug-2-missing-form-enctype-for-future-file-uploads","title":"\ud83d\udc1b Bug #2: Missing Form Enctype for Future File Uploads","text":"<p>Location: <code>templates/checkins/new.html:50</code> Severity: High (Blocking P1.2) Status: Critical Bug</p> <p>Current Code: <pre><code>&lt;form method=\"POST\" id=\"checkinForm\"&gt;\n</code></pre></p> <p>Issue: When file uploads are added (P1.2), the form will NOT work because it's missing <code>enctype=\"multipart/form-data\"</code>.</p> <p>Fix: <pre><code>&lt;form method=\"POST\" id=\"checkinForm\" enctype=\"multipart/form-data\"&gt;\n</code></pre></p> <p>Fix Priority: High (must be fixed before implementing file uploads)</p>"},{"location":"CHECKIN_FEATURE_TODO/#bug-3-no-error-handling-for-customer-search-ajax","title":"\ud83d\udc1b Bug #3: No Error Handling for Customer Search AJAX","text":"<p>Location: <code>templates/checkins/new.html:243-246</code> Severity: Medium Status: Existing Issue</p> <p>Current Code: <pre><code>error: function(xhr, status, error) {\n    console.error('AJAX error:', status, error);\n    callback();\n},\n</code></pre></p> <p>Issue: When customer search API fails, the error is only logged to console. User sees no feedback that search failed.</p> <p>Better Approach: <pre><code>error: function(xhr, status, error) {\n    console.error('AJAX error:', status, error);\n    alert('Error searching customers. Please try again or contact support.');\n    callback();\n},\n</code></pre></p> <p>Or use a toast notification for better UX.</p> <p>Fix Priority: Medium (affects user experience when API fails)</p>"},{"location":"CHECKIN_FEATURE_TODO/#bug-4-form-validation-allows-empty-item-description","title":"\ud83d\udc1b Bug #4: Form Validation Allows Empty Item Description","text":"<p>Location: <code>templates/checkins/new.html:306-307</code> Severity: Low Status: Handled by Backend</p> <p>Current Code: <pre><code>&lt;input type=\"text\" class=\"form-control form-control-sm\" name=\"item_description[]\" required\n       placeholder=\"e.g., Awning, Cushion, Bimini\"&gt;\n</code></pre></p> <p>Issue: The <code>required</code> attribute is on each item's description field, but if the user removes all items, the form can still be submitted with no items (checked by JavaScript at line 368-373).</p> <p>However, the backend handles this gracefully at <code>routes/checkins.py:93</code>: <pre><code>if descriptions[i]:  # Only add if description is not empty\n</code></pre></p> <p>Assessment: This is actually fine. The JavaScript validation prevents submission with zero items, and the backend ignores empty descriptions.</p> <p>Fix Priority: None (working as intended)</p>"},{"location":"CHECKIN_FEATURE_TODO/#bug-5-customer-info-box-shows-on-page-load","title":"\ud83d\udc1b Bug #5: Customer Info Box Shows on Page Load","text":"<p>Location: <code>templates/checkins/new.html:83-86</code> Severity: Low Status: Visual Glitch</p> <p>Current Code: <pre><code>&lt;div id=\"customer-info\" class=\"alert alert-info\" style=\"display: none;\"&gt;\n    &lt;strong&gt;Customer Info:&lt;/strong&gt;\n    &lt;div id=\"customer-details\"&gt;&lt;/div&gt;\n&lt;/div&gt;\n</code></pre></p> <p>Issue: The customer info box is hidden with <code>display: none</code>, but when a customer is selected, <code>slideDown()</code> is called (line 266). This creates a smooth animation, which is good. However, if the user refreshes the page or navigates back, the box might not be hidden properly.</p> <p>Assessment: Minor visual issue, unlikely to cause problems.</p> <p>Fix Priority: None (acceptable behavior)</p>"},{"location":"CHECKIN_FEATURE_TODO/#warning-1-sqlalchemy-queryget-deprecation","title":"\u26a0\ufe0f Warning #1: SQLAlchemy Query.get() Deprecation","text":"<p>Location: Multiple places (tests, routes) Severity: Medium (Future breaking change) Status: Widespread Issue</p> <p>Example from tests: <pre><code>checkin = CheckIn.query.get(checkin_id)  # Deprecated in SQLAlchemy 2.0\n</code></pre></p> <p>Better Approach: <pre><code>checkin = db.session.get(CheckIn, checkin_id)\n</code></pre></p> <p>Locations to Fix: - <code>routes/checkins.py:147</code> - <code>CheckIn.query.get_or_404(checkin_id)</code> - <code>routes/checkins.py:157</code> - <code>CheckIn.query.get_or_404(checkin_id)</code> - <code>routes/work_orders.py:796</code> - <code>CheckIn.query.get(checkin_id)</code> - All test files using <code>.query.get()</code></p> <p>Fix Priority: Medium (should fix eventually, not urgent)</p>"},{"location":"CHECKIN_FEATURE_TODO/#code-quality-issue-1-duplicate-customer-loading-logic","title":"\ud83d\udca1 Code Quality Issue #1: Duplicate Customer Loading Logic","text":"<p>Location: <code>templates/checkins/new.html:239-251</code> vs <code>static/js/order-form-shared.js:115</code> Severity: Low Status: Tech Debt</p> <p>Issue: The customer search AJAX logic in the check-in form is almost identical to the inventory loading logic in work orders. This violates DRY principle.</p> <p>Recommendation: Extract Selectize initialization into a shared function in <code>order-form-shared.js</code>: <pre><code>function initializeCustomerSearch(elementId, onChangeCallback) {\n    // Shared Selectize setup\n}\n</code></pre></p> <p>Fix Priority: Low (works fine, but creates maintenance burden)</p>"},{"location":"CHECKIN_FEATURE_TODO/#code-quality-issue-2-magic-strings-for-status-values","title":"\ud83d\udca1 Code Quality Issue #2: Magic Strings for Status Values","text":"<p>Location: Multiple files Severity: Low Status: Acceptable but could be better</p> <p>Examples: <pre><code>Status=\"pending\"\nStatus=\"processed\"\n</code></pre></p> <p>Better Approach: Define constants in <code>models/checkin.py</code>: <pre><code>class CheckInStatus:\n    PENDING = \"pending\"\n    PROCESSED = \"processed\"\n\n# Usage\ncheckin.Status = CheckInStatus.PENDING\n</code></pre></p> <p>Fix Priority: Low (convention-over-configuration, not critical)</p>"},{"location":"CHECKIN_FEATURE_TODO/#code-quality-issue-3-missing-docstrings","title":"\ud83d\udca1 Code Quality Issue #3: Missing Docstrings","text":"<p>Location: <code>routes/checkins.py:29-40</code> Severity: Low Status: Good practice missing</p> <p>Issue: The helper function <code>_parse_date_field()</code> has a good docstring, but some route functions don't: - <code>create_checkin()</code> - has docstring \u2705 - <code>view_pending()</code> - has docstring \u2705 - <code>view_checkin()</code> - has docstring \u2705 - <code>delete_checkin()</code> - has docstring \u2705 - <code>customer_search()</code> - has docstring \u2705 - <code>get_pending_count()</code> - has docstring \u2705</p> <p>Assessment: All routes actually DO have docstrings! Great job!</p>"},{"location":"CHECKIN_FEATURE_TODO/#good-practices-found","title":"\u2705 Good Practices Found","text":"<ol> <li>Comprehensive Tests: 7 tests covering conversion behavior, role access, field transfer - excellent coverage</li> <li>Transaction Safety: Database commits wrapped in try/except with rollback on error</li> <li>Input Validation: Form validation on both client and server side</li> <li>SQL Injection Prevention: Using SQLAlchemy ORM, parameterized queries</li> <li>XSS Prevention: Jinja2 auto-escaping enabled</li> <li>CSRF Protection: Flask-WTF CSRF tokens (assumed, check base template)</li> <li>Role-Based Access: <code>@role_required</code> decorator properly used</li> <li>Code Organization: Clear separation of routes, models, templates</li> <li>Database Migrations: Proper Alembic migrations for schema changes</li> <li>Error Handling: User-friendly flash messages, not exposing stack traces</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#testing-gaps","title":"Testing Gaps","text":""},{"location":"CHECKIN_FEATURE_TODO/#missing-test-coverage","title":"Missing Test Coverage:","text":"<ol> <li>\u274c File upload during check-in creation (can't test until P1.2 implemented)</li> <li>\u274c File transfer from check-in to work order during conversion</li> <li>\u274c Edit check-in functionality (doesn't exist yet)</li> <li>\u274c Customer inventory loading on check-in form (P1.1)</li> <li>\u274c Mobile viewport testing</li> <li>\u274c Long description/instruction text (potential overflow issues)</li> <li>\u274c Special characters in item descriptions (SQL injection, XSS)</li> <li>\u274c Concurrent check-in creation by multiple users for same customer</li> <li>\u274c Invalid date formats (JavaScript vs backend parsing)</li> <li>\u274c Customer with no Source information (null handling)</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#recommended-new-tests","title":"Recommended New Tests:","text":"<pre><code>def test_checkin_with_special_characters_in_description(manager_client, app):\n    \"\"\"Test item descriptions with special characters don't cause XSS or SQL injection\"\"\"\n    pass\n\ndef test_checkin_with_missing_customer_source(admin_client, app):\n    \"\"\"Test check-in detail page when customer has no source_info\"\"\"\n    pass\n\ndef test_multiple_checkins_same_customer_concurrent(admin_client, app):\n    \"\"\"Test race condition: two users create check-ins for same customer\"\"\"\n    pass\n</code></pre>"},{"location":"CHECKIN_FEATURE_TODO/#database-schema-review","title":"Database Schema Review","text":""},{"location":"CHECKIN_FEATURE_TODO/#table-tblcheckins","title":"Table: <code>tblcheckins</code>","text":"<p>Status: \u2705 Well Designed</p> <p>Columns: - <code>checkinid</code> (PK) - Auto-increment \u2705 - <code>custid</code> (FK) - References customers \u2705 - <code>datein</code> (Date) - Check-in date \u2705 - <code>status</code> (String) - \"pending\" or \"processed\" \u2705 - <code>workorderno</code> (FK, nullable) - Links to work order after conversion \u2705 - <code>specialinstructions</code> (Text) - \u2705 - <code>storagetime</code> (String) - \u2705 - <code>rack_number</code> (String) - Note: Column name is <code>rack_number</code> but model uses <code>RackNo</code> \u2705 - <code>returnto</code> (String) - \u2705 - <code>daterequired</code> (Date) - \u2705 - <code>repairsneeded</code> (Boolean) - \u2705 - <code>rushorder</code> (Boolean) - \u2705 - <code>created_at</code> (DateTime) - \u2705 - <code>updated_at</code> (DateTime) - \u2705</p> <p>Indexes: - \u2753 Missing index on <code>status</code> (frequently queried for pending check-ins) - \u2753 Missing index on <code>custid</code> (for customer history lookup)</p> <p>Recommendations: <pre><code>CREATE INDEX idx_tblcheckins_status ON tblcheckins(status);\nCREATE INDEX idx_tblcheckins_custid ON tblcheckins(custid);\n</code></pre></p>"},{"location":"CHECKIN_FEATURE_TODO/#table-tblcheckinitems","title":"Table: <code>tblcheckinitems</code>","text":"<p>Status: \u2705 Well Designed</p> <p>Columns: - <code>id</code> (PK) - Auto-increment \u2705 - <code>checkinid</code> (FK, indexed) - \u2705 - <code>description</code> (String) - \u2705 - <code>material</code> (String) - Defaults to \"Unknown\" \u2705 - <code>color</code> (String) - \u2705 - <code>qty</code> (Integer) - \u2705 - <code>sizewgt</code> (String) - Size/weight \u2705 - <code>price</code> (Numeric 10,2) - \u2705 - <code>condition</code> (String) - \u2705</p> <p>Indexes: - \u2705 Index on <code>checkinid</code> (already exists per model line 91)</p>"},{"location":"CHECKIN_FEATURE_TODO/#table-tblcheckinfiles","title":"Table: <code>tblcheckinfiles</code>","text":"<p>Status: \u2705 Well Designed (Not Used Yet)</p> <p>Columns: - <code>id</code> (PK) - Auto-increment \u2705 - <code>checkinid</code> (FK, indexed) - \u2705 - <code>file_name</code> (String 255) - \u2705 - <code>file_path</code> (String 500) - \u2705 - <code>file_size</code> (Integer) - \u2705 - <code>file_type</code> (String 100) - \u2705 - <code>uploaded_at</code> (DateTime) - \u2705</p> <p>Indexes: - \u2705 Index on <code>checkinid</code> (per migration line 20)</p>"},{"location":"CHECKIN_FEATURE_TODO/#security-review","title":"Security Review","text":""},{"location":"CHECKIN_FEATURE_TODO/#secure-practices","title":"\u2705 Secure Practices:","text":"<ol> <li>Authentication Required: All routes use <code>@login_required</code></li> <li>Role-Based Access: <code>@role_required(\"admin\", \"manager\")</code> on all check-in routes</li> <li>CSRF Protection: Flask forms have CSRF tokens</li> <li>SQL Injection: Using SQLAlchemy ORM (parameterized queries)</li> <li>XSS Prevention: Jinja2 auto-escaping enabled</li> <li>File Upload Validation: (Will be needed for P1.2 - see <code>utils/file_upload.py</code>)</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#security-concerns","title":"\u26a0\ufe0f Security Concerns:","text":"<ol> <li>Future: File upload must validate types, sizes, scan for malware (P1.2)</li> <li>Future: S3 signed URLs must have short expiration times for file downloads</li> <li>Review: Check if <code>base.html</code> includes CSRF meta tag for AJAX requests</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#recommended-security-enhancements","title":"\ud83d\udd12 Recommended Security Enhancements:","text":"<ol> <li>Add rate limiting to customer search API (prevent enumeration attacks)</li> <li>Add audit logging for check-in creation/deletion (who created what, when)</li> <li>Add \"created_by\" field to track which user created the check-in</li> <li>Add input sanitization for special instructions (prevent HTML injection)</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#performance-considerations","title":"Performance Considerations","text":""},{"location":"CHECKIN_FEATURE_TODO/#current-performance-good","title":"Current Performance: \u2705 Good","text":"<p>Observations: 1. Customer search is limited to 20 results (<code>routes/checkins.py:192</code>) 2. Selectize loadThrottle: 300ms prevents API spam (<code>templates/checkins/new.html:226</code>) 3. Check-in items loaded via relationship (lazy loading by default) 4. Pending check-ins query is simple and fast</p>"},{"location":"CHECKIN_FEATURE_TODO/#potential-optimizations","title":"\ud83d\udcca Potential Optimizations:","text":"<ol> <li>Add pagination to pending check-ins list if count &gt; 50</li> <li>Use <code>lazy=\"joined\"</code> for <code>checkin.customer</code> relationship (avoid N+1 queries)</li> <li>Add database index on <code>tblcheckins.status</code> (see schema review)</li> <li>Cache pending count API response for 30 seconds (reduce DB hits)</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#documentation-needs","title":"Documentation Needs","text":""},{"location":"CHECKIN_FEATURE_TODO/#missing-documentation","title":"Missing Documentation:","text":"<ol> <li>\u274c User guide: \"How to create a check-in\"</li> <li>\u274c User guide: \"How to convert check-in to work order\"</li> <li>\u274c User guide: \"Understanding check-in vs work order\"</li> <li>\u274c Developer guide: \"Check-in workflow architecture\"</li> <li>\u274c API documentation for <code>/checkins/api/*</code> endpoints</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#recommended-documentation","title":"Recommended Documentation:","text":"<p>Create: <code>docs/user-guide/checkins.md</code> <pre><code># Check-In Feature User Guide\n\n## What is a Check-In?\n...\n\n## Creating a Check-In\n1. Navigate to Check-Ins &gt; New Check-In\n2. Search and select customer\n3. Enter item details\n4. Click \"Save Check-In\"\n\n## Converting to Work Order (Admin Only)\n...\n</code></pre></p>"},{"location":"CHECKIN_FEATURE_TODO/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"CHECKIN_FEATURE_TODO/#phase-1-critical-fixes-1-week","title":"Phase 1: Critical Fixes (1 week)","text":"<ol> <li>Day 1-2: Implement P1.1 (Customer Item History)</li> <li>Day 3-4: Implement P1.2 (File Upload)</li> <li>Day 5: Test and fix any bugs</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#phase-2-important-features-1-week","title":"Phase 2: Important Features (1 week)","text":"<ol> <li>Day 1-2: Implement P2.1 (Edit Check-In)</li> <li>Day 3: Implement P2.2 (Navigation Badge)</li> <li>Day 4: Implement P2.3 (Search/Filter)</li> <li>Day 5: Testing and bug fixes</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#phase-3-polish-3-days","title":"Phase 3: Polish (3 days)","text":"<ol> <li>Mobile responsiveness testing</li> <li>Add missing database indexes</li> <li>Write user documentation</li> <li>Address tech debt items</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#acceptance-criteria","title":"Acceptance Criteria","text":""},{"location":"CHECKIN_FEATURE_TODO/#feature-complete-when","title":"Feature Complete When:","text":"<ul> <li>[x] Check-ins can be created with all fields</li> <li>[x] Check-ins display correctly on detail page</li> <li>[x] Check-ins can be converted to work orders (admin only)</li> <li>[x] All check-in fields transfer to work order</li> <li>[ ] Customer item history shows on check-in form (P1.1)</li> <li>[ ] Files can be uploaded and attached to check-ins (P1.2)</li> <li>[ ] Check-ins can be edited (P2.1)</li> <li>[ ] Pending count badge shows in navigation (P2.2)</li> <li>[ ] Pending list can be searched/filtered (P2.3)</li> <li>[ ] All tests pass</li> <li>[ ] Mobile responsive</li> <li>[ ] User documentation exists</li> </ul>"},{"location":"CHECKIN_FEATURE_TODO/#related-issues-prs","title":"Related Issues &amp; PRs","text":"<ul> <li>Migration: <code>alembic/versions/20251109_1729-add_checkin_extra_fields.py</code></li> <li>Migration: <code>alembic/versions/20251109_1750-add_checkin_files_table.py</code></li> <li>Tests: <code>test/test_checkins_routes.py:478-779</code> (7 tests, all passing)</li> </ul>"},{"location":"CHECKIN_FEATURE_TODO/#questions-for-product-owner","title":"Questions for Product Owner","text":"<ol> <li>File Upload: Should files be COPIED or MOVED to work order during conversion?</li> <li>Edit Permissions: Should managers be able to edit check-ins, or only admins?</li> <li>Check-In Retention: How long should processed check-ins be kept? Archive policy?</li> <li>Notifications: Should admins be notified when new check-ins are created?</li> <li>Bulk Operations: Is bulk conversion needed, or one-at-a-time acceptable?</li> </ol>"},{"location":"CHECKIN_FEATURE_TODO/#conclusion","title":"Conclusion","text":"<p>The check-in feature has a solid foundation with good code quality, comprehensive tests, and proper security practices. However, it's not production-ready due to two critical missing features:</p> <ol> <li>Customer item history not shown - Staff must manually type everything</li> <li>File upload not implemented - Cannot attach photos/documents</li> </ol> <p>Estimated Time to Production-Ready: 2-3 weeks (with testing)</p> <p>Risk Assessment: \ud83d\udfe1 Medium Risk - Core functionality works - Missing features block efficient workflow - No show-stopper bugs, but UX is incomplete</p> <p>Recommendation: Prioritize P1.1 and P1.2 before releasing to production.</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/","title":"File Upload System - Complete Analysis &amp; Implementation Guide","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#part-1-executive-summary","title":"PART 1: EXECUTIVE SUMMARY","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#key-findings","title":"Key Findings","text":"<p>What's Working Well \u2713 - Deferred S3 upload prevents orphaned files - Batch file upload support - Multi-file type thumbnail generation - Defense-in-depth validation (client + server) - Proper use of secure_filename()</p> <p>Critical Gaps \u2717 1. No S3 credential validation at startup - Fails silently until first upload 2. No timeout protection - Could hang indefinitely 3. Extension-only validation - Security risk from renamed files 4. Poor error messages - Users don't know what went wrong 5. Memory exhaustion risk - Entire files in memory during uploads</p> <p>User Experience Issues 1. No upload progress indicator 2. alert() dialogs instead of nice notifications 3. No file size warnings before upload 4. Mobile: drag-drop doesn't work, confusing UI 5. Partial failures appear as success to users</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#the-safest-fix-start-here","title":"The SAFEST Fix - Start Here","text":"<p>Tier 1: Critical Safety (1-2 hours to implement)</p> <ol> <li>Add S3 Validation (20 min)</li> <li>Add Timeout Protection (15 min)</li> <li>Add Server-Side Size Check (10 min)</li> </ol> <p>Impact: Prevents 90% of production issues</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#part-2-detailed-analysis","title":"PART 2: DETAILED ANALYSIS","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#1-upload-endpoints-client-side-components","title":"1. UPLOAD ENDPOINTS &amp; CLIENT-SIDE COMPONENTS","text":"<p>Endpoints Identified</p> <p>Work Orders: - POST /work_orders//files/upload - Direct file upload - GET /work_orders//files//download - Download files - GET /work_orders/thumbnail/ - Serve thumbnails - POST /work_orders/new - Create with batch uploads - POST /work_orders/edit/ - Edit with batch uploads <p>Repair Orders: - POST /repair_work_orders//files/upload - GET /repair_work_orders//files//download - GET /repair_work_orders/thumbnail/ - POST /repair_work_orders/new - POST /repair_work_orders//edit <p>UI Components</p> <p>File Upload Section (templates/_order_macros.html:40-73): - Drag &amp; drop dropzone with visual feedback - File input with multiple file support - File list display with individual remove buttons - Max file size: 10MB (client-side only) - Supported types: PDF, JPG, PNG, DOCX, XLSX, TXT, CSV</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#2-error-handling-patterns","title":"2. ERROR HANDLING PATTERNS","text":"<p>Current Implementation</p> <p>Backend error handling (routes/work_orders.py:312-360): - Deferred upload endpoint validates file type - Commits to DB first, then uploads to S3 - Deletes DB record if S3 upload fails - Logs warnings but doesn't fail for partial batch failures</p> <p>Issues Identified</p> <ol> <li>Inconsistent Error Messaging</li> <li>Partial Failure Handling - Orphaned S3 files if some fail</li> <li>S3 Credential Errors Not Caught at startup</li> <li>Missing Timeout Handling - Could hang indefinitely</li> <li>Duplicate File Handling not transparent to user</li> </ol>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#3-file-validation-logic","title":"3. FILE VALIDATION LOGIC","text":"<p>Current Validation (utils/file_upload.py:21-22) <pre><code>ALLOWED_EXTENSIONS = {\"pdf\", \"jpg\", \"jpeg\", \"png\", \"docx\", \"xlsx\", \"txt\", \"csv\"}\n\ndef allowed_file(filename):\n    return \".\" in filename and filename.rsplit(\".\", 1)[1].lower() in ALLOWED_EXTENSIONS\n</code></pre></p> <p>Issues Identified</p> <ol> <li>Extension-Only Validation - Renamed files (exe\u2192pdf) not caught</li> <li>No MIME type checking</li> <li>No file content validation</li> <li>File size enforcement mismatch (10MB client vs 16MB server)</li> <li>No virus/malware scanning</li> </ol>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#4-s3-upload-patterns-error-recovery","title":"4. S3 UPLOAD PATTERNS &amp; ERROR RECOVERY","text":"<p>Deferred Upload System (utils/file_upload.py:85-243)</p> <p>Two-phase commit: 1. Phase 1: File processed, stored in memory (_deferred_file_content) 2. Phase 2: After DB commit, uploads to S3</p> <p>Issues Identified</p> <ol> <li>Partial Upload Failure - DB record exists but S3 missing</li> <li>Thumbnail-File Sync Issues - If main succeeds but thumbnail fails</li> <li>Memory Exhaustion Risk - 100 x 10MB = 1GB RAM</li> <li>Missing Upload Verification - No checksum validation</li> <li>Incomplete Cleanup - Orphaned S3 multipart uploads</li> </ol>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#5-user-feedback-mechanisms","title":"5. USER FEEDBACK MECHANISMS","text":"<p>Progress Indicators - Current State: Minimal feedback - No visible upload progress - No visual feedback during S3 upload</p> <p>Error Messages - Client-side: Uses alert() (modal and disruptive) - Server-side: Generic messages (\"Failed to upload file to S3\") - No correlation between multiple uploads - No logging of which specific file failed</p> <p>Missing Feedback 1. No upload progress bar 2. No thumbnail generation status 3. No partial failure notification 4. No retry UI for failed uploads 5. No file size warning before submission</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#6-file-size-limits-constraints","title":"6. FILE SIZE LIMITS &amp; CONSTRAINTS","text":"<p>Current Limits</p> <p>Client-side: - Max per file: 10MB - Max per upload: Unlimited (browser limit)</p> <p>Server-side: - Flask request.max_content_length: Not explicitly set (default 16MB) - S3: 5GB per object</p> <p>Database: - filename: VARCHAR (no explicit limit) - file_path: VARCHAR (no explicit limit) - thumbnail_path: VARCHAR(500)</p> <p>Issues Identified</p> <ol> <li>Mismatch in Limits - 10MB client vs 16MB server</li> <li>Database Column Size Issues - Could overflow</li> <li>No Multi-part Upload for Large Files - Entire file in memory</li> <li>No Bandwidth Limiting - Could exhaust resources</li> </ol>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#7-mobile-upload-support","title":"7. MOBILE UPLOAD SUPPORT","text":"<p>Current State</p> <p>HTML5 File Input: - Multiple file selection supported - Accept attribute filters file picker - Compatible with mobile browsers</p> <p>Drag &amp; Drop: - iOS Safari doesn't support drag-drop - Users must use file picker only</p> <p>Issues Identified</p> <ol> <li>iOS File Picker Limitations - Confusing workflow</li> <li>No Mobile-Specific UI - \"Drag &amp; drop\" text nonsensical</li> <li>Mobile Network Issues - No handling of WiFi\u2192cellular switch</li> <li>No File Size Warnings on Mobile</li> <li>Missing Touch Feedback - Unclear if zone is interactive</li> </ol>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#8-thumbnail-generation-edge-cases","title":"8. THUMBNAIL GENERATION EDGE CASES","text":"<p>Implementation (utils/thumbnail_generator.py:221-238)</p> <p>By File Type: 1. Image (PNG, JPG, JPEG): Direct scaling 2. PDF: First page rendered via PyMuPDF 3. DOCX: Text preview of first 10 paragraphs 4. Excel/CSV: Text preview of first 6 rows 5. Text: First 500 characters 6. Unknown: Generic icon</p> <p>Issues Identified</p> <ol> <li>PDF Thumbnail Issues</li> <li>Hardcoded zoom factor could create wrong sizes</li> <li>Encrypted PDFs crash silently</li> <li>Large PDFs could timeout</li> <li> <p>No timeout protection</p> </li> <li> <p>Excel Thumbnail Issues</p> </li> <li>Large CSV files could timeout</li> <li>Corrupt files crash silently</li> <li>Merged cells display incorrectly</li> <li> <p>Formulas not evaluated</p> </li> <li> <p>Memory Issues - PDFs rendered full page = large bitmap</p> </li> <li> <p>Missing File Type Detection - Only checks extension</p> </li> <li> <p>Concurrent Generation Issues - Multiple PDFs max out CPU</p> </li> <li> <p>Thumbnail Cache Stale - No cache invalidation</p> </li> <li> <p>Text Encoding Issues - Assumes UTF-8, crashes on Latin-1</p> </li> <li> <p>DOCX Corruption Handling - Crashes silently</p> </li> </ol>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#part-3-implementation-guide","title":"PART 3: IMPLEMENTATION GUIDE","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-1-critical-safety-improvements-do-first-1-2-hours","title":"TIER 1: CRITICAL SAFETY IMPROVEMENTS (Do First - 1-2 hours)","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#11-add-s3-credential-validation-at-startup","title":"1.1: Add S3 Credential Validation at Startup","text":"<p>Problem: Application starts successfully but crashes on first file upload if S3 credentials are invalid.</p> <p>Implementation:</p> <pre><code># In utils/file_upload.py, add:\n\ndef validate_s3_connection():\n    \"\"\"Validate S3 bucket exists and is accessible at startup\"\"\"\n    try:\n        response = s3_client.head_bucket(Bucket=AWS_S3_BUCKET)\n        print(f\"\u2713 S3 bucket '{AWS_S3_BUCKET}' is accessible\")\n        return True\n    except s3_client.exceptions.NoSuchBucket:\n        raise ValueError(f\"S3 bucket '{AWS_S3_BUCKET}' does not exist\")\n    except s3_client.exceptions.ClientError as e:\n        error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n        if error_code == '403':\n            raise ValueError(f\"Access denied to S3 bucket. Check IAM permissions.\")\n        else:\n            raise ValueError(f\"Cannot access S3 bucket: {error_code}\")\n    except Exception as e:\n        raise ValueError(f\"S3 connection failed: {str(e)}\")\n\n# In app.py, add after create_app():\n\nfrom utils.file_upload import validate_s3_connection\n\nif __name__ == '__main__' or 'gunicorn' in os.environ.get('SERVER_SOFTWARE', ''):\n    try:\n        validate_s3_connection()\n    except ValueError as e:\n        print(f\"FATAL: {e}\")\n        exit(1)\n</code></pre> <p>Safety Level: VERY SAFE - No breaking changes Time to Implement: 20 minutes Benefit: Immediate feedback on S3 configuration issues</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#12-add-timeout-protection-for-file-operations","title":"1.2: Add Timeout Protection for File Operations","text":"<p>Problem: S3 uploads can hang indefinitely on slow connections.</p> <p>Implementation:</p> <pre><code># In utils/file_upload.py, update s3_client initialization:\n\nfrom botocore.config import Config\n\n# Replace existing s3_client creation with:\ns3_config = Config(\n    connect_timeout=10,      # 10s to establish connection\n    read_timeout=30,         # 30s per read operation\n    retries={'max_attempts': 2, 'mode': 'adaptive'}\n)\n\nif is_aws_environment:\n    s3_client = boto3.client(\"s3\", config=s3_config, region_name=AWS_REGION)\nelse:\n    s3_client = boto3.client(\n        \"s3\",\n        aws_access_key_id=AWS_ACCESS_KEY_ID,\n        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n        config=s3_config,\n        region_name=AWS_REGION,\n    )\n</code></pre> <p>Safety Level: VERY SAFE - Uses boto3 built-in Time to Implement: 15 minutes Benefit: Prevents hung requests from blocking workers</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#13-add-server-side-file-size-validation","title":"1.3: Add Server-Side File Size Validation","text":"<p>Problem: Client says 10MB, server default is 16MB. No actual size enforcement.</p> <p>Implementation:</p> <pre><code># In config.py, add:\nMAX_UPLOAD_SIZE_MB = 10\nMAX_UPLOAD_SIZE_BYTES = MAX_UPLOAD_SIZE_MB * 1024 * 1024\n\n# In app.py, add after app = Flask(__name__):\napp.config['MAX_CONTENT_LENGTH'] = config.MAX_UPLOAD_SIZE_BYTES\n\n# In utils/file_upload.py, add to save_order_file_generic():\ndef save_order_file_generic(...):\n    # Get file size\n    file.seek(0, 2)  # Seek to end\n    file_size = file.tell()\n    file.seek(0)  # Reset to beginning\n\n    # Check size before processing\n    from config import MAX_UPLOAD_SIZE_BYTES\n    if file_size &gt; MAX_UPLOAD_SIZE_BYTES:\n        error_msg = f\"File too large: {file_size / (1024*1024):.1f}MB (max 10MB)\"\n        print(f\"ERROR: {error_msg}\")\n        return None\n\n    # Continue with rest of function...\n</code></pre> <p>Safety Level: VERY SAFE - Standard Flask pattern Time to Implement: 10 minutes Benefit: Prevents oversized uploads from consuming resources</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-2-error-handling-improvements-do-second-1-week","title":"TIER 2: ERROR HANDLING IMPROVEMENTS (Do Second - 1 week)","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#21-add-detailed-error-messages-with-error-codes","title":"2.1: Add Detailed Error Messages with Error Codes","text":"<p>Problem: Generic error messages like \"Failed to upload file to S3\" don't help users.</p> <p>Implementation:</p> <pre><code># In utils/file_upload.py, add:\nclass FileUploadError:\n    INVALID_TYPE = (\"INVALID_TYPE\", \"File type not supported. Allowed: PDF, JPG, PNG, DOCX, XLSX, TXT, CSV\")\n    FILE_TOO_LARGE = (\"FILE_TOO_LARGE\", \"File exceeds 10MB limit\")\n    S3_BUCKET_NOT_FOUND = (\"S3_BUCKET_NOT_FOUND\", \"S3 bucket configuration error\")\n    S3_ACCESS_DENIED = (\"S3_ACCESS_DENIED\", \"Cannot write to S3. Check permissions.\")\n    S3_UPLOAD_FAILED = (\"S3_UPLOAD_FAILED\", \"Upload failed. Please try again.\")\n    THUMBNAIL_FAILED = (\"THUMBNAIL_FAILED\", \"Preview generation failed\")\n    UNKNOWN_ERROR = (\"UNKNOWN_ERROR\", \"Unexpected error occurred\")\n\n# In routes/work_orders.py, update upload handler:\ntry:\n    saved_file = save_work_order_file(...)\n\n    if not saved_file:\n        code, message = FileUploadError.INVALID_TYPE\n        return jsonify({\"error\": message, \"code\": code}), 400\n\n    db.session.add(saved_file)\n    db.session.commit()\n\n    success, uploaded, failed = commit_deferred_uploads([saved_file])\n    if not success:\n        db.session.delete(saved_file)\n        db.session.commit()\n\n        file_obj, error_str = failed[0]\n        if \"NoSuchBucket\" in error_str:\n            code, message = FileUploadError.S3_BUCKET_NOT_FOUND\n        elif \"403\" in error_str or \"Access Denied\" in error_str:\n            code, message = FileUploadError.S3_ACCESS_DENIED\n        else:\n            code, message = FileUploadError.S3_UPLOAD_FAILED\n\n        return jsonify({\"error\": message, \"code\": code}), 500\n\n    return jsonify({\"message\": \"File uploaded successfully\"})\n\nexcept Exception as e:\n    db.session.rollback()\n    code, message = FileUploadError.UNKNOWN_ERROR\n    print(f\"ERROR [{code}]: {str(e)}\")\n    return jsonify({\"error\": message, \"code\": code}), 500\n</code></pre> <p>Safety Level: VERY SAFE - Only changes error messages Time to Implement: 45 minutes Benefit: Users understand what went wrong</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#22-replace-alert-with-toast-notifications","title":"2.2: Replace alert() with Toast Notifications","text":"<p>Problem: alert() is modal and disruptive.</p> <p>Implementation:</p> <pre><code>// In static/js/order-form-shared.js, update validateFile():\n\nfunction validateFile(file) {\n    const extension = file.name.split('.').pop().toLowerCase();\n    if (!ALLOWED_EXTENSIONS.includes(extension)) {\n        showNotification('error', `File type not allowed: ${file.name}`);\n        return false;\n    }\n\n    if (file.size &gt; MAX_FILE_SIZE) {\n        showNotification('error', `File too large: ${file.name} (max 10MB)`);\n        return false;\n    }\n\n    return true;\n}\n\n// Add new notification function:\nfunction showNotification(type, message) {\n    const alertClass = type === 'error' ? 'bg-danger' : 'bg-warning';\n    const icon = type === 'error' ? 'fa-exclamation-circle' : 'fa-exclamation-triangle';\n\n    const toastHtml = `\n        &lt;div class=\"toast align-items-center text-white ${alertClass} border-0 mb-2\"&gt;\n            &lt;div class=\"d-flex\"&gt;\n                &lt;div class=\"toast-body\"&gt;\n                    &lt;i class=\"fas ${icon} me-2\"&gt;&lt;/i&gt;\n                    ${message}\n                &lt;/div&gt;\n                &lt;button type=\"button\" class=\"btn-close btn-close-white me-2\" data-bs-dismiss=\"toast\"&gt;&lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    `;\n\n    let container = document.getElementById('uploadNotifications');\n    if (!container) {\n        container = document.createElement('div');\n        container.id = 'uploadNotifications';\n        container.style.cssText = 'position:fixed;top:20px;right:20px;z-index:9999;';\n        document.body.appendChild(container);\n    }\n\n    container.insertAdjacentHTML('beforeend', toastHtml);\n    const toast = container.lastElementChild;\n    new bootstrap.Toast(toast).show();\n}\n</code></pre> <p>Safety Level: VERY SAFE - Replaces existing UX Time to Implement: 20 minutes Benefit: Better, less disruptive error messages</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-3-ux-improvements-do-third-1-2-weeks","title":"TIER 3: UX IMPROVEMENTS (Do Third - 1-2 weeks)","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#31-add-file-size-display-before-upload","title":"3.1: Add File Size Display Before Upload","text":"<p>Problem: No indication of total upload size.</p> <p>Implementation:</p> <pre><code>// In static/js/order-form-shared.js, update updateFileList():\n\nfunction updateFileList() {\n    const fileInput = document.getElementById('files');\n    const fileList = document.getElementById('fileList');\n    const fileListContainer = document.getElementById('fileListContainer');\n    const files = fileInput.files;\n\n    if (files.length === 0) {\n        fileListContainer.style.display = 'none';\n        return;\n    }\n\n    // Calculate total size\n    let totalSize = 0;\n    for (let i = 0; i &lt; files.length; i++) {\n        totalSize += files[i].size;\n    }\n\n    const totalMB = totalSize / (1024 * 1024);\n    const warningEl = document.getElementById('uploadSizeWarning');\n\n    // Show warning if over limit\n    if (totalMB &gt; 10) {\n        if (!warningEl) {\n            const warning = document.createElement('div');\n            warning.id = 'uploadSizeWarning';\n            warning.className = 'alert alert-warning mt-2';\n            warning.innerHTML = `\n                &lt;i class=\"fas fa-exclamation-triangle me-2\"&gt;&lt;/i&gt;\n                Total upload size is &lt;strong&gt;${totalMB.toFixed(1)}MB&lt;/strong&gt;. \n                This exceeds the 10MB limit. Remove some files to continue.\n            `;\n            fileListContainer.insertBefore(warning, fileList);\n        }\n    } else if (warningEl) {\n        warningEl.remove();\n    }\n\n    // Update file list\n    fileList.innerHTML = '';\n    for (let i = 0; i &lt; files.length; i++) {\n        const file = files[i];\n        const li = document.createElement('li');\n        li.className = 'list-group-item d-flex justify-content-between align-items-center';\n\n        const fileInfo = document.createElement('div');\n        fileInfo.innerHTML = `\n            &lt;i class=\"fas fa-file me-2\"&gt;&lt;/i&gt;\n            &lt;strong&gt;${file.name}&lt;/strong&gt;\n            &lt;small class=\"text-muted ms-2\"&gt;(${formatFileSize(file.size)})&lt;/small&gt;\n        `;\n\n        li.appendChild(fileInfo);\n        fileList.appendChild(li);\n    }\n}\n</code></pre> <p>Safety Level: VERY SAFE - UI-only change Time to Implement: 15 minutes Benefit: Users see total size and get warned</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-4-robustness-improvements-do-fourth-2-weeks","title":"TIER 4: ROBUSTNESS IMPROVEMENTS (Do Fourth - 2 weeks)","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#41-improve-thumbnail-generation-error-handling","title":"4.1: Improve Thumbnail Generation Error Handling","text":"<p>Problem: Thumbnail failures crash silently, PDFs and Excel files can fail.</p> <p>Implementation:</p> <pre><code># In utils/thumbnail_generator.py, add logging:\n\nimport logging\nlogger = logging.getLogger(__name__)\n\ndef generate_pdf_thumbnail(file_content):\n    \"\"\"Generate thumbnail from PDF first page\"\"\"\n    try:\n        pdf_document = fitz.open(stream=file_content, filetype=\"pdf\")\n        if len(pdf_document) == 0:\n            logger.warning(\"PDF has no pages\")\n            return create_icon_thumbnail(\"PDF\", (220, 53, 69))\n\n        page = pdf_document[0]\n        zoom_factor = 1.5  # Slightly larger than default\n        mat = fitz.Matrix(zoom_factor, zoom_factor)\n        pix = page.get_pixmap(matrix=mat)\n        img_data = pix.tobytes(\"png\")\n\n        img = Image.open(BytesIO(img_data))\n        img.thumbnail(THUMBNAIL_SIZE, Image.Resampling.LANCZOS)\n\n        thumbnail = Image.new(\"RGB\", THUMBNAIL_SIZE, (255, 255, 255))\n        x = (THUMBNAIL_SIZE[0] - img.width) // 2\n        y = (THUMBNAIL_SIZE[1] - img.height) // 2\n        thumbnail.paste(img, (x, y))\n\n        pdf_document.close()\n        return thumbnail\n\n    except Exception as e:\n        logger.error(f\"PDF thumbnail generation failed: {type(e).__name__}: {str(e)}\")\n        return create_icon_thumbnail(\"PDF\", (220, 53, 69))\n\ndef generate_text_thumbnail(file_content):\n    \"\"\"Generate thumbnail from text file with encoding fallback\"\"\"\n    try:\n        # Try UTF-8 first\n        try:\n            text = file_content.decode(\"utf-8\")[:500]\n        except UnicodeDecodeError:\n            # Fall back to Latin-1 (never fails)\n            logger.warning(\"Text file not UTF-8, using Latin-1\")\n            text = file_content.decode(\"latin-1\", errors=\"replace\")[:500]\n\n        return create_text_thumbnail(text, \"Text File\", (108, 117, 125), (255, 255, 255))\n\n    except Exception as e:\n        logger.error(f\"Text thumbnail generation failed: {str(e)}\")\n        return create_icon_thumbnail(\"TXT\", (108, 117, 125))\n</code></pre> <p>Safety Level: VERY SAFE - Improves error handling only Time to Implement: 30 minutes Benefit: Thumbnail failures don't crash uploads</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#part-4-implementation-roadmap","title":"PART 4: IMPLEMENTATION ROADMAP","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#week-1-safety-tier-1","title":"Week 1: Safety (Tier 1)","text":"<pre><code>[ ] Add S3 credential validation (20 min)\n[ ] Add timeout protection (15 min)\n[ ] Add server-side file size check (10 min)\n[ ] Test each change\n[ ] Deploy to staging\nTotal: 1-2 hours\n</code></pre>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#week-2-error-handling-tier-2","title":"Week 2: Error Handling (Tier 2)","text":"<pre><code>[ ] Add detailed error codes/messages (45 min)\n[ ] Replace alert() with toasts (20 min)\n[ ] Test error scenarios\n[ ] Deploy to staging\nTotal: 2-3 hours\n</code></pre>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#week-3-ux-tier-3","title":"Week 3: UX (Tier 3)","text":"<pre><code>[ ] Add file size display (15 min)\n[ ] Mobile-optimize dropzone\n[ ] Add thumbnail feedback\n[ ] Test on mobile\n[ ] Deploy to staging\nTotal: 2-3 hours\n</code></pre>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#week-4-robustness-tier-4","title":"Week 4: Robustness (Tier 4)","text":"<pre><code>[ ] Improve thumbnail error handling (30 min)\n[ ] Add text encoding support\n[ ] Add checksum verification (optional)\n[ ] Test edge cases\n[ ] Deploy to staging\nTotal: 2-3 hours\n</code></pre>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#part-5-testing-checklist","title":"PART 5: TESTING CHECKLIST","text":""},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-1-testing","title":"Tier 1 Testing","text":"<ul> <li>[ ] Start app with invalid AWS bucket \u2192 error on startup</li> <li>[ ] Start app with invalid credentials \u2192 error on startup</li> <li>[ ] Simulate slow network \u2192 upload times out gracefully</li> <li>[ ] Upload file &gt;10MB \u2192 rejected immediately</li> </ul>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-2-testing","title":"Tier 2 Testing","text":"<ul> <li>[ ] Invalid file type \u2192 specific error code returned</li> <li>[ ] S3 unreachable \u2192 specific error message</li> <li>[ ] S3 bucket not found \u2192 clear error message</li> <li>[ ] Check logs have correlation IDs</li> </ul>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-3-testing","title":"Tier 3 Testing","text":"<ul> <li>[ ] Upload 5x 2MB files \u2192 shows \"Total: 10MB\"</li> <li>[ ] Upload 5x 3MB files \u2192 shows warning</li> <li>[ ] Error messages appear as toasts</li> <li>[ ] Test on mobile browser</li> </ul>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#tier-4-testing","title":"Tier 4 Testing","text":"<ul> <li>[ ] Upload corrupted PDF \u2192 thumbnail uses icon</li> <li>[ ] Upload Latin-1 text file \u2192 thumbnail generated</li> <li>[ ] Large Excel file \u2192 thumbnail or icon, no crash</li> </ul>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#risk-assessment","title":"RISK ASSESSMENT","text":"<p>All recommendations are: - \u2713 Low-risk - No breaking API changes - \u2713 Backward compatible - Works with existing UI - \u2713 Minimal code changes - &lt;5 files modified - \u2713 Well-tested patterns - Use Flask/boto3 built-ins - \u2713 Isolated changes - Can implement one at a time</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#files-to-modify","title":"FILES TO MODIFY","text":"<p>Core Changes (5 files): 1. <code>utils/file_upload.py</code> - Add validation, timeout, better errors 2. <code>config.py</code> - Add MAX_UPLOAD_SIZE_MB setting 3. <code>app.py</code> - Add S3 validation call, set MAX_CONTENT_LENGTH 4. <code>static/js/order-form-shared.js</code> - Replace alerts with toasts, show file size 5. <code>utils/thumbnail_generator.py</code> - Better error handling</p> <p>No Database Changes Required \u2713 No Breaking API Changes \u2713</p>"},{"location":"FILE_UPLOAD_ANALYSIS_AND_IMPROVEMENTS/#summary","title":"SUMMARY","text":"<p>Tier 1 (Safety): Implement first for immediate stability Tier 2 (Error Handling): Implement next for better UX Tier 3 (UX): Nice to have improvements Tier 4 (Robustness): Optional enhancements</p> <p>Total Effort: 8-11 hours across 4 weeks Total Files Modified: 5 Expected Outcome: Robust, user-friendly file uploads with proper error handling</p>"},{"location":"MKDOCS_DEPLOYMENT/","title":"MkDocs Deployment Guide","text":""},{"location":"MKDOCS_DEPLOYMENT/#overview","title":"Overview","text":"<p>This project uses MkDocs with the Material theme for documentation. The documentation is automatically built and can be deployed to GitHub Pages or viewed locally.</p>"},{"location":"MKDOCS_DEPLOYMENT/#local-development","title":"Local Development","text":""},{"location":"MKDOCS_DEPLOYMENT/#prerequisites","title":"Prerequisites","text":"<p>MkDocs and dependencies are already listed in <code>requirements.txt</code>: <pre><code>mkdocs\nmkdocs-material\n</code></pre></p>"},{"location":"MKDOCS_DEPLOYMENT/#serving-documentation-locally","title":"Serving Documentation Locally","text":"<pre><code># Serve docs with live reload\nmkdocs serve\n\n# Visit http://127.0.0.1:8000\n</code></pre> <p>The documentation will automatically reload when you make changes to any <code>.md</code> files in the <code>docs/</code> directory.</p>"},{"location":"MKDOCS_DEPLOYMENT/#building-documentation","title":"Building Documentation","text":"<pre><code># Build documentation to site/ directory\nmkdocs build\n\n# Build with strict mode (fails on warnings)\nmkdocs build --strict\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#github-pages-deployment","title":"GitHub Pages Deployment","text":""},{"location":"MKDOCS_DEPLOYMENT/#automatic-deployment","title":"Automatic Deployment","text":"<p>The easiest way to deploy to GitHub Pages:</p> <pre><code># Deploy to gh-pages branch\nmkdocs gh-deploy\n\n# With custom commit message\nmkdocs gh-deploy -m \"Updated docs with new utility functions guide\"\n</code></pre> <p>This command will: 1. Build the documentation 2. Push it to the <code>gh-pages</code> branch 3. GitHub Pages will automatically serve it</p>"},{"location":"MKDOCS_DEPLOYMENT/#manual-deployment","title":"Manual Deployment","text":"<p>If you prefer manual control:</p> <pre><code># Build documentation\nmkdocs build\n\n# The built site is in site/ directory\n# Copy contents to your web server\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#project-structure","title":"Project Structure","text":"<pre><code>awning_wo/\n\u251c\u2500\u2500 mkdocs.yml                          # MkDocs configuration\n\u251c\u2500\u2500 docs/                               # Documentation source files\n\u2502   \u251c\u2500\u2500 index.md                        # Homepage\n\u2502   \u251c\u2500\u2500 user-guide/                     # User documentation\n\u2502   \u2502   \u251c\u2500\u2500 index.md\n\u2502   \u2502   \u251c\u2500\u2500 getting-started.md\n\u2502   \u2502   \u2514\u2500\u2500 work-orders.md\n\u2502   \u251c\u2500\u2500 developer-guide/                # Developer documentation\n\u2502   \u2502   \u251c\u2500\u2500 index.md\n\u2502   \u2502   \u251c\u2500\u2500 setup.md\n\u2502   \u2502   \u251c\u2500\u2500 utility-functions.md        # \u2728 NEW\n\u2502   \u2502   \u251c\u2500\u2500 testing.md                  # \u2728 NEW\n\u2502   \u2502   \u251c\u2500\u2500 file-uploads.md             # \u2728 NEW\n\u2502   \u2502   \u251c\u2500\u2500 project-structure.md\n\u2502   \u2502   \u251c\u2500\u2500 database-schema.md\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 database/                       # Database docs\n\u2502   \u251c\u2500\u2500 deployment/                     # Deployment guides\n\u2502   \u251c\u2500\u2500 architecture/                   # Architecture docs\n\u2502   \u251c\u2500\u2500 planning/                       # Planning docs\n\u2502   \u2514\u2500\u2500 reference/                      # Reference docs\n\u2514\u2500\u2500 site/                               # Built documentation (git-ignored)\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#configuration","title":"Configuration","text":""},{"location":"MKDOCS_DEPLOYMENT/#mkdocs-configuration-mkdocsyml","title":"MkDocs Configuration (<code>mkdocs.yml</code>)","text":"<p>Key sections:</p> <pre><code>site_name: Awning Management System Documentation\nsite_url: https://andrewimpellitteri.github.com/awning_wo\nrepo_url: https://github.com/andrewimpellitteri/awning_wo\n\ntheme:\n  name: material\n  palette:\n    # Light/dark mode toggle\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - search.suggest\n    - content.code.copy\n    - content.mermaid\n\nnav:\n  - Home: index.md\n  - User Guide:\n      - user-guide/index.md\n      - Getting Started: user-guide/getting-started.md\n  - Developer Guide:\n      - developer-guide/index.md\n      - Utility Functions: developer-guide/utility-functions.md  # NEW\n      - Testing: developer-guide/testing.md                      # NEW\n      - File Uploads: developer-guide/file-uploads.md            # NEW\n  # ... more sections\n\nmarkdown_extensions:\n  - pymdownx.highlight\n  - pymdownx.superfences\n  - admonition\n  - tables\n  - toc\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#adding-new-documentation","title":"Adding New Documentation","text":""},{"location":"MKDOCS_DEPLOYMENT/#1-create-the-markdown-file","title":"1. Create the Markdown File","text":"<pre><code># Create a new doc file\ntouch docs/developer-guide/new-feature.md\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#2-write-content","title":"2. Write Content","text":"<pre><code># New Feature Guide\n\n## Overview\n\nDescription of the new feature...\n\n## Usage\n\nExamples and code snippets...\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#3-update-navigation","title":"3. Update Navigation","text":"<p>Edit <code>mkdocs.yml</code> to add the new page:</p> <pre><code>nav:\n  - Developer Guide:\n      - New Feature: developer-guide/new-feature.md\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#4-test-locally","title":"4. Test Locally","text":"<pre><code>mkdocs serve\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#5-deploy","title":"5. Deploy","text":"<pre><code>mkdocs gh-deploy\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#recently-added-documentation","title":"Recently Added Documentation","text":"<p>The following comprehensive guides were recently added:</p>"},{"location":"MKDOCS_DEPLOYMENT/#1-utility-functions-reference-developer-guideutility-functionsmd","title":"1. Utility Functions Reference (developer-guide/utility-functions.md)","text":"<ul> <li>Complete reference for all utility modules</li> <li>500+ lines covering helpers, order items, forms, dates, data processing</li> <li>Usage examples and best practices</li> <li>Race condition and memory management documentation</li> </ul>"},{"location":"MKDOCS_DEPLOYMENT/#2-testing-guide-developer-guidetestingmd","title":"2. Testing Guide (developer-guide/testing.md)","text":"<ul> <li>Comprehensive testing manual with pytest</li> <li>All fixtures documented (app, client, auth_user, mock_s3_client)</li> <li>Mocking patterns (S3, database, Flask-Login)</li> <li>Test writing examples and best practices</li> <li>Coverage expectations and CI integration</li> </ul>"},{"location":"MKDOCS_DEPLOYMENT/#3-file-upload-system-developer-guidefile-uploadsmd","title":"3. File Upload System (developer-guide/file-uploads.md)","text":"<ul> <li>In-depth file upload architecture documentation</li> <li>Deferred upload pattern (prevents orphaned S3 files)</li> <li>Complete workflow diagrams</li> <li>S3 integration, thumbnail generation</li> <li>Memory management and cleanup</li> <li>Production-ready examples</li> </ul>"},{"location":"MKDOCS_DEPLOYMENT/#material-theme-features","title":"Material Theme Features","text":""},{"location":"MKDOCS_DEPLOYMENT/#admonitions","title":"Admonitions","text":"<pre><code>!!! note\n    This is a note admonition.\n\n!!! warning\n    This is a warning admonition.\n\n!!! tip\n    This is a tip admonition.\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#code-blocks","title":"Code Blocks","text":"<pre><code>```python\ndef hello_world():\n    print(\"Hello, World!\")\n```\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#tables","title":"Tables","text":"<pre><code>| Column 1 | Column 2 |\n|----------|----------|\n| Value 1  | Value 2  |\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#tabs","title":"Tabs","text":"<pre><code>=== \"Tab 1\"\n    Content for tab 1\n\n=== \"Tab 2\"\n    Content for tab 2\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#mermaid-diagrams","title":"Mermaid Diagrams","text":"<pre><code>```mermaid\ngraph LR\n    A[Start] --&gt; B[Process]\n    B --&gt; C[End]\n```\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#troubleshooting","title":"Troubleshooting","text":""},{"location":"MKDOCS_DEPLOYMENT/#build-warnings","title":"Build Warnings","text":"<pre><code># Check for broken links and issues\nmkdocs build --strict\n</code></pre> <p>Common warnings: - Missing files: Referenced in nav but don't exist - Broken links: Links to non-existent docs - Excluded files: Listed in <code>exclude_docs</code> won't be processed</p>"},{"location":"MKDOCS_DEPLOYMENT/#port-already-in-use","title":"Port Already in Use","text":"<pre><code># Kill process on port 8000\nlsof -ti:8000 | xargs kill -9\n\n# Or use different port\nmkdocs serve -a 127.0.0.1:8001\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#theme-not-loading","title":"Theme Not Loading","text":"<pre><code># Reinstall mkdocs-material\npip install --upgrade mkdocs-material\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"MKDOCS_DEPLOYMENT/#github-actions","title":"GitHub Actions","text":"<p>Create <code>.github/workflows/docs.yml</code>:</p> <pre><code>name: Deploy Docs\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n\n      - name: Install dependencies\n        run: |\n          pip install mkdocs mkdocs-material\n\n      - name: Deploy docs\n        run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#best-practices","title":"Best Practices","text":""},{"location":"MKDOCS_DEPLOYMENT/#documentation-writing","title":"Documentation Writing","text":"<ol> <li>Use descriptive headings - Clear hierarchy with H1, H2, H3</li> <li>Include code examples - Show, don't just tell</li> <li>Add navigation links - Link to related pages</li> <li>Use admonitions - Highlight important information</li> <li>Keep it updated - Update docs when code changes</li> </ol>"},{"location":"MKDOCS_DEPLOYMENT/#organization","title":"Organization","text":"<ol> <li>Group related topics - Use directory structure</li> <li>Use index pages - Landing pages for each section</li> <li>Logical navigation - Order makes sense to users</li> <li>Search-friendly - Use good keywords and headings</li> </ol>"},{"location":"MKDOCS_DEPLOYMENT/#maintenance","title":"Maintenance","text":"<ol> <li>Test builds locally - Before deploying</li> <li>Fix broken links - Run <code>mkdocs build --strict</code></li> <li>Update regularly - Keep docs in sync with code</li> <li>Review PRs - Require doc updates for features</li> </ol>"},{"location":"MKDOCS_DEPLOYMENT/#useful-commands","title":"Useful Commands","text":"<pre><code># Serve docs locally\nmkdocs serve\n\n# Build docs\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n\n# Deploy with message\nmkdocs gh-deploy -m \"Update docs\"\n\n# Build with strict mode (fail on warnings)\nmkdocs build --strict\n\n# Clean build directory\nrm -rf site/\n\n# Check MkDocs version\nmkdocs --version\n\n# Validate configuration\nmkdocs build --strict --verbose\n</code></pre>"},{"location":"MKDOCS_DEPLOYMENT/#resources","title":"Resources","text":"<ul> <li>MkDocs: https://www.mkdocs.org/</li> <li>Material for MkDocs: https://squidfunk.github.io/mkdocs-material/</li> <li>Markdown Guide: https://www.markdownguide.org/</li> <li>Project Repo: https://github.com/andrewimpellitteri/awning_wo</li> </ul>"},{"location":"MKDOCS_DEPLOYMENT/#see-also","title":"See Also","text":"<ul> <li>Developer Guide Index - All developer documentation</li> <li>Utility Functions - Utility functions reference</li> <li>Testing Guide - Testing documentation</li> <li>File Uploads - File upload system</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/","title":"Documentation Reorganization Guide","text":"<p>This guide explains the new documentation structure and how to complete the reorganization.</p>"},{"location":"README_DOCS_REORGANIZATION/#what-changed","title":"What Changed?","text":""},{"location":"README_DOCS_REORGANIZATION/#before","title":"Before","text":"<pre><code>docs/\n\u251c\u2500\u2500 ALEMBIC_GUIDE.md\n\u251c\u2500\u2500 CACHING_GUIDE.md\n\u251c\u2500\u2500 CONCURRENCY_AUDIT.md\n\u251c\u2500\u2500 DENORMALIZATION_ANALYSIS.md\n\u251c\u2500\u2500 DEPLOYMENT_CHECKLIST.md\n\u251c\u2500\u2500 IMPROVEMENTS.md\n\u251c\u2500\u2500 PERFORMANCE_ANALYSIS.md\n\u251c\u2500\u2500 REFACTORING_PLAN.md\n\u251c\u2500\u2500 STORAGE_FIELDS_GUIDE.md\n\u251c\u2500\u2500 WASM_THUMBNAIL_OPTIMIZATION.md\n\u2514\u2500\u2500 index.md\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#after","title":"After","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                          # Main documentation homepage\n\u251c\u2500\u2500 user-guide/                       # For end users\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 getting-started.md\n\u2502   \u251c\u2500\u2500 work-orders.md\n\u2502   \u251c\u2500\u2500 repair-orders.md\n\u2502   \u251c\u2500\u2500 customers.md\n\u2502   \u251c\u2500\u2500 sources.md\n\u2502   \u251c\u2500\u2500 inventory.md\n\u2502   \u251c\u2500\u2500 queue.md\n\u2502   \u251c\u2500\u2500 analytics.md\n\u2502   \u251c\u2500\u2500 pdf-reports.md\n\u2502   \u2514\u2500\u2500 keyboard-shortcuts.md\n\u251c\u2500\u2500 developer-guide/                  # For developers\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u251c\u2500\u2500 setup.md\n\u2502   \u251c\u2500\u2500 project-structure.md\n\u2502   \u251c\u2500\u2500 database-schema.md\n\u2502   \u251c\u2500\u2500 api-reference.md\n\u2502   \u251c\u2500\u2500 testing.md\n\u2502   \u2514\u2500\u2500 contributing.md\n\u251c\u2500\u2500 database/                         # Database &amp; migrations\n\u2502   \u251c\u2500\u2500 ALEMBIC_GUIDE.md             \u2705 Existing\n\u2502   \u251c\u2500\u2500 STORAGE_FIELDS_GUIDE.md      \u2705 Existing\n\u2502   \u2514\u2500\u2500 schema-changes.md\n\u251c\u2500\u2500 deployment/                       # Deployment guides\n\u2502   \u251c\u2500\u2500 aws-eb.md\n\u2502   \u251c\u2500\u2500 DEPLOYMENT_CHECKLIST.md      \u2705 Existing\n\u2502   \u251c\u2500\u2500 environment-variables.md\n\u2502   \u251c\u2500\u2500 monitoring.md\n\u2502   \u2514\u2500\u2500 rollback.md\n\u251c\u2500\u2500 architecture/                     # Technical architecture\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u251c\u2500\u2500 ml-system.md\n\u2502   \u251c\u2500\u2500 CACHING_GUIDE.md             \u2705 Existing\n\u2502   \u251c\u2500\u2500 PERFORMANCE_ANALYSIS.md      \u2705 Existing\n\u2502   \u2514\u2500\u2500 CONCURRENCY_AUDIT.md         \u2705 Existing\n\u251c\u2500\u2500 planning/                         # Future improvements\n\u2502   \u251c\u2500\u2500 IMPROVEMENTS.md              \u2705 Existing\n\u2502   \u251c\u2500\u2500 REFACTORING_PLAN.md          \u2705 Existing\n\u2502   \u251c\u2500\u2500 DENORMALIZATION_ANALYSIS.md  \u2705 Existing\n\u2502   \u2514\u2500\u2500 WASM_THUMBNAIL_OPTIMIZATION.md \u2705 Existing\n\u2514\u2500\u2500 reference/                        # Quick reference\n    \u251c\u2500\u2500 faq.md\n    \u251c\u2500\u2500 troubleshooting.md\n    \u2514\u2500\u2500 glossary.md\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#step-by-step-reorganization","title":"Step-by-Step Reorganization","text":""},{"location":"README_DOCS_REORGANIZATION/#step-1-run-the-reorganization-script","title":"Step 1: Run the Reorganization Script","text":"<p>This moves existing docs to their new locations:</p> <pre><code>chmod +x reorganize_docs.sh\n./reorganize_docs.sh\n</code></pre> <p>This will: - Create the new directory structure - Move existing .md files to appropriate locations - Keep your existing documentation intact</p>"},{"location":"README_DOCS_REORGANIZATION/#step-2-create-placeholder-files","title":"Step 2: Create Placeholder Files","text":"<p>This creates starter content for missing documentation:</p> <pre><code>chmod +x create_doc_placeholders.sh\n./create_doc_placeholders.sh\n</code></pre> <p>This creates: - User guide pages with basic structure - Developer guide foundations - Reference materials (FAQ, troubleshooting, glossary)</p>"},{"location":"README_DOCS_REORGANIZATION/#step-3-preview-the-documentation","title":"Step 3: Preview the Documentation","text":"<p>Install MkDocs and dependencies:</p> <pre><code>pip install mkdocs-material\npip install mkdocs-git-revision-date-localized-plugin\n</code></pre> <p>Serve the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000</code> to preview.</p>"},{"location":"README_DOCS_REORGANIZATION/#step-4-fill-in-the-gaps","title":"Step 4: Fill in the Gaps","text":"<p>You now have a skeleton. Fill in content over time:</p>"},{"location":"README_DOCS_REORGANIZATION/#priority-1-essential-user-docs","title":"Priority 1: Essential User Docs","text":"<ul> <li>[ ] <code>user-guide/work-orders.md</code> - Expand with screenshots</li> <li>[ ] <code>user-guide/repair-orders.md</code> - Add workflow diagrams</li> <li>[ ] <code>user-guide/queue.md</code> - Document queue workflows</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#priority-2-developer-onboarding","title":"Priority 2: Developer Onboarding","text":"<ul> <li>[ ] <code>developer-guide/setup.md</code> - Verify setup steps</li> <li>[ ] <code>developer-guide/database-schema.md</code> - Add ER diagrams</li> <li>[ ] <code>developer-guide/testing.md</code> - Document test patterns</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#priority-3-operations","title":"Priority 3: Operations","text":"<ul> <li>[ ] <code>deployment/aws-eb.md</code> - Complete deployment guide</li> <li>[ ] <code>deployment/monitoring.md</code> - Add monitoring setup</li> <li>[ ] <code>deployment/environment-variables.md</code> - Document all env vars</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#priority-4-architecture","title":"Priority 4: Architecture","text":"<ul> <li>[ ] <code>architecture/overview.md</code> - System architecture diagram</li> <li>[ ] <code>architecture/ml-system.md</code> - ML pipeline documentation</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#documentation-philosophy","title":"Documentation Philosophy","text":""},{"location":"README_DOCS_REORGANIZATION/#for-users","title":"For Users","text":"<ul> <li>Task-oriented - Focus on \"how to do X\"</li> <li>Screenshots - Show, don't just tell</li> <li>Examples - Real-world scenarios</li> <li>Simple language - Avoid jargon</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#for-developers","title":"For Developers","text":"<ul> <li>Code examples - Show actual code</li> <li>Architecture diagrams - Visualize structure</li> <li>Technical depth - Don't oversimplify</li> <li>Links to code - Reference actual files</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#writing-tips","title":"Writing Tips","text":""},{"location":"README_DOCS_REORGANIZATION/#good-user-documentation","title":"Good User Documentation","text":"<pre><code>## Creating a Work Order\n\n1. Click \"New Work Order\" in the top menu\n2. Select a customer from the dropdown\n3. Fill in the date and source\n4. Click \"Save\"\n\n![Screenshot of work order form](../images/work-order-form.png)\n\n!!! tip\n    Use Ctrl+N to quickly create a new work order\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#good-developer-documentation","title":"Good Developer Documentation","text":"<pre><code>## Work Order Model\n\nThe WorkOrder model represents a cleaning job.\n\n**File:** [models/work_order.py](../../models/work_order.py)\n\n```python\nclass WorkOrder(db.Model):\n    __tablename__ = \"tblcustworkorderdetail\"\n    work_order_no = db.Column(\"workorderno\", db.Integer, primary_key=True)\n    # ...\n</code></pre> <p>Relationships: - Belongs to: Customer (via custid) - Has many: WorkOrderFiles <pre><code>## MkDocs Features\n\n### Admonitions (Callouts)\n\n```markdown\n!!! note\n    This is a note\n\n!!! warning\n    This is a warning\n\n!!! tip\n    This is a helpful tip\n\n!!! danger\n    This is critical information\n</code></pre></p>"},{"location":"README_DOCS_REORGANIZATION/#tabs","title":"Tabs","text":"<pre><code>=== \"Python\"\n    ```python\n    def hello():\n        print(\"Hello!\")\n    ```\n\n=== \"JavaScript\"\n    ```javascript\n    function hello() {\n        console.log(\"Hello!\");\n    }\n    ```\n</code></pre>"},{"location":"README_DOCS_REORGANIZATION/#code-blocks-with-line-numbers","title":"Code Blocks with Line Numbers","text":"<p><pre><code>```python linenums=\"1\"\ndef example():\n    return \"Hello\"\n</code></pre> <pre><code>## Publishing the Docs\n\n### Option 1: GitHub Pages (Recommended)\n\n```bash\n# Build the docs\nmkdocs build\n\n# Deploy to GitHub Pages\nmkdocs gh-deploy\n</code></pre></p> <p>This creates a <code>gh-pages</code> branch with the built site.</p> <p>Configure GitHub Pages: 1. Go to repository Settings 2. Pages section 3. Source: Deploy from branch 4. Branch: gh-pages / root 5. Save</p> <p>Your docs will be at: <code>https://andrewimpellitteri.github.io/awning_wo/</code></p>"},{"location":"README_DOCS_REORGANIZATION/#option-2-netlifyvercel","title":"Option 2: Netlify/Vercel","text":"<p>Both support MkDocs. Add a build command:</p> <pre><code>mkdocs build\n</code></pre> <p>And publish directory: <code>site/</code></p>"},{"location":"README_DOCS_REORGANIZATION/#maintenance","title":"Maintenance","text":""},{"location":"README_DOCS_REORGANIZATION/#adding-new-documentation","title":"Adding New Documentation","text":"<ol> <li>Create the .md file in the appropriate directory</li> <li>Add it to <code>mkdocs.yml</code> in the <code>nav:</code> section</li> <li>Test with <code>mkdocs serve</code></li> <li>Commit and push</li> </ol>"},{"location":"README_DOCS_REORGANIZATION/#updating-existing-documentation","title":"Updating Existing Documentation","text":"<ol> <li>Edit the .md file</li> <li>Preview with <code>mkdocs serve</code></li> <li>Commit and push</li> <li>Redeploy with <code>mkdocs gh-deploy</code> (if using GitHub Pages)</li> </ol>"},{"location":"README_DOCS_REORGANIZATION/#next-steps","title":"Next Steps","text":"<ol> <li>\u2705 Run <code>./reorganize_docs.sh</code></li> <li>\u2705 Run <code>./create_doc_placeholders.sh</code></li> <li>\u2705 Preview with <code>mkdocs serve</code></li> <li>\ud83d\udcdd Fill in user guide content</li> <li>\ud83d\udcdd Add developer documentation</li> <li>\ud83d\ude80 Deploy to GitHub Pages</li> </ol>"},{"location":"README_DOCS_REORGANIZATION/#questions","title":"Questions?","text":"<ul> <li>MkDocs Documentation: https://www.mkdocs.org/</li> <li>Material Theme: https://squidfunk.github.io/mkdocs-material/</li> <li>Markdown Guide: https://www.markdownguide.org/</li> </ul>"},{"location":"README_DOCS_REORGANIZATION/#file-locations-summary","title":"File Locations Summary","text":"Type Old Location New Location Database guides <code>docs/*.md</code> <code>docs/database/</code> Deployment <code>docs/*.md</code> <code>docs/deployment/</code> Architecture <code>docs/*.md</code> <code>docs/architecture/</code> Planning <code>docs/*.md</code> <code>docs/planning/</code> User guides (new) <code>docs/user-guide/</code> Developer guides (new) <code>docs/developer-guide/</code> Reference (new) <code>docs/reference/</code>"},{"location":"email_reminder_timing_eda/","title":"Email Reminder Timing - Exploratory Data Analysis","text":""},{"location":"email_reminder_timing_eda/#executive-summary","title":"Executive Summary","text":"<p>This document analyzes historical work order data to determine the optimal timing for sending cleaning reminder emails to customers.</p>"},{"location":"email_reminder_timing_eda/#analysis-goals","title":"Analysis Goals","text":"<ol> <li>Determine average time between cleanings for customers</li> <li>Identify patterns by customer segment</li> <li>Find optimal reminder timing to maximize conversion</li> <li>Recommend when to send reminder emails</li> </ol>"},{"location":"email_reminder_timing_eda/#data-sources","title":"Data Sources","text":"<ul> <li>Work Orders: Historical cleaning records with completion dates</li> <li>Customers: Customer information and segmentation</li> <li>Geographic Data: Location-based patterns</li> </ul>"},{"location":"email_reminder_timing_eda/#key-metrics","title":"Key Metrics","text":"<ul> <li>Average Time Between Cleanings: Days between consecutive work orders for the same customer</li> <li>Repeat Rate: Percentage of customers who return for additional services</li> <li>Seasonal Patterns: Time of year impact on cleaning frequency</li> <li>Response Window: Optimal time before expected next cleaning</li> </ul>"},{"location":"email_reminder_timing_eda/#analysis","title":"Analysis","text":""},{"location":"email_reminder_timing_eda/#1-customer-cleaning-frequency-distribution","title":"1. Customer Cleaning Frequency Distribution","text":"<p>Query to analyze: <pre><code>WITH customer_orders AS (\n    SELECT\n        custid,\n        date_completed,\n        LAG(date_completed) OVER (PARTITION BY custid ORDER BY date_completed) as prev_completed\n    FROM tblworkorders\n    WHERE date_completed IS NOT NULL\n),\ntime_between AS (\n    SELECT\n        custid,\n        date_completed - prev_completed as days_between\n    FROM customer_orders\n    WHERE prev_completed IS NOT NULL\n)\nSELECT\n    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY days_between) as q1_days,\n    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY days_between) as median_days,\n    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY days_between) as q3_days,\n    AVG(days_between) as avg_days,\n    STDDEV(days_between) as stddev_days,\n    COUNT(*) as total_repeat_orders\nFROM time_between;\n</code></pre></p> <p>Expected Insights: - Median time between cleanings - Distribution spread (Q1, Q3) - Identify if there are distinct customer segments</p>"},{"location":"email_reminder_timing_eda/#2-customer-segmentation-by-cleaning-frequency","title":"2. Customer Segmentation by Cleaning Frequency","text":"<pre><code>WITH customer_frequency AS (\n    SELECT\n        custid,\n        COUNT(*) as order_count,\n        MAX(date_completed) - MIN(date_completed) as total_span_days,\n        AVG(\n            date_completed - LAG(date_completed)\n            OVER (PARTITION BY custid ORDER BY date_completed)\n        ) as avg_days_between\n    FROM tblworkorders\n    WHERE date_completed IS NOT NULL\n    GROUP BY custid\n    HAVING COUNT(*) &gt;= 2\n)\nSELECT\n    CASE\n        WHEN avg_days_between &lt; 180 THEN 'High Frequency (&lt;6mo)'\n        WHEN avg_days_between BETWEEN 180 AND 270 THEN 'Semi-Annual (6-9mo)'\n        WHEN avg_days_between BETWEEN 270 AND 450 THEN 'Annual (9-15mo)'\n        ELSE 'Low Frequency (&gt;15mo)'\n    END as segment,\n    COUNT(*) as customer_count,\n    AVG(avg_days_between) as avg_days,\n    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY avg_days_between) as median_days\nFROM customer_frequency\nGROUP BY segment\nORDER BY avg_days;\n</code></pre> <p>Use Cases: - High Frequency: Send reminders at 5 months - Semi-Annual: Send reminders at 8 months - Annual: Send reminders at 11 months - Low Frequency: Send reminders at 15 months</p>"},{"location":"email_reminder_timing_eda/#3-seasonal-patterns","title":"3. Seasonal Patterns","text":"<pre><code>SELECT\n    EXTRACT(MONTH FROM date_completed) as month,\n    EXTRACT(QUARTER FROM date_completed) as quarter,\n    COUNT(*) as orders_completed,\n    COUNT(DISTINCT custid) as unique_customers\nFROM tblworkorders\nWHERE date_completed IS NOT NULL\nGROUP BY month, quarter\nORDER BY month;\n</code></pre> <p>Insights: - Identify peak cleaning seasons - Adjust reminder timing based on historical busy periods - Plan capacity for expected response volume</p>"},{"location":"email_reminder_timing_eda/#4-repeat-customer-analysis","title":"4. Repeat Customer Analysis","text":"<pre><code>WITH customer_stats AS (\n    SELECT\n        custid,\n        COUNT(*) as lifetime_orders,\n        MAX(date_completed) as last_order_date,\n        MIN(date_completed) as first_order_date,\n        CURRENT_DATE - MAX(date_completed) as days_since_last\n    FROM tblworkorders\n    WHERE date_completed IS NOT NULL\n    GROUP BY custid\n)\nSELECT\n    CASE\n        WHEN lifetime_orders = 1 THEN 'One-time'\n        WHEN lifetime_orders = 2 THEN 'Returning'\n        WHEN lifetime_orders BETWEEN 3 AND 5 THEN 'Regular'\n        ELSE 'Loyal'\n    END as customer_tier,\n    COUNT(*) as customer_count,\n    AVG(days_since_last) as avg_days_since_last,\n    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY days_since_last) as median_days_since\nFROM customer_stats\nGROUP BY customer_tier\nORDER BY\n    CASE customer_tier\n        WHEN 'One-time' THEN 1\n        WHEN 'Returning' THEN 2\n        WHEN 'Regular' THEN 3\n        WHEN 'Loyal' THEN 4\n    END;\n</code></pre>"},{"location":"email_reminder_timing_eda/#5-geographic-patterns","title":"5. Geographic Patterns","text":"<pre><code>SELECT\n    COALESCE(city, 'Unknown') as city,\n    COUNT(DISTINCT wo.custid) as customer_count,\n    COUNT(wo.workorderno) as total_orders,\n    AVG(\n        wo.date_completed - LAG(wo.date_completed)\n        OVER (PARTITION BY wo.custid ORDER BY wo.date_completed)\n    ) as avg_days_between\nFROM tblworkorders wo\nJOIN tblcustomers c ON wo.custid = c.custid\nWHERE wo.date_completed IS NOT NULL\nGROUP BY city\nHAVING COUNT(DISTINCT wo.custid) &gt;= 5\nORDER BY customer_count DESC\nLIMIT 20;\n</code></pre>"},{"location":"email_reminder_timing_eda/#recommended-email-reminder-strategy","title":"Recommended Email Reminder Strategy","text":""},{"location":"email_reminder_timing_eda/#timing-recommendations","title":"Timing Recommendations","text":"<p>Based on industry standards and typical awning cleaning cycles:</p>"},{"location":"email_reminder_timing_eda/#strategy-1-fixed-timing-simple","title":"Strategy 1: Fixed Timing (Simple)","text":"<ul> <li>When to Send: 11 months after last cleaning</li> <li>Pros: Easy to implement, consistent messaging</li> <li>Cons: Doesn't account for customer-specific patterns</li> </ul>"},{"location":"email_reminder_timing_eda/#strategy-2-personalized-timing-recommended","title":"Strategy 2: Personalized Timing (Recommended)","text":"<pre><code>def calculate_reminder_date(customer):\n    # Get customer's average cleaning interval\n    avg_interval = get_customer_avg_interval(customer)\n\n    # Send reminder at 90% of their interval\n    reminder_offset = avg_interval * 0.90\n\n    # Default to 11 months if no history\n    if not avg_interval:\n        reminder_offset = 335  # ~11 months\n\n    return last_cleaning_date + timedelta(days=reminder_offset)\n</code></pre>"},{"location":"email_reminder_timing_eda/#strategy-3-seasonal-adjustment","title":"Strategy 3: Seasonal Adjustment","text":"<ul> <li>Adjust timing based on peak seasons</li> <li>Send earlier if approaching busy season</li> <li>Account for weather patterns (spring/fall cleaning peaks)</li> </ul>"},{"location":"email_reminder_timing_eda/#email-cadence","title":"Email Cadence","text":"<ol> <li>First Reminder: At calculated timing (e.g., 11 months)</li> <li>Second Reminder: 2 weeks after first (if no response)</li> <li>Final Reminder: 4 weeks after first (if no response)</li> </ol> <p>Suppression Rules: - Don't send if customer has scheduled service - Don't send if reminder sent in last 60 days - Don't send if customer opted out</p>"},{"location":"email_reminder_timing_eda/#success-metrics-to-track","title":"Success Metrics to Track","text":"<ol> <li>Open Rate: % of reminders opened</li> <li>Click Rate: % who click call-to-action</li> <li>Conversion Rate: % who schedule service</li> <li>Time to Response: Days between email and scheduling</li> <li>Opt-out Rate: % who unsubscribe</li> </ol>"},{"location":"email_reminder_timing_eda/#implementation-in-code","title":"Implementation in Code","text":"<p>The current implementation (in <code>routes/email_reminders.py</code>) uses: - Fixed Window: 335-365 days since last cleaning - Suppression: No reminders if sent in last 60 days</p>"},{"location":"email_reminder_timing_eda/#recommended-improvements","title":"Recommended Improvements","text":"<ol> <li> <p>Add Customer Segmentation: <pre><code>def get_customer_segment(customer):\n    avg_interval = calculate_avg_interval(customer)\n    if avg_interval &lt; 180:\n        return 'high_frequency', 150  # 5 months\n    elif avg_interval &lt; 270:\n        return 'semi_annual', 240  # 8 months\n    elif avg_interval &lt; 450:\n        return 'annual', 335  # 11 months\n    else:\n        return 'low_frequency', 450  # 15 months\n</code></pre></p> </li> <li> <p>Track Email Metrics:</p> </li> <li> <p>Add fields to <code>EmailReminder</code> model:</p> <ul> <li><code>opened_at</code>: When email was opened</li> <li><code>clicked_at</code>: When CTA was clicked</li> <li><code>converted_at</code>: When service was scheduled</li> <li><code>conversion_work_order</code>: Link to resulting work order</li> </ul> </li> <li> <p>A/B Testing:</p> </li> <li>Test different reminder timings</li> <li>Test different email content</li> <li>Measure which performs better</li> </ol>"},{"location":"email_reminder_timing_eda/#data-collection-for-ongoing-optimization","title":"Data Collection for Ongoing Optimization","text":""},{"location":"email_reminder_timing_eda/#metrics-to-collect","title":"Metrics to Collect","text":"<ol> <li>Email Performance:</li> <li>Sent count</li> <li>Open rate</li> <li>Click-through rate</li> <li> <p>Unsubscribe rate</p> </li> <li> <p>Business Metrics:</p> </li> <li>Conversion to scheduled service</li> <li>Revenue attributed to reminders</li> <li> <p>Customer lifetime value impact</p> </li> <li> <p>Timing Analysis:</p> </li> <li>Response time distribution</li> <li>Optimal day of week to send</li> <li>Optimal time of day to send</li> </ol>"},{"location":"email_reminder_timing_eda/#recommended-dashboard","title":"Recommended Dashboard","text":"<p>Create an analytics view showing: - Reminders sent this month - Conversion rate trend - Revenue attributed to reminders - Optimal timing insights</p>"},{"location":"email_reminder_timing_eda/#next-steps","title":"Next Steps","text":"<ol> <li>Run Initial Analysis: Execute SQL queries above on production data</li> <li>Validate Assumptions: Check if 11-month default is optimal</li> <li>Implement Segmentation: Add customer-specific timing logic</li> <li>Track Metrics: Begin collecting email performance data</li> <li>Iterate: Adjust timing based on real-world results</li> </ol>"},{"location":"email_reminder_timing_eda/#tools-resources","title":"Tools &amp; Resources","text":"<ul> <li>Analysis: Run queries in PostgreSQL directly or via Jupyter notebook</li> <li>Visualization: Use Plotly (already in stack) for charts</li> <li>Monitoring: Add to Analytics dashboard</li> <li>Testing: Use existing pytest framework for validation</li> </ul>"},{"location":"email_reminder_timing_eda/#conclusion","title":"Conclusion","text":"<p>The current 11-month reminder timing is a reasonable starting point based on industry standards for annual awning cleaning. However, personalized timing based on each customer's historical patterns will likely improve conversion rates significantly.</p> <p>Start with the fixed timing, collect data, then iterate toward personalized, segment-based timing as patterns emerge.</p>"},{"location":"architecture/CACHING_GUIDE/","title":"Caching Implementation Guide","text":""},{"location":"architecture/CACHING_GUIDE/#whats-been-implemented","title":"What's Been Implemented","text":""},{"location":"architecture/CACHING_GUIDE/#core-setup-complete","title":"Core Setup (Complete)","text":"<ul> <li>\u2705 Flask-Caching installed and configured</li> <li>\u2705 SimpleCache for production/dev (in-memory)</li> <li>\u2705 NullCache for tests (no caching during tests)</li> <li>\u2705 Cache utilities in <code>utils/cache_helpers.py</code></li> </ul>"},{"location":"architecture/CACHING_GUIDE/#customer-routes-complete","title":"Customer Routes (Complete)","text":"<p>File: <code>routes/customers.py</code> - \u2705 Cached <code>get_customer_filter_options()</code> - 10min cache - \u2705 Cache invalidation in create/edit/delete - Savings: 2 queries eliminated per page load</p>"},{"location":"architecture/CACHING_GUIDE/#recommended-additions","title":"Recommended Additions","text":""},{"location":"architecture/CACHING_GUIDE/#high-priority-easy-wins","title":"High Priority (Easy Wins)","text":""},{"location":"architecture/CACHING_GUIDE/#1-source-routes-routessourcepy","title":"1. Source Routes (<code>routes/source.py</code>)","text":"<p>Similar to customers - filter dropdowns rarely change.</p> <pre><code>@cache.memoize(timeout=900)  # 15 minutes\ndef get_source_filter_options():\n    states = db.session.query(Source.SourceState).distinct().all()\n    return unique_states\n\n# Invalidate in: create_source(), edit_source(), delete_source()\n</code></pre> <p>Impact: 1-2 queries saved per source list page load</p>"},{"location":"architecture/CACHING_GUIDE/#2-dashboard-metrics-routesdashboardpy","title":"2. Dashboard Metrics (<code>routes/dashboard.py</code>)","text":"<p>Counts and stats don't need to be real-time.</p> <pre><code>@cache.memoize(timeout=300)  # 5 minutes\ndef get_dashboard_counts():\n    pending = WorkOrder.query.filter(...).count()\n    in_progress = WorkOrder.query.filter(...).count()\n    completed_today = WorkOrder.query.filter(...).count()\n    return {'pending': pending, 'in_progress': in_progress, ...}\n\n# Invalidate when work orders change\n</code></pre> <p>Impact: 3-5 count queries saved per dashboard load</p>"},{"location":"architecture/CACHING_GUIDE/#3-analytics-data-routesanalyticspy","title":"3. Analytics Data (<code>routes/analytics.py</code>)","text":"<p>Most expensive - pandas/plotly operations.</p> <pre><code>@cache.memoize(timeout=1800)  # 30 minutes\ndef get_revenue_chart_data(date_range):\n    df = pd.read_sql(query, db.engine)\n    # ... expensive processing ...\n    return fig.to_json()\n\n# Invalidate when work orders completed\n</code></pre> <p>Impact: Huge - 2-5 second queries reduced to milliseconds</p>"},{"location":"architecture/CACHING_GUIDE/#medium-priority","title":"Medium Priority","text":""},{"location":"architecture/CACHING_GUIDE/#4-work-order-filter-options-routeswork_orderspy","title":"4. Work Order Filter Options (<code>routes/work_orders.py</code>)","text":"<p>Similar pattern to customers.</p> <pre><code>@cache.memoize(timeout=600)\ndef get_work_order_filter_options():\n    # Ship-to sources, statuses, etc.\n    pass\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#5-inventory-lookups-routesinventorypy","title":"5. Inventory Lookups (<code>routes/inventory.py</code>)","text":"<p>If customers have large inventories.</p> <pre><code>@cache.memoize(timeout=300)\ndef get_customer_inventory(cust_id):\n    return Inventory.query.filter_by(CustID=cust_id).all()\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#low-priority-optional","title":"Low Priority (Optional)","text":""},{"location":"architecture/CACHING_GUIDE/#6-source-lookups","title":"6. Source Lookups","text":"<p>Frequently accessed but rarely changed.</p> <pre><code>@cache.memoize(timeout=1800)\ndef get_source_by_name(source_name):\n    return Source.query.filter_by(SSource=source_name).first()\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#7-queue-summary-stats-routesqueuepy","title":"7. Queue Summary Stats (<code>routes/queue.py</code>)","text":"<p>If summary endpoint is slow.</p> <pre><code>@cache.memoize(timeout=120)  # 2 minutes - more dynamic\ndef get_queue_summary():\n    # firm_rush_count, rush_count, regular_count\n    pass\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#cache-invalidation-strategy","title":"Cache Invalidation Strategy","text":""},{"location":"architecture/CACHING_GUIDE/#when-to-invalidate","title":"When to Invalidate","text":"Event Invalidate Customer created/edited/deleted <code>invalidate_customer_cache()</code> Source created/edited/deleted <code>invalidate_source_cache()</code> Work order created/edited/completed <code>invalidate_work_order_cache()</code> Repair order created/edited/completed <code>invalidate_repair_order_cache()</code> Dashboard should refresh <code>invalidate_work_order_cache()</code> Analytics should refresh <code>invalidate_analytics_cache()</code> <p>All helpers are in <code>utils/cache_helpers.py</code>.</p>"},{"location":"architecture/CACHING_GUIDE/#testing","title":"Testing","text":"<p>Caching is automatically disabled in tests (<code>CACHE_TYPE = \"NullCache\"</code>).</p> <p>To manually test caching in development:</p> <pre><code># In Flask shell or route\nfrom extensions import cache\n\n# Check if cached\ncached_val = cache.get('some_key')\n\n# Clear specific cache\ncache.delete_memoized(get_customer_filter_options)\n\n# Clear all caches\ncache.clear()\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#performance-monitoring","title":"Performance Monitoring","text":"<p>To see cache effectiveness, enable SQLAlchemy query logging:</p> <pre><code># In development\nimport logging\nlogging.basicConfig()\nlogging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n# Load page twice - second time should show fewer queries\n</code></pre>"},{"location":"architecture/CACHING_GUIDE/#notes","title":"Notes","text":"<ul> <li>SimpleCache is in-memory and process-specific</li> <li>Cache is cleared on app restart (by design)</li> <li>For 8 users and 50MB DB, this is perfect</li> <li>If you scale beyond 1 instance, consider Redis (but not needed now)</li> <li>Cache timeouts are conservative - adjust based on usage patterns</li> </ul>"},{"location":"architecture/CACHING_GUIDE/#quick-reference","title":"Quick Reference","text":"<pre><code># Import in routes\nfrom extensions import cache\nfrom utils.cache_helpers import invalidate_customer_cache\n\n# Cache a function\n@cache.memoize(timeout=600)  # seconds\ndef my_expensive_query():\n    return db.session.query(...).all()\n\n# Invalidate when data changes\ndb.session.commit()\ninvalidate_customer_cache()\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/","title":"Concurrency &amp; Race Condition Audit Report","text":"<p>Date: 2025-10-12 Application: Awning Work Order Management System Target Load: 8 concurrent users on AWS Elastic Beanstalk</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#executive-summary","title":"Executive Summary","text":"<p>This audit identified 11 distinct concurrency issues in the Flask application, ranging from critical race conditions in ID generation to architectural concerns with global state management. The application is generally well-structured with good practices, but several issues could cause data corruption or inconsistent behavior under concurrent load.</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#issue-breakdown","title":"Issue Breakdown","text":"<ul> <li>\ud83d\udd34 Critical (4): Race conditions that can cause data corruption</li> <li>\ud83d\udfe1 High Priority (3): Architectural issues affecting consistency</li> <li>\ud83d\udfe0 Medium Priority (4): Potential data loss or inconsistency scenarios</li> </ul>"},{"location":"architecture/CONCURRENCY_AUDIT/#critical-issues","title":"\ud83d\udd34 Critical Issues","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#1-race-condition-work-order-number-generation","title":"1. Race Condition: Work Order Number Generation","text":"<p>Impact: Duplicate work order numbers under concurrent load Location: <code>routes/work_orders.py:355-358</code> Affected Operations: Creating new work orders</p> <p>Current Code: <pre><code>latest_num = db.session.query(func.max(cast(WorkOrder.WorkOrderNo, Integer))).scalar()\nnext_wo_no = str(latest_num + 1) if latest_num is not None else \"1\"\n</code></pre></p> <p>Problem: Two simultaneous requests can retrieve the same max value and attempt to create work orders with identical numbers.</p> <p>Solution: - Add UNIQUE constraint to <code>WorkOrderNo</code> in database - Implement retry logic with IntegrityError handling - Use database sequences or serial columns</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#2-race-condition-customer-id-generation","title":"2. Race Condition: Customer ID Generation","text":"<p>Impact: Duplicate customer IDs Location: <code>routes/customers.py:220-223</code> Affected Operations: Creating new customers</p> <p>Current Code: <pre><code>max_cust_id = db.session.query(func.max(cast(Customer.CustID, Integer))).scalar()\nnew_cust_id = str(max_cust_id + 1) if max_cust_id else \"1\"\n</code></pre></p> <p>Problem: Same read-then-increment race condition as work orders.</p> <p>Solution: Same as Issue #1</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#3-race-condition-repair-order-number-generation","title":"3. Race Condition: Repair Order Number Generation","text":"<p>Impact: Duplicate repair order numbers Location: <code>routes/repair_order.py:366-377</code> Affected Operations: Creating new repair orders</p> <p>Current Code: <pre><code>latest_order = RepairWorkOrder.query.order_by(desc(RepairWorkOrder.RepairOrderNo)).first()\nif latest_order:\n    try:\n        next_num = int(latest_order.RepairOrderNo) + 1\n    except ValueError:\n        next_num = int(datetime.now().timestamp())\nelse:\n    next_num = 1\n</code></pre></p> <p>Problem: Same pattern - vulnerable to concurrent creation.</p> <p>Solution: Same as Issue #1</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#4-race-condition-queue-position-updates","title":"4. Race Condition: Queue Position Updates","text":"<p>Impact: Conflicting queue position assignments Location: <code>routes/queue.py:481-493</code> Affected Operations: Manual queue reordering</p> <p>Current Code: <pre><code>for index, wo_id in enumerate(work_order_ids):\n    work_order = WorkOrder.query.filter_by(WorkOrderNo=wo_id).first()\n    work_order.QueuePosition = start_position + index\ndb.session.commit()\n</code></pre></p> <p>Problem: Two users reordering simultaneously can create position conflicts.</p> <p>Solution: - Use <code>SELECT FOR UPDATE</code> (pessimistic locking) - Add version column for optimistic locking - Add mutex/lock for queue operations</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#high-priority-issues","title":"\ud83d\udfe1 High Priority Issues","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#5-global-mutable-state-ml-model","title":"5. Global Mutable State: ML Model","text":"<p>Impact: Inconsistent predictions, model update race conditions Location: <code>routes/ml.py:49-50</code> Affected Operations: ML predictions, model retraining</p> <p>Current Code: <pre><code>current_model = None\nmodel_metadata = {}\n</code></pre></p> <p>Problem: - Global variables shared across requests in same worker - No synchronization during updates - Each Gunicorn worker has different model state - Race conditions during concurrent predictions and retraining</p> <p>Solution: - Use threading.Lock for model updates - Store model in Redis or shared storage - Load model on worker startup - Implement proper multi-worker coordination</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#6-weak-authentication-ml-cron-endpoint","title":"6. Weak Authentication: ML Cron Endpoint","text":"<p>Impact: Unauthorized model retraining Location: <code>routes/ml.py:704-712</code> Affected Operations: Automated ML model retraining</p> <p>Current Code: <pre><code>secret = request.headers.get(\"X-Cron-Secret\") or (request.json or {}).get(\"secret\")\nexpected_secret = os.getenv(\"CRON_SECRET\", \"your-secret-key\")\nif secret != expected_secret:\n    return jsonify({\"error\": \"Unauthorized\"}), 401\n</code></pre></p> <p>Problem: Only header-based secret, no additional protection</p> <p>Solution: - Add IP whitelist for cron jobs - Implement rate limiting - Use request signing with timestamp - Consider AWS EventBridge with IAM</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#7-missing-transaction-boundaries","title":"7. Missing Transaction Boundaries","text":"<p>Impact: Partial updates on failure Location: Multiple routes (e.g., <code>repair_order.py:661-663</code>) Affected Operations: Repair order item updates</p> <p>Current Code: <pre><code>RepairWorkOrderItem.query.filter_by(RepairOrderNo=repair_order_no).delete()\n# ... then add new items\n</code></pre></p> <p>Problem: If process fails after delete but before adding new items, data is lost.</p> <p>Solution: - Use explicit <code>db.session.begin_nested()</code> for savepoints - Ensure atomic delete+insert operations - Add proper rollback on any exception</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#medium-priority-issues","title":"\ud83d\udfe0 Medium Priority Issues","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#8-inventory-quantity-race-condition","title":"8. Inventory Quantity Race Condition","text":"<p>Impact: Lost inventory updates Location: <code>routes/work_orders.py:624-630</code> Affected Operations: Adding new items to catalog</p> <p>Current Code: <pre><code>current_catalog_qty = safe_int_conversion(existing_inventory.Qty)\nnew_catalog_qty = current_catalog_qty + work_order_qty\nexisting_inventory.Qty = str(new_catalog_qty)\n</code></pre></p> <p>Problem: Read-modify-write without locking; concurrent additions lose updates</p> <p>Solution: Use atomic SQL update <pre><code>db.session.query(Inventory).filter_by(\n    InventoryKey=key\n).update({\n    Inventory.Qty: Inventory.Qty + work_order_qty\n})\n</code></pre></p>"},{"location":"architecture/CONCURRENCY_AUDIT/#9-cache-invalidation-timing","title":"9. Cache Invalidation Timing","text":"<p>Impact: Stale cache on commit failure Location: <code>routes/customers.py:259, 328, 372</code> Affected Operations: Customer create/update/delete</p> <p>Current Pattern: <pre><code>db.session.commit()\ninvalidate_customer_cache()  # After commit\n</code></pre></p> <p>Problem: If commit fails after cache invalidation is called (in exception handler), cache is unnecessarily cleared.</p> <p>Solution: Invalidate only after successful commit (current code is actually correct, but add explicit error handling)</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#10-file-upload-transaction-coordination","title":"10. File Upload Transaction Coordination","text":"<p>Impact: Orphaned S3 files on database failure Location: <code>utils/file_upload.py</code> Affected Operations: Work order and repair order file uploads</p> <p>Problem: S3 upload happens before database commit. If commit fails, S3 files remain orphaned.</p> <p>Solution: - Upload to S3 AFTER database commit succeeds - Implement cleanup job for orphaned files - Use two-phase commit pattern - Store files locally first, upload async</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#11-backlink-update-race-condition","title":"11. Backlink Update Race Condition","text":"<p>Impact: Unexpected overwrite of repair-to-work-order links Location: <code>routes/work_orders.py:422-433</code> Affected Operations: Linking work orders to repair orders</p> <p>Current Code: <pre><code>if see_repair and see_repair.strip():\n    referenced_repair = RepairWorkOrder.query.filter_by(\n        RepairOrderNo=see_repair.strip()\n    ).first()\n    if referenced_repair:\n        referenced_repair.SEECLEAN = next_wo_no\n</code></pre></p> <p>Problem: Two work orders linking to same repair simultaneously can cause last-write-wins.</p> <p>Solution: - Use optimistic locking with version column - Add validation for conflicting links - Consider link table instead of direct foreign keys</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#good-practices-found","title":"\u2705 Good Practices Found","text":"<ol> <li>Proper exception handling with <code>db.session.rollback()</code></li> <li>Connection pool configuration - <code>pool_size=10</code>, <code>max_overflow=20</code></li> <li>Pool pre-ping enabled to prevent stale connections</li> <li>Connection recycling at 300s</li> <li>CSRF protection enabled</li> <li>Role-based access control with decorators</li> <li>Eager loading with <code>joinedload()</code> prevents N+1 queries</li> <li>Denormalized data (<code>source_name</code>) for performance</li> <li>Inventory as \"static catalog only\" avoids complex stock management races</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#configuration-review","title":"Configuration Review","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#current-database-pool-settings-configpy","title":"Current Database Pool Settings (<code>config.py</code>)","text":"<pre><code>SQLALCHEMY_ENGINE_OPTIONS = {\n    \"pool_pre_ping\": True,\n    \"pool_recycle\": 300,\n    \"pool_size\": 10,\n    \"max_overflow\": 20,\n}\n</code></pre> <p>Assessment: \u2705 Excellent for 8 concurrent users - 10 persistent connections + 20 overflow = 30 max connections - Well-sized for 8 users with buffer</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#cache-configuration-configpy","title":"Cache Configuration (<code>config.py</code>)","text":"<pre><code>CACHE_TYPE = \"SimpleCache\"  # In-memory, thread-safe\nCACHE_DEFAULT_TIMEOUT = 300\n</code></pre> <p>Assessment: \u26a0\ufe0f Not ideal for multi-worker deployment - <code>SimpleCache</code> is thread-safe but NOT process-safe - Each Gunicorn worker has separate cache - Cache invalidation only affects one worker</p> <p>Recommendation: Use Redis for production <pre><code>CACHE_TYPE = \"redis\"\nCACHE_REDIS_URL = \"redis://localhost:6379/0\"\n</code></pre></p>"},{"location":"architecture/CONCURRENCY_AUDIT/#session-configuration","title":"Session Configuration","text":"<pre><code>PERMANENT_SESSION_LIFETIME = timedelta(hours=24)\nSESSION_COOKIE_SECURE = FLASK_ENV == \"production\"\nSESSION_COOKIE_HTTPONLY = True\n</code></pre> <p>Assessment: \u2705 Good security practices</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#recommended-action-plan","title":"Recommended Action Plan","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#phase-1-critical-fixes-week-1","title":"Phase 1: Critical Fixes (Week 1)","text":"<ol> <li>Add UNIQUE constraints to database schema</li> <li>Implement retry logic for ID generation</li> <li>Add threading.Lock to ML model updates</li> <li>Use SELECT FOR UPDATE for queue operations</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#phase-2-high-priority-week-2","title":"Phase 2: High Priority (Week 2)","text":"<ol> <li>Migrate to Redis cache</li> <li>Strengthen cron endpoint security</li> <li>Add explicit transaction boundaries</li> <li>Implement ML model coordination across workers</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#phase-3-medium-priority-week-3-4","title":"Phase 3: Medium Priority (Week 3-4)","text":"<ol> <li>Fix inventory atomic updates</li> <li>Improve file upload transaction handling</li> <li>Add optimistic locking for backlinks</li> <li>Implement orphaned file cleanup job</li> </ol>"},{"location":"architecture/CONCURRENCY_AUDIT/#testing-recommendations","title":"Testing Recommendations","text":""},{"location":"architecture/CONCURRENCY_AUDIT/#load-testing","title":"Load Testing","text":"<pre><code># Apache Bench - 100 requests, 8 concurrent\nab -n 100 -c 8 -p form_data.json -T application/json \\\n   http://your-app/work_orders/new\n\n# Check for duplicate IDs\npsql -c \"SELECT workorderno, COUNT(*) FROM tblcustworkorderdetail\n         GROUP BY workorderno HAVING COUNT(*) &gt; 1;\"\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/#locust-test-script","title":"Locust Test Script","text":"<pre><code>from locust import HttpUser, task, between\n\nclass WorkOrderUser(HttpUser):\n    wait_time = between(1, 3)\n\n    @task(3)\n    def create_work_order(self):\n        self.client.post(\"/work_orders/new\", json={...})\n\n    @task(1)\n    def reorder_queue(self):\n        self.client.post(\"/cleaning_queue/api/cleaning-queue/reorder\", json={...})\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/#monitor-for-issues","title":"Monitor for Issues","text":"<ul> <li>Database: Look for duplicate primary keys in logs</li> <li>Connection pool: Watch for pool exhaustion warnings</li> <li>ML predictions: Compare predictions across multiple requests</li> <li>Queue: Check for position conflicts</li> </ul>"},{"location":"architecture/CONCURRENCY_AUDIT/#database-schema-additions-needed","title":"Database Schema Additions Needed","text":"<pre><code>-- Add unique constraints\nALTER TABLE tblcustworkorderdetail\n  ADD CONSTRAINT uk_workorderno UNIQUE (workorderno);\n\nALTER TABLE tblcustomers\n  ADD CONSTRAINT uk_custid UNIQUE (custid);\n\nALTER TABLE tblrepairworkorder\n  ADD CONSTRAINT uk_repairorderno UNIQUE (repairorderno);\n\n-- Add version column for optimistic locking (optional)\nALTER TABLE tblcustworkorderdetail\n  ADD COLUMN version INTEGER DEFAULT 0;\n\nALTER TABLE tblrepairworkorder\n  ADD COLUMN version INTEGER DEFAULT 0;\n</code></pre>"},{"location":"architecture/CONCURRENCY_AUDIT/#gunicorn-configuration","title":"Gunicorn Configuration","text":"<p>Recommended <code>gunicorn.conf.py</code>: <pre><code>workers = 3  # CPU cores\nthreads = 2  # 3 * 2 = 6 concurrent handlers\nworker_class = 'gthread'\ntimeout = 120\nkeepalive = 5\nmax_requests = 1000\nmax_requests_jitter = 100\n</code></pre></p> <p>Total capacity: 6 concurrent request handlers for 8 users = \u2705 Adequate</p>"},{"location":"architecture/CONCURRENCY_AUDIT/#conclusion","title":"Conclusion","text":"<p>The application has a solid foundation with good database configuration and security practices. The main concerns are:</p> <ol> <li>ID generation race conditions - highest priority, can cause immediate data corruption</li> <li>Global ML model state - architectural issue affecting prediction consistency</li> <li>Multi-worker cache coordination - causes stale data across workers</li> </ol> <p>For 8 concurrent users, these issues are manageable but should be fixed to prevent: - Duplicate order numbers (confusing for staff) - Inconsistent ML predictions (erodes trust in system) - Stale cached data (customer sees old information)</p> <p>Estimated effort: 2-3 weeks for comprehensive fixes across all priority levels.</p> <p>Risk assessment: - Without fixes: Medium risk - issues will surface occasionally under load - With Phase 1 fixes: Low risk - critical data integrity issues resolved - With all phases: Very low risk - production-ready for concurrent users</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/","title":"Work Order List Query Performance Analysis","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#executive-summary","title":"Executive Summary","text":"<p>Your database is 60MB with 49,074 work orders, and most queries are ALREADY VERY FAST (&lt; 1ms execution time). However, there are 3 critical bottlenecks that need fixing:</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#critical-issues-found","title":"\ud83d\udea8 Critical Issues Found:","text":"<ol> <li>WorkOrderNo filters with CAST - 9-15ms (should be &lt; 1ms)</li> <li>DateRequired sorting - 16ms with Seq Scan (should be &lt; 1ms)</li> <li>Source sorting - 93ms with 3x Seq Scans (should be &lt; 10ms)</li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#whats-working-well","title":"\u2705 What's Working Well:","text":"<ul> <li>Primary key lookups: 0.086ms \u26a1</li> <li>Pending filter: 0.213ms \u26a1</li> <li>Rush orders: 0.086ms \u26a1</li> <li>CustID filter: 0.035ms \u26a1</li> <li>WOName text search: 0.237ms \u26a1</li> <li>DateIn sorting: 0.070ms \u26a1</li> <li>Customer joins: Well-optimized with Memoize</li> </ul>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#detailed-query-analysis","title":"Detailed Query Analysis","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-1-baseline-default-sort-by-workorderno","title":"Query #1: Baseline (Default Sort by WorkOrderNo)","text":"<p>Route: <code>/api/work_orders?page=1&amp;size=25</code></p> <pre><code>Execution Time: 0.086 ms \u26a1\nMethod: Index Scan Backward using tblcustworkorderdetail_pkey\nBuffers: shared hit=4 (all cached)\n</code></pre> <p>Status: \u2705 PERFECT - Using primary key index efficiently.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-2-count-query-pagination-total","title":"Query #2: Count Query (Pagination Total)","text":"<p>Route: Used for pagination total count</p> <pre><code>Execution Time: 7.215 ms\nMethod: Index Only Scan using idx_workorder_datein\nBuffers: shared hit=331\nHeap Fetches: 650 (needs to check visibility)\n</code></pre> <p>Status: \u26a0\ufe0f ACCEPTABLE - Count queries are inherently slower. 7ms is reasonable for 49K rows.</p> <p>Note: This is why modern UIs use \"approximate counts\" or \"load more\" instead of pagination.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-3-with-customer-join","title":"Query #3: With Customer Join","text":"<p>Route: <code>/api/work_orders</code> (default view with customer data)</p> <pre><code>Execution Time: 0.840 ms \u26a1\nMethod: Nested Loop with Memoize\nBuffers: shared hit=76\nMemoize: Hits=1, Misses=24 (96% cache hit rate)\n</code></pre> <p>Status: \u2705 EXCELLENT - PostgreSQL's Memoize feature is working perfectly to avoid N+1 queries.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-4-with-source-join","title":"Query #4: With Source Join","text":"<p>Route: <code>/api/work_orders</code> (when filtering or sorting by Source)</p> <pre><code>Execution Time: 0.758 ms \u26a1\nMethod: Double Nested Loop with double Memoize\nBuffers: shared hit=91\n</code></pre> <p>Status: \u2705 EXCELLENT - Even with 2 joins, still under 1ms.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-5-pending-filter-most-common","title":"Query #5: Pending Filter (Most Common)","text":"<p>Route: <code>/api/work_orders?status=pending</code></p> <pre><code>Execution Time: 0.213 ms \u26a1\nMethod: Index Scan using idx_workorder_pending\nBuffers: shared hit=24\n</code></pre> <p>Status: \u2705 PERFECT - Partial index working beautifully.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-6-completed-filter","title":"Query #6: Completed Filter","text":"<p>Route: <code>/api/work_orders?status=completed</code></p> <pre><code>Execution Time: 0.038 ms \u26a1\u26a1\nMethod: Index Scan Backward with filter\nBuffers: shared hit=4\n</code></pre> <p>Status: \u2705 PERFECT - Extremely fast.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-7-rush-orders","title":"Query #7: Rush Orders","text":"<p>Route: <code>/api/work_orders?status=rush</code></p> <pre><code>Execution Time: 0.086 ms \u26a1\nMethod: Bitmap Index Scan on idx_workorder_rush\nBuffers: shared hit=7\n</code></pre> <p>Status: \u2705 PERFECT - Rush order index working great.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-8-workorderno-range-filter-problem-1","title":"Query #8: \ud83d\udea8 WorkOrderNo Range Filter (PROBLEM #1)","text":"<p>Route: <code>/api/work_orders?filter_WorkOrderNo=100-200</code></p> <pre><code>Execution Time: 14.620 ms \ud83d\udc0c\nMethod: Index Scan with CAST filter\nBuffers: shared hit=2780\nRows Removed by Filter: 49,074 (FULL TABLE SCAN!)\n</code></pre> <p>Status: \ud83d\udea8 CRITICAL ISSUE</p> <p>Problem: <pre><code>Filter: (((wo.workorderno)::integer &gt;= 100) AND ((wo.workorderno)::integer &lt;= 200))\n</code></pre></p> <p>The <code>CAST(workorderno AS INTEGER)</code> prevents index usage, causing a full table scan.</p> <p>Solution: Create a computed index or change WorkOrderNo to an integer column.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-9-workorderno-exact-filter-problem-2","title":"Query #9: \ud83d\udea8 WorkOrderNo Exact Filter (PROBLEM #2)","text":"<p>Route: <code>/api/work_orders?filter_WorkOrderNo=100</code></p> <pre><code>Execution Time: 9.504 ms \ud83d\udc0c\nMethod: Index Scan with CAST filter\nBuffers: shared hit=2780\nRows Removed by Filter: 49,074 (FULL TABLE SCAN!)\n</code></pre> <p>Status: \ud83d\udea8 CRITICAL ISSUE - Same as Query #8.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-10-custid-filter","title":"Query #10: CustID Filter","text":"<p>Route: <code>/api/work_orders?filter_CustID=123</code></p> <pre><code>Execution Time: 0.035 ms \u26a1\u26a1\nMethod: Index Scan using idx_workorder_custid\nBuffers: shared hit=2\n</code></pre> <p>Status: \u2705 PERFECT - Extremely fast.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-11-woname-text-search","title":"Query #11: WOName Text Search","text":"<p>Route: <code>/api/work_orders?filter_WOName=test</code></p> <pre><code>Execution Time: 0.237 ms \u26a1\nMethod: Bitmap Index Scan on idx_workorder_woname_trgm\nBuffers: shared hit=22\n</code></pre> <p>Status: \u2705 EXCELLENT - Trigram index working great for ILIKE searches.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-12-source-filter","title":"Query #12: Source Filter","text":"<p>Route: <code>/api/work_orders?filter_Source=Smith</code></p> <pre><code>Execution Time: 0.071 ms \u26a1\u26a1\nMethod: Nested Loop with multiple indexes\nBuffers: shared hit=7\n</code></pre> <p>Status: \u2705 PERFECT - Complex join with multiple indexes, still under 1ms.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-13-sort-by-datein","title":"Query #13: Sort by DateIn","text":"<p>Route: <code>/api/work_orders?sort[0][field]=DateIn&amp;sort[0][dir]=desc</code></p> <pre><code>Execution Time: 0.070 ms \u26a1\u26a1\nMethod: Index Scan using idx_workorder_datein\nBuffers: shared hit=26\n</code></pre> <p>Status: \u2705 PERFECT - DateIn index working perfectly.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-14-sort-by-daterequired-problem-3","title":"Query #14: \ud83d\udea8 Sort by DateRequired (PROBLEM #3)","text":"<p>Route: <code>/api/work_orders?sort[0][field]=DateRequired&amp;sort[0][dir]=asc</code></p> <pre><code>Execution Time: 16.321 ms \ud83d\udc0c\nMethod: Sort with Seq Scan\nBuffers: shared hit=1267\nRows scanned: 49,074 (FULL TABLE SCAN!)\n</code></pre> <p>Status: \ud83d\udea8 NEEDS INDEX</p> <p>Problem: No index on <code>daterequired</code>, forcing a full table scan + in-memory sort.</p> <p>Solution: Add index on <code>daterequired</code>.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-15-sort-by-source-problem-4","title":"Query #15: \ud83d\udea8 Sort by Source (PROBLEM #4)","text":"<p>Route: <code>/api/work_orders?sort[0][field]=Source&amp;sort[0][dir]=asc</code></p> <pre><code>Execution Time: 93.005 ms \ud83d\udc0c\ud83d\udc0c\nMethod: Hash Join with 3x Seq Scans\nBuffers: shared hit=1673\n</code></pre> <p>Status: \ud83d\udea8 CRITICAL PERFORMANCE ISSUE</p> <p>Problem: - Seq Scan on <code>tblcustworkorderdetail</code> (49K rows) - Seq Scan on <code>tblcustomers</code> (26K rows) - Seq Scan on <code>tblsource</code> (563 rows) - Then Hash Join + Sort</p> <p>Solution: This query pattern is inherently expensive. Consider: 1. Denormalizing source name into work orders table 2. Using a materialized view 3. Caching this query result</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-16-complex-query-pending-filter-sort","title":"Query #16: Complex Query (Pending + Filter + Sort)","text":"<p>Route: <code>/api/work_orders?status=pending&amp;filter_WOName=test&amp;sort[0][field]=DateIn</code></p> <pre><code>Execution Time: 0.111 ms \u26a1\nMethod: BitmapAnd with multiple indexes\nBuffers: shared hit=8\n</code></pre> <p>Status: \u2705 EXCELLENT - Multiple indexes combined efficiently.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#query-17-deep-pagination","title":"Query #17: Deep Pagination","text":"<p>Route: <code>/api/work_orders?page=10&amp;size=25</code></p> <pre><code>Execution Time: 0.111 ms \u26a1\nMethod: Index Scan Backward with offset\nBuffers: shared hit=11\n</code></pre> <p>Status: \u2705 EXCELLENT - Even deep pagination is fast with index.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#performance-issues-summary","title":"Performance Issues Summary","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#issue-1-workorderno-cast-operations","title":"\ud83d\udea8 Issue #1: WorkOrderNo CAST Operations","text":"<p>Impact: Medium (14ms for range, 9ms for exact match) Frequency: Unknown (depends on user filtering behavior) Affected Queries: #8, #9</p> <p>Root Cause: - <code>workorderno</code> is stored as <code>VARCHAR/TEXT</code> - Filters require <code>CAST(workorderno AS INTEGER)</code> for numeric comparison - CAST prevents index usage \u2192 full table scan</p> <p>Solutions (pick one):</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-a-create-function-based-index-recommended","title":"Option A: Create Function-Based Index (RECOMMENDED)","text":"<p><pre><code>CREATE INDEX idx_workorder_no_int\nON tblcustworkorderdetail((workorderno::integer));\n</code></pre> Pros: No schema changes, backward compatible Cons: Adds index storage overhead</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-b-change-column-type","title":"Option B: Change Column Type","text":"<p><pre><code>ALTER TABLE tblcustworkorderdetail\nALTER COLUMN workorderno TYPE INTEGER USING workorderno::integer;\n</code></pre> Pros: Best performance, removes CAST overhead Cons: Requires application changes, migration effort</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#issue-2-daterequired-sorting","title":"\ud83d\udea8 Issue #2: DateRequired Sorting","text":"<p>Impact: Medium (16ms) Frequency: Likely low (DateIn sorting is more common) Affected Queries: #14</p> <p>Root Cause: No index on <code>daterequired ASC NULLS LAST</code></p> <p>Solution: <pre><code>CREATE INDEX idx_workorder_daterequired_asc\nON tblcustworkorderdetail(daterequired ASC NULLS LAST);\n</code></pre></p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#issue-3-source-sorting","title":"\ud83d\udea8 Issue #3: Source Sorting","text":"<p>Impact: CRITICAL (93ms - 100x slower than other sorts) Frequency: Unknown Affected Queries: #15</p> <p>Root Cause: - Requires joining 3 tables: work_orders \u2192 customers \u2192 sources - No way to avoid scanning all 49K work orders + 26K customers - Hash join is expensive</p> <p>Solutions (ranked):</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-a-denormalize-source-into-work-orders-best","title":"Option A: Denormalize Source into Work Orders (BEST)","text":"<p><pre><code>ALTER TABLE tblcustworkorderdetail ADD COLUMN source_name TEXT;\nCREATE INDEX idx_workorder_source_name ON tblcustworkorderdetail(source_name);\n\n-- Populate\nUPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nJOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n\n-- Maintain with trigger or application logic\n</code></pre> Pros: 100x faster (will be ~1ms), simple queries Cons: Data duplication, need to maintain consistency</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-b-materialized-view","title":"Option B: Materialized View","text":"<p><pre><code>CREATE MATERIALIZED VIEW work_orders_with_source AS\nSELECT wo.*, s.ssource as source_name\nFROM tblcustworkorderdetail wo\nLEFT JOIN tblcustomers c ON wo.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource;\n\nCREATE INDEX ON work_orders_with_source(source_name);\nREFRESH MATERIALIZED VIEW CONCURRENTLY work_orders_with_source;\n</code></pre> Pros: No schema changes, can be refreshed periodically Cons: Stale data, requires refresh strategy</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-c-cache-the-query-result","title":"Option C: Cache the Query Result","text":"<p>Use application-level caching (Redis, Memcached) with TTL.</p> <p>Pros: No database changes Cons: Cache invalidation complexity</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#option-d-accept-the-performance","title":"Option D: Accept the Performance","text":"<p>93ms is still under 100ms, which is generally acceptable for user interfaces. If this sort is rarely used, it may not be worth optimizing.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#database-statistics","title":"Database Statistics","text":"<pre><code>Table: tblcustworkorderdetail\n- Size: 17 MB (10 MB table + 7.5 MB indexes)\n- Rows: 49,074\n- Indexes: 9 (well-indexed!)\n\nTable: tblcustomers\n- Size: 7.6 MB (3.2 MB table + 4.4 MB indexes)\n- Rows: 26,841\n\nTable: tblsource\n- Size: 280 KB (56 KB table + 224 KB indexes)\n- Rows: 563\n</code></pre> <p>Analysis: Your database is small and well-indexed. Most slow queries are due to algorithmic issues (CAST, missing indexes) rather than data volume.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#index-usage-summary","title":"Index Usage Summary","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#existing-indexes-all-working-well","title":"Existing Indexes (All Working Well)","text":"<p>\u2705 <code>tblcustworkorderdetail_pkey</code> - Primary key \u2705 <code>idx_workorder_pending</code> - Partial index for incomplete orders \u2705 <code>idx_workorder_completed</code> - Partial index for completed orders \u2705 <code>idx_workorder_custid</code> - Foreign key lookups \u2705 <code>idx_workorder_datein</code> - Date sorting (most common) \u2705 <code>idx_workorder_rush</code> - Rush orders \u2705 <code>idx_workorder_processing</code> - In-progress orders \u2705 <code>idx_workorder_queue</code> - Queue management \u2705 <code>idx_workorder_woname_trgm</code> - Text search (trigram)</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#missing-indexes","title":"Missing Indexes","text":"<p>\u274c <code>(workorderno::integer)</code> - For numeric filters \u274c <code>(daterequired ASC NULLS LAST)</code> - For date sorting \u274c <code>(source_name)</code> - If you denormalize (recommended)</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#recommendations","title":"Recommendations","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#priority-1-do-now","title":"\ud83c\udfaf Priority 1 (Do Now)","text":"<ol> <li> <p>Add WorkOrderNo integer index:    <pre><code>CREATE INDEX CONCURRENTLY idx_workorder_no_int\nON tblcustworkorderdetail((workorderno::integer));\n</code></pre> Impact: Fixes 9-15ms slowdown \u2192 &lt; 1ms</p> </li> <li> <p>Add DateRequired index:    <pre><code>CREATE INDEX CONCURRENTLY idx_workorder_daterequired\nON tblcustworkorderdetail(daterequired ASC NULLS LAST);\n</code></pre> Impact: 16ms \u2192 &lt; 1ms</p> </li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#priority-2-evaluate-costbenefit","title":"\ud83c\udfaf Priority 2 (Evaluate Cost/Benefit)","text":"<ol> <li>Denormalize source name (if Source sorting is frequently used):    <pre><code>ALTER TABLE tblcustworkorderdetail ADD COLUMN source_name TEXT;\nCREATE INDEX idx_workorder_source_name ON tblcustworkorderdetail(source_name);\n</code></pre> Impact: 93ms \u2192 ~1ms    Cost: Schema change, data maintenance</li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#priority-3-optional-optimizations","title":"\ud83c\udfaf Priority 3 (Optional Optimizations)","text":"<ol> <li>Optimize count query (if pagination is slow):</li> <li>Use approximate counts: <code>SELECT reltuples FROM pg_class WHERE relname = 'tblcustworkorderdetail'</code></li> <li> <p>Or implement \"Load More\" UI instead of pagination</p> </li> <li> <p>Monitor query performance with <code>pg_stat_statements</code>:    <pre><code>CREATE EXTENSION pg_stat_statements;\n</code></pre></p> </li> </ol>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#application-level-recommendations","title":"Application-Level Recommendations","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#1-use-eager-loading-already-doing-well","title":"1. Use Eager Loading (Already Doing Well \u2705)","text":"<p>Your code already uses <code>joinedload</code>: <pre><code>query = query.options(joinedload(WorkOrder.customer))\n</code></pre> This is correct and prevents N+1 queries.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#2-avoid-cast-in-filters","title":"2. Avoid CAST in Filters","text":"<p>Consider changing the application code to avoid casting:</p> <p>Current (routes/work_orders.py:978): <pre><code>query = query.filter(\n    cast(WorkOrder.WorkOrderNo, Integer) &gt;= start,\n    cast(WorkOrder.WorkOrderNo, Integer) &lt;= end,\n)\n</code></pre></p> <p>Better (after adding index): <pre><code># Index will now work!\nquery = query.filter(\n    cast(WorkOrder.WorkOrderNo, Integer) &gt;= start,\n    cast(WorkOrder.WorkOrderNo, Integer) &lt;= end,\n)\n</code></pre></p> <p>Or even better, change WorkOrderNo to INTEGER type and remove casts entirely.</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#3-add-database-connection-pooling","title":"3. Add Database Connection Pooling","text":"<p>Ensure you're using SQLAlchemy connection pooling: <pre><code># In config.py\nSQLALCHEMY_ENGINE_OPTIONS = {\n    'pool_size': 10,\n    'max_overflow': 20,\n    'pool_pre_ping': True,  # Verify connections before use\n    'pool_recycle': 3600,   # Recycle connections after 1 hour\n}\n</code></pre></p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#4-consider-caching-for-expensive-queries","title":"4. Consider Caching for Expensive Queries","text":"<p>For the Source sorting query, consider caching: <pre><code>from flask_caching import Cache\n\ncache = Cache(config={'CACHE_TYPE': 'redis'})\n\n@cache.memoize(timeout=300)  # Cache for 5 minutes\ndef get_work_orders_by_source(page, size):\n    # ... expensive query ...\n</code></pre></p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#testing-the-fixes","title":"Testing the Fixes","text":""},{"location":"architecture/PERFORMANCE_ANALYSIS/#step-1-apply-priority-1-indexes","title":"Step 1: Apply Priority 1 Indexes","text":"<pre><code>psql \"postgresql://...\" &lt;&lt;EOF\nCREATE INDEX CONCURRENTLY idx_workorder_no_int\nON tblcustworkorderdetail((workorderno::integer));\n\nCREATE INDEX CONCURRENTLY idx_workorder_daterequired\nON tblcustworkorderdetail(daterequired ASC NULLS LAST);\n\nANALYZE tblcustworkorderdetail;\nEOF\n</code></pre>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#step-2-re-run-analysis","title":"Step 2: Re-run Analysis","text":"<pre><code>psql \"postgresql://...\" -f query_optimization/analyze_work_orders.sql\n</code></pre>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#step-3-verify-improvements","title":"Step 3: Verify Improvements","text":"<p>Expected results: - Query #8 (WorkOrderNo range): 14ms \u2192 &lt; 1ms \u26a1 - Query #9 (WorkOrderNo exact): 9ms \u2192 &lt; 1ms \u26a1 - Query #14 (DateRequired sort): 16ms \u2192 &lt; 1ms \u26a1</p>"},{"location":"architecture/PERFORMANCE_ANALYSIS/#conclusion","title":"Conclusion","text":"<p>Your database is well-architected and well-indexed. Most queries are extremely fast (&lt; 1ms). The issues you're experiencing are likely due to:</p> <ol> <li>Network latency - Even with 1ms queries, network round-trips add overhead</li> <li>Application rendering - React/browser rendering time</li> <li>The 3 specific slow queries identified above</li> </ol> <p>Quick wins: Add the 2 missing indexes (Priority 1). This will take 5 minutes and fix 90% of your slow queries.</p> <p>Bigger optimization: Denormalize source name if Source sorting is critical.</p> <p>Reality check: For a 60MB database with 50K rows, you should expect: - Simple queries: &lt; 5ms \u2705 (you're already there!) - Complex joins: &lt; 50ms \u2705 (you're already there!) - The slowest query (Source sort): &lt; 100ms \u26a0\ufe0f (93ms is acceptable, but fixable)</p> <p>Your queries are close to instantaneous. If the UI feels slow, the bottleneck is likely: - Frontend rendering (check React DevTools) - Network latency (check browser Network tab) - Database connection overhead (use connection pooling)</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/","title":"RAG Chatbot Design for Awning Management System","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#executive-summary","title":"Executive Summary","text":"<p>This document outlines the design and implementation plan for a business-focused RAG (Retrieval-Augmented Generation) chatbot for the Awning Work Order Management System. The chatbot will provide intelligent assistance to users by answering questions about customers, work orders, repair orders, inventory, and business analytics using natural language queries.</p> <p>Key Design Decisions: - Hybrid Architecture: Flask app on Elastic Beanstalk + AWS Lambda for LLM inference - Vector Database: AWS OpenSearch Serverless or PostgreSQL with pgvector extension - LLM Provider: AWS Bedrock (Claude 3.5 Sonnet recommended) or OpenAI API - Embedding Model: Amazon Titan Embeddings or OpenAI text-embedding-3-small - Data Sources: PostgreSQL database, S3 documents, business analytics</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Architecture</li> <li>Component Design</li> <li>Data Pipeline</li> <li>RAG Implementation</li> <li>AWS Lambda Integration</li> <li>Security &amp; Access Control</li> <li>Implementation Phases</li> <li>Cost Estimation</li> <li>Monitoring &amp; Maintenance</li> <li>Alternative Architectures</li> </ol>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#system-architecture","title":"System Architecture","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    User Interface (Browser)                      \u2502\n\u2502                  Flask Templates + JavaScript                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Flask App (Elastic Beanstalk)                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Chat Route (/api/chat)                                   \u2502  \u2502\n\u2502  \u2502  - Authentication &amp; Authorization                         \u2502  \u2502\n\u2502  \u2502  - Query Processing &amp; Context Building                    \u2502  \u2502\n\u2502  \u2502  - Session Management                                      \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                               \u2502\n                \u2502                               \u2502\n                \u25bc                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Vector Search Service       \u2502   \u2502   AWS Lambda Function       \u2502\n\u2502   (OpenSearch/pgvector)       \u2502   \u2502   - LLM Inference           \u2502\n\u2502                               \u2502   \u2502   - Prompt Engineering      \u2502\n\u2502   - Semantic Search           \u2502   \u2502   - Response Generation     \u2502\n\u2502   - Hybrid Search (BM25+Vec)  \u2502   \u2502                             \u2502\n\u2502   - Filtered Search           \u2502   \u2502   Models:                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   - AWS Bedrock (Claude)    \u2502\n                \u2502                   \u2502   - or OpenAI API           \u2502\n                \u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Data Sources                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   PostgreSQL     \u2502  \u2502   S3 Bucket      \u2502  \u2502  Analytics    \u2502 \u2502\n\u2502  \u2502   (RDS)          \u2502  \u2502   - PDFs         \u2502  \u2502  Cache        \u2502 \u2502\n\u2502  \u2502   - Customers    \u2502  \u2502   - Work Orders  \u2502  \u2502               \u2502 \u2502\n\u2502  \u2502   - Work Orders  \u2502  \u2502   - Documents    \u2502  \u2502               \u2502 \u2502\n\u2502  \u2502   - Inventory    \u2502  \u2502                  \u2502  \u2502               \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#architecture-benefits","title":"Architecture Benefits","text":"<ol> <li>Separation of Concerns: Flask handles web logic, Lambda handles compute-intensive LLM calls</li> <li>Cost Efficiency: Lambda only runs when needed, avoiding constant LLM inference costs</li> <li>Scalability: Lambda auto-scales for concurrent users</li> <li>Elastic Beanstalk Compatibility: Minimal changes to existing infrastructure</li> <li>Timeout Handling: Lambda functions support longer timeouts (up to 15 minutes) for complex queries</li> </ol>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#component-design","title":"Component Design","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#1-chat-interface-frontend","title":"1. Chat Interface (Frontend)","text":"<p>Location: <code>templates/chat/</code> and <code>static/js/chat.js</code></p> <p>Features: - Conversational UI with message history - Typing indicators during LLM response - Code/table formatting for structured data - Source citations (links to work orders, customers, etc.) - Quick action buttons (e.g., \"Show me today's queue\") - Voice input support (optional)</p> <p>Technology: - HTML/CSS with existing base template styling - JavaScript (vanilla or lightweight library) - WebSocket or Server-Sent Events for streaming responses - Markdown rendering for formatted responses</p> <p>Example UI: <pre><code>&lt;div class=\"chat-container\"&gt;\n  &lt;div class=\"chat-messages\" id=\"chatMessages\"&gt;\n    &lt;!-- Message history --&gt;\n  &lt;/div&gt;\n  &lt;div class=\"chat-input\"&gt;\n    &lt;textarea id=\"userInput\" placeholder=\"Ask about work orders, customers, inventory...\"&gt;&lt;/textarea&gt;\n    &lt;button id=\"sendBtn\"&gt;Send&lt;/button&gt;\n  &lt;/div&gt;\n  &lt;div class=\"quick-actions\"&gt;\n    &lt;button data-query=\"What work orders are in the queue today?\"&gt;Today's Queue&lt;/button&gt;\n    &lt;button data-query=\"Show me overdue work orders\"&gt;Overdue Orders&lt;/button&gt;\n    &lt;button data-query=\"What's our inventory status?\"&gt;Inventory Status&lt;/button&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#2-flask-chat-route","title":"2. Flask Chat Route","text":"<p>Location: <code>routes/chat.py</code></p> <p>Responsibilities: - Receive user queries - Authenticate and authorize users - Retrieve relevant context from vector database - Build prompts with retrieved context - Invoke AWS Lambda for LLM inference - Stream responses back to frontend - Log conversations for analytics</p> <p>Code Structure: <pre><code># routes/chat.py\nfrom flask import Blueprint, request, jsonify, stream_with_context\nfrom flask_login import login_required, current_user\nimport boto3\nimport json\n\nchat_bp = Blueprint('chat', __name__, url_prefix='/api/chat')\n\n@chat_bp.route('/query', methods=['POST'])\n@login_required\ndef query():\n    \"\"\"\n    Handle user chat queries with RAG pipeline\n    \"\"\"\n    data = request.get_json()\n    user_query = data.get('query')\n    session_id = data.get('session_id')\n\n    # 1. Retrieve relevant context from vector DB\n    context_docs = retrieve_context(user_query, user_id=current_user.id)\n\n    # 2. Build prompt with context\n    prompt = build_prompt(user_query, context_docs, session_id)\n\n    # 3. Invoke Lambda for LLM inference\n    response = invoke_lambda_llm(prompt)\n\n    # 4. Return response with sources\n    return jsonify({\n        'response': response['text'],\n        'sources': response['sources'],\n        'session_id': session_id\n    })\n\ndef retrieve_context(query, user_id, top_k=5):\n    \"\"\"\n    Retrieve relevant documents from vector database\n    \"\"\"\n    # Vector search implementation\n    pass\n\ndef build_prompt(query, context_docs, session_id):\n    \"\"\"\n    Build LLM prompt with retrieved context\n    \"\"\"\n    pass\n\ndef invoke_lambda_llm(prompt):\n    \"\"\"\n    Call AWS Lambda function for LLM inference\n    \"\"\"\n    lambda_client = boto3.client('lambda', region_name='us-east-1')\n\n    payload = {\n        'prompt': prompt,\n        'max_tokens': 1000,\n        'temperature': 0.7\n    }\n\n    response = lambda_client.invoke(\n        FunctionName='awning-rag-llm',\n        InvocationType='RequestResponse',\n        Payload=json.dumps(payload)\n    )\n\n    return json.loads(response['Payload'].read())\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#3-vector-database","title":"3. Vector Database","text":"<p>Option A: PostgreSQL with pgvector (Recommended for MVP)</p> <p>Pros: - Leverages existing RDS PostgreSQL instance - No additional AWS service costs - Familiar SQL interface - Easy integration with existing models</p> <p>Cons: - Less optimized for large-scale vector search - Manual index management</p> <p>Setup: <pre><code>-- Enable pgvector extension\nCREATE EXTENSION IF NOT EXISTS vector;\n\n-- Create embeddings table\nCREATE TABLE document_embeddings (\n    id SERIAL PRIMARY KEY,\n    content TEXT NOT NULL,\n    embedding vector(1536),  -- OpenAI ada-002 or Titan embeddings\n    metadata JSONB,\n    doc_type VARCHAR(50),  -- 'work_order', 'customer', 'inventory', etc.\n    doc_id VARCHAR(100),\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Create index for fast similarity search\nCREATE INDEX ON document_embeddings\nUSING ivfflat (embedding vector_cosine_ops)\nWITH (lists = 100);\n\n-- Create GIN index for metadata filtering\nCREATE INDEX idx_metadata ON document_embeddings USING GIN (metadata);\n</code></pre></p> <p>Option B: AWS OpenSearch Serverless</p> <p>Pros: - Purpose-built for vector search at scale - Serverless (auto-scaling) - Hybrid search (BM25 + vector) - Advanced filtering and faceting</p> <p>Cons: - Additional AWS service cost (~$700/month minimum) - More complex setup - Learning curve for OpenSearch APIs</p> <p>When to Choose: - Use pgvector for MVP and low-medium scale (&lt; 1M documents) - Use OpenSearch for production scale (&gt; 1M documents) or advanced search features</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#4-embedding-pipeline","title":"4. Embedding Pipeline","text":"<p>Location: <code>utils/embeddings.py</code> and <code>scripts/build_embeddings.py</code></p> <p>Responsibilities: - Generate embeddings for all business data - Incremental updates when data changes - Batch processing for initial indexing - Deduplication and chunking strategies</p> <p>Data Sources to Embed:</p> <ol> <li>Work Orders:</li> <li>Order details (WOName, SpecialInstructions, RepairsNeeded)</li> <li>Customer context (name, address, contact)</li> <li>Items (descriptions, materials, conditions)</li> <li> <p>Status and dates</p> </li> <li> <p>Customers:</p> </li> <li>Customer profile (name, contact, address)</li> <li>Order history summaries</li> <li> <p>Source/vendor information</p> </li> <li> <p>Repair Orders:</p> </li> <li>Repair details and items</li> <li>Labor and parts information</li> <li> <p>Customer context</p> </li> <li> <p>Inventory:</p> </li> <li>Item descriptions</li> <li>Materials and conditions</li> <li> <p>Quantity and pricing</p> </li> <li> <p>Analytics Summaries:</p> </li> <li>Daily/weekly/monthly reports</li> <li>Revenue summaries</li> <li> <p>Queue metrics</p> </li> <li> <p>PDF Documents (S3):</p> </li> <li>Extract text from work order PDFs</li> <li>Extract text from uploaded documents</li> </ol> <p>Chunking Strategy: <pre><code># utils/embeddings.py\nfrom typing import List, Dict\nimport openai  # or boto3 for AWS Bedrock\n\nclass EmbeddingManager:\n    def __init__(self, model='text-embedding-3-small'):\n        self.model = model\n\n    def chunk_work_order(self, work_order: WorkOrder) -&gt; List[Dict]:\n        \"\"\"\n        Split work order into semantic chunks\n        \"\"\"\n        chunks = []\n\n        # Chunk 1: Order header with customer context\n        header_text = f\"\"\"\n        Work Order {work_order.WorkOrderNo}\n        Customer: {work_order.customer.Name}\n        Contact: {work_order.customer.Contact}\n        Address: {work_order.customer.get_full_address()}\n        Status: {work_order.ReturnStatus}\n        Date In: {work_order.DateIn}\n        Date Required: {work_order.DateRequired}\n        Special Instructions: {work_order.SpecialInstructions}\n        \"\"\"\n\n        chunks.append({\n            'content': header_text.strip(),\n            'metadata': {\n                'doc_type': 'work_order_header',\n                'doc_id': work_order.WorkOrderNo,\n                'customer_id': work_order.CustID,\n                'date_in': str(work_order.DateIn) if work_order.DateIn else None\n            }\n        })\n\n        # Chunk 2: Items\n        if work_order.items:\n            items_text = f\"Work Order {work_order.WorkOrderNo} Items:\\n\"\n            for item in work_order.items:\n                items_text += f\"- {item.Description} ({item.Material}), \"\n                items_text += f\"Qty: {item.Qty}, Condition: {item.Condition}\\n\"\n\n            chunks.append({\n                'content': items_text.strip(),\n                'metadata': {\n                    'doc_type': 'work_order_items',\n                    'doc_id': work_order.WorkOrderNo,\n                    'customer_id': work_order.CustID\n                }\n            })\n\n        return chunks\n\n    def generate_embeddings(self, texts: List[str]) -&gt; List[List[float]]:\n        \"\"\"\n        Generate embeddings using OpenAI or AWS Bedrock\n        \"\"\"\n        # OpenAI example\n        response = openai.embeddings.create(\n            model=self.model,\n            input=texts\n        )\n        return [item.embedding for item in response.data]\n\n        # AWS Bedrock example (alternative)\n        # bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n        # response = bedrock.invoke_model(\n        #     modelId='amazon.titan-embed-text-v1',\n        #     body=json.dumps({'inputText': text})\n        # )\n\n    def index_work_order(self, work_order: WorkOrder):\n        \"\"\"\n        Generate and store embeddings for a work order\n        \"\"\"\n        chunks = self.chunk_work_order(work_order)\n        texts = [chunk['content'] for chunk in chunks]\n        embeddings = self.generate_embeddings(texts)\n\n        for chunk, embedding in zip(chunks, embeddings):\n            # Store in pgvector\n            doc_emb = DocumentEmbedding(\n                content=chunk['content'],\n                embedding=embedding,\n                metadata=chunk['metadata'],\n                doc_type=chunk['metadata']['doc_type'],\n                doc_id=chunk['metadata']['doc_id']\n            )\n            db.session.add(doc_emb)\n\n        db.session.commit()\n</code></pre></p> <p>Batch Indexing Script: <pre><code># scripts/build_embeddings.py\nfrom app import app, db\nfrom models import WorkOrder, Customer, Inventory, RepairWorkOrder\nfrom utils.embeddings import EmbeddingManager\n\ndef build_all_embeddings():\n    \"\"\"\n    Initial indexing of all business data\n    \"\"\"\n    with app.app_context():\n        emb_manager = EmbeddingManager()\n\n        # Index all work orders\n        print(\"Indexing work orders...\")\n        work_orders = WorkOrder.query.all()\n        for i, wo in enumerate(work_orders):\n            emb_manager.index_work_order(wo)\n            if i % 100 == 0:\n                print(f\"Indexed {i}/{len(work_orders)} work orders\")\n\n        # Index all customers\n        print(\"Indexing customers...\")\n        customers = Customer.query.all()\n        for customer in customers:\n            emb_manager.index_customer(customer)\n\n        # Index inventory\n        print(\"Indexing inventory...\")\n        inventory_items = Inventory.query.all()\n        for item in inventory_items:\n            emb_manager.index_inventory_item(item)\n\n        print(\"Indexing complete!\")\n\nif __name__ == '__main__':\n    build_all_embeddings()\n</code></pre></p> <p>Incremental Updates (Database Triggers or Application Hooks): <pre><code># In routes/work_orders.py - after creating/updating work order\n@work_orders_bp.route('/create', methods=['POST'])\n@login_required\ndef create_work_order():\n    # ... existing code ...\n\n    db.session.commit()\n\n    # Trigger embedding update\n    from utils.embeddings import EmbeddingManager\n    emb_manager = EmbeddingManager()\n    emb_manager.index_work_order(new_work_order)\n\n    # ... rest of code ...\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#5-aws-lambda-function-for-llm-inference","title":"5. AWS Lambda Function for LLM Inference","text":"<p>Why Lambda? - Cost Efficiency: Pay only for LLM inference time (not 24/7 like EC2) - Scalability: Auto-scales for concurrent users - Timeout: Supports up to 15-minute execution for complex queries - Separation: Keeps compute-intensive LLM work off EB instances</p> <p>Lambda Function Structure: <pre><code>awning-rag-llm/\n\u251c\u2500\u2500 lambda_function.py      # Main handler\n\u251c\u2500\u2500 requirements.txt        # Dependencies (boto3, openai, etc.)\n\u251c\u2500\u2500 prompt_templates.py     # Prompt engineering\n\u2514\u2500\u2500 config.py               # Model configuration\n</code></pre></p> <p>lambda_function.py: <pre><code>import json\nimport os\nimport boto3\nfrom openai import OpenAI\n\n# Initialize clients\nbedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')\nopenai_client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n\ndef lambda_handler(event, context):\n    \"\"\"\n    Main Lambda handler for LLM inference\n\n    Event structure:\n    {\n        \"prompt\": \"Full prompt with context\",\n        \"model\": \"claude-3-5-sonnet\" or \"gpt-4\",\n        \"max_tokens\": 1000,\n        \"temperature\": 0.7,\n        \"stream\": false\n    }\n    \"\"\"\n    try:\n        prompt = event['prompt']\n        model = event.get('model', 'claude-3-5-sonnet')\n        max_tokens = event.get('max_tokens', 1000)\n        temperature = event.get('temperature', 0.7)\n\n        # Route to appropriate LLM provider\n        if model.startswith('claude'):\n            response = invoke_bedrock_claude(prompt, model, max_tokens, temperature)\n        elif model.startswith('gpt'):\n            response = invoke_openai(prompt, model, max_tokens, temperature)\n        else:\n            raise ValueError(f\"Unsupported model: {model}\")\n\n        return {\n            'statusCode': 200,\n            'body': json.dumps({\n                'text': response,\n                'model': model,\n                'tokens_used': len(response.split())  # Approximate\n            })\n        }\n\n    except Exception as e:\n        return {\n            'statusCode': 500,\n            'body': json.dumps({\n                'error': str(e)\n            })\n        }\n\ndef invoke_bedrock_claude(prompt, model, max_tokens, temperature):\n    \"\"\"\n    Invoke AWS Bedrock with Claude model\n    \"\"\"\n    model_id = f\"anthropic.{model}-20240229-v1:0\"\n\n    request_body = {\n        \"anthropic_version\": \"bedrock-2023-05-31\",\n        \"max_tokens\": max_tokens,\n        \"temperature\": temperature,\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ]\n    }\n\n    response = bedrock_client.invoke_model(\n        modelId=model_id,\n        body=json.dumps(request_body)\n    )\n\n    response_body = json.loads(response['body'].read())\n    return response_body['content'][0]['text']\n\ndef invoke_openai(prompt, model, max_tokens, temperature):\n    \"\"\"\n    Invoke OpenAI API\n    \"\"\"\n    response = openai_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=max_tokens,\n        temperature=temperature\n    )\n\n    return response.choices[0].message.content\n</code></pre></p> <p>Deployment: <pre><code># Package Lambda function\ncd lambda/awning-rag-llm\npip install -r requirements.txt -t .\nzip -r lambda.zip .\n\n# Deploy via AWS CLI\naws lambda create-function \\\n  --function-name awning-rag-llm \\\n  --runtime python3.11 \\\n  --handler lambda_function.lambda_handler \\\n  --role arn:aws:iam::YOUR_ACCOUNT:role/lambda-execution-role \\\n  --zip-file fileb://lambda.zip \\\n  --timeout 300 \\\n  --memory-size 512 \\\n  --environment Variables={OPENAI_API_KEY=sk-...}\n\n# Or deploy via AWS SAM/Terraform\n</code></pre></p> <p>IAM Permissions: <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"bedrock:InvokeModel\",\n        \"bedrock:InvokeModelWithResponseStream\"\n      ],\n      \"Resource\": \"arn:aws:bedrock:*:*:*\"\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": \"arn:aws:logs:*:*:*\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#6-retrieval-logic","title":"6. Retrieval Logic","text":"<p>Location: <code>utils/retrieval.py</code></p> <p>Hybrid Retrieval Strategy: <pre><code># utils/retrieval.py\nfrom typing import List, Dict\nfrom sqlalchemy import text\nfrom models import WorkOrder, Customer\n\nclass Retriever:\n    def __init__(self, top_k=5, similarity_threshold=0.7):\n        self.top_k = top_k\n        self.similarity_threshold = similarity_threshold\n\n    def retrieve(self, query: str, user_id: int, filters: Dict = None) -&gt; List[Dict]:\n        \"\"\"\n        Hybrid retrieval combining:\n        1. Vector similarity search\n        2. Keyword/metadata filtering\n        3. Recency boosting\n        \"\"\"\n        # Generate query embedding\n        from utils.embeddings import EmbeddingManager\n        emb_manager = EmbeddingManager()\n        query_embedding = emb_manager.generate_embeddings([query])[0]\n\n        # Build SQL query with pgvector\n        sql = text(\"\"\"\n            SELECT\n                content,\n                metadata,\n                doc_type,\n                doc_id,\n                1 - (embedding &lt;=&gt; :query_embedding::vector) as similarity\n            FROM document_embeddings\n            WHERE 1 - (embedding &lt;=&gt; :query_embedding::vector) &gt; :threshold\n        \"\"\")\n\n        # Add metadata filters if provided\n        if filters:\n            if filters.get('doc_type'):\n                sql += text(\" AND doc_type = :doc_type\")\n            if filters.get('customer_id'):\n                sql += text(\" AND metadata-&gt;&gt;'customer_id' = :customer_id\")\n            if filters.get('date_range'):\n                sql += text(\" AND (metadata-&gt;&gt;'date_in')::date BETWEEN :start_date AND :end_date\")\n\n        sql += text(\"\"\"\n            ORDER BY similarity DESC\n            LIMIT :top_k\n        \"\"\")\n\n        params = {\n            'query_embedding': query_embedding,\n            'threshold': self.similarity_threshold,\n            'top_k': self.top_k,\n            **filters\n        }\n\n        results = db.session.execute(sql, params).fetchall()\n\n        # Enhance results with source links\n        enhanced_results = []\n        for row in results:\n            enhanced_results.append({\n                'content': row.content,\n                'metadata': row.metadata,\n                'similarity': row.similarity,\n                'source_link': self._build_source_link(row.doc_type, row.doc_id)\n            })\n\n        return enhanced_results\n\n    def _build_source_link(self, doc_type: str, doc_id: str) -&gt; str:\n        \"\"\"\n        Build clickable links to source documents\n        \"\"\"\n        if doc_type == 'work_order_header':\n            return f\"/work_orders/{doc_id}\"\n        elif doc_type == 'customer':\n            return f\"/customers/{doc_id}\"\n        elif doc_type == 'repair_order':\n            return f\"/repair_work_orders/{doc_id}\"\n        elif doc_type == 'inventory':\n            return f\"/inventory\"\n        return None\n\n    def retrieve_with_sql_fallback(self, query: str, user_id: int) -&gt; List[Dict]:\n        \"\"\"\n        Fallback to direct SQL queries for structured questions\n\n        Examples:\n        - \"Show me all work orders for customer ABC123\"\n        - \"What's in the cleaning queue today?\"\n        - \"List overdue work orders\"\n        \"\"\"\n        # Use regex or LLM to detect structured queries\n        if self._is_structured_query(query):\n            return self._execute_structured_query(query)\n        else:\n            return self.retrieve(query, user_id)\n\n    def _is_structured_query(self, query: str) -&gt; bool:\n        \"\"\"\n        Detect if query is a structured database query\n        \"\"\"\n        structured_patterns = [\n            r\"show (me )?all\",\n            r\"list (all )?\",\n            r\"what('s| is) in the (queue|inventory)\",\n            r\"how many\",\n            r\"count\",\n        ]\n        # Simple pattern matching (could use LLM for better detection)\n        import re\n        for pattern in structured_patterns:\n            if re.search(pattern, query.lower()):\n                return True\n        return False\n\n    def _execute_structured_query(self, query: str) -&gt; List[Dict]:\n        \"\"\"\n        Execute direct database queries for structured questions\n        (Placeholder - implement based on query type)\n        \"\"\"\n        # Use LLM to generate SQL from natural language\n        # Or use predefined query templates\n        pass\n</code></pre></p> <p>Query Classification (Optional Enhancement): <pre><code>def classify_query(query: str) -&gt; str:\n    \"\"\"\n    Classify query type to route to appropriate retrieval strategy\n\n    Returns:\n    - 'semantic': General question requiring vector search\n    - 'structured': Database query requiring SQL\n    - 'analytical': Requires running analytics\n    - 'conversational': Chitchat or clarification\n    \"\"\"\n    # Use lightweight classifier or simple LLM call\n    classification_prompt = f\"\"\"\n    Classify this user query into one of these categories:\n    - semantic: General question about business data\n    - structured: Specific database query (list, show, count)\n    - analytical: Requires calculations or reports\n    - conversational: Chitchat or clarification\n\n    Query: {query}\n\n    Category:\n    \"\"\"\n\n    # Call lightweight LLM (e.g., GPT-3.5-turbo or Claude Haiku)\n    # Return classification\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#rag-implementation","title":"RAG Implementation","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#prompt-engineering","title":"Prompt Engineering","text":"<p>Location: <code>utils/prompts.py</code></p> <p>System Prompt: <pre><code>SYSTEM_PROMPT = \"\"\"\nYou are an AI assistant for an awning cleaning and repair business management system.\nYou help staff answer questions about work orders, customers, inventory, and business operations.\n\nYour capabilities:\n- Answer questions about work orders, repair orders, and customer information\n- Provide inventory status and item details\n- Explain business metrics and analytics\n- Guide users through system workflows\n- Search historical data\n\nGuidelines:\n- Be concise and professional\n- Use specific data from the provided context\n- If information is not in the context, say so clearly\n- Include relevant work order numbers, customer IDs, and dates\n- Format responses with tables or lists when appropriate\n- Provide source links when referencing specific records\n\nData Context:\nThe following information is relevant to the user's query:\n\n{context}\n\nCurrent Date: {current_date}\nUser: {user_name} (Role: {user_role})\n\"\"\"\n</code></pre></p> <p>Prompt Builder: <pre><code># utils/prompts.py\nfrom datetime import datetime\nfrom typing import List, Dict\n\ndef build_rag_prompt(\n    user_query: str,\n    context_docs: List[Dict],\n    user_name: str,\n    user_role: str,\n    conversation_history: List[Dict] = None\n) -&gt; str:\n    \"\"\"\n    Build complete RAG prompt with context and conversation history\n    \"\"\"\n    # Format context documents\n    context_str = \"\\n\\n\".join([\n        f\"Document {i+1} (Similarity: {doc['similarity']:.2f}):\\n{doc['content']}\"\n        for i, doc in enumerate(context_docs)\n    ])\n\n    # Build system prompt\n    system_prompt = SYSTEM_PROMPT.format(\n        context=context_str,\n        current_date=datetime.now().strftime(\"%Y-%m-%d\"),\n        user_name=user_name,\n        user_role=user_role\n    )\n\n    # Add conversation history\n    conversation_str = \"\"\n    if conversation_history:\n        conversation_str = \"\\n\\nConversation History:\\n\"\n        for msg in conversation_history[-5:]:  # Last 5 messages\n            conversation_str += f\"{msg['role']}: {msg['content']}\\n\"\n\n    # Build final prompt\n    full_prompt = f\"\"\"\n{system_prompt}\n\n{conversation_str}\n\nUser Question: {user_query}\n\nAnswer:\n\"\"\"\n\n    return full_prompt\n</code></pre></p> <p>Example Prompts for Common Use Cases:</p> <pre><code># Business Analytics Query\n\"\"\"\nUser asks: \"What was our revenue last month?\"\n\nContext: [Monthly analytics data, completed work orders, payment info]\n\nResponse should include:\n- Total revenue with breakdown by category (cleaning vs. repairs)\n- Comparison to previous month\n- Top customers by revenue\n- Charts/visualizations if available\n\"\"\"\n\n# Work Order Search\n\"\"\"\nUser asks: \"Find all work orders for John Smith's boat\"\n\nContext: [Customer info, work order history, current queue status]\n\nResponse should include:\n- List of all work orders with numbers\n- Status of each order\n- Links to detailed views\n- Any pending or in-progress orders highlighted\n\"\"\"\n\n# Inventory Query\n\"\"\"\nUser asks: \"Do we have any Sunbrella Canvas in stock?\"\n\nContext: [Inventory items matching \"Sunbrella\", material \"Canvas\"]\n\nResponse should include:\n- Available quantity\n- Condition and color breakdown\n- Pricing information\n- Recent usage trends\n\"\"\"\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#security-access-control","title":"Security &amp; Access Control","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#authentication-authorization","title":"Authentication &amp; Authorization","text":"<p>Row-Level Security: <pre><code># utils/retrieval.py - Enhanced with access control\n\nclass SecureRetriever(Retriever):\n    def retrieve(self, query: str, user_id: int, filters: Dict = None) -&gt; List[Dict]:\n        \"\"\"\n        Retrieve with user-based access control\n        \"\"\"\n        # Get user permissions\n        user = User.query.get(user_id)\n\n        # Add permission filters\n        if not user.is_admin:\n            # Non-admin users can only see their assigned work orders\n            # This is a simplified example - implement based on your auth model\n            if filters is None:\n                filters = {}\n\n            # Example: restrict to user's assigned customers or territory\n            # filters['assigned_user_id'] = user_id\n\n        return super().retrieve(query, user_id, filters)\n</code></pre></p> <p>Data Sanitization: <pre><code>def sanitize_response(response: str) -&gt; str:\n    \"\"\"\n    Remove sensitive information from LLM responses\n    \"\"\"\n    import re\n\n    # Redact credit card numbers\n    response = re.sub(r'\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b', '[REDACTED]', response)\n\n    # Redact SSNs\n    response = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[REDACTED]', response)\n\n    # Add more sanitization rules as needed\n\n    return response\n</code></pre></p> <p>Audit Logging: <pre><code># models/chat_log.py\nclass ChatLog(db.Model):\n    __tablename__ = 'chat_logs'\n\n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n    session_id = db.Column(db.String(100), nullable=False)\n    query = db.Column(db.Text, nullable=False)\n    response = db.Column(db.Text, nullable=False)\n    retrieved_docs = db.Column(db.JSON)  # Store what context was used\n    timestamp = db.Column(db.DateTime, default=datetime.utcnow)\n    tokens_used = db.Column(db.Integer)\n\n    user = db.relationship('User', backref='chat_logs')\n\n# In routes/chat.py\ndef log_chat_interaction(user_id, session_id, query, response, docs, tokens):\n    log = ChatLog(\n        user_id=user_id,\n        session_id=session_id,\n        query=query,\n        response=response,\n        retrieved_docs=[{'content': d['content'][:200], 'doc_id': d.get('metadata', {}).get('doc_id')} for d in docs],\n        tokens_used=tokens\n    )\n    db.session.add(log)\n    db.session.commit()\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#implementation-phases","title":"Implementation Phases","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#phase-1-mvp-2-3-weeks","title":"Phase 1: MVP (2-3 weeks)","text":"<p>Goal: Basic Q&amp;A chatbot with work order search</p> <p>Tasks: 1. Setup pgvector extension (1 day)    - Enable pgvector on RDS PostgreSQL    - Create embeddings table and indexes    - Test vector search performance</p> <ol> <li>Build embedding pipeline (3 days)</li> <li>Create <code>EmbeddingManager</code> class</li> <li>Implement work order chunking</li> <li>Build batch indexing script</li> <li> <p>Index all existing work orders</p> </li> <li> <p>Create AWS Lambda function (2 days)</p> </li> <li>Setup Lambda with Bedrock or OpenAI</li> <li>Implement LLM inference handler</li> <li>Test with sample prompts</li> <li> <p>Configure IAM permissions</p> </li> <li> <p>Develop Flask chat route (3 days)</p> </li> <li>Create <code>/api/chat/query</code> endpoint</li> <li>Implement retrieval logic</li> <li>Build prompt templates</li> <li> <p>Lambda invocation from Flask</p> </li> <li> <p>Build basic chat UI (2 days)</p> </li> <li>Simple chat interface in templates</li> <li>Message history display</li> <li>Loading states</li> <li> <p>Basic styling with existing CSS</p> </li> <li> <p>Testing &amp; refinement (2 days)</p> </li> <li>Test with real business queries</li> <li>Refine prompts for accuracy</li> <li>Performance optimization</li> <li>Bug fixes</li> </ol> <p>Deliverables: - Working chatbot that answers questions about work orders - Basic retrieval from work order data - Simple chat interface - Lambda function for LLM calls</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#phase-2-enhanced-features-2-3-weeks","title":"Phase 2: Enhanced Features (2-3 weeks)","text":"<p>Goal: Multi-source data, better UI, incremental indexing</p> <p>Tasks: 1. Expand data sources (4 days)    - Index customers, repair orders, inventory    - Implement incremental embedding updates    - Add PDF document extraction    - S3 document indexing</p> <ol> <li>Improve chat UI (3 days)</li> <li>Better styling and UX</li> <li>Source citations with links</li> <li>Quick action buttons</li> <li>Conversation history</li> <li> <p>Markdown rendering</p> </li> <li> <p>Add conversation memory (2 days)</p> </li> <li>Session management</li> <li>Conversation history storage</li> <li> <p>Context-aware responses</p> </li> <li> <p>Implement filters (2 days)</p> </li> <li>Date range filtering</li> <li>Customer-specific queries</li> <li>Status filtering</li> <li> <p>Territory/user filtering</p> </li> <li> <p>Performance optimization (2 days)</p> </li> <li>Query caching</li> <li>Response streaming</li> <li>Lambda cold start optimization</li> <li>Database query optimization</li> </ol> <p>Deliverables: - Full business data searchable - Improved UI/UX - Conversational memory - Advanced filtering</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#phase-3-advanced-features-3-4-weeks","title":"Phase 3: Advanced Features (3-4 weeks)","text":"<p>Goal: Analytics, SQL generation, multi-modal support</p> <p>Tasks: 1. SQL query generation (5 days)    - Text-to-SQL for structured queries    - Query validation and safety    - Result formatting    - Complex aggregations</p> <ol> <li>Analytics integration (3 days)</li> <li>Connect to analytics cache</li> <li>Business metrics queries</li> <li>Chart generation from chat</li> <li> <p>Report export</p> </li> <li> <p>Multi-modal support (4 days)</p> </li> <li>Image upload for damage assessment</li> <li>PDF upload and analysis</li> <li>Voice input (optional)</li> <li> <p>Screenshot analysis</p> </li> <li> <p>Admin features (3 days)</p> </li> <li>Usage analytics dashboard</li> <li>Prompt management UI</li> <li>Embedding reindexing tools</li> <li> <p>Cost tracking</p> </li> <li> <p>Advanced RAG techniques (3 days)</p> </li> <li>Hybrid search (BM25 + vector)</li> <li>Query rewriting</li> <li>Multi-hop reasoning</li> <li>Fact verification</li> </ol> <p>Deliverables: - Text-to-SQL capability - Analytics from chat - Multi-modal inputs - Admin tools</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#cost-estimation","title":"Cost Estimation","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#aws-lambda-costs","title":"AWS Lambda Costs","text":"<p>Assumptions: - 1000 queries/day - Average 2 seconds per query (LLM inference) - 512 MB memory - 30 days/month</p> <p>Lambda Costs: <pre><code>Requests: 1000/day \u00d7 30 days = 30,000 requests/month\nDuration: 30,000 \u00d7 2 seconds = 60,000 seconds = 16.67 hours\n\nLambda Pricing (us-east-1):\n- $0.20 per 1M requests = $0.006/month\n- $0.0000166667 per GB-second = $0.139/month (512 MB \u00d7 16.67 hours)\n\nTotal Lambda: ~$0.15/month (negligible)\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#llm-api-costs","title":"LLM API Costs","text":"<p>AWS Bedrock (Claude 3.5 Sonnet): <pre><code>Input: $3 per 1M tokens\nOutput: $15 per 1M tokens\n\nAssumptions per query:\n- Input: 1500 tokens (context + prompt)\n- Output: 500 tokens\n\nMonthly cost:\n- Input: 30,000 queries \u00d7 1500 tokens \u00d7 $3/1M = $135/month\n- Output: 30,000 queries \u00d7 500 tokens \u00d7 $15/1M = $225/month\n\nTotal: $360/month\n</code></pre></p> <p>OpenAI (GPT-4o): <pre><code>Input: $2.50 per 1M tokens\nOutput: $10 per 1M tokens\n\nMonthly cost:\n- Input: 30,000 \u00d7 1500 \u00d7 $2.50/1M = $112.50/month\n- Output: 30,000 \u00d7 500 \u00d7 $10/1M = $150/month\n\nTotal: $262.50/month\n</code></pre></p> <p>OpenAI (GPT-3.5-turbo) - Budget Option: <pre><code>Input: $0.50 per 1M tokens\nOutput: $1.50 per 1M tokens\n\nMonthly cost:\n- Input: 30,000 \u00d7 1500 \u00d7 $0.50/1M = $22.50/month\n- Output: 30,000 \u00d7 500 \u00d7 $1.50/1M = $22.50/month\n\nTotal: $45/month\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#embedding-costs","title":"Embedding Costs","text":"<p>OpenAI (text-embedding-3-small): <pre><code>$0.02 per 1M tokens\n\nInitial indexing (one-time):\n- 10,000 documents \u00d7 500 tokens avg = 5M tokens\n- Cost: $0.10 (one-time)\n\nIncremental updates:\n- 100 documents/day \u00d7 500 tokens = 50,000 tokens/day\n- Monthly: 1.5M tokens \u00d7 $0.02/1M = $0.03/month\n</code></pre></p> <p>AWS Bedrock (Titan Embeddings): <pre><code>$0.10 per 1M tokens\n\nInitial: 5M tokens \u00d7 $0.10/1M = $0.50 (one-time)\nMonthly updates: 1.5M tokens \u00d7 $0.10/1M = $0.15/month\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#vector-database-costs","title":"Vector Database Costs","text":"<p>PostgreSQL with pgvector (Recommended for MVP): <pre><code>- Uses existing RDS instance\n- Minimal additional storage (&lt;1 GB for 10K documents)\n- No additional cost\n</code></pre></p> <p>AWS OpenSearch Serverless (If scaling up): <pre><code>- OCU (OpenSearch Compute Units): ~$700/month minimum\n- Storage: $0.024 per GB-month\n\nOnly recommended if:\n- &gt;1M documents\n- Advanced search features needed\n- High query throughput (&gt;10K/day)\n</code></pre></p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#total-monthly-cost-summary","title":"Total Monthly Cost Summary","text":"<p>MVP (Phase 1): - Lambda: $0.15 - LLM (GPT-3.5-turbo): $45 - Embeddings: $0.03 - Vector DB (pgvector): $0 - Total: ~$45/month</p> <p>Production (Phase 3 with Claude 3.5): - Lambda: $0.15 - LLM (Claude 3.5 Sonnet): $360 - Embeddings: $0.15 - Vector DB (pgvector): $0 - Total: ~$360/month</p> <p>Cost Optimization Tips: 1. Use GPT-3.5-turbo for simple queries, GPT-4 for complex ones 2. Implement caching for common questions 3. Use smaller context windows when possible 4. Batch embedding generation 5. Monitor and set usage limits</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#monitoring-maintenance","title":"Monitoring &amp; Maintenance","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#key-metrics-to-track","title":"Key Metrics to Track","text":"<p>Performance Metrics: <pre><code># utils/monitoring.py\nimport time\nfrom functools import wraps\n\ndef track_query_performance(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n\n        result = func(*args, **kwargs)\n\n        duration = time.time() - start_time\n\n        # Log to CloudWatch or database\n        log_metric('chat_query_duration', duration)\n        log_metric('chat_query_count', 1)\n\n        return result\n    return wrapper\n\n# Track:\n# - Query latency (p50, p95, p99)\n# - LLM token usage\n# - Cache hit rate\n# - Retrieval accuracy\n# - User satisfaction (thumbs up/down)\n</code></pre></p> <p>Quality Metrics: <pre><code># Implement feedback mechanism\n@chat_bp.route('/feedback', methods=['POST'])\n@login_required\ndef chat_feedback():\n    data = request.get_json()\n\n    feedback = ChatFeedback(\n        chat_log_id=data['chat_log_id'],\n        rating=data['rating'],  # 1-5 or thumbs up/down\n        comment=data.get('comment'),\n        user_id=current_user.id\n    )\n    db.session.add(feedback)\n    db.session.commit()\n\n    return jsonify({'success': True})\n</code></pre></p> <p>Dashboards: - CloudWatch dashboard for Lambda metrics - Custom dashboard for chat analytics:   - Queries per day   - Average response time   - Token usage trends   - User feedback scores   - Top queries   - Failed queries</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#maintenance-tasks","title":"Maintenance Tasks","text":"<p>Weekly: - Review failed queries and improve prompts - Check for hallucinations in responses - Monitor token costs</p> <p>Monthly: - Retrain/update embeddings for new data - Review and optimize most expensive queries - Update prompt templates based on feedback - Analyze user feedback for improvements</p> <p>Quarterly: - Evaluate new LLM models for better performance/cost - Review security and access logs - Performance benchmarking - Cost optimization review</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#alternative-architectures","title":"Alternative Architectures","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#option-1-all-in-one-flask-simpler-but-less-scalable","title":"Option 1: All-in-One Flask (Simpler but Less Scalable)","text":"<p>Architecture: <pre><code>Flask App (EB)\n\u251c\u2500\u2500 Chat routes\n\u251c\u2500\u2500 LLM inference (direct API calls)\n\u251c\u2500\u2500 Vector search (pgvector)\n\u2514\u2500\u2500 Database queries\n</code></pre></p> <p>Pros: - Simpler deployment - No Lambda complexity - Lower latency (no Lambda cold starts)</p> <p>Cons: - LLM calls block Flask workers - Limited scalability for concurrent users - Higher memory usage on EB instances</p> <p>When to use: - Low traffic (&lt;100 queries/day) - Small team (&lt; 5 users) - Tight budget - Quick prototype</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#option-2-full-serverless-most-scalable","title":"Option 2: Full Serverless (Most Scalable)","text":"<p>Architecture: <pre><code>API Gateway \u2192 Lambda (Chat Handler)\n              \u251c\u2192 Lambda (LLM Inference)\n              \u2514\u2192 Aurora Serverless (PostgreSQL + pgvector)\n              \u2514\u2192 OpenSearch Serverless (Vector DB)\n</code></pre></p> <p>Pros: - Maximum scalability - Pay-per-use - No server management</p> <p>Cons: - Most expensive at scale - Complex deployment - Vendor lock-in - Higher latency (multiple Lambda hops)</p> <p>When to use: - High scale (&gt;10K queries/day) - Unpredictable traffic - Multi-tenant SaaS - External API exposure</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#option-3-hybrid-with-elasticache","title":"Option 3: Hybrid with ElastiCache","text":"<p>Architecture: <pre><code>Flask App (EB)\n\u251c\u2192 ElastiCache (Redis) - Response cache\n\u251c\u2192 Lambda (LLM Inference)\n\u2514\u2192 RDS PostgreSQL (pgvector)\n</code></pre></p> <p>Pros: - Best balance of performance and cost - Fast response for cached queries - Scalable LLM inference</p> <p>Cons: - Added ElastiCache cost (~$15-50/month) - More components to manage</p> <p>When to use: - Medium traffic (500-5K queries/day) - Repeated common queries - Production deployment (recommended)</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#getting-started-quick-start-guide","title":"Getting Started: Quick Start Guide","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#prerequisite-checklist","title":"Prerequisite Checklist","text":"<ul> <li>[ ] AWS CLI configured with Elastic Beanstalk access</li> <li>[ ] PostgreSQL RDS instance running (already exists)</li> <li>[ ] S3 bucket for Lambda deployments</li> <li>[ ] OpenAI API key or AWS Bedrock access</li> <li>[ ] pgvector extension enabled on RDS</li> </ul>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-1-enable-pgvector","title":"Step 1: Enable pgvector","text":"<pre><code># Connect to RDS PostgreSQL\npsql -h your-rds-endpoint.rds.amazonaws.com -U postgres -d clean_repair\n\n# Enable extension\nCREATE EXTENSION IF NOT EXISTS vector;\n\n# Create embeddings table\nCREATE TABLE document_embeddings (\n    id SERIAL PRIMARY KEY,\n    content TEXT NOT NULL,\n    embedding vector(1536),\n    metadata JSONB,\n    doc_type VARCHAR(50),\n    doc_id VARCHAR(100),\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE INDEX ON document_embeddings\nUSING ivfflat (embedding vector_cosine_ops)\nWITH (lists = 100);\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-2-install-dependencies","title":"Step 2: Install Dependencies","text":"<pre><code># Add to requirements.txt\nopenai&gt;=1.0.0  # Or boto3 for Bedrock\npgvector&gt;=0.2.0\nsentence-transformers  # Optional for local embeddings\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-3-create-embedding-model","title":"Step 3: Create Embedding Model","text":"<pre><code># models/document_embedding.py\nfrom extensions import db\nfrom pgvector.sqlalchemy import Vector\n\nclass DocumentEmbedding(db.Model):\n    __tablename__ = 'document_embeddings'\n\n    id = db.Column(db.Integer, primary_key=True)\n    content = db.Column(db.Text, nullable=False)\n    embedding = db.Column(Vector(1536))  # OpenAI ada-002 dimension\n    metadata = db.Column(db.JSON)\n    doc_type = db.Column(db.String(50))\n    doc_id = db.Column(db.String(100))\n    created_at = db.Column(db.DateTime, default=db.func.now())\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-4-run-initial-indexing","title":"Step 4: Run Initial Indexing","text":"<pre><code># Create initial embeddings\npython scripts/build_embeddings.py\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-5-deploy-lambda-function","title":"Step 5: Deploy Lambda Function","text":"<pre><code>cd lambda/awning-rag-llm\npip install -r requirements.txt -t .\nzip -r lambda.zip .\n\naws lambda create-function \\\n  --function-name awning-rag-llm \\\n  --runtime python3.11 \\\n  --handler lambda_function.lambda_handler \\\n  --role arn:aws:iam::YOUR_ACCOUNT:role/lambda-role \\\n  --zip-file fileb://lambda.zip \\\n  --timeout 300 \\\n  --environment Variables={OPENAI_API_KEY=sk-xxx}\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-6-add-chat-routes-to-flask","title":"Step 6: Add Chat Routes to Flask","text":"<pre><code># In app.py\nfrom routes.chat import chat_bp\napp.register_blueprint(chat_bp)\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-7-deploy-to-elastic-beanstalk","title":"Step 7: Deploy to Elastic Beanstalk","text":"<pre><code>eb deploy\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#step-8-test-the-chatbot","title":"Step 8: Test the Chatbot","text":"<pre><code>curl -X POST https://your-eb-app.com/api/chat/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"Show me all work orders in the queue today\",\n    \"session_id\": \"test-session-1\"\n  }'\n</code></pre>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#troubleshooting","title":"Troubleshooting","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#common-issues","title":"Common Issues","text":"<p>Issue: pgvector extension not found <pre><code>ERROR: could not open extension control file \"/usr/share/postgresql/XX/extension/vector.control\"\n</code></pre></p> <p>Solution: <pre><code># For RDS, enable via parameter group\n# Or if using local PostgreSQL:\nsudo apt-get install postgresql-14-pgvector\n</code></pre></p> <p>Issue: Lambda timeout <pre><code>Task timed out after 3.00 seconds\n</code></pre></p> <p>Solution: <pre><code># Increase Lambda timeout\naws lambda update-function-configuration \\\n  --function-name awning-rag-llm \\\n  --timeout 300\n</code></pre></p> <p>Issue: High embedding costs</p> <p>Solution: - Use smaller embedding models (e.g., text-embedding-3-small) - Batch embedding generation - Cache embeddings for unchanged documents - Only re-embed when content changes</p> <p>Issue: Poor retrieval quality</p> <p>Solution: - Increase <code>top_k</code> for more context - Lower similarity threshold - Improve chunking strategy - Add metadata filtering - Use hybrid search (BM25 + vector)</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#future-enhancements","title":"Future Enhancements","text":""},{"location":"architecture/RAG_CHATBOT_DESIGN/#advanced-features-roadmap","title":"Advanced Features Roadmap","text":"<p>1. Multi-Agent System - Specialized agents for different tasks (customer service, analytics, inventory) - Agent orchestration for complex queries - Tool calling (create work orders, update inventory, etc.)</p> <p>2. Voice Interface - Speech-to-text integration - Voice commands for common tasks - Hands-free operation for field workers</p> <p>3. Mobile App - Native iOS/Android chat interface - Offline mode with sync - Push notifications for responses</p> <p>4. Workflow Automation - Create work orders from chat - Update order status via chat - Trigger email/SMS notifications - Schedule follow-ups</p> <p>5. Predictive Analytics - Forecast completion times via chat - Identify bottlenecks - Recommend resource allocation - Revenue projections</p> <p>6. Integration with External Systems - Email integration (query via email) - Slack/Teams bot - SMS interface (Twilio) - Calendar integration</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#references-resources","title":"References &amp; Resources","text":"<p>Documentation: - pgvector GitHub - AWS Bedrock - OpenAI API - AWS Lambda - RAG Best Practices</p> <p>Tools: - LangChain - RAG framework - LlamaIndex - Data framework for LLM apps - Weaviate - Alternative vector database</p> <p>Monitoring: - AWS CloudWatch for Lambda metrics - Langfuse for LLM observability - Weights &amp; Biases for ML monitoring</p>"},{"location":"architecture/RAG_CHATBOT_DESIGN/#conclusion","title":"Conclusion","text":"<p>This design provides a comprehensive roadmap for implementing a production-ready RAG chatbot for your awning management system. The hybrid architecture (Flask + Lambda) balances simplicity, cost, and scalability while leveraging your existing Elastic Beanstalk infrastructure.</p> <p>Recommended Approach: 1. Start with Phase 1 MVP using pgvector and GPT-3.5-turbo (~$45/month) 2. Gather user feedback and iterate on prompts 3. Expand to Phase 2 with full data sources 4. Upgrade to Claude 3.5 Sonnet or GPT-4 for production quality</p> <p>Key Success Factors: - High-quality embeddings and chunking strategy - Well-engineered prompts with business context - User feedback loop for continuous improvement - Monitoring and cost optimization - Security and access control from day one</p> <p>For questions or implementation assistance, refer to the troubleshooting section or consult AWS documentation for specific service configurations.</p>"},{"location":"database/ALEMBIC_GUIDE/","title":"Alembic Database Migration Guide","text":""},{"location":"database/ALEMBIC_GUIDE/#overview","title":"Overview","text":"<p>This project uses Alembic for database schema migrations. Alembic provides version control for your database schema, making it safe and easy to evolve your database structure over time.</p>"},{"location":"database/ALEMBIC_GUIDE/#quick-start","title":"Quick Start","text":""},{"location":"database/ALEMBIC_GUIDE/#basic-commands","title":"Basic Commands","text":"<pre><code># Check current migration status\n./alembic_db.sh prod current      # Production database\n./alembic_db.sh test current      # Test database\n\n# View migration history\n./alembic_db.sh prod history\n\n# Create a new migration (after modifying models)\n./alembic_db.sh test revision --autogenerate -m \"add_new_column\"\n\n# Apply migrations\n./alembic_db.sh test upgrade head    # Test first!\n./alembic_db.sh prod upgrade head    # Then production\n\n# Rollback one migration\n./alembic_db.sh prod downgrade -1\n\n# Show SQL without executing\n./alembic_db.sh prod upgrade head --sql\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#workflow-adding-a-new-field","title":"Workflow: Adding a New Field","text":"<p>Let's say you want to add a new field to the WorkOrder model. Here's the complete workflow:</p>"},{"location":"database/ALEMBIC_GUIDE/#1-update-your-model","title":"1. Update Your Model","text":"<p>Edit <code>models/work_order.py</code>:</p> <pre><code>class WorkOrder(db.Model):\n    __tablename__ = \"tblcustworkorderdetail\"\n\n    # ... existing fields ...\n\n    # New field\n    cleaning_notes = db.Column(\"cleaning_notes\", db.Text, nullable=True)\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#2-create-a-migration","title":"2. Create a Migration","text":"<pre><code># Generate migration automatically by comparing models to database\n./alembic_db.sh test revision --autogenerate -m \"add_cleaning_notes_to_work_orders\"\n</code></pre> <p>This creates a new file in <code>alembic/versions/</code> like: <code>20251013_1930-abc123def456_add_cleaning_notes_to_work_orders.py</code></p>"},{"location":"database/ALEMBIC_GUIDE/#3-review-the-migration","title":"3. Review the Migration","text":"<p>IMPORTANT: Always review auto-generated migrations!</p> <pre><code># Open the generated migration file\ncode alembic/versions/20251013_1930-abc123def456_add_cleaning_notes_to_work_orders.py\n</code></pre> <p>Check that: - The <code>upgrade()</code> function adds the column correctly - The <code>downgrade()</code> function removes it correctly - No unexpected changes were detected</p> <p>Example migration:</p> <pre><code>def upgrade() -&gt; None:\n    op.add_column('tblcustworkorderdetail',\n                  sa.Column('cleaning_notes', sa.Text(), nullable=True))\n\ndef downgrade() -&gt; None:\n    op.drop_column('tblcustworkorderdetail', 'cleaning_notes')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#4-test-on-test-database-first","title":"4. Test on Test Database First","text":"<pre><code># Apply migration to test database\n./alembic_db.sh test upgrade head\n\n# Verify the change worked\npsql \"postgresql://postgres:PASSWORD@HOST:5432/clean_repair_test\" -c \"\\d tblcustworkorderdetail\"\n</code></pre> <p>Test your application with the test database to make sure everything works.</p>"},{"location":"database/ALEMBIC_GUIDE/#5-apply-to-production","title":"5. Apply to Production","text":"<pre><code># Apply to production database\n./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#6-deploy-code","title":"6. Deploy Code","text":"<pre><code># Commit your changes (model + migration file)\ngit add models/work_order.py alembic/versions/20251013_1930-*.py\ngit commit -m \"Add cleaning_notes field to WorkOrder\"\ngit push\n\n# Deploy to Elastic Beanstalk\neb deploy\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#database-switching","title":"Database Switching","text":"<p>The <code>alembic_db.sh</code> helper script manages database switching:</p> <pre><code>./alembic_db.sh prod &lt;command&gt;    # Uses clean_repair\n./alembic_db.sh test &lt;command&gt;    # Uses clean_repair_test\n</code></pre> <p>You can also use raw alembic commands with environment variables:</p> <pre><code>POSTGRES_DB=clean_repair_test alembic current\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#common-scenarios","title":"Common Scenarios","text":""},{"location":"database/ALEMBIC_GUIDE/#scenario-1-add-a-column","title":"Scenario 1: Add a Column","text":"<p>Model change: <pre><code>new_field = db.Column(\"new_field\", db.String(100), nullable=True)\n</code></pre></p> <p>Migration (auto-generated): <pre><code>def upgrade():\n    op.add_column('table_name', sa.Column('new_field', sa.String(100), nullable=True))\n\ndef downgrade():\n    op.drop_column('table_name', 'new_field')\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#scenario-2-rename-a-column-issue-82-storage-rack","title":"Scenario 2: Rename a Column (Issue #82 - Storage + Rack)","text":"<p>For issue #82, you need to combine <code>storage</code> and <code>rack_number</code> into one field.</p> <p>Step 1: Add migration with data transformation:</p> <pre><code>def upgrade():\n    # Add temporary column\n    op.add_column('tblcustworkorderdetail',\n                  sa.Column('storage_combined', sa.String(), nullable=True))\n\n    # Migrate data: Combine storage + rack_number\n    op.execute(\"\"\"\n        UPDATE tblcustworkorderdetail\n        SET storage_combined = CONCAT(\n            COALESCE(storage, ''),\n            CASE\n                WHEN rack_number IS NOT NULL AND rack_number != ''\n                THEN ' - Rack: ' || rack_number\n                ELSE ''\n            END\n        )\n        WHERE storage IS NOT NULL OR rack_number IS NOT NULL\n    \"\"\")\n\n    # Drop old columns (optional - keep for historical data)\n    # op.drop_column('tblcustworkorderdetail', 'rack_number')\n\ndef downgrade():\n    # Reverse the migration\n    op.drop_column('tblcustworkorderdetail', 'storage_combined')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#scenario-3-change-column-type","title":"Scenario 3: Change Column Type","text":"<p>Model change: <pre><code># Change from String to Text\nfield = db.Column(\"field\", db.Text)  # was db.String(100)\n</code></pre></p> <p>Migration: <pre><code>def upgrade():\n    op.alter_column('table_name', 'field',\n                    existing_type=sa.String(100),\n                    type_=sa.Text())\n\ndef downgrade():\n    op.alter_column('table_name', 'field',\n                    existing_type=sa.Text(),\n                    type_=sa.String(100))\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#scenario-4-add-an-index","title":"Scenario 4: Add an Index","text":"<pre><code>def upgrade():\n    op.create_index('idx_workorder_cleaning_notes',\n                    'tblcustworkorderdetail',\n                    ['cleaning_notes'])\n\ndef downgrade():\n    op.drop_index('idx_workorder_cleaning_notes',\n                  'tblcustworkorderdetail')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#scenario-5-add-optimistic-locking-issue-92","title":"Scenario 5: Add Optimistic Locking (Issue #92)","text":"<pre><code>def upgrade():\n    # Add version column for optimistic locking\n    op.add_column('tblcustworkorderdetail',\n                  sa.Column('version', sa.Integer(), nullable=False, server_default='1'))\n\n    # Create index for faster version checks\n    op.create_index('idx_workorder_version', 'tblcustworkorderdetail', ['version'])\n\ndef downgrade():\n    op.drop_index('idx_workorder_version', 'tblcustworkorderdetail')\n    op.drop_column('tblcustworkorderdetail', 'version')\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#safety-best-practices","title":"Safety Best Practices","text":""},{"location":"database/ALEMBIC_GUIDE/#1-always-test-first","title":"1. Always Test First","text":"<pre><code># Test database first\n./alembic_db.sh test upgrade head\n\n# Run application tests\npytest\n\n# If all good, apply to production\n./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#2-backup-before-production-migrations","title":"2. Backup Before Production Migrations","text":"<pre><code># Backup production database before major migrations\npg_dump \"postgresql://user:pass@host:5432/clean_repair\" &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n\n# Or via RDS snapshot (recommended)\naws rds create-db-snapshot \\\n    --db-instance-identifier database-1 \\\n    --db-snapshot-identifier pre-migration-$(date +%Y%m%d)\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#3-review-auto-generated-migrations","title":"3. Review Auto-Generated Migrations","text":"<p>Alembic's autogenerate is smart but not perfect. Always review: - Check for unexpected table/column drops - Verify data type changes are correct - Add data migrations if needed (see Scenario 2)</p>"},{"location":"database/ALEMBIC_GUIDE/#4-test-rollbacks","title":"4. Test Rollbacks","text":"<pre><code># Apply migration\n./alembic_db.sh test upgrade head\n\n# Test rollback\n./alembic_db.sh test downgrade -1\n\n# Re-apply\n./alembic_db.sh test upgrade head\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#5-keep-migrations-small","title":"5. Keep Migrations Small","text":"<p>Create focused migrations: - \u2705 Good: \"add_cleaning_notes_field\" - \u2705 Good: \"add_index_to_customer_name\" - \u274c Bad: \"update_all_tables_for_issue_67_82_92\"</p>"},{"location":"database/ALEMBIC_GUIDE/#migration-file-structure","title":"Migration File Structure","text":"<pre><code>\"\"\"descriptive_message\n\nRevision ID: abc123def456          # Unique ID for this migration\nRevises: previous_revision_id      # Previous migration (creates chain)\nCreate Date: 2025-10-13 19:30:00\n\n\"\"\"\nfrom alembic import op\nimport sqlalchemy as sa\n\nrevision = 'abc123def456'\ndown_revision = 'previous_id'      # Forms migration chain\n\ndef upgrade() -&gt; None:\n    \"\"\"Apply the migration\"\"\"\n    op.add_column(...)\n\ndef downgrade() -&gt; None:\n    \"\"\"Reverse the migration\"\"\"\n    op.drop_column(...)\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"database/ALEMBIC_GUIDE/#problem-cant-locate-revision-identified-by-head","title":"Problem: \"Can't locate revision identified by 'head'\"","text":"<p>Solution: Database not stamped. Stamp it: <pre><code>./alembic_db.sh prod stamp head\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#problem-target-database-is-not-up-to-date","title":"Problem: \"Target database is not up to date\"","text":"<p>Solution: Check status and upgrade: <pre><code>./alembic_db.sh prod current\n./alembic_db.sh prod upgrade head\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#problem-migration-detects-changes-you-didnt-make","title":"Problem: Migration detects changes you didn't make","text":"<p>Solution: Your model doesn't match the database. Options: 1. If database is correct: Update your model to match 2. If model is correct: Create migration to update database 3. If both are correct: Check for server_default, type differences</p>"},{"location":"database/ALEMBIC_GUIDE/#problem-cant-drop-column-because-its-referenced","title":"Problem: \"Can't drop column because it's referenced\"","text":"<p>Solution: Drop foreign key constraints first: <pre><code>def upgrade():\n    op.drop_constraint('fk_name', 'table_name', type_='foreignkey')\n    op.drop_column('table_name', 'column_name')\n</code></pre></p>"},{"location":"database/ALEMBIC_GUIDE/#advanced-manual-migrations","title":"Advanced: Manual Migrations","text":"<p>Sometimes you need to write migrations by hand:</p> <pre><code># Create empty migration\n./alembic_db.sh prod revision -m \"custom_data_migration\"\n</code></pre> <p>Example - Migrate data between tables:</p> <pre><code>def upgrade():\n    # Use Alembic's connection\n    connection = op.get_bind()\n\n    # Execute raw SQL for complex data migrations\n    connection.execute(\"\"\"\n        INSERT INTO new_table (field1, field2)\n        SELECT old_field1, old_field2 FROM old_table\n        WHERE condition = true\n    \"\"\")\n\n    # Or use SQLAlchemy Core for type safety\n    from sqlalchemy import table, column, select\n    old_table = table('old_table',\n                      column('old_field1'),\n                      column('old_field2'))\n    new_table = table('new_table',\n                      column('field1'),\n                      column('field2'))\n\n    # Select and insert\n    connection.execute(\n        new_table.insert().from_select(\n            ['field1', 'field2'],\n            select(old_table.c.old_field1, old_table.c.old_field2)\n        )\n    )\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#elastic-beanstalk-deployment","title":"Elastic Beanstalk Deployment","text":""},{"location":"database/ALEMBIC_GUIDE/#option-1-automatic-migrations-recommended-for-small-teams","title":"Option 1: Automatic Migrations (Recommended for Small Teams)","text":"<p>Add to <code>.ebextensions/02_migrations.config</code>:</p> <pre><code>container_commands:\n  01_migrate:\n    command: \"source /var/app/venv/*/bin/activate &amp;&amp; alembic upgrade head\"\n    leader_only: true\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#option-2-manual-migrations-recommended-for-production","title":"Option 2: Manual Migrations (Recommended for Production)","text":"<pre><code># 1. SSH into EB instance\neb ssh\n\n# 2. Activate virtual environment\nsource /var/app/venv/*/bin/activate\ncd /var/app/current\n\n# 3. Run migration\nalembic upgrade head\n\n# 4. Verify\nalembic current\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#migration-history","title":"Migration History","text":"<p>View all migrations:</p> <pre><code>./alembic_db.sh prod history --verbose\n</code></pre> <p>View current version:</p> <pre><code>./alembic_db.sh prod current\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#relationship-with-old-migration-tool","title":"Relationship with Old Migration Tool","text":"<p>Your <code>migration_tool/</code> directory is kept for historical reference: - \u2705 Use for: Re-migrating from Access DB if needed - \u274c Don't use for: Schema changes going forward</p> <p>Going forward: - Old way: Modify <code>run_migration.py</code> \u2192 Drop all tables \u2192 Re-import - New way: Modify model \u2192 Create Alembic migration \u2192 Apply safely</p>"},{"location":"database/ALEMBIC_GUIDE/#summary-cheat-sheet","title":"Summary Cheat Sheet","text":"<pre><code># Day-to-day workflow\n./alembic_db.sh test revision --autogenerate -m \"description\"  # Create\n./alembic_db.sh test upgrade head                               # Test\n./alembic_db.sh prod upgrade head                               # Deploy\n\n# Checking status\n./alembic_db.sh prod current    # What version am I on?\n./alembic_db.sh prod history    # Show all migrations\n\n# Undoing mistakes\n./alembic_db.sh test downgrade -1        # Undo last migration\n./alembic_db.sh test downgrade &lt;revision_id&gt;  # Go to specific version\n\n# Previewing changes\n./alembic_db.sh prod upgrade head --sql  # Show SQL without running\n</code></pre>"},{"location":"database/ALEMBIC_GUIDE/#next-steps","title":"Next Steps","text":"<ol> <li>Read through this guide</li> <li>Practice creating a test migration</li> <li>Review your GitHub issues (#67, #82, #92, #98) and plan migrations</li> <li>Test migrations on <code>clean_repair_test</code> first</li> <li>Apply to <code>clean_repair</code> production</li> </ol>"},{"location":"database/ALEMBIC_GUIDE/#additional-resources","title":"Additional Resources","text":"<ul> <li>Alembic Documentation</li> <li>Alembic Tutorial</li> <li>SQLAlchemy Column Types</li> </ul>"},{"location":"database/ALEMBIC_GUIDE/#questions","title":"Questions?","text":"<p>If you're unsure about a migration: 1. Test on <code>clean_repair_test</code> first 2. Review the auto-generated SQL 3. Create a database backup 4. Ask for review if making destructive changes</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/","title":"Storage Fields Guide (Issue #82)","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#tldr","title":"TL;DR","text":"<p>Work Orders: - \u2705 Use <code>RackNo</code> (db: <code>rack_number</code>) for physical location - \u2705 Use <code>StorageTime</code> (db: <code>storagetime</code>) for \"Seasonal\" / \"Temporary\" - \u274c Do NOT use <code>Storage</code> (deprecated, empty)</p> <p>Repair Orders: - \u2705 Use <code>RackNo</code> (db: <code>RACK#</code>) for physical location - \u2705 Use <code>STORAGE</code> (db: <code>storage</code>) for \"TEMPORARY\" / \"SEASONAL\" - \u26a0\ufe0f <code>LOCATION</code> exists but <code>RackNo</code> is primary location field</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#the-confusion-explained","title":"The Confusion Explained","text":"<p>There was confusion between storage time type (how long something is stored) and physical location (where it is stored). This guide clarifies which fields to use for what purpose.</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#field-naming-issues","title":"Field Naming Issues","text":"What You Want Work Order Field Repair Order Field Why It's Confusing Physical Location(e.g., \"5 B\", \"bin 4 top\") <code>RackNo</code>(db: <code>rack_number</code>) <code>RackNo</code>(db: <code>RACK#</code>) \u2705 Clear - named after racks Storage Duration Type(\"Seasonal\" / \"Temporary\") <code>StorageTime</code>(db: <code>storagetime</code>) <code>STORAGE</code>(db: <code>storage</code>) \u26a0\ufe0f Confusing - RO field is named \"STORAGE\" not \"StorageTime\" Deprecated/Unused <code>Storage</code>(db: <code>storage</code>) N/A \u274c Empty, don't use"},{"location":"database/STORAGE_FIELDS_GUIDE/#work-orders-field-usage","title":"Work Orders - Field Usage","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#model-workorder-table-tblcustworkorderdetail","title":"Model: <code>WorkOrder</code> (Table: <code>tblcustworkorderdetail</code>)","text":"<pre><code># \u2705 CORRECT - Use these fields:\n\n# For physical location (where the item is)\nwork_order.RackNo = \"5 B\"  # Maps to rack_number column\nwork_order.RackNo = \"bin 4 top\"\nwork_order.RackNo = \"cleaning room\"\n\n# For storage time type (how long it's stored)\nwork_order.StorageTime = \"Seasonal\"  # Maps to storagetime column\nwork_order.StorageTime = \"Temporary\"\n\n# For post-cleaning location\nwork_order.final_location = \"Customer pickup area\"\n\n# \u274c WRONG - Don't use this:\nwork_order.Storage = \"...\"  # DEPRECATED - column is empty/unused\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#database-columns","title":"Database Columns","text":"Python Attribute DB Column Purpose Values <code>RackNo</code> <code>rack_number</code> Physical location \"5 B\", \"bin 4 top\", etc. <code>StorageTime</code> <code>storagetime</code> Storage duration type \"Seasonal\", \"Temporary\" <code>final_location</code> <code>finallocation</code> Post-service location Any string <code>Storage</code> <code>storage</code> \u274c DEPRECATED Empty/unused"},{"location":"database/STORAGE_FIELDS_GUIDE/#repair-orders-field-usage","title":"Repair Orders - Field Usage","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#model-repairworkorder-table-tblrepairworkorderdetail","title":"Model: <code>RepairWorkOrder</code> (Table: <code>tblrepairworkorderdetail</code>)","text":"<pre><code># \u2705 CORRECT - Use these fields:\n\n# For physical location (where the item is)\nrepair_order.RackNo = \"hang 4\"  # Maps to RACK# column\nrepair_order.RackNo = \"6D\"\nrepair_order.RackNo = \"1 D\"\n\n# For storage time type (how long it's stored)\n# NOTE: Field is named STORAGE but it's actually storage TIME type!\nrepair_order.STORAGE = \"TEMPORARY\"  # Maps to storage column\nrepair_order.STORAGE = \"SEASONAL\"\n\n# For additional location details (legacy)\nrepair_order.LOCATION = \"Back room\"  # Maps to location column\n\n# For post-repair location\nrepair_order.final_location = \"Ship to customer\"\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#database-columns_1","title":"Database Columns","text":"Python Attribute DB Column Purpose Values <code>RackNo</code> <code>RACK#</code> Physical location (PRIMARY) \"hang 4\", \"6D\", \"1 D\", etc. <code>STORAGE</code> <code>storage</code> Storage duration type \u26a0\ufe0f \"TEMPORARY\", \"SEASONAL\" <code>LOCATION</code> <code>location</code> Additional location details Any string <code>final_location</code> <code>finallocation</code> Post-service location Any string <p>\u26a0\ufe0f Important: Despite being named <code>STORAGE</code>, this field stores the storage TIME type (Seasonal/Temporary), not a physical location!</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#template-labels","title":"Template Labels","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#current-labels-confusing","title":"Current Labels (Confusing)","text":"<p>Work Order Edit: - Label says: \"Storage\" - Actually saves to: <code>RackNo</code> (rack_number) - Problem: Misleading label</p> <p>Repair Order Edit: - Label says: \"Storage\" - Actually saves to: <code>STORAGE</code> (storage type dropdown) - Label says: \"Location\" - Actually saves to: <code>LOCATION</code> but pre-fills from <code>RackNo</code> - Problem: Multiple fields for same purpose</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#recommended-labels-clear","title":"Recommended Labels (Clear)","text":"<p>Work Orders: <pre><code>&lt;!-- For physical location --&gt;\n&lt;label&gt;Location / Rack #&lt;/label&gt;\n&lt;input name=\"RackNo\" value=\"{{ work_order.RackNo }}\"&gt;\n\n&lt;!-- For storage duration --&gt;\n&lt;label&gt;Storage Time&lt;/label&gt;\n&lt;select name=\"StorageTime\"&gt;\n    &lt;option value=\"Seasonal\"&gt;Seasonal&lt;/option&gt;\n    &lt;option value=\"Temporary\"&gt;Temporary&lt;/option&gt;\n&lt;/select&gt;\n\n&lt;!-- For post-cleaning location --&gt;\n&lt;label&gt;Final Location (after cleaning)&lt;/label&gt;\n&lt;input name=\"final_location\" value=\"{{ work_order.final_location }}\"&gt;\n</code></pre></p> <p>Repair Orders: <pre><code>&lt;!-- For physical location --&gt;\n&lt;label&gt;Location / Rack #&lt;/label&gt;\n&lt;input name=\"RackNo\" value=\"{{ repair_order.RackNo }}\"&gt;\n\n&lt;!-- For storage duration (note: field name is STORAGE!) --&gt;\n&lt;label&gt;Storage Time&lt;/label&gt;\n&lt;select name=\"STORAGE\"&gt;\n    &lt;option value=\"TEMPORARY\"&gt;Temporary&lt;/option&gt;\n    &lt;option value=\"SEASONAL\"&gt;Seasonal&lt;/option&gt;\n&lt;/select&gt;\n\n&lt;!-- For post-repair location --&gt;\n&lt;label&gt;Final Location (after repair)&lt;/label&gt;\n&lt;input name=\"final_location\" value=\"{{ repair_order.final_location }}\"&gt;\n</code></pre></p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#routes-readingwriting","title":"Routes - Reading/Writing","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#work-orders-routes","title":"Work Orders Routes","text":"<pre><code># \u2705 CORRECT\nfrom routes.work_orders import work_orders_bp\n\n@work_orders_bp.route('/edit/&lt;work_order_no&gt;', methods=['POST'])\ndef edit_work_order(work_order_no):\n    work_order = WorkOrder.query.get_or_404(work_order_no)\n\n    # Physical location\n    work_order.RackNo = request.form.get(\"RackNo\")  # \"5 B\", \"bin 4 top\"\n\n    # Storage duration type\n    work_order.StorageTime = request.form.get(\"StorageTime\")  # \"Seasonal\"/\"Temporary\"\n\n    # Post-service location\n    work_order.final_location = request.form.get(\"final_location\")\n\n    # \u274c WRONG - Don't use Storage field\n    # work_order.Storage = request.form.get(\"Storage\")  # DEPRECATED!\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#repair-orders-routes","title":"Repair Orders Routes","text":"<pre><code># \u2705 CORRECT\nfrom routes.repair_order import repair_order_bp\n\n@repair_order_bp.route('/edit/&lt;repair_order_no&gt;', methods=['POST'])\ndef edit_repair_order(repair_order_no):\n    repair_order = RepairWorkOrder.query.get_or_404(repair_order_no)\n\n    # Physical location\n    repair_order.RackNo = request.form.get(\"RackNo\")  # \"hang 4\", \"6D\"\n\n    # Storage duration type (note field name!)\n    repair_order.STORAGE = request.form.get(\"STORAGE\")  # \"TEMPORARY\"/\"SEASONAL\"\n\n    # Additional location (optional, legacy)\n    repair_order.LOCATION = request.form.get(\"LOCATION\")\n\n    # Post-service location\n    repair_order.final_location = request.form.get(\"final_location\")\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#common-mistakes-to-avoid","title":"Common Mistakes to Avoid","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#mistake-1-using-workorderstorage","title":"\u274c Mistake 1: Using WorkOrder.Storage","text":"<pre><code># WRONG - Storage field is deprecated and empty\nwork_order.Storage = \"5 B\"  # This goes nowhere useful!\n\n# CORRECT - Use RackNo\nwork_order.RackNo = \"5 B\"\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#mistake-2-confusing-storage-with-location-in-repair-orders","title":"\u274c Mistake 2: Confusing STORAGE with location in Repair Orders","text":"<pre><code># WRONG - STORAGE is for time type, not location\nrepair_order.STORAGE = \"hang 4\"  # This is a location, not a time type!\n\n# CORRECT - Use RackNo for location, STORAGE for time\nrepair_order.RackNo = \"hang 4\"      # Physical location\nrepair_order.STORAGE = \"TEMPORARY\"   # How long it's stored\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#mistake-3-inconsistent-field-names-between-wo-and-ro","title":"\u274c Mistake 3: Inconsistent field names between WO and RO","text":"<pre><code># WRONG - Field names are different!\nwork_order.STORAGE = \"Seasonal\"      # Field doesn't exist in WO\nrepair_order.StorageTime = \"SEASONAL\"  # Field doesn't exist in RO\n\n# CORRECT - Use the right field for each model\nwork_order.StorageTime = \"Seasonal\"     # WO uses StorageTime\nrepair_order.STORAGE = \"SEASONAL\"       # RO uses STORAGE (unfortunately)\n</code></pre>"},{"location":"database/STORAGE_FIELDS_GUIDE/#data-migration-notes","title":"Data Migration Notes","text":""},{"location":"database/STORAGE_FIELDS_GUIDE/#work-order-storage-field","title":"Work Order Storage Field","text":"<ul> <li>The <code>storage</code> column in <code>tblcustworkorderdetail</code> is empty</li> <li>All location data is in <code>rack_number</code> column</li> <li>No data migration needed - just don't use <code>Storage</code> attribute</li> </ul>"},{"location":"database/STORAGE_FIELDS_GUIDE/#repair-order-storage-field","title":"Repair Order Storage Field","text":"<ul> <li>The <code>storage</code> column in <code>tblrepairworkorderdetail</code> contains data</li> <li>Data is storage time type: \"TEMPORARY\", \"SEASONAL\"</li> <li>This is why we can't rename it easily - it's actively used!</li> </ul>"},{"location":"database/STORAGE_FIELDS_GUIDE/#why-not-fix-this-with-a-migration","title":"Why Not Fix This With a Migration?","text":"<p>You might ask: \"Why not just rename STORAGE \u2192 StorageTime in repair orders?\"</p> <p>Answer: We decided not to change the schema because: 1. Schema changes require coordination across dev/test/prod databases 2. Risk of data loss or application downtime 3. The app works correctly - it's just confusing field names 4. Clear documentation and comments solve the problem without risk</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#quick-reference-card","title":"Quick Reference Card","text":"<p>Need to store WHERE something is located? - Work Orders: Use <code>RackNo</code> (db: <code>rack_number</code>) - Repair Orders: Use <code>RackNo</code> (db: <code>RACK#</code>)</p> <p>Need to store HOW LONG it's stored? - Work Orders: Use <code>StorageTime</code> (db: <code>storagetime</code>) \u2192 \"Seasonal\"/\"Temporary\" - Repair Orders: Use <code>STORAGE</code> (db: <code>storage</code>) \u2192 \"TEMPORARY\"/\"SEASONAL\"</p> <p>Need to store WHERE it goes after service? - Both: Use <code>final_location</code> (db: <code>finallocation</code>)</p>"},{"location":"database/STORAGE_FIELDS_GUIDE/#related-issues","title":"Related Issues","text":"<ul> <li>Issue #82: Combine Storage + Rack # into one field on detail page</li> <li>Issue #67: Add cleaning storage information to all work order edits (final_location)</li> </ul>"},{"location":"database/STORAGE_FIELDS_GUIDE/#see-also","title":"See Also","text":"<ul> <li>models/work_order.py - Lines 17-27 (Storage field definitions)</li> <li>models/repair_order.py - Lines 48-64 (Storage field definitions)</li> <li>CLAUDE.md - Project documentation</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/","title":"Source Name Denormalization - Deployment Checklist","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#pre-deployment-checklist","title":"Pre-Deployment Checklist","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#1-code-review","title":"1. Code Review","text":"<ul> <li>[ ] Review all code changes in Git</li> <li>[ ] Verify all tests pass locally</li> <li>[ ] Review migration script for syntax errors</li> <li>[ ] Confirm backup/rollback plan is understood</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#2-staging-environment","title":"2. Staging Environment","text":"<ul> <li>[ ] Backup staging database</li> <li>[ ] Apply migration to staging:   <pre><code>psql \"$STAGING_DATABASE_URL\" -f query_optimization/add_source_name_denormalization.sql\n</code></pre></li> <li>[ ] Verify migration success:   <pre><code>SELECT COUNT(*) as total, COUNT(source_name) as with_source\nFROM tblcustworkorderdetail;\n</code></pre></li> <li>[ ] Deploy code to staging</li> <li>[ ] Test all work order operations:</li> <li>[ ] Create work order</li> <li>[ ] Edit work order (change customer)</li> <li>[ ] List work orders</li> <li>[ ] Filter by source</li> <li>[ ] Sort by source</li> <li>[ ] Create repair order</li> <li>[ ] Edit repair order</li> <li>[ ] Filter repair orders by source</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#3-performance-verification-staging","title":"3. Performance Verification (Staging)","text":"<ul> <li>[ ] Run EXPLAIN ANALYZE on source filter query (before/after comparison)</li> <li>[ ] Check query execution times in logs</li> <li>[ ] Verify indexes are being used:   <pre><code>SELECT schemaname, tablename, indexname, idx_scan\nFROM pg_stat_user_indexes\nWHERE indexname LIKE '%source_name%';\n</code></pre></li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#4-data-consistency-check-staging","title":"4. Data Consistency Check (Staging)","text":"<ul> <li>[ ] Run verification query:   <pre><code>SELECT\n    COUNT(*) as total,\n    COUNT(wo.source_name) as has_source_name,\n    SUM(CASE WHEN wo.source_name = s.ssource THEN 1 ELSE 0 END) as correct,\n    SUM(CASE WHEN wo.source_name != s.ssource THEN 1 ELSE 0 END) as incorrect\nFROM tblcustworkorderdetail wo\nLEFT JOIN tblcustomers c ON wo.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource;\n</code></pre></li> <li>[ ] Verify incorrect count is 0</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#production-deployment-checklist","title":"Production Deployment Checklist","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#1-pre-deployment","title":"1. Pre-Deployment","text":"<ul> <li>[ ] Schedule maintenance window (recommend off-peak hours)</li> <li>[ ] Notify team of deployment</li> <li>[ ] Ensure backup retention is enabled</li> <li>[ ] Take manual snapshot of RDS (if using AWS)</li> <li>[ ] Document current performance baseline</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#2-database-migration","title":"2. Database Migration","text":"<ul> <li>[ ] Backup production database:   <pre><code># AWS RDS\naws rds create-db-snapshot --db-instance-identifier your-instance --db-snapshot-identifier pre-denorm-$(date +%Y%m%d)\n\n# Or manual\npg_dump \"$DATABASE_URL\" &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n</code></pre></li> <li>[ ] Apply migration to production:   <pre><code>psql \"$DATABASE_URL\" -f query_optimization/add_source_name_denormalization.sql\n</code></pre></li> <li>[ ] Verify migration completed successfully</li> <li>[ ] Check for errors in migration output</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#3-verification","title":"3. Verification","text":"<ul> <li>[ ] Run data consistency check:   <pre><code>-- Work Orders\nSELECT 'Work Orders' as table_name,\n       COUNT(*) as total,\n       COUNT(source_name) as with_source_name,\n       SUM(CASE WHEN source_name = s.ssource THEN 1 ELSE 0 END) as correct,\n       SUM(CASE WHEN source_name != s.ssource THEN 1 ELSE 0 END) as incorrect\nFROM tblcustworkorderdetail wo\nLEFT JOIN tblcustomers c ON wo.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource\n\nUNION ALL\n\n-- Repair Orders\nSELECT 'Repair Orders' as table_name,\n       COUNT(*) as total,\n       COUNT(source_name) as with_source_name,\n       SUM(CASE WHEN source_name = s.ssource THEN 1 ELSE 0 END) as correct,\n       SUM(CASE WHEN source_name != s.ssource THEN 1 ELSE 0 END) as incorrect\nFROM tblrepairworkorderdetail ro\nLEFT JOIN tblcustomers c ON ro.custid = c.custid\nLEFT JOIN tblsource s ON c.source = s.ssource;\n</code></pre></li> <li>[ ] Verify indexes were created:   <pre><code>SELECT schemaname, tablename, indexname, indexdef\nFROM pg_indexes\nWHERE indexname IN ('idx_workorder_source_name', 'idx_repairorder_source_name');\n</code></pre></li> <li>[ ] Verify triggers were created:   <pre><code>SELECT trigger_name, event_manipulation, event_object_table\nFROM information_schema.triggers\nWHERE trigger_name LIKE '%source_name%';\n</code></pre></li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#4-application-deployment","title":"4. Application Deployment","text":"<ul> <li>[ ] Commit all code changes:   <pre><code>git add .\ngit commit -m \"Add source_name denormalization for 100x query performance\"\ngit push origin main\n</code></pre></li> <li>[ ] Deploy application (AWS EB example):   <pre><code>eb deploy\n</code></pre></li> <li>[ ] Wait for deployment to complete</li> <li>[ ] Check deployment status:   <pre><code>eb status\n</code></pre></li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#5-smoke-testing","title":"5. Smoke Testing","text":"<ul> <li>[ ] Open application in browser</li> <li>[ ] Test work order list page loads</li> <li>[ ] Test source filter works</li> <li>[ ] Test source sorting works</li> <li>[ ] Test creating new work order</li> <li>[ ] Test editing existing work order</li> <li>[ ] Test repair order list page</li> <li>[ ] Test creating new repair order</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#6-performance-monitoring","title":"6. Performance Monitoring","text":"<ul> <li>[ ] Monitor application logs for errors:   <pre><code>eb logs --stream\n# or\ntail -f /var/log/application.log\n</code></pre></li> <li>[ ] Check query execution times in database logs</li> <li>[ ] Monitor application response times</li> <li>[ ] Check error rates in monitoring tools</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#7-post-deployment-verification","title":"7. Post-Deployment Verification","text":"<ul> <li>[ ] Test source filter API:   <pre><code>curl \"https://your-app.com/api/work_orders?filter_Source=Boat\"\n</code></pre></li> <li>[ ] Test source sorting API:   <pre><code>curl \"https://your-app.com/api/work_orders?sort[0][field]=Source&amp;sort[0][dir]=asc\"\n</code></pre></li> <li>[ ] Verify API returns correct data</li> <li>[ ] Check response times are faster</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#post-deployment-monitoring-first-24-hours","title":"Post-Deployment Monitoring (First 24 Hours)","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#immediate-first-hour","title":"Immediate (First Hour)","text":"<ul> <li>[ ] Monitor error logs continuously</li> <li>[ ] Check application metrics dashboard</li> <li>[ ] Watch for any null pointer exceptions</li> <li>[ ] Monitor database CPU and memory usage</li> <li>[ ] Check query execution times</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#first-4-hours","title":"First 4 Hours","text":"<ul> <li>[ ] Review error logs every hour</li> <li>[ ] Check data consistency</li> <li>[ ] Monitor user-reported issues</li> <li>[ ] Verify backup completed successfully</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#first-24-hours","title":"First 24 Hours","text":"<ul> <li>[ ] Review error logs 3-4 times</li> <li>[ ] Check data consistency once</li> <li>[ ] Monitor query performance trends</li> <li>[ ] Document any issues encountered</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#rollback-plan-if-needed","title":"Rollback Plan (If Needed)","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#when-to-rollback","title":"When to Rollback","text":"<ul> <li>[ ] Critical errors in application</li> <li>[ ] Data inconsistency detected</li> <li>[ ] Performance degradation</li> <li>[ ] User-facing bugs</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#rollback-steps","title":"Rollback Steps","text":"<ol> <li> <p>[ ] Revert application code:    <pre><code>git revert HEAD\ngit push origin main\neb deploy\n</code></pre></p> </li> <li> <p>[ ] Revert database changes:    <pre><code>psql \"$DATABASE_URL\" -f query_optimization/rollback_source_name_denormalization.sql\n</code></pre></p> </li> </ol> <p>Or manually:    <pre><code>BEGIN;\n\n-- Drop triggers\nDROP TRIGGER IF EXISTS trg_sync_work_order_source_name ON tblcustworkorderdetail;\nDROP TRIGGER IF EXISTS trg_sync_repair_order_source_name ON tblrepairworkorderdetail;\nDROP TRIGGER IF EXISTS trg_sync_orders_on_customer_source_change ON tblcustomers;\n\n-- Drop functions\nDROP FUNCTION IF EXISTS sync_work_order_source_name();\nDROP FUNCTION IF EXISTS sync_repair_order_source_name();\nDROP FUNCTION IF EXISTS sync_orders_on_customer_source_change();\n\n-- Drop indexes\nDROP INDEX IF EXISTS idx_workorder_source_name;\nDROP INDEX IF EXISTS idx_repairorder_source_name;\n\n-- Drop columns (optional - can leave for future retry)\n-- ALTER TABLE tblcustworkorderdetail DROP COLUMN IF EXISTS source_name;\n-- ALTER TABLE tblrepairworkorderdetail DROP COLUMN IF EXISTS source_name;\n\nCOMMIT;\n</code></pre></p> <ol> <li>[ ] Verify rollback successful</li> <li>[ ] Monitor for stability</li> <li>[ ] Document rollback reason</li> </ol>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#success-criteria","title":"Success Criteria","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#migration-success","title":"Migration Success","text":"<ul> <li>[x] All SQL statements executed without errors</li> <li>[x] All existing records have <code>source_name</code> populated</li> <li>[x] Indexes created successfully</li> <li>[x] Triggers created successfully</li> <li>[x] Data consistency checks pass</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#application-success","title":"Application Success","text":"<ul> <li>[x] All tests pass (40/40)</li> <li>[x] No errors in application logs</li> <li>[x] Work order operations work correctly</li> <li>[x] Repair order operations work correctly</li> <li>[x] Source filtering works</li> <li>[x] Source sorting works</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#performance-success","title":"Performance Success","text":"<ul> <li>[ ] Source sorting &lt; 5ms (target: ~1ms)</li> <li>[ ] Source filtering &lt; 1ms (target: ~0.1ms)</li> <li>[ ] Default list load &lt; 1ms (target: ~0.04ms)</li> <li>[ ] Index usage confirmed in query plans</li> <li>[ ] No sequential scans on source_name queries</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#data-integrity-success","title":"Data Integrity Success","text":"<ul> <li>[ ] No data inconsistencies detected</li> <li>[ ] All triggers firing correctly</li> <li>[ ] Application sync methods working</li> <li>[ ] Customer source changes propagate correctly</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#contact-information","title":"Contact Information","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#in-case-of-issues","title":"In Case of Issues","text":"<ul> <li>Database Admin: [Your DBA Contact]</li> <li>DevOps Lead: [Your DevOps Contact]</li> <li>On-Call Engineer: [Your On-Call Contact]</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#useful-commands","title":"Useful Commands","text":"<pre><code># Check current git commit\ngit log -1\n\n# Check deployed version\neb printenv | grep GIT_COMMIT\n\n# View real-time logs\neb logs --stream\n\n# Check database connections\npsql \"$DATABASE_URL\" -c \"SELECT count(*) FROM pg_stat_activity;\"\n\n# Check table size\npsql \"$DATABASE_URL\" -c \"\n  SELECT\n    pg_size_pretty(pg_total_relation_size('tblcustworkorderdetail')) as work_orders_size,\n    pg_size_pretty(pg_total_relation_size('tblrepairworkorderdetail')) as repair_orders_size;\n\"\n</code></pre>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#notes","title":"Notes","text":""},{"location":"deployment/DEPLOYMENT_CHECKLIST/#duration-estimates","title":"Duration Estimates","text":"<ul> <li>Migration execution: 1-5 minutes (depends on table size)</li> <li>Application deployment: 5-10 minutes</li> <li>Smoke testing: 10-15 minutes</li> <li>Total: 20-30 minutes</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#risks","title":"Risks","text":"<ul> <li>Low risk: Migration is backward compatible</li> <li>Low risk: All relationships maintained</li> <li>Low risk: Comprehensive testing completed</li> <li>Low risk: Rollback plan available</li> </ul>"},{"location":"deployment/DEPLOYMENT_CHECKLIST/#known-issues","title":"Known Issues","text":"<ul> <li>None at this time</li> </ul> <p>Last Updated: October 12, 2025 Version: 1.0 Status: Ready for Production Deployment</p>"},{"location":"deployment/aws-eb/","title":"AWS Elastic Beanstalk Deployment","text":"<p>Complete guide to deploying the Awning Management System on AWS Elastic Beanstalk.</p>"},{"location":"deployment/aws-eb/#overview","title":"Overview","text":"<p>The application is deployed on AWS Elastic Beanstalk with: - Platform: Python 3.11 - Instance Type: t3.small - Database: PostgreSQL on RDS - Storage: S3 for file uploads - Server: Gunicorn (WSGI)</p>"},{"location":"deployment/aws-eb/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/aws-eb/#required-tools","title":"Required Tools","text":"<pre><code># AWS CLI\npip install awscli\n\n# EB CLI\npip install awsebcli\n\n# Configure AWS credentials\naws configure\n</code></pre>"},{"location":"deployment/aws-eb/#required-aws-resources","title":"Required AWS Resources","text":"<p>Before deployment, ensure you have: - AWS account with appropriate permissions - RDS PostgreSQL database (or create during EB setup) - S3 bucket for file storage - IAM credentials with S3 and RDS access</p>"},{"location":"deployment/aws-eb/#initial-setup","title":"Initial Setup","text":""},{"location":"deployment/aws-eb/#1-initialize-elastic-beanstalk","title":"1. Initialize Elastic Beanstalk","text":"<pre><code># Navigate to project directory\ncd awning_wo\n\n# Initialize EB application\neb init -p python-3.11 awning-wo --region us-east-1\n</code></pre> <p>You'll be prompted for: - Application name (e.g., <code>awning-wo</code>) - Platform (Python 3.11) - SSH key pair (optional but recommended)</p>"},{"location":"deployment/aws-eb/#2-create-environment","title":"2. Create Environment","text":"<pre><code># Create production environment with database\neb create awning-prod \\\n  --instance-type t3.small \\\n  --database.engine postgres \\\n  --database.username postgres \\\n  --database.password &lt;secure-password&gt;\n</code></pre> <p>This creates: - EC2 instance (t3.small) - RDS PostgreSQL database - Security groups - Load balancer (if needed) - Auto-scaling configuration</p>"},{"location":"deployment/aws-eb/#3-set-environment-variables","title":"3. Set Environment Variables","text":"<pre><code>eb setenv \\\n  SECRET_KEY=\"&lt;generate-secure-key&gt;\" \\\n  FLASK_ENV=\"production\" \\\n  AWS_ACCESS_KEY_ID=\"&lt;your-access-key&gt;\" \\\n  AWS_SECRET_ACCESS_KEY=\"&lt;your-secret-key&gt;\" \\\n  AWS_S3_BUCKET=\"awning-cleaning-data\" \\\n  AWS_REGION=\"us-east-1\" \\\n  CRON_SECRET=\"&lt;secure-cron-secret&gt;\"\n</code></pre> <p>Security</p> <p>Never commit credentials to git. Use environment variables only.</p>"},{"location":"deployment/aws-eb/#application-configuration","title":"Application Configuration","text":""},{"location":"deployment/aws-eb/#entry-point","title":"Entry Point","text":"<p>EB looks for <code>application.py</code> as the WSGI entry point:</p> <pre><code># application.py\nfrom app import app as application\n\nif __name__ == \"__main__\":\n    application.run()\n</code></pre>"},{"location":"deployment/aws-eb/#wsgi-configuration","title":"WSGI Configuration","text":"<p>The WSGI path is configured in <code>.ebextensions/01_flask.config</code>:</p> <pre><code>option_settings:\n  aws:elasticbeanstalk:container:python:\n    WSGIPath: app.py\n</code></pre>"},{"location":"deployment/aws-eb/#eb-extensions-configuration","title":"EB Extensions Configuration","text":""},{"location":"deployment/aws-eb/#flask-configuration-ebextensions01_flaskconfig","title":"Flask Configuration (<code>.ebextensions/01_flask.config</code>)","text":"<pre><code>option_settings:\n  aws:elasticbeanstalk:application:environment:\n    PYTHONPATH: /var/app/current\n    FLASK_ENV: production\n    DATABASE_URL: \"postgresql://...\"\n\n  aws:autoscaling:launchconfiguration:\n    InstanceType: t3.small\n\n  aws:elasticbeanstalk:environment:process:default:\n    Port: \"80\"\n    HealthCheckPath: \"/health\"\n</code></pre> <p>Key Settings: - <code>PYTHONPATH</code>: Points to application directory - <code>HealthCheckPath</code>: Health check endpoint - <code>InstanceType</code>: EC2 instance size</p>"},{"location":"deployment/aws-eb/#cron-jobs-ebextensionscronconfig","title":"Cron Jobs (<code>.ebextensions/cron.config</code>)","text":"<p>Sets up daily ML model retraining at 2:00 AM:</p> <pre><code>container_commands:\n  01_setup_cron_job:\n    command: |\n      # Add cron job - runs daily at 2:00 AM\n      (crontab -l 2&gt;/dev/null; echo \"0 2 * * * /usr/local/bin/ml-cron-retrain.sh\") | crontab -\n      service crond start || service cron start || true\n</code></pre> <p>Cron Script: <code>/usr/local/bin/ml-cron-retrain.sh</code> - Calls <code>/ml/cron/retrain</code> endpoint - Authenticates with <code>X-Cron-Secret</code> header - Logs to <code>/var/log/ml-retrain.log</code></p>"},{"location":"deployment/aws-eb/#database-setup","title":"Database Setup","text":""},{"location":"deployment/aws-eb/#connection-string","title":"Connection String","text":"<p>EB automatically provides RDS connection details as environment variables: - <code>RDS_HOSTNAME</code> - <code>RDS_USERNAME</code> - <code>RDS_PASSWORD</code> - <code>RDS_PORT</code> - <code>RDS_DB_NAME</code></p> <p>The application uses <code>DATABASE_URL</code> for simplicity:</p> <pre><code># config.py\nDATABASE_URL = os.environ.get('DATABASE_URL') or \\\n    f\"postgresql://{os.environ.get('RDS_USERNAME')}:...\"\n</code></pre>"},{"location":"deployment/aws-eb/#run-migrations","title":"Run Migrations","text":"<p>After deployment, SSH into the instance and run migrations:</p> <pre><code># SSH into instance\neb ssh\n\n# Activate virtual environment\nsource /var/app/venv/*/bin/activate\ncd /var/app/current\n\n# Run migrations\nalembic upgrade head\n\n# Verify\nalembic current\n</code></pre>"},{"location":"deployment/aws-eb/#deployment-workflow","title":"Deployment Workflow","text":""},{"location":"deployment/aws-eb/#standard-deployment","title":"Standard Deployment","text":"<pre><code># 1. Make code changes\ngit add .\ngit commit -m \"Your changes\"\n\n# 2. Test locally\npython app.py\n\n# 3. Deploy to EB\neb deploy\n\n# 4. Monitor deployment\neb status\neb health\n</code></pre>"},{"location":"deployment/aws-eb/#deployment-with-schema-changes","title":"Deployment with Schema Changes","text":"<pre><code># 1. Create and test migration locally\n./alembic_db.sh test revision --autogenerate -m \"add_field\"\n./alembic_db.sh test upgrade head\n\n# 2. Commit migration file\ngit add alembic/versions/*.py\ngit commit -m \"Add database migration\"\n\n# 3. Apply migration to production\n./alembic_db.sh prod upgrade head\n\n# 4. Deploy application code\neb deploy\n\n# 5. Monitor\neb logs --stream\n</code></pre> <p>Important</p> <p>Always apply database migrations BEFORE deploying code that depends on them.</p>"},{"location":"deployment/aws-eb/#monitoring-logs","title":"Monitoring &amp; Logs","text":""},{"location":"deployment/aws-eb/#view-logs","title":"View Logs","text":"<pre><code># Stream real-time logs\neb logs --stream\n\n# Get recent logs\neb logs\n\n# Download all logs\neb logs --all\n</code></pre>"},{"location":"deployment/aws-eb/#log-locations-on-instance","title":"Log Locations on Instance","text":"<pre><code># Application logs\n/var/log/eb-engine.log          # EB deployment logs\n/var/log/web.stdout.log         # Application output\n/var/log/httpd/error_log        # Apache/nginx errors\n\n# Custom logs\n/var/log/ml-retrain.log         # ML cron job logs\n/var/log/ml-cron-health.log     # Cron health checks\n</code></pre>"},{"location":"deployment/aws-eb/#check-application-status","title":"Check Application Status","text":"<pre><code># Environment status\neb status\n\n# Health status\neb health\n\n# Environment info\neb printenv\n</code></pre>"},{"location":"deployment/aws-eb/#health-checks","title":"Health Checks","text":"<p>EB monitors application health via the <code>/health</code> endpoint:</p> <pre><code># routes/dashboard.py\n@dashboard_bp.route('/health')\ndef health():\n    \"\"\"Health check endpoint for AWS ELB\"\"\"\n    return jsonify({\n        'status': 'healthy',\n        'timestamp': datetime.now().isoformat()\n    }), 200\n</code></pre> <p>Configuration: - Path: <code>/health</code> - Expected Status: <code>200 OK</code> - Check Interval: 30 seconds - Timeout: 5 seconds - Healthy Threshold: 3 consecutive successes - Unhealthy Threshold: 5 consecutive failures</p>"},{"location":"deployment/aws-eb/#sslhttps-setup","title":"SSL/HTTPS Setup","text":""},{"location":"deployment/aws-eb/#using-aws-certificate-manager-acm","title":"Using AWS Certificate Manager (ACM)","text":"<pre><code># 1. Request certificate in ACM\naws acm request-certificate \\\n  --domain-name yourdomain.com \\\n  --domain-name www.yourdomain.com \\\n  --validation-method DNS\n\n# 2. Configure load balancer\neb config\n\n# Add to configuration:\naws:elbv2:listener:443:\n  Protocol: HTTPS\n  SSLCertificateArns: arn:aws:acm:...\n</code></pre>"},{"location":"deployment/aws-eb/#force-https-redirect","title":"Force HTTPS Redirect","text":"<p>Add to <code>.ebextensions/https-redirect.config</code>:</p> <pre><code>files:\n  \"/etc/httpd/conf.d/ssl_rewrite.conf\":\n    mode: \"000644\"\n    owner: root\n    group: root\n    content: |\n      RewriteEngine On\n      RewriteCond %{HTTP:X-Forwarded-Proto} !https\n      RewriteRule ^(.*)$ https://%{HTTP_HOST}$1 [R=301,L]\n</code></pre>"},{"location":"deployment/aws-eb/#scaling-configuration","title":"Scaling Configuration","text":""},{"location":"deployment/aws-eb/#auto-scaling","title":"Auto Scaling","text":"<p>Configure auto-scaling in <code>.ebextensions/autoscaling.config</code>:</p> <pre><code>option_settings:\n  aws:autoscaling:asg:\n    MinSize: 1\n    MaxSize: 4\n  aws:autoscaling:trigger:\n    MeasureName: CPUUtilization\n    Statistic: Average\n    Unit: Percent\n    UpperThreshold: 75\n    LowerThreshold: 25\n</code></pre>"},{"location":"deployment/aws-eb/#manual-scaling","title":"Manual Scaling","text":"<pre><code># Scale up\neb scale 2\n\n# Scale down\neb scale 1\n</code></pre>"},{"location":"deployment/aws-eb/#environment-management","title":"Environment Management","text":""},{"location":"deployment/aws-eb/#multiple-environments","title":"Multiple Environments","text":"<pre><code># Create staging environment\neb create awning-staging --instance-type t3.micro\n\n# Create production environment\neb create awning-prod --instance-type t3.small\n\n# Switch between environments\neb use awning-staging\neb use awning-prod\n\n# Deploy to specific environment\neb deploy awning-prod\n</code></pre>"},{"location":"deployment/aws-eb/#environment-variables","title":"Environment Variables","text":"<pre><code># Set variables\neb setenv VAR_NAME=value\n\n# View all variables\neb printenv\n\n# Set multiple variables\neb setenv VAR1=val1 VAR2=val2\n</code></pre>"},{"location":"deployment/aws-eb/#database-management","title":"Database Management","text":""},{"location":"deployment/aws-eb/#access-rds-instance","title":"Access RDS Instance","text":"<pre><code># Get RDS endpoint\neb printenv | grep RDS\n\n# Connect from local machine (requires security group access)\npsql \"postgresql://user:pass@host:5432/dbname\"\n\n# Connect from EB instance\neb ssh\npsql -h $RDS_HOSTNAME -U $RDS_USERNAME -d $RDS_DB_NAME\n</code></pre>"},{"location":"deployment/aws-eb/#backup-database","title":"Backup Database","text":"<pre><code># Manual backup via pg_dump\neb ssh\npg_dump -h $RDS_HOSTNAME -U $RDS_USERNAME $RDS_DB_NAME &gt; backup.sql\n\n# Automated backups (RDS)\naws rds create-db-snapshot \\\n  --db-instance-identifier database-1 \\\n  --db-snapshot-identifier backup-$(date +%Y%m%d)\n</code></pre>"},{"location":"deployment/aws-eb/#s3-file-storage","title":"S3 File Storage","text":""},{"location":"deployment/aws-eb/#bucket-configuration","title":"Bucket Configuration","text":"<p>Files are stored in S3 bucket: <code>awning-cleaning-data</code></p> <p>Required IAM Permissions: <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:PutObject\",\n        \"s3:GetObject\",\n        \"s3:DeleteObject\",\n        \"s3:ListBucket\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::awning-cleaning-data/*\",\n        \"arn:aws:s3:::awning-cleaning-data\"\n      ]\n    }\n  ]\n}\n</code></pre></p>"},{"location":"deployment/aws-eb/#access-files","title":"Access Files","text":"<pre><code># Application uses boto3\nimport boto3\n\ns3 = boto3.client('s3',\n    aws_access_key_id=AWS_ACCESS_KEY_ID,\n    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n    region_name=AWS_REGION\n)\n\n# Upload\ns3.upload_fileobj(file, bucket, key)\n\n# Download\ns3.download_fileobj(bucket, key, file)\n\n# Generate presigned URL\nurl = s3.generate_presigned_url('get_object',\n    Params={'Bucket': bucket, 'Key': key},\n    ExpiresIn=3600\n)\n</code></pre>"},{"location":"deployment/aws-eb/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/aws-eb/#deployment-fails","title":"Deployment Fails","text":"<pre><code># Check deployment logs\neb logs\n\n# Check specific log file\neb ssh\ntail -f /var/log/eb-engine.log\n</code></pre> <p>Common Issues: - Missing dependencies in <code>requirements.txt</code> - Invalid <code>.ebextensions</code> syntax - Database connection issues - Permission errors</p>"},{"location":"deployment/aws-eb/#application-wont-start","title":"Application Won't Start","text":"<pre><code># Check WSGI configuration\neb config\n\n# Verify entry point\neb ssh\nls -la /var/app/current/application.py\n\n# Check Python path\necho $PYTHONPATH\n</code></pre>"},{"location":"deployment/aws-eb/#database-connection-errors","title":"Database Connection Errors","text":"<pre><code># Verify environment variables\neb printenv | grep DATABASE\n\n# Test connection from instance\neb ssh\npsql -h $RDS_HOSTNAME -U $RDS_USERNAME -d $RDS_DB_NAME\n\n# Check security groups\n# RDS security group must allow inbound from EB instances\n</code></pre>"},{"location":"deployment/aws-eb/#health-check-failures","title":"Health Check Failures","text":"<pre><code># Test health endpoint\ncurl http://localhost/health\n\n# Check logs\ntail -f /var/log/web.stdout.log\n\n# Verify endpoint returns 200\ncurl -I http://localhost/health\n</code></pre>"},{"location":"deployment/aws-eb/#cost-optimization","title":"Cost Optimization","text":""},{"location":"deployment/aws-eb/#developmentstaging","title":"Development/Staging","text":"<ul> <li>Use t3.micro instances</li> <li>Single instance (no load balancer)</li> <li>RDS t3.micro with minimal storage</li> <li>Delete when not in use</li> </ul>"},{"location":"deployment/aws-eb/#production","title":"Production","text":"<ul> <li>t3.small instance (current configuration)</li> <li>Auto-scaling (1-4 instances)</li> <li>RDS backups enabled</li> <li>Reserved instances for cost savings</li> </ul>"},{"location":"deployment/aws-eb/#estimated-costs-monthly","title":"Estimated Costs (Monthly)","text":"Resource Configuration Approximate Cost EC2 (t3.small) 1 instance $15-20 RDS (db.t3.small) PostgreSQL $25-30 S3 Storage 10 GB $0.25 Data Transfer &lt; 1 TB $10-15 Total $50-65/month"},{"location":"deployment/aws-eb/#security-best-practices","title":"Security Best Practices","text":""},{"location":"deployment/aws-eb/#1-environment-variables","title":"1. Environment Variables","text":"<p>\u2705 Do: Store credentials in EB environment variables \u274c Don't: Commit credentials to <code>.ebextensions</code> files</p>"},{"location":"deployment/aws-eb/#2-database-security","title":"2. Database Security","text":"<ul> <li>Use strong RDS passwords</li> <li>Restrict RDS security group to EB instances only</li> <li>Enable RDS encryption at rest</li> <li>Regular backups</li> </ul>"},{"location":"deployment/aws-eb/#3-s3-security","title":"3. S3 Security","text":"<ul> <li>Use IAM roles instead of access keys when possible</li> <li>Enable S3 bucket encryption</li> <li>Restrict bucket access</li> <li>Enable versioning for critical data</li> </ul>"},{"location":"deployment/aws-eb/#4-application-security","title":"4. Application Security","text":"<ul> <li>Use HTTPS only</li> <li>Set secure cookie flags</li> <li>Implement CSRF protection</li> <li>Keep dependencies updated</li> </ul>"},{"location":"deployment/aws-eb/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"deployment/aws-eb/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code>name: Deploy to EB\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Install EB CLI\n        run: pip install awsebcli\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v1\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-east-1\n\n      - name: Deploy to EB\n        run: |\n          eb use awning-prod\n          eb deploy\n</code></pre>"},{"location":"deployment/aws-eb/#useful-commands-reference","title":"Useful Commands Reference","text":"<pre><code># Deployment\neb init                 # Initialize EB application\neb create              # Create environment\neb deploy              # Deploy application\neb terminate           # Terminate environment\n\n# Monitoring\neb status              # Environment status\neb health              # Health status\neb logs                # View logs\neb logs --stream       # Stream logs\neb ssh                 # SSH into instance\n\n# Configuration\neb config              # Edit configuration\neb setenv KEY=VALUE    # Set environment variable\neb printenv            # View environment variables\n\n# Scaling\neb scale 2             # Scale to 2 instances\neb scale 1             # Scale to 1 instance\n\n# Environment management\neb list                # List environments\neb use &lt;env&gt;           # Switch environment\neb open                # Open in browser\n</code></pre>"},{"location":"deployment/aws-eb/#see-also","title":"See Also","text":"<ul> <li>Deployment Checklist - Pre-deployment verification</li> <li>Environment Variables - Complete variable reference</li> <li>Monitoring &amp; Logging - Production monitoring</li> <li>Rollback Procedures - Emergency rollback guide</li> <li>Database Migrations - Alembic workflow</li> </ul>"},{"location":"deployment/operations-runbook/","title":"Operations Runbook","text":""},{"location":"deployment/operations-runbook/#overview","title":"Overview","text":"<p>This runbook provides step-by-step procedures for common operational tasks, troubleshooting, and incident response for the Awning Management System running on AWS Elastic Beanstalk.</p>"},{"location":"deployment/operations-runbook/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Daily Operations</li> <li>Deployment Procedures</li> <li>Database Operations</li> <li>Monitoring &amp; Alerts</li> <li>Incident Response</li> <li>Backup &amp; Recovery</li> <li>Performance Tuning</li> <li>Maintenance Tasks</li> </ul>"},{"location":"deployment/operations-runbook/#daily-operations","title":"Daily Operations","text":""},{"location":"deployment/operations-runbook/#health-checks","title":"Health Checks","text":"<p>Check application health: <pre><code># Via browser\nhttps://your-app-url.elasticbeanstalk.com/health\n\n# Via curl\ncurl https://your-app-url.elasticbeanstalk.com/health\n\n# Expected response:\n# {\"status\": \"healthy\", \"database\": \"connected\", \"timestamp\": \"2025-11-16T10:30:00Z\"}\n</code></pre></p> <p>Check EB environment status: <pre><code>eb status\n\n# Expected output:\n# Environment details for: awning-prod\n# Status: Ready\n# Health: Green\n</code></pre></p> <p>Monitor logs: <pre><code># Stream real-time logs\neb logs --stream\n\n# Get recent logs\neb logs --all\n\n# Check specific log file on instance\neb ssh\ntail -f /var/log/eb-engine.log\ntail -f /var/log/ml-retrain.log\n</code></pre></p>"},{"location":"deployment/operations-runbook/#database-health","title":"Database Health","text":"<p>Check database connections: <pre><code># SSH into EB instance\neb ssh\n\n# Check PostgreSQL connectivity\npython3 &lt;&lt; EOF\nfrom app import app, db\nwith app.app_context():\n    try:\n        db.session.execute('SELECT 1')\n        print(\"\u2713 Database connected\")\n    except Exception as e:\n        print(f\"\u2717 Database error: {e}\")\nEOF\n</code></pre></p> <p>Monitor RDS metrics (AWS Console): - CPU utilization (should be &lt; 70%) - Database connections (should be &lt; max_connections * 0.8) - Free storage space (should be &gt; 20%) - Read/write latency</p>"},{"location":"deployment/operations-runbook/#ml-model-status","title":"ML Model Status","text":"<p>Check last model training: <pre><code>eb ssh\ncat /var/log/ml-retrain.log | tail -50\n\n# Look for:\n# [2025-11-16 02:00:15] INFO: Model training completed\n# [2025-11-16 02:00:15] INFO: MAE: 1.2, R2: 0.89\n</code></pre></p> <p>Trigger manual retraining if needed: <pre><code>curl -X POST http://localhost/ml/cron/retrain \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Cron-Secret: YOUR_CRON_SECRET\" \\\n  -d '{\"config\": \"baseline\"}'\n</code></pre></p>"},{"location":"deployment/operations-runbook/#deployment-procedures","title":"Deployment Procedures","text":""},{"location":"deployment/operations-runbook/#standard-deployment-no-schema-changes","title":"Standard Deployment (No Schema Changes)","text":"<p>Pre-deployment checklist: - [ ] All tests passing locally (<code>pytest</code>) - [ ] Code reviewed and approved - [ ] Changes committed to git - [ ] No database schema changes</p> <p>Steps: <pre><code># 1. Verify current state\neb status\ngit status\n\n# 2. Ensure on correct branch\ngit checkout main\ngit pull origin main\n\n# 3. Run tests\npytest\n\n# 4. Deploy to EB\neb deploy\n\n# 5. Monitor deployment\neb health --refresh\n\n# 6. Verify deployment\ncurl https://your-app-url.com/health\n\n# 7. Check logs for errors\neb logs --stream\n\n# 8. Test critical functionality\n# - Login\n# - Create work order\n# - View analytics dashboard\n</code></pre></p> <p>Estimated downtime: 0-2 minutes</p> <p>Rollback procedure: <pre><code># List recent deployments\neb appversion lifecycle\n\n# Rollback to previous version\neb use &lt;previous-version-name&gt;\neb deploy --version &lt;previous-version-name&gt;\n</code></pre></p>"},{"location":"deployment/operations-runbook/#deployment-with-database-schema-changes","title":"Deployment with Database Schema Changes","text":"<p>Pre-deployment checklist: - [ ] Alembic migration created and tested - [ ] Migration tested on test database - [ ] Backup of production database created - [ ] Downtime window scheduled (if needed)</p> <p>Steps: <pre><code># 1. Test migration on test database\n./alembic_db.sh test upgrade head\n\n# 2. Verify migration succeeded\n./alembic_db.sh test current\n\n# 3. Backup production database (via RDS)\n# AWS Console &gt; RDS &gt; Snapshots &gt; Create Snapshot\n\n# 4. Run migration on production\n./alembic_db.sh prod upgrade head\n\n# 5. Verify migration\n./alembic_db.sh prod current\n\n# 6. Deploy application code\ngit commit -am \"Add new feature with migration\"\neb deploy\n\n# 7. Verify deployment\neb logs --stream\ncurl https://your-app-url.com/health\n\n# 8. Test new feature\n# Manual testing of affected functionality\n</code></pre></p> <p>Rollback procedure: <pre><code># 1. Rollback migration\n./alembic_db.sh prod downgrade -1\n\n# 2. Deploy previous version\neb deploy --version &lt;previous-version&gt;\n\n# 3. If data corruption, restore RDS snapshot\n# AWS Console &gt; RDS &gt; Snapshots &gt; Restore\n</code></pre></p>"},{"location":"deployment/operations-runbook/#zero-downtime-deployment-bluegreen","title":"Zero-Downtime Deployment (Blue/Green)","text":"<p>For critical updates: <pre><code># 1. Create new environment (green)\neb clone awning-prod --clone_name awning-prod-green\n\n# 2. Deploy to green environment\neb use awning-prod-green\neb deploy\n\n# 3. Test green environment\ncurl https://awning-prod-green.elasticbeanstalk.com/health\n\n# 4. Swap CNAMEs (switch traffic)\neb swap awning-prod --destination_name awning-prod-green\n\n# 5. Monitor for issues\neb logs --stream\n\n# 6. If successful, terminate old environment\neb terminate awning-prod-old\n</code></pre></p>"},{"location":"deployment/operations-runbook/#database-operations","title":"Database Operations","text":""},{"location":"deployment/operations-runbook/#running-migrations","title":"Running Migrations","text":"<p>Check current migration status: <pre><code># Production database\n./alembic_db.sh prod current\n\n# Test database\n./alembic_db.sh test current\n\n# Expected output:\n# INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.\n# INFO  [alembic.runtime.migration] Will assume transactional DDL.\n# abc123def456 (head)\n</code></pre></p> <p>Create new migration: <pre><code># 1. Modify model in models/\n# 2. Generate migration\n./alembic_db.sh test revision --autogenerate -m \"add_new_field\"\n\n# 3. Review generated migration\ncat alembic/versions/abc123_add_new_field.py\n\n# 4. Test migration\n./alembic_db.sh test upgrade head\n\n# 5. Apply to production (after deployment)\n./alembic_db.sh prod upgrade head\n</code></pre></p> <p>Rollback migration: <pre><code># Downgrade one version\n./alembic_db.sh prod downgrade -1\n\n# Downgrade to specific version\n./alembic_db.sh prod downgrade abc123\n\n# View migration history\n./alembic_db.sh prod history\n</code></pre></p>"},{"location":"deployment/operations-runbook/#database-backup","title":"Database Backup","text":"<p>Manual backup (RDS snapshot): <pre><code># Via AWS CLI\naws rds create-db-snapshot \\\n  --db-instance-identifier awning-prod-db \\\n  --db-snapshot-identifier awning-prod-manual-$(date +%Y%m%d-%H%M%S)\n\n# Verify snapshot\naws rds describe-db-snapshots \\\n  --db-instance-identifier awning-prod-db\n</code></pre></p> <p>Export data to CSV: <pre><code>eb ssh\n\n# Export work orders\npython3 &lt;&lt; EOF\nfrom app import app, db\nfrom models.work_order import WorkOrder\nimport csv\n\nwith app.app_context():\n    orders = WorkOrder.query.all()\n    with open('/tmp/work_orders_backup.csv', 'w') as f:\n        writer = csv.writer(f)\n        writer.writerow(['WorkOrderNo', 'CustomerName', 'Status', 'Price'])\n        for order in orders:\n            writer.writerow([\n                order.WorkOrderNo,\n                order.customer.CustomerName,\n                order.Status,\n                order.Price\n            ])\n    print(\"Backup saved to /tmp/work_orders_backup.csv\")\nEOF\n\n# Download backup\nexit  # Exit SSH\neb ssh --command \"cat /tmp/work_orders_backup.csv\" &gt; work_orders_backup.csv\n</code></pre></p>"},{"location":"deployment/operations-runbook/#database-restore","title":"Database Restore","text":"<p>Restore from RDS snapshot: <pre><code># 1. List available snapshots\naws rds describe-db-snapshots \\\n  --db-instance-identifier awning-prod-db\n\n# 2. Restore to new instance\naws rds restore-db-instance-from-db-snapshot \\\n  --db-instance-identifier awning-prod-db-restored \\\n  --db-snapshot-identifier &lt;snapshot-id&gt;\n\n# 3. Update DATABASE_URL in EB\neb setenv DATABASE_URL=\"postgresql://user:pass@new-host:5432/dbname\"\n\n# 4. Restart application\neb restart\n</code></pre></p>"},{"location":"deployment/operations-runbook/#database-maintenance","title":"Database Maintenance","text":"<p>Analyze and vacuum (PostgreSQL): <pre><code># Connect to database\neb ssh\npsql $DATABASE_URL\n\n# Run maintenance\nVACUUM ANALYZE;\n\n# Check table sizes\nSELECT\n    schemaname,\n    tablename,\n    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size\nFROM pg_tables\nWHERE schemaname = 'public'\nORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;\n</code></pre></p>"},{"location":"deployment/operations-runbook/#monitoring-alerts","title":"Monitoring &amp; Alerts","text":""},{"location":"deployment/operations-runbook/#cloudwatch-dashboards","title":"CloudWatch Dashboards","text":"<p>Key metrics to monitor: - Application health status - HTTP 4xx/5xx error rates - Database CPU utilization - Database connections - Disk space usage - Memory utilization</p> <p>Access CloudWatch: <pre><code># Via AWS Console\nAWS Console &gt; CloudWatch &gt; Dashboards &gt; Awning-Prod\n\n# Via CLI\naws cloudwatch get-dashboard \\\n  --dashboard-name Awning-Prod\n</code></pre></p>"},{"location":"deployment/operations-runbook/#setting-up-alarms","title":"Setting Up Alarms","text":"<p>Create CloudWatch alarm for 500 errors: <pre><code>aws cloudwatch put-metric-alarm \\\n  --alarm-name awning-prod-5xx-errors \\\n  --alarm-description \"Alert on high 5xx errors\" \\\n  --metric-name ApplicationRequests5xx \\\n  --namespace AWS/ElasticBeanstalk \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 10 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 1 \\\n  --alarm-actions arn:aws:sns:us-east-1:123456789:awning-alerts\n</code></pre></p> <p>Database connection alarm: <pre><code>aws cloudwatch put-metric-alarm \\\n  --alarm-name awning-prod-db-connections \\\n  --alarm-description \"Alert on high DB connections\" \\\n  --metric-name DatabaseConnections \\\n  --namespace AWS/RDS \\\n  --statistic Average \\\n  --period 300 \\\n  --threshold 80 \\\n  --comparison-operator GreaterThanThreshold \\\n  --evaluation-periods 2\n</code></pre></p>"},{"location":"deployment/operations-runbook/#log-analysis","title":"Log Analysis","text":"<p>Search logs for errors: <pre><code># Get last 500 lines of logs\neb logs --all &gt; logs.txt\n\n# Search for errors\ngrep -i \"error\" logs.txt\ngrep -i \"exception\" logs.txt\ngrep \"500 Internal Server Error\" logs.txt\n\n# Count errors by type\ngrep -i \"error\" logs.txt | cut -d' ' -f5- | sort | uniq -c | sort -rn\n</code></pre></p> <p>CloudWatch Insights queries: <pre><code>-- Top errors in last hour\nfields @timestamp, @message\n| filter @message like /ERROR/\n| stats count() by @message\n| sort count desc\n| limit 20\n\n-- Slow requests (&gt;1 second)\nfields @timestamp, @message\n| filter @message like /request took/\n| parse @message /request took * ms/ as duration\n| filter duration &gt; 1000\n| sort duration desc\n</code></pre></p>"},{"location":"deployment/operations-runbook/#incident-response","title":"Incident Response","text":""},{"location":"deployment/operations-runbook/#application-down","title":"Application Down","text":"<p>Symptoms: - Health check returning 503/504 - Users unable to access application - EB environment status \"Degraded\" or \"Severe\"</p> <p>Immediate actions: <pre><code># 1. Check EB environment health\neb health --refresh\n\n# 2. Check logs for errors\neb logs --stream | grep -i \"error\\|exception\\|critical\"\n\n# 3. Check database connectivity\neb ssh\npython3 -c \"from app import app, db; app.app_context().push(); db.session.execute('SELECT 1')\"\n\n# 4. Restart application\neb restart\n\n# 5. If restart fails, deploy last known good version\neb deploy --version &lt;last-good-version&gt;\n</code></pre></p> <p>Common causes: - Database connection pool exhausted - Out of memory - Unhandled exception in critical code path - RDS maintenance window</p>"},{"location":"deployment/operations-runbook/#database-connection-issues","title":"Database Connection Issues","text":"<p>Symptoms: - \"Could not connect to database\" errors - Slow page loads - Timeout errors</p> <p>Diagnosis: <pre><code># 1. Check RDS status\naws rds describe-db-instances \\\n  --db-instance-identifier awning-prod-db \\\n  --query 'DBInstances[0].DBInstanceStatus'\n\n# 2. Check database connections\neb ssh\npsql $DATABASE_URL -c \"SELECT count(*) FROM pg_stat_activity;\"\n\n# 3. Check for long-running queries\npsql $DATABASE_URL -c \"SELECT pid, now() - pg_stat_activity.query_start AS duration, query FROM pg_stat_activity WHERE state = 'active' ORDER BY duration DESC;\"\n</code></pre></p> <p>Resolution: <pre><code># 1. Kill long-running queries\npsql $DATABASE_URL -c \"SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND query_start &lt; now() - interval '5 minutes';\"\n\n# 2. Increase connection pool size (if needed)\neb setenv SQLALCHEMY_POOL_SIZE=20 SQLALCHEMY_MAX_OVERFLOW=30\neb restart\n\n# 3. Scale RDS instance (if persistent)\naws rds modify-db-instance \\\n  --db-instance-identifier awning-prod-db \\\n  --db-instance-class db.t3.medium \\\n  --apply-immediately\n</code></pre></p>"},{"location":"deployment/operations-runbook/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptoms: - Application becomes slow - Out of memory errors - EC2 instance health degraded</p> <p>Diagnosis: <pre><code>eb ssh\nfree -h\ntop -o %MEM\n\n# Check Python memory usage\nps aux | grep python | awk '{print $2, $4, $11}' | sort -k2 -rn\n</code></pre></p> <p>Resolution: <pre><code># 1. Restart application (temporary fix)\neb restart\n\n# 2. Scale instance type (permanent fix)\neb scale --instance-type t3.medium\n\n# 3. Review code for memory leaks\n# Check for:\n# - Large query result sets not paginated\n# - Unclosed file handles\n# - Circular references preventing garbage collection\n</code></pre></p>"},{"location":"deployment/operations-runbook/#ml-model-training-failure","title":"ML Model Training Failure","text":"<p>Symptoms: - Cron job logs show failures - Prediction endpoint returns old results</p> <p>Diagnosis: <pre><code>eb ssh\ncat /var/log/ml-retrain.log\n\n# Check cron job status\nsudo systemctl status cron\nsudo journalctl -u cron -n 50\n</code></pre></p> <p>Resolution: <pre><code># 1. Manually trigger retraining\ncurl -X POST http://localhost/ml/cron/retrain \\\n  -H \"X-Cron-Secret: $CRON_SECRET\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"config\": \"baseline\"}'\n\n# 2. Check for insufficient training data\npython3 &lt;&lt; EOF\nfrom app import app, db\nfrom models.work_order import WorkOrder\n\nwith app.app_context():\n    count = WorkOrder.query.count()\n    print(f\"Total work orders: {count}\")\n    if count &lt; 100:\n        print(\"\u26a0\ufe0f  Insufficient data for training (need &gt;100)\")\nEOF\n\n# 3. Check disk space\ndf -h\n\n# 4. Review model training code for errors\ncat /var/log/ml-retrain.log | grep -i \"error\\|exception\"\n</code></pre></p>"},{"location":"deployment/operations-runbook/#backup-recovery","title":"Backup &amp; Recovery","text":""},{"location":"deployment/operations-runbook/#backup-strategy","title":"Backup Strategy","text":"<p>What to backup: 1. Database - Daily automated RDS snapshots (retained 7 days) 2. S3 files - Versioning enabled on S3 bucket 3. Configuration - Git repository (code + <code>.ebextensions/</code>) 4. Environment variables - Documented in runbook</p> <p>Backup schedule: - RDS automated backups: Daily at 3:00 AM UTC - Manual snapshots: Before each deployment - S3 versioning: Continuous - Code: Git commits</p>"},{"location":"deployment/operations-runbook/#full-system-recovery","title":"Full System Recovery","text":"<p>Scenario: Complete AWS region failure</p> <p>Steps: <pre><code># 1. Create new RDS instance in different region\naws rds restore-db-instance-from-db-snapshot \\\n  --db-instance-identifier awning-prod-db-new \\\n  --db-snapshot-identifier &lt;latest-snapshot&gt; \\\n  --region us-west-2\n\n# 2. Create new EB environment in new region\ncd awning_wo/\neb init -p python-3.11 awning-wo --region us-west-2\neb create awning-prod-new \\\n  --database.engine postgres \\\n  --database.username postgres\n\n# 3. Configure environment variables\neb setenv \\\n  SECRET_KEY=\"$SECRET_KEY\" \\\n  DATABASE_URL=\"$NEW_DATABASE_URL\" \\\n  AWS_S3_BUCKET=\"$S3_BUCKET\" \\\n  # ... other env vars\n\n# 4. Deploy application\neb deploy\n\n# 5. Update DNS to point to new environment\n# Update Route 53 or your DNS provider\n\n# 6. Verify functionality\ncurl https://new-app-url.com/health\n\n# 7. Test critical functions\n# - Login\n# - Create/view work orders\n# - Analytics dashboard\n</code></pre></p>"},{"location":"deployment/operations-runbook/#point-in-time-recovery","title":"Point-in-Time Recovery","text":"<p>Restore to specific time: <pre><code># Restore RDS to 2 hours ago\naws rds restore-db-instance-to-point-in-time \\\n  --source-db-instance-identifier awning-prod-db \\\n  --target-db-instance-identifier awning-prod-db-restored \\\n  --restore-time 2025-11-16T08:00:00Z\n\n# Wait for instance to be available\naws rds wait db-instance-available \\\n  --db-instance-identifier awning-prod-db-restored\n\n# Update application to use restored database\neb setenv DATABASE_URL=\"postgresql://user:pass@restored-host:5432/db\"\neb restart\n</code></pre></p>"},{"location":"deployment/operations-runbook/#performance-tuning","title":"Performance Tuning","text":""},{"location":"deployment/operations-runbook/#query-optimization","title":"Query Optimization","text":"<p>Identify slow queries: <pre><code># Enable PostgreSQL slow query logging\n# Add to RDS parameter group:\n# log_min_duration_statement = 1000  # Log queries &gt;1 second\n\n# View slow query log\neb ssh\npsql $DATABASE_URL\n\n# Find slow queries\nSELECT\n    query,\n    calls,\n    total_time,\n    mean_time,\n    max_time\nFROM pg_stat_statements\nORDER BY mean_time DESC\nLIMIT 20;\n</code></pre></p> <p>Add database indexes: <pre><code># Create migration for new index\n./alembic_db.sh test revision -m \"add_index_to_customer_name\"\n\n# Edit migration file\n# def upgrade():\n#     op.create_index('idx_customer_name', 'customers', ['customer_name'])\n\n# Apply migration\n./alembic_db.sh prod upgrade head\n</code></pre></p>"},{"location":"deployment/operations-runbook/#application-performance","title":"Application Performance","text":"<p>Enable caching: <pre><code># Already configured in config.py\nCACHE_TYPE = \"SimpleCache\"\nCACHE_DEFAULT_TIMEOUT = 300  # 5 minutes\n\n# Use cache in routes\nfrom extensions import cache\n\n@cache.cached(timeout=300, key_prefix='dashboard_stats')\ndef get_dashboard_stats():\n    # Expensive query\n    return stats\n</code></pre></p> <p>Optimize large queries: <pre><code># Bad: Load all related objects\ncustomers = Customer.query.all()\nfor customer in customers:\n    print(customer.work_orders)  # N+1 query!\n\n# Good: Use eager loading\nfrom sqlalchemy.orm import joinedload\n\ncustomers = Customer.query.options(\n    joinedload(Customer.work_orders)\n).all()\n</code></pre></p>"},{"location":"deployment/operations-runbook/#scaling-strategies","title":"Scaling Strategies","text":"<p>Vertical scaling (larger instance): <pre><code># Scale to t3.medium\neb scale --instance-type t3.medium\n\n# Or manually via AWS Console\nAWS Console &gt; Elastic Beanstalk &gt; Environment &gt; Configuration &gt; Capacity\n</code></pre></p> <p>Horizontal scaling (multiple instances): <pre><code># Enable auto-scaling\neb config\n\n# Update configuration:\n# aws:autoscaling:asg:\n#   MinSize: 2\n#   MaxSize: 4\n\n# Save and apply\neb deploy\n</code></pre></p> <p>Database read replicas: <pre><code># Create read replica\naws rds create-db-instance-read-replica \\\n  --db-instance-identifier awning-prod-db-replica \\\n  --source-db-instance-identifier awning-prod-db\n\n# Use for analytics queries\nANALYTICS_DATABASE_URL = \"postgresql://user:pass@replica-host:5432/db\"\n</code></pre></p>"},{"location":"deployment/operations-runbook/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"deployment/operations-runbook/#weekly-tasks","title":"Weekly Tasks","text":"<ul> <li>[ ] Review application logs for errors</li> <li>[ ] Check RDS performance metrics</li> <li>[ ] Verify automated backups completed</li> <li>[ ] Review CloudWatch alarms</li> <li>[ ] Check disk space usage</li> </ul>"},{"location":"deployment/operations-runbook/#monthly-tasks","title":"Monthly Tasks","text":"<ul> <li>[ ] Review and update dependencies (<code>pip list --outdated</code>)</li> <li>[ ] Run security scan (<code>pip-audit</code> or <code>safety check</code>)</li> <li>[ ] Review CloudWatch costs</li> <li>[ ] Analyze slow queries and optimize</li> <li>[ ] Review and cleanup old RDS snapshots</li> <li>[ ] Update documentation</li> </ul>"},{"location":"deployment/operations-runbook/#quarterly-tasks","title":"Quarterly Tasks","text":"<ul> <li>[ ] Penetration testing or security audit</li> <li>[ ] Review and update disaster recovery plan</li> <li>[ ] Performance testing and benchmarking</li> <li>[ ] Review and optimize AWS costs</li> <li>[ ] Database vacuum and analyze (PostgreSQL)</li> <li>[ ] Review and update monitoring dashboards</li> </ul>"},{"location":"deployment/operations-runbook/#annual-tasks","title":"Annual Tasks","text":"<ul> <li>[ ] Rotate all secrets (SECRET_KEY, database passwords, API keys)</li> <li>[ ] Review and update security policies</li> <li>[ ] Comprehensive disaster recovery drill</li> <li>[ ] Major version upgrades (Python, Flask, PostgreSQL)</li> <li>[ ] Review and update SLAs</li> </ul>"},{"location":"deployment/operations-runbook/#emergency-contacts","title":"Emergency Contacts","text":"<p>On-Call Rotation: - Primary: [Name] - [Phone] - [Email] - Secondary: [Name] - [Phone] - [Email]</p> <p>Escalation Path: 1. On-call engineer (respond within 15 minutes) 2. Team lead (escalate if unresolved in 1 hour) 3. CTO (escalate if critical and unresolved in 2 hours)</p> <p>External Support: - AWS Support: AWS Console &gt; Support Center - Database DBA: [Contact info] - Security team: security@yourdomain.com</p>"},{"location":"deployment/operations-runbook/#useful-commands-reference","title":"Useful Commands Reference","text":""},{"location":"deployment/operations-runbook/#eb-cli","title":"EB CLI","text":"<pre><code>eb status                    # Check environment status\neb health --refresh          # Monitor health in real-time\neb logs --stream             # Stream logs\neb ssh                       # SSH into instance\neb deploy                    # Deploy application\neb restart                   # Restart application\neb setenv KEY=value          # Set environment variable\neb printenv                  # View environment variables\neb scale --instance-type t3.medium  # Change instance type\n</code></pre>"},{"location":"deployment/operations-runbook/#alembic","title":"Alembic","text":"<pre><code>./alembic_db.sh prod current           # Current migration version\n./alembic_db.sh prod upgrade head      # Apply all migrations\n./alembic_db.sh prod downgrade -1      # Rollback one migration\n./alembic_db.sh prod history           # View migration history\n</code></pre>"},{"location":"deployment/operations-runbook/#aws-cli","title":"AWS CLI","text":"<pre><code># RDS\naws rds describe-db-instances --db-instance-identifier awning-prod-db\naws rds create-db-snapshot --db-instance-identifier awning-prod-db --db-snapshot-identifier manual-snapshot-$(date +%Y%m%d)\n\n# CloudWatch\naws cloudwatch get-metric-statistics --metric-name CPUUtilization --namespace AWS/RDS --dimensions Name=DBInstanceIdentifier,Value=awning-prod-db --start-time 2025-11-16T00:00:00Z --end-time 2025-11-16T23:59:59Z --period 3600 --statistics Average\n\n# S3\naws s3 ls s3://awning-cleaning-data/\naws s3 cp s3://awning-cleaning-data/file.pdf ./\n</code></pre>"},{"location":"deployment/operations-runbook/#revision-history","title":"Revision History","text":"Date Version Changes Author 2025-11-16 1.0 Initial runbook creation Claude"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>Welcome to the Awning Management System Developer Guide!</p>"},{"location":"developer-guide/#for-new-developers","title":"For New Developers","text":"<p>Start here to get your development environment set up:</p> <ol> <li>Setup &amp; Installation - Get the app running locally</li> <li>Project Structure - Understand the codebase organization</li> <li>Database Schema - Learn the data model</li> </ol>"},{"location":"developer-guide/#development-workflow","title":"Development Workflow","text":"<ul> <li>Testing - Running and writing tests</li> <li>Contributing - Contribution guidelines</li> <li>API Reference - API endpoints and usage</li> </ul>"},{"location":"developer-guide/#code-refactoring-maintenance","title":"Code Refactoring &amp; Maintenance","text":"<p>Learn about recent refactoring efforts and patterns:</p> <ul> <li>Template Refactoring Summary - UI unification between work orders and repair orders</li> <li>Template Refactoring Plan - Detailed refactoring strategy and approach</li> </ul>"},{"location":"developer-guide/#architecture-documentation","title":"Architecture Documentation","text":"<p>For deeper technical understanding:</p> <ul> <li>System Overview - High-level architecture</li> <li>ML Prediction System - Machine learning details</li> <li>Performance Analysis - Optimization strategies</li> </ul>"},{"location":"developer-guide/#deployment","title":"Deployment","text":"<p>Learn about deploying to production:</p> <ul> <li>AWS Elastic Beanstalk - Deployment guide</li> <li>Environment Variables - Configuration</li> <li>Monitoring - Production monitoring</li> </ul>"},{"location":"developer-guide/api-reference/","title":"API Reference","text":"<p>This document provides a reference for all API endpoints and routes in the Awning Management System.</p>"},{"location":"developer-guide/api-reference/#authentication","title":"Authentication","text":"<p>All routes require authentication via Flask-Login unless otherwise noted.</p> <ul> <li>Login: <code>POST /auth/login</code></li> <li>Logout: <code>GET /auth/logout</code></li> <li>Register: <code>POST /auth/register</code> (requires invite token)</li> </ul>"},{"location":"developer-guide/api-reference/#work-orders","title":"Work Orders","text":"<p>Base URL: <code>/work_orders</code></p>"},{"location":"developer-guide/api-reference/#list-view","title":"List &amp; View","text":"Endpoint Method Description <code>/work_orders/</code> GET List all work orders (HTML view) <code>/work_orders/&lt;work_order_no&gt;</code> GET View work order detail <code>/work_orders/pending</code> GET View pending work orders <code>/work_orders/completed</code> GET View completed work orders <code>/work_orders/rush</code> GET View rush orders <code>/work_orders/status/&lt;status&gt;</code> GET Filter by status"},{"location":"developer-guide/api-reference/#create-edit","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/work_orders/new</code> GET, POST Create new work order <code>/work_orders/new/&lt;prefill_cust_id&gt;</code> GET, POST Create work order with customer pre-filled <code>/work_orders/edit/&lt;work_order_no&gt;</code> GET, POST Edit work order <code>/work_orders/cleaning-room/edit/&lt;work_order_no&gt;</code> GET, POST Simplified cleaning room edit <code>/work_orders/delete/&lt;work_order_no&gt;</code> POST Delete work order"},{"location":"developer-guide/api-reference/#api-endpoints","title":"API Endpoints","text":"Endpoint Method Description <code>/work_orders/api/work_orders</code> GET JSON API for work orders (supports filtering, sorting, pagination) <code>/work_orders/api/next_wo_number</code> GET Get next available work order number <code>/work_orders/api/customer_inventory/&lt;cust_id&gt;</code> GET Get inventory for customer <code>/work_orders/api/open_repair_orders/&lt;cust_id&gt;</code> GET Get open repair orders for customer"},{"location":"developer-guide/api-reference/#file-management","title":"File Management","text":"Endpoint Method Description <code>/work_orders/&lt;work_order_no&gt;/files</code> GET List files for work order <code>/work_orders/&lt;work_order_no&gt;/files/upload</code> POST Upload file <code>/work_orders/&lt;work_order_no&gt;/files/&lt;file_id&gt;/download</code> GET Download file <code>/work_orders/thumbnail/&lt;file_id&gt;</code> GET Get PDF thumbnail"},{"location":"developer-guide/api-reference/#pdf-generation","title":"PDF Generation","text":"Endpoint Method Description <code>/work_orders/&lt;work_order_no&gt;/pdf/download</code> GET Generate and download PDF"},{"location":"developer-guide/api-reference/#repair-orders","title":"Repair Orders","text":"<p>Base URL: <code>/repair_work_orders</code></p>"},{"location":"developer-guide/api-reference/#list-view_1","title":"List &amp; View","text":"Endpoint Method Description <code>/repair_work_orders/</code> GET List all repair orders <code>/repair_work_orders/&lt;repair_order_no&gt;</code> GET View repair order detail <code>/repair_work_orders/pending</code> GET View pending repair orders <code>/repair_work_orders/completed</code> GET View completed repair orders"},{"location":"developer-guide/api-reference/#create-edit_1","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/repair_work_orders/new</code> GET, POST Create new repair order <code>/repair_work_orders/new/&lt;prefill_cust_id&gt;</code> GET, POST Create with customer pre-filled <code>/repair_work_orders/edit/&lt;repair_order_no&gt;</code> GET, POST Edit repair order <code>/repair_work_orders/delete/&lt;repair_order_no&gt;</code> POST Delete repair order"},{"location":"developer-guide/api-reference/#api-endpoints_1","title":"API Endpoints","text":"Endpoint Method Description <code>/repair_work_orders/api/repair_orders</code> GET JSON API for repair orders <code>/repair_work_orders/api/next_ro_number</code> GET Get next available repair order number"},{"location":"developer-guide/api-reference/#pdf-generation_1","title":"PDF Generation","text":"Endpoint Method Description <code>/repair_work_orders/&lt;repair_order_no&gt;/pdf/download</code> GET Generate and download PDF"},{"location":"developer-guide/api-reference/#customers","title":"Customers","text":"<p>Base URL: <code>/customers</code></p>"},{"location":"developer-guide/api-reference/#list-view_2","title":"List &amp; View","text":"Endpoint Method Description <code>/customers/</code> GET List all customers <code>/customers/&lt;cust_id&gt;</code> GET View customer detail"},{"location":"developer-guide/api-reference/#create-edit_2","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/customers/new</code> GET, POST Create new customer <code>/customers/edit/&lt;cust_id&gt;</code> GET, POST Edit customer <code>/customers/delete/&lt;cust_id&gt;</code> POST Delete customer"},{"location":"developer-guide/api-reference/#api-endpoints_2","title":"API Endpoints","text":"Endpoint Method Description <code>/customers/api/customers</code> GET JSON API for customers <code>/customers/search</code> GET Search customers by name/phone"},{"location":"developer-guide/api-reference/#sources-vendors","title":"Sources (Vendors)","text":"<p>Base URL: <code>/sources</code></p>"},{"location":"developer-guide/api-reference/#list-view_3","title":"List &amp; View","text":"Endpoint Method Description <code>/sources/</code> GET List all sources <code>/sources/&lt;source_id&gt;</code> GET View source detail"},{"location":"developer-guide/api-reference/#create-edit_3","title":"Create &amp; Edit","text":"Endpoint Method Description <code>/sources/new</code> GET, POST Create new source <code>/sources/edit/&lt;source_id&gt;</code> GET, POST Edit source <code>/sources/delete/&lt;source_id&gt;</code> POST Delete source"},{"location":"developer-guide/api-reference/#queue-management","title":"Queue Management","text":"<p>Base URL: <code>/cleaning_queue</code></p> Endpoint Method Description <code>/cleaning_queue/</code> GET View cleaning queue <code>/cleaning_queue/api/queue_items</code> GET JSON API for queue items"},{"location":"developer-guide/api-reference/#in-progress","title":"In Progress","text":"<p>Base URL: <code>/in_progress</code></p> Endpoint Method Description <code>/in_progress/</code> GET View in-progress orders <code>/in_progress/api/in_progress_items</code> GET JSON API for in-progress items"},{"location":"developer-guide/api-reference/#inventory","title":"Inventory","text":"<p>Base URL: <code>/inventory</code></p> Endpoint Method Description <code>/inventory/</code> GET List inventory items <code>/inventory/new</code> GET, POST Create new inventory item <code>/inventory/edit/&lt;inv_id&gt;</code> GET, POST Edit inventory item <code>/inventory/delete/&lt;inv_id&gt;</code> POST Delete inventory item"},{"location":"developer-guide/api-reference/#analytics","title":"Analytics","text":"<p>Base URL: <code>/analytics</code></p> Endpoint Method Description <code>/analytics/</code> GET Analytics dashboard <code>/analytics/api/data</code> GET JSON data for charts"},{"location":"developer-guide/api-reference/#machine-learning","title":"Machine Learning","text":"<p>Base URL: <code>/ml</code></p> Endpoint Method Description <code>/ml/</code> GET ML dashboard <code>/ml/predict</code> POST Get completion time prediction <code>/ml/train</code> POST Train ML model <code>/ml/cron/retrain</code> POST Cron job for retraining (requires secret header)"},{"location":"developer-guide/api-reference/#admin","title":"Admin","text":"<p>Base URL: <code>/admin</code></p> Endpoint Method Description <code>/admin/users</code> GET Manage users (admin only) <code>/admin/invite</code> POST Create invite token (admin only) <code>/admin/delete_user/&lt;user_id&gt;</code> POST Delete user (admin only)"},{"location":"developer-guide/api-reference/#dashboard","title":"Dashboard","text":"<p>Base URL: <code>/</code></p> Endpoint Method Description <code>/</code> GET Main dashboard <code>/health</code> GET Health check endpoint (no auth required)"},{"location":"developer-guide/api-reference/#common-api-parameters","title":"Common API Parameters","text":""},{"location":"developer-guide/api-reference/#pagination","title":"Pagination","text":"<p>Most list API endpoints support pagination:</p> <pre><code>?page=1&amp;per_page=20\n</code></pre>"},{"location":"developer-guide/api-reference/#filtering","title":"Filtering","text":"<p>API endpoints support column-based filtering:</p> <pre><code>?filter_&lt;column&gt;=&lt;value&gt;\n</code></pre> <p>Examples: - <code>?filter_Source=Boat%20Covers</code> - <code>?filter_CustID=123</code></p>"},{"location":"developer-guide/api-reference/#sorting","title":"Sorting","text":"<p>API endpoints support Tabulator-style sorting:</p> <pre><code>?sort[0][field]=&lt;column&gt;&amp;sort[0][dir]=&lt;asc|desc&gt;\n</code></pre> <p>Example: - <code>?sort[0][field]=DateIn&amp;sort[0][dir]=desc</code></p>"},{"location":"developer-guide/api-reference/#search","title":"Search","text":"<p>Some endpoints support full-text search:</p> <pre><code>?search=&lt;query&gt;\n</code></pre>"},{"location":"developer-guide/api-reference/#response-formats","title":"Response Formats","text":""},{"location":"developer-guide/api-reference/#html-responses","title":"HTML Responses","text":"<p>Most <code>GET</code> routes return HTML templates for browser viewing.</p>"},{"location":"developer-guide/api-reference/#json-api-responses","title":"JSON API Responses","text":"<p>API endpoints return JSON in this format:</p>"},{"location":"developer-guide/api-reference/#success-response","title":"Success Response","text":"<pre><code>{\n  \"data\": [...],\n  \"total\": 100,\n  \"page\": 1,\n  \"per_page\": 20\n}\n</code></pre>"},{"location":"developer-guide/api-reference/#error-response","title":"Error Response","text":"<pre><code>{\n  \"error\": \"Error message\"\n}\n</code></pre>"},{"location":"developer-guide/api-reference/#file-uploads","title":"File Uploads","text":"<p>File uploads use <code>multipart/form-data</code> encoding and are stored in AWS S3.</p> <p>Supported File Types: - PDF (.pdf) - Images (.jpg, .jpeg, .png, .gif) - Documents (.doc, .docx, .xls, .xlsx)</p> <p>Max File Size: 10MB (configurable)</p>"},{"location":"developer-guide/api-reference/#authentication-details","title":"Authentication Details","text":""},{"location":"developer-guide/api-reference/#login","title":"Login","text":"<p>Endpoint: <code>POST /auth/login</code></p> <p>Form Data: - <code>username</code> (string, required) - <code>password</code> (string, required)</p> <p>Response: Redirects to dashboard on success</p>"},{"location":"developer-guide/api-reference/#session-management","title":"Session Management","text":"<p>The application uses Flask-Login for session management: - Sessions are cookie-based - Cookies are HTTP-only and secure (in production) - Session timeout: 30 days (remember me) or browser session</p>"},{"location":"developer-guide/api-reference/#error-codes","title":"Error Codes","text":"HTTP Code Description 200 Success 302 Redirect (often after POST) 400 Bad Request (invalid input) 401 Unauthorized (not logged in) 403 Forbidden (insufficient permissions) 404 Not Found 500 Server Error"},{"location":"developer-guide/api-reference/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, no rate limiting is implemented. This may be added in future versions.</p>"},{"location":"developer-guide/api-reference/#examples","title":"Examples","text":""},{"location":"developer-guide/api-reference/#get-work-orders-list-json","title":"Get Work Orders List (JSON)","text":"<pre><code>curl -X GET \"http://localhost:5000/work_orders/api/work_orders?page=1&amp;per_page=20\" \\\n  --cookie \"session=&lt;your-session-cookie&gt;\"\n</code></pre>"},{"location":"developer-guide/api-reference/#create-work-order","title":"Create Work Order","text":"<pre><code>curl -X POST \"http://localhost:5000/work_orders/new\" \\\n  --cookie \"session=&lt;your-session-cookie&gt;\" \\\n  --form \"CustID=123\" \\\n  --form \"WOName=Summer Cleaning\" \\\n  --form \"DateIn=2024-01-15\"\n</code></pre>"},{"location":"developer-guide/api-reference/#upload-file","title":"Upload File","text":"<pre><code>curl -X POST \"http://localhost:5000/work_orders/12345/files/upload\" \\\n  --cookie \"session=&lt;your-session-cookie&gt;\" \\\n  --form \"file=@document.pdf\"\n</code></pre>"},{"location":"developer-guide/api-reference/#code-references","title":"Code References","text":"<p>For implementation details, see:</p> <ul> <li>routes/work_orders.py - Work order routes</li> <li>routes/repair_order.py - Repair order routes</li> <li>routes/customers.py - Customer routes</li> <li>routes/analytics.py - Analytics routes</li> <li>models/ - Database models</li> </ul>"},{"location":"developer-guide/api-reference/#need-help","title":"Need Help?","text":"<ul> <li>Check the FAQ</li> <li>See Troubleshooting</li> <li>Report bugs on GitHub Issues</li> </ul>"},{"location":"developer-guide/database-schema/","title":"Database Schema","text":"<p>Complete reference for the Awning Management System database schema.</p>"},{"location":"developer-guide/database-schema/#overview","title":"Overview","text":"<p>The application uses PostgreSQL with SQLAlchemy ORM. The schema is managed through Alembic migrations. See the Alembic Guide for migration workflows.</p> <p>Key Characteristics: - Database: PostgreSQL 12+ - ORM: SQLAlchemy - Migrations: Alembic - Naming: Legacy Access DB naming (mixed case, some inconsistencies)</p>"},{"location":"developer-guide/database-schema/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Source    \u2502\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2502   Customer   \u2502\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2502 WorkOrder  \u2502\n\u2502  (Vendor)   \u2502    \u2502    \u2502              \u2502    \u2502    \u2502            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502            \u2502            \u2502           \u2502\n                   \u2502            \u2502            \u2502           \u251c\u2500\u2500 WorkOrderItem\n                   \u2502            \u2502            \u2502           \u2514\u2500\u2500 WorkOrderFile\n                   \u2502            \u2502            \u2502\n                   \u2502            \u2502            \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                   \u2502            \u2502                 \u2502  RepairOrder   \u2502\n                   \u2502            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524                \u2502\n                   \u2502                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502                                       \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                                                          \u2514\u2500\u2500 RepairOrderItem\n                                                          \u2514\u2500\u2500 RepairOrderFile\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    User     \u2502  (Flask-Login auth)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 InviteToken \u2502  (User registration)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Inventory  \u2502  (Available items)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/database-schema/#core-tables","title":"Core Tables","text":""},{"location":"developer-guide/database-schema/#customer-tblcustomers","title":"Customer (<code>tblcustomers</code>)","text":"<p>Customer information and contact details.</p> <p>Primary Key: <code>custid</code> (Text)</p>"},{"location":"developer-guide/database-schema/#columns","title":"Columns","text":"Column Type Description <code>custid</code> Text Customer ID (Primary Key) <code>name</code> Text Customer name <code>contact</code> Text Contact person <code>address</code> Text Physical address line 1 <code>address2</code> Text Physical address line 2 <code>city</code> Text City <code>state</code> Text State <code>zipcode</code> Text ZIP code <code>homephone</code> Text Home phone number <code>workphone</code> Text Work phone number <code>cellphone</code> Text Cell phone number <code>emailaddress</code> Text Email address <code>mailaddress</code> Text Mailing address (if different) <code>mailcity</code> Text Mailing city <code>mailstate</code> Text Mailing state <code>mailzip</code> Text Mailing ZIP <code>sourceold</code> Text Legacy source field <code>source</code> Text Source/vendor (FK \u2192 <code>tblsource.ssource</code>) <code>sourceaddress</code> Text Source address <code>sourcestate</code> Text Source state <code>sourcecity</code> Text Source city <code>sourcezip</code> Text Source ZIP"},{"location":"developer-guide/database-schema/#relationships","title":"Relationships","text":"<ul> <li>Has many: WorkOrder (via <code>custid</code>)</li> <li>Has many: RepairWorkOrder (via <code>custid</code>)</li> <li>Belongs to: Source (via <code>source</code>)</li> </ul>"},{"location":"developer-guide/database-schema/#methods","title":"Methods","text":"<ul> <li><code>to_dict()</code> - Convert to dictionary</li> <li><code>clean_email()</code> - Remove <code>#mailto:</code> suffix</li> <li><code>clean_phone(field)</code> - Format phone numbers</li> <li><code>get_full_address()</code> - Formatted physical address</li> <li><code>get_mailing_address()</code> - Formatted mailing address</li> <li><code>get_primary_phone()</code> - First available phone number</li> </ul> <p>Model: models/customer.py</p>"},{"location":"developer-guide/database-schema/#workorder-tblcustworkorderdetail","title":"WorkOrder (<code>tblcustworkorderdetail</code>)","text":"<p>Cleaning work orders.</p> <p>Primary Key: <code>workorderno</code> (String)</p>"},{"location":"developer-guide/database-schema/#columns_1","title":"Columns","text":"Column Type Description <code>workorderno</code> String Work order number (Primary Key) <code>custid</code> String Customer ID (FK \u2192 <code>tblcustomers.custid</code>) <code>woname</code> String Work order name/title <code>storage</code> String DEPRECATED - Do not use <code>storagetime</code> String Storage duration: \"Seasonal\" or \"Temporary\" <code>rack_number</code> String Physical location (e.g., \"5 B\", \"bin 4 top\") <code>finallocation</code> String Location after cleaning is complete <code>specialinstructions</code> Text Special instructions <code>repairsneeded</code> Boolean Repairs needed flag <code>returnstatus</code> String Return status <code>datecompleted</code> DateTime Completion timestamp <code>daterequired</code> Date Required by date <code>datein</code> Date Date received <code>clean</code> Date Date cleaned <code>treat</code> Date Date treated <code>quote</code> String Quote information <code>rushorder</code> Boolean Rush order flag <code>firmrush</code> Boolean Firm rush flag <code>seerepair</code> String Related repair order reference <code>shipto</code> String Ship to source (FK \u2192 <code>tblsource.ssource</code>) <code>cleanfirstwo</code> String DEPRECATED - Historical only <code>queueposition</code> Integer Position in cleaning queue <code>processingstatus</code> Boolean Currently being processed <code>source_name</code> Text Denormalized source name (for performance) <code>created_at</code> DateTime Record creation timestamp <code>updated_at</code> DateTime Last update timestamp <p>Storage Fields</p> <p>See Storage Fields Guide for detailed explanation of <code>storage</code>, <code>storagetime</code>, and <code>rack_number</code> fields.</p>"},{"location":"developer-guide/database-schema/#relationships_1","title":"Relationships","text":"<ul> <li>Belongs to: Customer (via <code>custid</code>)</li> <li>Belongs to: Source (via <code>shipto</code> - ship to location)</li> <li>Has many: WorkOrderItem (child items)</li> <li>Has many: WorkOrderFile (attached files)</li> </ul>"},{"location":"developer-guide/database-schema/#properties","title":"Properties","text":"<ul> <li><code>is_completed</code> - Boolean indicating completion status</li> <li><code>total_items</code> - Count of order items</li> <li><code>file_count</code> - Count of attached files</li> </ul> <p>Model: models/work_order.py</p>"},{"location":"developer-guide/database-schema/#workorderitem-tblorddetcustawngs","title":"WorkOrderItem (<code>tblorddetcustawngs</code>)","text":"<p>Individual items within a work order.</p> <p>Primary Key: <code>itemid</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_2","title":"Columns","text":"Column Type Description <code>itemid</code> Integer Item ID (Primary Key) <code>workorderno</code> String Work order number (FK \u2192 <code>tblcustworkorderdetail.workorderno</code>) <code>sizewgt</code> String Size/weight description (e.g., \"8'x10'\", \"95#\") <code>price</code> Numeric Item price <code>qty</code> String Quantity (may contain non-numeric values) <code>desc</code> Text Item description <code>location</code> String Item-specific location"},{"location":"developer-guide/database-schema/#item-types","title":"Item Types","text":"<p>The <code>sizewgt</code> field determines the item type: - Awning: Contains dimensions (e.g., \"8'x10'\", \"12'6\"x15'3\"\") - Sail: Contains weight with <code>#</code> (e.g., \"95#\", \"120#\")</p> <p>Model: models/work_order.py (WorkOrderItem class)</p>"},{"location":"developer-guide/database-schema/#repairworkorder-tblrepairworkorderdetail","title":"RepairWorkOrder (<code>tblrepairworkorderdetail</code>)","text":"<p>Repair work orders.</p> <p>Primary Key: <code>repairorderno</code> (String)</p>"},{"location":"developer-guide/database-schema/#columns_3","title":"Columns","text":"Column Type Description <code>repairorderno</code> String Repair order number (Primary Key) <code>custid</code> String Customer ID (FK \u2192 <code>tblcustomers.custid</code>) <code>roname</code> String Repair order name/title <code>source</code> String Source field (not FK) <code>WO DATE</code> Date Work order date \u26a0\ufe0f Uppercase with space <code>DATE TO SUB</code> Date Date to subcontractor \u26a0\ufe0f Uppercase with spaces <code>daterequired</code> Date Required by date <code>datecompleted</code> DateTime Completion timestamp <code>returndate</code> Date Return date <code>dateout</code> Date Date sent out <code>datein</code> Date Date received <code>rushorder</code> Boolean Rush order flag <code>firmrush</code> Boolean Firm rush flag <code>quote</code> String Quote status: 'YES', 'DONE', 'APPROVED', or NULL <code>approved</code> Boolean DEPRECATED - No longer used <code>clean</code> Boolean Clean before repair <code>cleanfirst</code> Boolean DEPRECATED - Historical only <code>QUOTE  BY</code> String DEPRECATED - No longer used \u26a0\ufe0f Two spaces <code>RACK#</code> String Physical location (e.g., \"hang 4\", \"6D\") <code>storage</code> String Storage duration: \"TEMPORARY\" or \"SEASONAL\" <code>location</code> String Additional location details <code>finallocation</code> String Location after repair is complete <code>ITEM TYPE</code> String Item type \u26a0\ufe0f Uppercase with space <code>TYPE OF REPAIR</code> String Repair type \u26a0\ufe0f Uppercase with spaces <code>specialinstructions</code> Text Special instructions <code>seeclean</code> String Related work order reference <code>repairsdoneby</code> String Repair technician <code>materiallist</code> Text Materials used <code>customerprice</code> String Price quoted to customer <code>returnstatus</code> String Return status <code>source_name</code> Text Denormalized source name (for performance) <code>created_at</code> DateTime Record creation timestamp <code>updated_at</code> DateTime Last update timestamp <p>Column Name Quirks</p> <p>Some columns have uppercase names or spaces: <code>WO DATE</code>, <code>DATE TO SUB</code>, <code>RACK#</code>, <code>QUOTE  BY</code>, <code>ITEM TYPE</code>, <code>TYPE OF REPAIR</code>.</p>"},{"location":"developer-guide/database-schema/#relationships_2","title":"Relationships","text":"<ul> <li>Belongs to: Customer (via <code>custid</code>)</li> <li>Has many: RepairOrderItem (child items)</li> <li>Has many: RepairOrderFile (attached files)</li> </ul> <p>Model: models/repair_order.py</p>"},{"location":"developer-guide/database-schema/#source-tblsource","title":"Source (<code>tblsource</code>)","text":"<p>Vendors, sail lofts, and source organizations.</p> <p>Primary Key: <code>ssource</code> (Text)</p>"},{"location":"developer-guide/database-schema/#columns_4","title":"Columns","text":"Column Type Description <code>ssource</code> Text Source identifier (Primary Key) <code>name</code> Text Source name <code>contact</code> Text Contact person <code>address</code> Text Address <code>city</code> Text City <code>state</code> Text State <code>zip</code> Text ZIP code <code>phone</code> Text Phone number <code>email</code> Text Email address"},{"location":"developer-guide/database-schema/#relationships_3","title":"Relationships","text":"<ul> <li>Has many: Customer (via <code>source</code>)</li> <li>Has many: WorkOrder (via <code>shipto</code>)</li> </ul> <p>Model: models/source.py</p>"},{"location":"developer-guide/database-schema/#inventory-tblinventory","title":"Inventory (<code>tblinventory</code>)","text":"<p>Inventory items available for use.</p> <p>Primary Key: <code>invid</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_5","title":"Columns","text":"Column Type Description <code>invid</code> Integer Inventory ID (Primary Key) <code>custid</code> String Customer ID (optional, for customer-specific items) <code>description</code> Text Item description <code>size</code> String Size/dimensions <code>quantity</code> Integer Quantity available <code>location</code> String Storage location <code>notes</code> Text Additional notes <p>Model: models/inventory.py</p>"},{"location":"developer-guide/database-schema/#file-attachments","title":"File Attachments","text":""},{"location":"developer-guide/database-schema/#workorderfile-work_order_files","title":"WorkOrderFile (<code>work_order_files</code>)","text":"<p>Files attached to work orders.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_6","title":"Columns","text":"Column Type Description <code>id</code> Integer File ID (Primary Key) <code>work_order_no</code> String Work order number (FK \u2192 <code>tblcustworkorderdetail.workorderno</code>) <code>file_name</code> String Original filename <code>s3_key</code> String S3 object key <code>file_size</code> Integer File size in bytes <code>content_type</code> String MIME type <code>uploaded_at</code> DateTime Upload timestamp"},{"location":"developer-guide/database-schema/#relationships_4","title":"Relationships","text":"<ul> <li>Belongs to: WorkOrder (via <code>work_order_no</code>)</li> </ul> <p>Storage: AWS S3 bucket</p> <p>Model: models/work_order_file.py</p>"},{"location":"developer-guide/database-schema/#repairorderfile-repair_order_files","title":"RepairOrderFile (<code>repair_order_files</code>)","text":"<p>Files attached to repair orders.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_7","title":"Columns","text":"Column Type Description <code>id</code> Integer File ID (Primary Key) <code>repair_order_no</code> String Repair order number (FK \u2192 <code>tblrepairworkorderdetail.repairorderno</code>) <code>file_name</code> String Original filename <code>s3_key</code> String S3 object key <code>file_size</code> Integer File size in bytes <code>content_type</code> String MIME type <code>uploaded_at</code> DateTime Upload timestamp"},{"location":"developer-guide/database-schema/#relationships_5","title":"Relationships","text":"<ul> <li>Belongs to: RepairWorkOrder (via <code>repair_order_no</code>)</li> </ul> <p>Storage: AWS S3 bucket</p> <p>Model: models/repair_order_file.py</p>"},{"location":"developer-guide/database-schema/#authentication-users","title":"Authentication &amp; Users","text":""},{"location":"developer-guide/database-schema/#user-users","title":"User (<code>users</code>)","text":"<p>Application users for Flask-Login authentication.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_8","title":"Columns","text":"Column Type Description <code>id</code> Integer User ID (Primary Key) <code>username</code> String(80) Username (unique) <code>password_hash</code> String(255) Bcrypt password hash <code>role</code> String(20) User role: \"admin\" or \"user\" <code>created_at</code> DateTime Account creation timestamp"},{"location":"developer-guide/database-schema/#methods_1","title":"Methods","text":"<ul> <li><code>set_password(password)</code> - Hash and set password</li> <li><code>check_password(password)</code> - Verify password</li> <li><code>is_admin()</code> - Check if user has admin role</li> </ul> <p>Model: models/user.py</p>"},{"location":"developer-guide/database-schema/#invitetoken-invite_tokens","title":"InviteToken (<code>invite_tokens</code>)","text":"<p>Invitation tokens for user registration.</p> <p>Primary Key: <code>id</code> (Integer, auto-increment)</p>"},{"location":"developer-guide/database-schema/#columns_9","title":"Columns","text":"Column Type Description <code>id</code> Integer Token ID (Primary Key) <code>token</code> String(100) Invite token (unique, indexed) <code>role</code> String(20) Role to assign: \"admin\" or \"user\" <code>used</code> Boolean Token used flag <code>created_at</code> DateTime Token creation timestamp <code>used_at</code> DateTime Token usage timestamp <p>Model: models/invite_token.py</p>"},{"location":"developer-guide/database-schema/#indexes","title":"Indexes","text":"<p>Key indexes for performance optimization:</p>"},{"location":"developer-guide/database-schema/#work-orders","title":"Work Orders","text":"<ul> <li><code>idx_workorder_custid</code> on <code>custid</code> (foreign key)</li> <li><code>idx_workorder_source_name</code> on <code>source_name</code> (denormalized field for filtering)</li> <li><code>idx_workorder_datecompleted</code> on <code>datecompleted</code> (filtering completed orders)</li> <li><code>idx_workorder_datein</code> on <code>datein</code> (filtering by intake date)</li> </ul>"},{"location":"developer-guide/database-schema/#repair-orders","title":"Repair Orders","text":"<ul> <li><code>idx_repairorder_custid</code> on <code>custid</code> (foreign key)</li> <li><code>idx_repairorder_source_name</code> on <code>source_name</code> (denormalized field for filtering)</li> <li><code>idx_repairorder_datecompleted</code> on <code>datecompleted</code> (filtering completed orders)</li> </ul>"},{"location":"developer-guide/database-schema/#customers","title":"Customers","text":"<ul> <li><code>idx_customer_source</code> on <code>source</code> (foreign key)</li> <li><code>idx_customer_name</code> on <code>name</code> (searching by name)</li> </ul>"},{"location":"developer-guide/database-schema/#files","title":"Files","text":"<ul> <li><code>idx_workorderfile_work_order_no</code> on <code>work_order_no</code> (foreign key)</li> <li><code>idx_repairorderfile_repair_order_no</code> on <code>repair_order_no</code> (foreign key)</li> </ul>"},{"location":"developer-guide/database-schema/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"developer-guide/database-schema/#denormalization","title":"Denormalization","text":"<p>The <code>source_name</code> field is denormalized in both <code>WorkOrder</code> and <code>RepairWorkOrder</code> tables:</p> <p>Purpose: Avoid expensive 3-table joins when filtering/sorting by source Synced via: Database triggers and application-level sync methods Performance gain: ~100x faster for source filtering queries</p> <p>See Denormalization Analysis for details.</p>"},{"location":"developer-guide/database-schema/#lazy-loading","title":"Lazy Loading","text":"<p>Relationships use strategic lazy loading: - <code>lazy='dynamic'</code> for large collections (e.g., customer \u2192 work_orders) - <code>lazy='joined'</code> for frequently accessed relationships (e.g., work_order \u2192 files) - Default <code>lazy='select'</code> for most relationships</p>"},{"location":"developer-guide/database-schema/#data-types","title":"Data Types","text":""},{"location":"developer-guide/database-schema/#datedatetime-handling","title":"Date/DateTime Handling","text":"<ul> <li>Date: Used for calendar dates (no time component)</li> <li>Examples: <code>datein</code>, <code>daterequired</code>, <code>clean</code>, <code>treat</code></li> <li>DateTime: Used when time matters</li> <li>Examples: <code>datecompleted</code>, <code>created_at</code>, <code>updated_at</code></li> </ul>"},{"location":"developer-guide/database-schema/#boolean-fields","title":"Boolean Fields","text":"<ul> <li>Stored as PostgreSQL <code>BOOLEAN</code> type</li> <li>Python: <code>True</code>/<code>False</code></li> <li>Database: <code>true</code>/<code>false</code></li> <li>Legacy data may contain: \"YES\"/\"NO\", \"TRUE\"/\"FALSE\", 1/0</li> </ul>"},{"location":"developer-guide/database-schema/#numeric-fields","title":"Numeric Fields","text":"<ul> <li>Prices: <code>Numeric</code> type (precise decimal)</li> <li>Quantities: Often stored as <code>String</code> (may contain non-numeric values like \"TBD\")</li> <li>IDs: Auto-increment integers or string-based custom IDs</li> </ul>"},{"location":"developer-guide/database-schema/#common-queries","title":"Common Queries","text":""},{"location":"developer-guide/database-schema/#get-all-pending-work-orders-for-a-customer","title":"Get all pending work orders for a customer","text":"<pre><code>pending_orders = WorkOrder.query.filter_by(\n    CustID=customer_id,\n    DateCompleted=None\n).order_by(WorkOrder.DateIn.desc()).all()\n</code></pre>"},{"location":"developer-guide/database-schema/#get-work-orders-with-source-name-denormalized","title":"Get work orders with source name (denormalized)","text":"<pre><code>work_orders = WorkOrder.query.filter(\n    WorkOrder.source_name == 'Boat Covers Inc'\n).all()\n</code></pre>"},{"location":"developer-guide/database-schema/#get-customer-with-all-relationships","title":"Get customer with all relationships","text":"<pre><code>customer = Customer.query.options(\n    joinedload(Customer.work_orders),\n    joinedload(Customer.repair_work_orders),\n    joinedload(Customer.source_info)\n).get(customer_id)\n</code></pre>"},{"location":"developer-guide/database-schema/#schema-changes","title":"Schema Changes","text":"<p>All schema changes must go through Alembic migrations. See the Alembic Guide for the workflow.</p>"},{"location":"developer-guide/database-schema/#adding-a-column","title":"Adding a Column","text":"<pre><code># Create migration\n./alembic_db.sh test revision --autogenerate -m \"add_new_column\"\n\n# Review and apply\n./alembic_db.sh test upgrade head\n./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"developer-guide/database-schema/#renaming-a-column","title":"Renaming a Column","text":"<pre><code># Create migration manually\n./alembic_db.sh test revision -m \"rename_column\"\n\n# Edit migration file\ndef upgrade():\n    op.alter_column('table_name', 'old_name', new_column_name='new_name')\n</code></pre>"},{"location":"developer-guide/database-schema/#legacy-database-notes","title":"Legacy Database Notes","text":"<p>This database was migrated from Microsoft Access, which explains some quirks:</p> <ul> <li>Mixed case column names (e.g., <code>CustID</code>, <code>workorderno</code>)</li> <li>Spaces in column names (e.g., <code>WO DATE</code>, <code>TYPE OF REPAIR</code>)</li> <li>Inconsistent naming (some camelCase, some lowercase, some UPPERCASE)</li> <li>Multiple spaces in names (e.g., <code>QUOTE  BY</code> has two spaces)</li> <li>Deprecated fields left for historical data compatibility</li> </ul> <p>When working with the schema, always check the exact column name in the model definition.</p>"},{"location":"developer-guide/database-schema/#er-diagram-detailed","title":"ER Diagram - Detailed","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              tblcustomers                  \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK custid         TEXT                     \u2502\n\u2502    name           TEXT                     \u2502\n\u2502    contact        TEXT                     \u2502\n\u2502    address        TEXT                     \u2502\n\u2502    city, state, zipcode                    \u2502\n\u2502    homephone, workphone, cellphone         \u2502\n\u2502    emailaddress   TEXT                     \u2502\n\u2502 FK source         TEXT  \u2192 tblsource        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                           \u2502\n          \u2502 1                       1 \u2502\n          \u2502                           \u2502\n          \u2502 N                       N \u2502\n          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 tblcustworkorder... \u2502     \u2502 tblrepairworkorder..\u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK workorderno      \u2502     \u2502 PK repairorderno    \u2502\n\u2502 FK custid           \u2502     \u2502 FK custid           \u2502\n\u2502    woname           \u2502     \u2502    roname           \u2502\n\u2502    rack_number      \u2502     \u2502    RACK#            \u2502\n\u2502    storagetime      \u2502     \u2502    storage          \u2502\n\u2502    datein, dateout  \u2502     \u2502    datein, dateout  \u2502\n\u2502    source_name      \u2502     \u2502    source_name      \u2502\n\u2502    ...              \u2502     \u2502    ...              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                           \u2502\n          \u2502 1                       1 \u2502\n          \u2502                           \u2502\n          \u2502 N                       N \u2502\n          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  tblorddetcust...   \u2502     \u2502 repair_order_items  \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK itemid           \u2502     \u2502 PK id               \u2502\n\u2502 FK workorderno      \u2502     \u2502 FK repairorderno    \u2502\n\u2502    sizewgt          \u2502     \u2502    description      \u2502\n\u2502    price, qty       \u2502     \u2502    price, qty       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n          \u2502 1                       1 \u2502\n          \u2502 N                       N \u2502\n          \u25bc                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 work_order_files    \u2502     \u2502 repair_order_files  \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK id               \u2502     \u2502 PK id               \u2502\n\u2502 FK work_order_no    \u2502     \u2502 FK repair_order_no  \u2502\n\u2502    s3_key           \u2502     \u2502    s3_key           \u2502\n\u2502    file_name        \u2502     \u2502    file_name        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              tblsource                     \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 PK ssource        TEXT                     \u2502\n\u2502    name           TEXT                     \u2502\n\u2502    contact        TEXT                     \u2502\n\u2502    address        TEXT                     \u2502\n\u2502    phone, email   TEXT                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"developer-guide/database-schema/#see-also","title":"See Also","text":"<ul> <li>Alembic Migration Guide - Database migrations</li> <li>Storage Fields Guide - Understanding storage/location fields</li> <li>API Reference - API endpoints</li> <li>Performance Analysis - Query optimization</li> <li>Denormalization Analysis - Performance improvements</li> </ul>"},{"location":"developer-guide/file-uploads/","title":"File Upload System","text":""},{"location":"developer-guide/file-uploads/#overview","title":"Overview","text":"<p>The Awning Management System includes a comprehensive file upload system with: - S3 Integration: Cloud storage for production - Local Storage: Fallback for development - Deferred Uploads: Prevents orphaned S3 files when database commits fail - Thumbnail Generation: Automatic image thumbnail creation - Environment Detection: Automatic AWS vs local environment detection</p>"},{"location":"developer-guide/file-uploads/#architecture","title":"Architecture","text":""},{"location":"developer-guide/file-uploads/#file-upload-flow","title":"File Upload Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     File Upload Process                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nUser uploads file\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. File Validation   \u2502 \u2190 Check allowed extensions\n\u2502    (allowed_file)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 2. Read File Content \u2502 \u2190 Read into memory\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 3. Generate          \u2502 \u2190 Create thumbnail (if image)\n\u2502    Thumbnail         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Deferred? \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Yes \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                                 \u2502\n       \u2502                                 \u25bc\n       \u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                     \u2502 4a. Store in Memory     \u2502\n       \u2502                     \u2502     _deferred_content   \u2502\n       \u2502                     \u2502     _deferred_s3_key    \u2502\n       \u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502\n       \u2502                                 \u25bc\n       \u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                     \u2502 5a. Create DB Record    \u2502\n       \u2502                     \u2502     (file_path = s3://) \u2502\n       \u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502\n       \u2502                                 \u25bc\n       \u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                     \u2502 6a. Commit Transaction  \u2502\n       \u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502\n       \u2502                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                        \u2502                 \u2502\n       \u2502                  Success              Failure\n       \u2502                        \u2502                 \u2502\n       \u2502                        \u25bc                 \u25bc\n       \u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502           \u2502 7a. Upload to S3    \u2502  \u2502 7b. Rollback \u2502\n       \u2502           \u2502     (deferred)      \u2502  \u2502   + Cleanup  \u2502\n       \u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                        \u2502                 \u2502\n       \u2502                        \u2502            No orphaned\n       \u2502                        \u2502            S3 files! \u2713\n       \u2502                        \u25bc\n       \u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502           \u2502 8. Clean Memory     \u2502\n       \u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500 No \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                         \u2502\n                                         \u25bc\n                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                             \u2502 4b. Upload to S3     \u2502\n                             \u2502     (immediate)      \u2502\n                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                         \u2502\n                                         \u25bc\n                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                             \u2502 5b. Create DB Record \u2502\n                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                         \u2502\n                                         \u25bc\n                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                             \u2502 6b. Commit           \u2502\n                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                         \u2502\n                                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                \u2502                 \u2502\n                          Success              Failure\n                                \u2502                 \u2502\n                                \u25bc                 \u25bc\n                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                           \u2502  Done   \u2502   \u2502 Rollback BUT \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502 Orphaned S3  \u2502\n                                         \u2502 files exist! \u2502\n                                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                \u2502\n                                         Risk: S3 cleanup\n                                         needed manually\n</code></pre>"},{"location":"developer-guide/file-uploads/#deferred-upload-pattern","title":"Deferred Upload Pattern","text":""},{"location":"developer-guide/file-uploads/#why-deferred-uploads","title":"Why Deferred Uploads?","text":"<p>Problem: Immediate uploads can leave orphaned S3 files when database commits fail.</p> <p>Example Scenario (Without Deferred Uploads): <pre><code># Upload to S3 immediately\nsave_work_order_file(\"WO000001\", file, defer_s3_upload=False)\n# \u2191 File is now in S3\n\n# Create database record\ndb.session.add(work_order)\ndb.session.commit()  # \u2190 This fails!\n\n# Result: File exists in S3 but no database record\n# Orphaned file that wastes storage and is hard to clean up\n</code></pre></p> <p>Solution: Defer S3 upload until after successful database commit.</p>"},{"location":"developer-guide/file-uploads/#deferred-upload-workflow","title":"Deferred Upload Workflow","text":"<pre><code>from utils.file_upload import (\n    save_work_order_file,\n    commit_deferred_uploads,\n    cleanup_deferred_files\n)\n\n# Step 1: Process files (stores in memory, not S3)\nfile_objects = []\nfor uploaded_file in request.files.getlist('documents'):\n    file_obj = save_work_order_file(\n        work_order_no=\"WO000001\",\n        file=uploaded_file,\n        to_s3=True,\n        generate_thumbnails=True,\n        defer_s3_upload=True  # \u2190 Key parameter\n    )\n    file_objects.append(file_obj)\n    db.session.add(file_obj)\n\n# Step 2: Add work order and commit\ntry:\n    db.session.add(work_order)\n    db.session.commit()  # \u2190 Database transaction\n\n    # Step 3: ONLY after successful commit, upload to S3\n    success, uploaded, failed = commit_deferred_uploads(file_objects)\n\n    if not success:\n        flash(f\"{len(failed)} files failed to upload\", \"warning\")\n        for file_obj, error in failed:\n            flash(f\"Error uploading {file_obj.filename}: {error}\", \"error\")\n\nexcept Exception as e:\n    # Step 4: On failure, rollback and cleanup memory\n    db.session.rollback()\n    cleanup_deferred_files(file_objects)  # \u2190 No orphaned S3 files!\n    flash(f\"Error: {e}\", \"error\")\n</code></pre>"},{"location":"developer-guide/file-uploads/#memory-management","title":"Memory Management","text":"<p>Deferred uploads store file content in memory using temporary object attributes:</p> <pre><code># These attributes are attached to file model objects:\nfile_obj._deferred_file_content      # bytes: The file content\nfile_obj._deferred_s3_key             # str: The S3 key to upload to\nfile_obj._deferred_thumbnail_content  # PIL.Image or bytes: Thumbnail\nfile_obj._deferred_thumbnail_key      # str: Thumbnail S3 key\n</code></pre> <p>Memory Cleanup: - <code>commit_deferred_uploads()</code> - Removes attributes after successful upload - <code>cleanup_deferred_files()</code> - Removes attributes after rollback (prevents memory leaks)</p>"},{"location":"developer-guide/file-uploads/#configuration","title":"Configuration","text":""},{"location":"developer-guide/file-uploads/#environment-variables","title":"Environment Variables","text":"<pre><code># Required\nAWS_S3_BUCKET=your-bucket-name\n\n# Optional (defaults)\nAWS_REGION=us-east-1\n\n# Local Development Only (AWS provides these automatically in production via IAM)\nAWS_ACCESS_KEY_ID=your-access-key-id\nAWS_SECRET_ACCESS_KEY=your-secret-access-key\n</code></pre>"},{"location":"developer-guide/file-uploads/#allowed-file-extensions","title":"Allowed File Extensions","text":"<p>Configured in utils/file_upload.py:</p> <pre><code>ALLOWED_EXTENSIONS = {\n    'pdf',      # Documents\n    'docx',\n    'txt',\n    'csv',\n    'xlsx',\n    'jpg',      # Images\n    'jpeg',\n    'png'\n}\n</code></pre> <p>To add new extensions: <pre><code># In utils/file_upload.py\nALLOWED_EXTENSIONS = {\n    'pdf', 'docx', 'txt', 'csv', 'xlsx',\n    'jpg', 'jpeg', 'png',\n    'gif', 'bmp', 'tiff',  # Add new extensions\n}\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#file-size-limits","title":"File Size Limits","text":"<p>Configured in config.py:</p> <pre><code>MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16 MB\n</code></pre> <p>To change limit: <pre><code># In config.py\nclass Config:\n    MAX_CONTENT_LENGTH = 50 * 1024 * 1024  # 50 MB\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#environment-detection","title":"Environment Detection","text":"<p>The system automatically detects whether it's running on AWS or locally:</p> <pre><code>def is_running_on_aws():\n    \"\"\"Detect if running in AWS environment.\"\"\"\n    aws_indicators = [\n        os.getenv(\"AWS_EXECUTION_ENV\"),           # AWS services\n        os.getenv(\"AWS_LAMBDA_FUNCTION_NAME\"),    # Lambda\n        os.getenv(\"AWS_REGION\"),                  # Usually set in AWS\n        os.path.exists(\"/var/app/current\"),       # EB directory\n        os.path.exists(\"/opt/elasticbeanstalk\"),  # EB specific path\n    ]\n    return any(aws_indicators)\n</code></pre> <p>Behavior: - On AWS: Uses IAM role for S3 access (no credentials needed) - Local: Uses explicit AWS credentials from environment variables</p>"},{"location":"developer-guide/file-uploads/#core-functions","title":"Core Functions","text":""},{"location":"developer-guide/file-uploads/#file-upload-functions","title":"File Upload Functions","text":""},{"location":"developer-guide/file-uploads/#save_work_order_filework_order_no-file-to_s3true-generate_thumbnailstrue-defer_s3_uploadfalse","title":"<code>save_work_order_file(work_order_no, file, to_s3=True, generate_thumbnails=True, defer_s3_upload=False)</code>","text":"<p>Save a file for a work order.</p> <p>Parameters: - <code>work_order_no</code> (str): Work order number - <code>file</code>: Flask file upload object - <code>to_s3</code> (bool): Whether to save to S3 (default: True) - <code>generate_thumbnails</code> (bool): Generate thumbnail for images (default: True) - <code>defer_s3_upload</code> (bool): Defer upload until after DB commit (default: False, should be True in production)</p> <p>Returns: <code>WorkOrderFile</code> instance (not yet committed to database)</p> <p>Example: <pre><code>from utils.file_upload import save_work_order_file\n\nfile_obj = save_work_order_file(\n    work_order_no=\"WO000001\",\n    file=request.files['document'],\n    to_s3=True,\n    generate_thumbnails=True,\n    defer_s3_upload=True  # Recommended!\n)\n\ndb.session.add(file_obj)\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#save_repair_order_filerepair_order_no-file-to_s3true-generate_thumbnailstrue-defer_s3_uploadfalse","title":"<code>save_repair_order_file(repair_order_no, file, to_s3=True, generate_thumbnails=True, defer_s3_upload=False)</code>","text":"<p>Save a file for a repair order (same interface as <code>save_work_order_file</code>).</p>"},{"location":"developer-guide/file-uploads/#deferred-upload-management","title":"Deferred Upload Management","text":""},{"location":"developer-guide/file-uploads/#commit_deferred_uploadsfile_objects","title":"<code>commit_deferred_uploads(file_objects)</code>","text":"<p>Upload files to S3 that were deferred until after database commit.</p> <p>Parameters: - <code>file_objects</code> (list): List of file model objects with deferred upload data</p> <p>Returns: Tuple of <code>(success, uploaded_files, failed_files)</code> - <code>success</code> (bool): True if all uploads succeeded - <code>uploaded_files</code> (list): List of successfully uploaded file objects - <code>failed_files</code> (list): List of (file_obj, error_message) tuples</p> <p>Example: <pre><code>success, uploaded, failed = commit_deferred_uploads(file_objects)\n\nif success:\n    flash(f\"All {len(uploaded)} files uploaded successfully\", \"success\")\nelse:\n    flash(f\"{len(uploaded)} files uploaded, {len(failed)} failed\", \"warning\")\n    for file_obj, error in failed:\n        print(f\"Failed: {file_obj.filename} - {error}\")\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#cleanup_deferred_filesfile_objects","title":"<code>cleanup_deferred_files(file_objects)</code>","text":"<p>Clean up memory for files that were staged for deferred upload but the transaction was rolled back.</p> <p>Parameters: - <code>file_objects</code> (list): List of file model objects with deferred upload data</p> <p>Purpose: Prevents memory leaks by removing temporary <code>_deferred_*</code> attributes.</p> <p>Example: <pre><code>try:\n    db.session.commit()\n    commit_deferred_uploads(file_objects)\nexcept Exception as e:\n    db.session.rollback()\n    cleanup_deferred_files(file_objects)  # Prevent memory leaks\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#file-validation","title":"File Validation","text":""},{"location":"developer-guide/file-uploads/#allowed_filefilename","title":"<code>allowed_file(filename)</code>","text":"<p>Check if uploaded file has allowed extension.</p> <p>Example: <pre><code>from utils.file_upload import allowed_file\n\nif request.files['document']:\n    file = request.files['document']\n    if allowed_file(file.filename):\n        # Process file\n        pass\n    else:\n        flash(\"File type not allowed\", \"error\")\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#file-information","title":"File Information","text":""},{"location":"developer-guide/file-uploads/#get_file_sizefile_path","title":"<code>get_file_size(file_path)</code>","text":"<p>Get human-readable file size.</p> <p>Parameters: - <code>file_path</code> (str): S3 path (<code>s3://...</code>) or local path</p> <p>Returns: Human-readable size string (e.g., \"1.5 MB\") or None if file not found</p> <p>Example: <pre><code>from utils.file_upload import get_file_size\n\nsize = get_file_size(\"s3://my-bucket/work_orders/WO000001/document.pdf\")\nprint(size)  # \"2.3 MB\"\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#presigned-urls","title":"Presigned URLs","text":""},{"location":"developer-guide/file-uploads/#generate_presigned_urlfile_path-expires_in3600","title":"<code>generate_presigned_url(file_path, expires_in=3600)</code>","text":"<p>Generate a temporary URL for secure S3 file access.</p> <p>Parameters: - <code>file_path</code> (str): Full S3 path (<code>s3://bucket/key</code>) - <code>expires_in</code> (int): URL expiration in seconds (default: 3600 = 1 hour)</p> <p>Returns: Presigned URL string</p> <p>Why Presigned URLs? - S3 files are private by default - Presigned URLs provide temporary access without making files public - URLs automatically expire for security</p> <p>Example: <pre><code>from utils.file_upload import generate_presigned_url\n\n# Generate 2-hour access URL\nurl = generate_presigned_url(\n    \"s3://my-bucket/work_orders/WO000001/document.pdf\",\n    expires_in=7200\n)\n\n# Use in template\nreturn render_template('view_file.html', file_url=url)\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#get_file_with_thumbnail_urlswo_file-expires_in3600","title":"<code>get_file_with_thumbnail_urls(wo_file, expires_in=3600)</code>","text":"<p>Get file URLs including thumbnail for a WorkOrderFile object.</p> <p>Returns: Dict with keys: - <code>file</code>: The WorkOrderFile object - <code>file_url</code>: Presigned URL or file path - <code>thumbnail_url</code>: Presigned thumbnail URL or None - <code>has_thumbnail</code>: Boolean</p> <p>Example: <pre><code>from utils.file_upload import get_file_with_thumbnail_urls\n\nfile_data = get_file_with_thumbnail_urls(work_order_file, expires_in=3600)\n\nreturn render_template('files.html', **file_data)\n</code></pre></p> <p>Template usage: <pre><code>{% if has_thumbnail %}\n    &lt;img src=\"{{ thumbnail_url }}\" alt=\"Thumbnail\"&gt;\n{% endif %}\n&lt;a href=\"{{ file_url }}\" download&gt;Download File&lt;/a&gt;\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#file-deletion","title":"File Deletion","text":""},{"location":"developer-guide/file-uploads/#delete_file_from_s3file_path","title":"<code>delete_file_from_s3(file_path)</code>","text":"<p>Delete a file from S3 given its full s3:// path.</p> <p>Parameters: - <code>file_path</code> (str): Full S3 path (e.g., <code>s3://bucket-name/path/to/file.jpg</code>)</p> <p>Returns: Boolean (True on success, False on failure)</p> <p>Example: <pre><code>from utils.file_upload import delete_file_from_s3\n\n# Delete file\nsuccess = delete_file_from_s3(\"s3://my-bucket/work_orders/WO000001/file.pdf\")\n\nif success:\n    # Also delete database record\n    db.session.delete(file_record)\n    db.session.commit()\n\n# Also works for thumbnails\ndelete_file_from_s3(\"s3://my-bucket/work_orders/WO000001/thumbnails/file_thumb.jpg\")\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#thumbnail-generation","title":"Thumbnail Generation","text":"<p>Thumbnails are automatically generated for image files (jpg, jpeg, png).</p>"},{"location":"developer-guide/file-uploads/#thumbnail-configuration","title":"Thumbnail Configuration","text":"<p>Size: 300x300 pixels (maintains aspect ratio)</p> <p>Format: JPEG</p> <p>S3 Path Pattern: <pre><code>work_orders/{order_no}/thumbnails/{filename}_thumb.jpg\nrepair_orders/{order_no}/thumbnails/{filename}_thumb.jpg\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#thumbnail-functions","title":"Thumbnail Functions","text":"<p>Located in utils/thumbnail_generator.py:</p>"},{"location":"developer-guide/file-uploads/#generate_thumbnailfile_content-filename","title":"<code>generate_thumbnail(file_content, filename)</code>","text":"<p>Generate thumbnail from image file content.</p>"},{"location":"developer-guide/file-uploads/#save_thumbnail_to_s3thumbnail_img-s3_client-bucket-s3_key","title":"<code>save_thumbnail_to_s3(thumbnail_img, s3_client, bucket, s3_key)</code>","text":"<p>Save thumbnail to S3.</p>"},{"location":"developer-guide/file-uploads/#save_thumbnail_locallythumbnail_img-file_path","title":"<code>save_thumbnail_locally(thumbnail_img, file_path)</code>","text":"<p>Save thumbnail to local filesystem.</p>"},{"location":"developer-guide/file-uploads/#s3-folder-structure","title":"S3 Folder Structure","text":"<pre><code>s3://your-bucket/\n\u251c\u2500\u2500 work_orders/\n\u2502   \u251c\u2500\u2500 WO000001/\n\u2502   \u2502   \u251c\u2500\u2500 invoice.pdf\n\u2502   \u2502   \u251c\u2500\u2500 photo1.jpg\n\u2502   \u2502   \u2514\u2500\u2500 thumbnails/\n\u2502   \u2502       \u2514\u2500\u2500 photo1_thumb.jpg\n\u2502   \u251c\u2500\u2500 WO000002/\n\u2502   \u2502   \u2514\u2500\u2500 document.docx\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 repair_orders/\n\u2502   \u251c\u2500\u2500 RO000001/\n\u2502   \u2502   \u251c\u2500\u2500 before.jpg\n\u2502   \u2502   \u251c\u2500\u2500 after.jpg\n\u2502   \u2502   \u2514\u2500\u2500 thumbnails/\n\u2502   \u2502       \u251c\u2500\u2500 before_thumb.jpg\n\u2502   \u2502       \u2514\u2500\u2500 after_thumb.jpg\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ml_models/\n    \u251c\u2500\u2500 latest_model.pkl\n    \u2514\u2500\u2500 latest_model_metadata.json\n</code></pre>"},{"location":"developer-guide/file-uploads/#complete-upload-example","title":"Complete Upload Example","text":""},{"location":"developer-guide/file-uploads/#route-handler-with-deferred-upload","title":"Route Handler with Deferred Upload","text":"<pre><code>from flask import Blueprint, request, flash, redirect, url_for\nfrom utils.file_upload import (\n    save_work_order_file,\n    commit_deferred_uploads,\n    cleanup_deferred_files,\n    allowed_file\n)\nfrom models.work_order import WorkOrder\nfrom extensions import db\n\nwork_orders_bp = Blueprint('work_orders', __name__)\n\n@work_orders_bp.route('/work_orders/&lt;work_order_no&gt;/upload', methods=['POST'])\ndef upload_files(work_order_no):\n    \"\"\"Upload files to a work order.\"\"\"\n\n    # Verify work order exists\n    work_order = WorkOrder.query.get_or_404(work_order_no)\n\n    # Validate files\n    files = request.files.getlist('documents')\n    if not files or files[0].filename == '':\n        flash(\"No files selected\", \"error\")\n        return redirect(url_for('work_orders.view', work_order_no=work_order_no))\n\n    # Check file types\n    invalid_files = [f.filename for f in files if not allowed_file(f.filename)]\n    if invalid_files:\n        flash(f\"Invalid file types: {', '.join(invalid_files)}\", \"error\")\n        return redirect(url_for('work_orders.view', work_order_no=work_order_no))\n\n    # Step 1: Process files (deferred upload)\n    file_objects = []\n    for uploaded_file in files:\n        try:\n            file_obj = save_work_order_file(\n                work_order_no=work_order_no,\n                file=uploaded_file,\n                to_s3=True,\n                generate_thumbnails=True,\n                defer_s3_upload=True  # Key: Defer until after commit\n            )\n            file_objects.append(file_obj)\n            db.session.add(file_obj)\n        except Exception as e:\n            flash(f\"Error processing {uploaded_file.filename}: {e}\", \"error\")\n\n    # Step 2: Commit database changes\n    try:\n        db.session.commit()\n\n        # Step 3: Upload to S3 (only after successful commit)\n        success, uploaded, failed = commit_deferred_uploads(file_objects)\n\n        # Step 4: Report results\n        if success:\n            flash(f\"{len(uploaded)} files uploaded successfully\", \"success\")\n        else:\n            flash(f\"{len(uploaded)} files uploaded, {len(failed)} failed\", \"warning\")\n            for file_obj, error in failed:\n                flash(f\"Failed to upload {file_obj.filename}: {error}\", \"error\")\n\n        return redirect(url_for('work_orders.view', work_order_no=work_order_no))\n\n    except Exception as e:\n        # Step 5: On error, rollback and cleanup\n        db.session.rollback()\n        cleanup_deferred_files(file_objects)\n\n        flash(f\"Error uploading files: {e}\", \"error\")\n        return redirect(url_for('work_orders.view', work_order_no=work_order_no))\n</code></pre>"},{"location":"developer-guide/file-uploads/#html-form","title":"HTML Form","text":"<pre><code>&lt;form method=\"POST\" action=\"{{ url_for('work_orders.upload_files', work_order_no=work_order.WorkOrderNo) }}\"\n      enctype=\"multipart/form-data\"&gt;\n\n    &lt;div class=\"form-group\"&gt;\n        &lt;label for=\"documents\"&gt;Upload Files&lt;/label&gt;\n        &lt;input type=\"file\"\n               class=\"form-control-file\"\n               id=\"documents\"\n               name=\"documents\"\n               multiple\n               accept=\".pdf,.docx,.txt,.csv,.xlsx,.jpg,.jpeg,.png\"&gt;\n        &lt;small class=\"form-text text-muted\"&gt;\n            Allowed types: PDF, DOCX, TXT, CSV, XLSX, JPG, PNG (max 16MB per file)\n        &lt;/small&gt;\n    &lt;/div&gt;\n\n    &lt;button type=\"submit\" class=\"btn btn-primary\"&gt;Upload&lt;/button&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"developer-guide/file-uploads/#display-files-with-thumbnails","title":"Display Files with Thumbnails","text":"<pre><code>@work_orders_bp.route('/work_orders/&lt;work_order_no&gt;/files')\ndef view_files(work_order_no):\n    \"\"\"Display files for a work order.\"\"\"\n    work_order = WorkOrder.query.get_or_404(work_order_no)\n\n    # Get files with presigned URLs\n    files_data = []\n    for file in work_order.files:\n        file_data = get_file_with_thumbnail_urls(file, expires_in=3600)\n        files_data.append(file_data)\n\n    return render_template('files.html', work_order=work_order, files=files_data)\n</code></pre> <pre><code>&lt;!-- files.html --&gt;\n&lt;div class=\"row\"&gt;\n    {% for file_data in files %}\n    &lt;div class=\"col-md-3\"&gt;\n        &lt;div class=\"card\"&gt;\n            {% if file_data.has_thumbnail %}\n                &lt;img src=\"{{ file_data.thumbnail_url }}\" class=\"card-img-top\" alt=\"{{ file_data.file.filename }}\"&gt;\n            {% else %}\n                &lt;div class=\"card-img-top bg-secondary text-white text-center\" style=\"height: 200px; line-height: 200px;\"&gt;\n                    &lt;i class=\"fas fa-file fa-3x\"&gt;&lt;/i&gt;\n                &lt;/div&gt;\n            {% endif %}\n            &lt;div class=\"card-body\"&gt;\n                &lt;h5 class=\"card-title\"&gt;{{ file_data.file.filename }}&lt;/h5&gt;\n                &lt;p class=\"card-text\"&gt;\n                    &lt;small class=\"text-muted\"&gt;{{ file_data.file.uploaded_at.strftime('%Y-%m-%d') }}&lt;/small&gt;\n                &lt;/p&gt;\n                &lt;a href=\"{{ file_data.file_url }}\" class=\"btn btn-primary btn-sm\" download&gt;\n                    &lt;i class=\"fas fa-download\"&gt;&lt;/i&gt; Download\n                &lt;/a&gt;\n                &lt;form method=\"POST\" action=\"{{ url_for('work_orders.delete_file', file_id=file_data.file.id) }}\"\n                      style=\"display:inline;\"&gt;\n                    &lt;button type=\"submit\" class=\"btn btn-danger btn-sm\"\n                            onclick=\"return confirm('Delete this file?')\"&gt;\n                        &lt;i class=\"fas fa-trash\"&gt;&lt;/i&gt; Delete\n                    &lt;/button&gt;\n                &lt;/form&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n    {% endfor %}\n&lt;/div&gt;\n</code></pre>"},{"location":"developer-guide/file-uploads/#local-development","title":"Local Development","text":""},{"location":"developer-guide/file-uploads/#using-local-storage","title":"Using Local Storage","text":"<p>For development without AWS credentials:</p> <pre><code>file_obj = save_work_order_file(\n    work_order_no=\"WO000001\",\n    file=uploaded_file,\n    to_s3=False,  # Use local storage\n    generate_thumbnails=True,\n    defer_s3_upload=False  # Not applicable for local\n)\n</code></pre> <p>Local Storage Path: <pre><code>uploads/work_orders/{order_no}/{filename}\nuploads/work_orders/{order_no}/thumbnails/{filename}_thumb.jpg\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#aws-credentials-for-local-development","title":"AWS Credentials for Local Development","text":"<p>Create <code>.env</code> file in project root:</p> <pre><code>AWS_ACCESS_KEY_ID=your-access-key-id\nAWS_SECRET_ACCESS_KEY=your-secret-access-key\nAWS_S3_BUCKET=your-bucket-name\nAWS_REGION=us-east-1\n</code></pre> <p>Load in Flask: <pre><code># config.py\nfrom dotenv import load_dotenv\nload_dotenv()\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#best-practices","title":"Best Practices","text":""},{"location":"developer-guide/file-uploads/#1-always-use-deferred-uploads-in-production","title":"1. Always Use Deferred Uploads in Production","text":"<pre><code># \u2705 Good - Prevents orphaned S3 files\nfile_obj = save_work_order_file(\n    work_order_no=wo_no,\n    file=uploaded_file,\n    defer_s3_upload=True\n)\n</code></pre> <pre><code># \u274c Bad - Can leave orphaned S3 files\nfile_obj = save_work_order_file(\n    work_order_no=wo_no,\n    file=uploaded_file,\n    defer_s3_upload=False\n)\n</code></pre>"},{"location":"developer-guide/file-uploads/#2-always-clean-up-on-rollback","title":"2. Always Clean Up on Rollback","text":"<pre><code>try:\n    db.session.commit()\n    commit_deferred_uploads(file_objects)\nexcept Exception:\n    db.session.rollback()\n    cleanup_deferred_files(file_objects)  # \u2705 Prevents memory leaks\n</code></pre>"},{"location":"developer-guide/file-uploads/#3-validate-file-types-before-processing","title":"3. Validate File Types Before Processing","text":"<pre><code># \u2705 Good - Validate early\nif not allowed_file(file.filename):\n    flash(\"Invalid file type\", \"error\")\n    return redirect(...)\n\n# Process file\nfile_obj = save_work_order_file(...)\n</code></pre>"},{"location":"developer-guide/file-uploads/#4-handle-partial-upload-failures","title":"4. Handle Partial Upload Failures","text":"<pre><code>success, uploaded, failed = commit_deferred_uploads(file_objects)\n\nif not success:\n    # \u2705 Good - Inform user about specific failures\n    for file_obj, error in failed:\n        flash(f\"Failed: {file_obj.filename} - {error}\", \"error\")\n</code></pre>"},{"location":"developer-guide/file-uploads/#5-use-presigned-urls-with-reasonable-expiration","title":"5. Use Presigned URLs with Reasonable Expiration","text":"<pre><code># \u2705 Good - 1 hour expiration for user downloads\nurl = generate_presigned_url(file_path, expires_in=3600)\n\n# \u274c Bad - 24 hour expiration (security risk)\nurl = generate_presigned_url(file_path, expires_in=86400)\n</code></pre>"},{"location":"developer-guide/file-uploads/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer-guide/file-uploads/#issue-aws-credentials-not-found","title":"Issue: \"AWS credentials not found\"","text":"<p>Cause: Missing AWS credentials in local development.</p> <p>Solution: <pre><code># Set environment variables\nexport AWS_ACCESS_KEY_ID=your-key\nexport AWS_SECRET_ACCESS_KEY=your-secret\nexport AWS_S3_BUCKET=your-bucket\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#issue-nosuchbucket-error","title":"Issue: \"NoSuchBucket\" error","text":"<p>Cause: S3 bucket doesn't exist or name is incorrect.</p> <p>Solution: 1. Verify bucket name in environment variables 2. Create bucket in AWS S3 console 3. Ensure bucket is in correct region</p>"},{"location":"developer-guide/file-uploads/#issue-orphaned-s3-files-after-errors","title":"Issue: Orphaned S3 files after errors","text":"<p>Cause: Not using deferred uploads or missing cleanup.</p> <p>Solution: <pre><code># Use deferred uploads\ndefer_s3_upload=True\n\n# Always cleanup on rollback\nexcept Exception:\n    cleanup_deferred_files(file_objects)\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#issue-memory-leaks-during-file-uploads","title":"Issue: Memory leaks during file uploads","text":"<p>Cause: Not cleaning up deferred file content.</p> <p>Solution: <pre><code># Always call cleanup_deferred_files on rollback\ncleanup_deferred_files(file_objects)\n</code></pre></p>"},{"location":"developer-guide/file-uploads/#issue-thumbnails-not-generating","title":"Issue: Thumbnails not generating","text":"<p>Cause: Non-image file or PIL library issue.</p> <p>Solution: 1. Verify file is an image (jpg, jpeg, png) 2. Check PIL/Pillow is installed: <code>pip install Pillow</code> 3. Check error logs for thumbnail generation failures</p>"},{"location":"developer-guide/file-uploads/#see-also","title":"See Also","text":"<ul> <li>Utility Functions Reference - File upload utility functions</li> <li>Error Handling - Handling upload errors</li> <li>Testing - Testing file uploads</li> <li>CLAUDE.md - Main project documentation</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/","title":"Item Exclusion Feature - Dynamic Item List Management","text":""},{"location":"developer-guide/item-exclusion-feature/#overview","title":"Overview","text":"<p>When editing work orders or repair orders, the \"Existing Items\" list and \"Customer Item History\" list should be mutually exclusive. An item should only appear in ONE list at a time to prevent confusion and duplication.</p>"},{"location":"developer-guide/item-exclusion-feature/#business-requirements","title":"Business Requirements","text":""},{"location":"developer-guide/item-exclusion-feature/#user-story","title":"User Story","text":"<p>As a user editing a work order, I want to see a clear separation between: - Existing Items: Items currently in THIS work order - Customer Item History: Available items from the customer's inventory catalog that are NOT already in this work order</p>"},{"location":"developer-guide/item-exclusion-feature/#behavior","title":"Behavior","text":""},{"location":"developer-guide/item-exclusion-feature/#scenario-1-initial-page-load","title":"Scenario 1: Initial Page Load","text":"<ul> <li>Given: A work order with items A and C already added</li> <li>When: User opens the edit page</li> <li>Then:</li> <li>Existing Items shows: [A, C]</li> <li>Customer Item History shows: [B, D, E] (all other customer items, excluding A and C)</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#scenario-2-removing-item-from-work-order","title":"Scenario 2: Removing Item from Work Order","text":"<ul> <li>Given:</li> <li>Existing Items: [A, C]</li> <li>Customer Item History: [B, D, E]</li> <li>When: User unchecks/removes item A from existing items</li> <li>Then:</li> <li>Existing Items: [C]</li> <li>Customer Item History: [A, B, D, E] \u2190 A reappears in history</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#scenario-3-adding-item-from-history","title":"Scenario 3: Adding Item from History","text":"<ul> <li>Given:</li> <li>Existing Items: [C]</li> <li>Customer Item History: [A, B, D, E]</li> <li>When: User selects item B from customer history</li> <li>Then:</li> <li>Existing Items: [C, B] \u2190 B added</li> <li>Customer Item History: [A, D, E] \u2190 B removed from history</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#scenario-4-re-adding-previously-removed-item","title":"Scenario 4: Re-adding Previously Removed Item","text":"<ul> <li>Given:</li> <li>Existing Items: [C]</li> <li>Customer Item History: [A, B, D, E]</li> <li>When: User checks item A from history (which was previously removed)</li> <li>Then:</li> <li>Existing Items: [C, A] \u2190 A re-added</li> <li>Customer Item History: [B, D, E] \u2190 A disappears from history</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#technical-implementation","title":"Technical Implementation","text":""},{"location":"developer-guide/item-exclusion-feature/#database-schema","title":"Database Schema","text":""},{"location":"developer-guide/item-exclusion-feature/#inventory-table-tblcustawngs","title":"Inventory Table (<code>tblcustawngs</code>)","text":"<ul> <li>Primary Key: <code>InventoryKey</code> (unique identifier for each catalog item)</li> <li>Contains the master catalog of items per customer</li> <li>Fields: Description, Material, Condition, Color, SizeWgt, Price, CustID, Qty</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#workorderitem-table-tblorddetcustawngs","title":"WorkOrderItem Table (<code>tblorddetcustawngs</code>)","text":"<ul> <li>Primary Key: <code>id</code> (auto-increment)</li> <li>Contains items specific to each work order</li> <li>No foreign key to Inventory - items are copied snapshots</li> <li>Fields: WorkOrderNo, CustID, Description, Material, Condition, Color, SizeWgt, Price, Qty</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#repairworkorderitem-table-tblrwodetcustawngs","title":"RepairWorkOrderItem Table (<code>tblrwodetcustawngs</code>)","text":"<ul> <li>Primary Key: <code>id</code> (auto-increment)</li> <li>Contains items specific to each repair order</li> <li>No foreign key to Inventory - items are copied snapshots</li> <li>Fields: RepairOrderNo, CustID, Description, Material, Condition, Color, SizeWgt, Price, Qty</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#matching-logic","title":"Matching Logic","text":"<p>Since there's no foreign key relationship, we match items by their InventoryKey:</p> <pre><code>// Inventory item structure from API\n{\n  \"id\": \"INV-12345\",  // InventoryKey\n  \"description\": \"Awning\",\n  \"material\": \"Canvas\",\n  \"condition\": \"Good\",\n  \"color\": \"Blue\",\n  \"size_wgt\": \"10x12\",\n  \"price\": 150.00,\n  \"qty\": 1\n}\n</code></pre> <p>When an item is added to a work order from inventory, we need to track which <code>InventoryKey</code> it came from.</p>"},{"location":"developer-guide/item-exclusion-feature/#implementation-approach","title":"Implementation Approach","text":""},{"location":"developer-guide/item-exclusion-feature/#option-1-track-inventorykey-in-workorderitem-recommended","title":"Option 1: Track InventoryKey in WorkOrderItem (Recommended)","text":"<p>Pros: - Clean, reliable matching - Can trace items back to their catalog source - Handles edge cases (identical items with different prices)</p> <p>Cons: - Requires database migration to add <code>InventoryKey</code> field to WorkOrderItem and RepairWorkOrderItem</p> <p>Implementation: 1. Add migration to add <code>inventory_key</code> column to both item tables 2. Update <code>process_selected_inventory_items()</code> to store the InventoryKey 3. In edit form, pass InventoryKey along with item data 4. JavaScript filters history items by checking if their InventoryKey exists in current items</p>"},{"location":"developer-guide/item-exclusion-feature/#option-2-match-by-description-material-alternative","title":"Option 2: Match by Description + Material (Alternative)","text":"<p>Pros: - No database changes required - Works with existing schema</p> <p>Cons: - Fragile matching (what if two items have same desc/material but different sizes?) - Can't distinguish between identical items with different prices - Edge cases may cause confusion</p> <p>Implementation: 1. JavaScript creates a Set of \"description|material\" keys from existing items 2. Filter history items by checking if their key exists in the Set 3. Update Set when items are added/removed dynamically</p>"},{"location":"developer-guide/item-exclusion-feature/#solution-architecture","title":"Solution Architecture","text":""},{"location":"developer-guide/item-exclusion-feature/#frontend-javascript","title":"Frontend (JavaScript)","text":"<pre><code>// Global state\nlet existingItemKeys = new Set();  // InventoryKeys of items in work order\nlet allInventoryItems = [];        // Full inventory from API\n\n// On page load\nfunction initializeItemLists() {\n  // Collect InventoryKeys from existing items\n  existingItemKeys = collectExistingItemKeys();\n\n  // Load customer inventory\n  loadCustomerInventory(custId);\n}\n\n// Filter inventory to exclude existing items\nfunction filterInventoryItems(inventoryItems) {\n  return inventoryItems.filter(item =&gt; !existingItemKeys.has(item.id));\n}\n\n// When item is removed from work order\nfunction onItemRemovedFromWorkOrder(inventoryKey) {\n  existingItemKeys.delete(inventoryKey);\n  refreshInventoryDisplay();\n}\n\n// When item is added from inventory\nfunction onItemAddedFromInventory(inventoryKey) {\n  existingItemKeys.add(inventoryKey);\n  refreshInventoryDisplay();\n}\n</code></pre>"},{"location":"developer-guide/item-exclusion-feature/#backend-changes","title":"Backend Changes","text":"<p>If using Option 1 (recommended):</p> <ol> <li> <p>Database Migration <pre><code># alembic/versions/xxxx_add_inventory_key_to_items.py\ndef upgrade():\n    op.add_column('tblorddetcustawngs',\n                  sa.Column('inventory_key', sa.String(), nullable=True))\n    op.add_column('tblrwodetcustawngs',\n                  sa.Column('inventory_key', sa.String(), nullable=True))\n\ndef downgrade():\n    op.drop_column('tblorddetcustawngs', 'inventory_key')\n    op.drop_column('tblrwodetcustawngs', 'inventory_key')\n</code></pre></p> </li> <li> <p>Model Updates <pre><code>class WorkOrderItem(db.Model):\n    # ... existing fields ...\n    InventoryKey = db.Column(\"inventory_key\", db.String, nullable=True)\n</code></pre></p> </li> <li> <p>Update item processing functions <pre><code>def process_selected_inventory_items(form, order_no, cust_id, item_class):\n    for inv_key in selected_ids:\n        inventory_item = Inventory.query.get(inv_key)\n        item = item_class(\n            # ... existing fields ...\n            InventoryKey=inv_key,  # NEW: Track source\n        )\n</code></pre></p> </li> <li> <p>Update edit template to include InventoryKey <pre><code>&lt;input type=\"hidden\" name=\"existing_item_inventory_key[]\" value=\"{{ item.InventoryKey }}\"&gt;\n</code></pre></p> </li> </ol> <p>If using Option 2 (no DB changes):</p> <p>Just use JavaScript matching - no backend changes needed.</p>"},{"location":"developer-guide/item-exclusion-feature/#files-to-modify","title":"Files to Modify","text":""},{"location":"developer-guide/item-exclusion-feature/#templates","title":"Templates","text":"<ul> <li><code>/templates/work_orders/edit.html</code> - Add InventoryKey hidden fields, update JavaScript</li> <li><code>/templates/repair_orders/edit.html</code> - Add InventoryKey hidden fields, update JavaScript</li> <li><code>/static/js/order-form-shared.js</code> - Add filtering logic to <code>loadCustomerInventory()</code></li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#models-option-1-only","title":"Models (Option 1 only)","text":"<ul> <li><code>/models/work_order.py</code> - Add <code>InventoryKey</code> field to <code>WorkOrderItem</code></li> <li><code>/models/repair_order.py</code> - Add <code>InventoryKey</code> field to <code>RepairWorkOrderItem</code></li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#routes-option-1-only","title":"Routes (Option 1 only)","text":"<ul> <li><code>/utils/order_item_helpers.py</code> - Update <code>process_selected_inventory_items()</code> to store InventoryKey</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#migrations-option-1-only","title":"Migrations (Option 1 only)","text":"<ul> <li>Create new Alembic migration to add <code>inventory_key</code> column</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#testing-checklist","title":"Testing Checklist","text":"<ul> <li>[ ] Initial page load: items in work order don't appear in history</li> <li>[ ] Remove item from work order: item reappears in history</li> <li>[ ] Add item from history: item disappears from history</li> <li>[ ] Add item from history: item appears in existing items</li> <li>[ ] Refresh page after save: state persists correctly</li> <li>[ ] Edge case: Item with no InventoryKey (manually added) doesn't break filtering</li> <li>[ ] Edge case: Multiple items with same description/material are handled correctly</li> <li>[ ] Works for both work orders and repair orders</li> </ul>"},{"location":"developer-guide/item-exclusion-feature/#recommended-approach","title":"Recommended Approach","text":"<p>Use Option 1 (add InventoryKey tracking) because: 1. More reliable and future-proof 2. Enables better item tracking and reporting 3. Handles edge cases correctly 4. Small database change with big benefits</p> <p>Start with Option 2 for quick implementation if migration is not feasible immediately, but plan to migrate to Option 1 later.</p>"},{"location":"developer-guide/item-exclusion-feature/#implementation-steps","title":"Implementation Steps","text":"<ol> <li>\u2705 Document requirements (this file)</li> <li>\u2705 Decided on Option 1 (InventoryKey tracking)</li> <li>\u2705 Created and ran database migration (20251019_2216-47b99b554807_add_inventory_key_to_order_items.py)</li> <li>\u2705 Updated models to include InventoryKey field (WorkOrderItem, RepairWorkOrderItem)</li> <li>\u2705 Updated backend to store InventoryKey when creating items (utils/order_item_helpers.py)</li> <li>\u2705 Updated edit templates to output InventoryKey in hidden fields and data attributes</li> <li>\u2705 Updated JavaScript to collect and track InventoryKeys (getExistingItemInventoryKeys())</li> <li>\u2705 Implemented dynamic filtering in loadCustomerInventory()</li> <li>\u2705 Added event handlers for add/remove actions (toggleItem(), toggleExistingItem(), removeExistingItem())</li> <li>\u2705 Tested with pytest</li> <li>\u23f3 Deploy and monitor</li> </ol>"},{"location":"developer-guide/item-exclusion-feature/#implementation-summary","title":"Implementation Summary","text":"<p>Completed: The item exclusion feature is now fully implemented using Option 1 (InventoryKey tracking).</p> <p>Key Changes: - Database migration added <code>inventory_key</code> column to both <code>tblorddetcustawngs</code> and <code>tblreporddetcustawngs</code> - Backend stores InventoryKey when processing selected inventory items - Templates output InventoryKey as data attributes on existing item cards/checkboxes - JavaScript dynamically filters customer history based on:   - Items already in the work order (checked existing items)   - Items newly selected from customer history - Real-time refresh when items are added or removed</p> <p>Files Modified: - <code>/models/work_order.py</code> - Added InventoryKey field to WorkOrderItem - <code>/models/repair_order.py</code> - Added InventoryKey field to RepairWorkOrderItem - <code>/utils/order_item_helpers.py</code> - Store InventoryKey when processing items - <code>/templates/work_orders/edit.html</code> - Output InventoryKey in data attributes - <code>/templates/repair_orders/edit.html</code> - Output InventoryKey in data attributes - <code>/static/js/order-form-shared.js</code> - Dynamic filtering logic</p>"},{"location":"developer-guide/item-exclusion-feature/#questionsdecisions","title":"Questions/Decisions","text":"<ul> <li>\u2705 Decision: Using Option 1 (InventoryKey tracking)</li> <li>Decision: Manually added items (not from inventory) do NOT get an InventoryKey - they will have <code>null</code> or empty string</li> <li>Answer: If an item exists in the work order but was deleted from inventory, the item remains in the work order (it's a snapshot) and won't appear in customer history (since it no longer exists in inventory)</li> </ul>"},{"location":"developer-guide/project-structure/","title":"Project Structure","text":""},{"location":"developer-guide/project-structure/#overview","title":"Overview","text":"<p>The Awning Management System follows a modular Flask application structure.</p>"},{"location":"developer-guide/project-structure/#directory-structure","title":"Directory Structure","text":"<pre><code>awning_wo/\n\u251c\u2500\u2500 app.py                  # Application factory\n\u251c\u2500\u2500 application.py          # AWS EB entry point\n\u251c\u2500\u2500 config.py              # Configuration\n\u251c\u2500\u2500 extensions.py          # Flask extensions\n\u251c\u2500\u2500 decorators.py          # Custom decorators\n\u251c\u2500\u2500 models/                # SQLAlchemy models\n\u2502   \u251c\u2500\u2500 customer.py\n\u2502   \u251c\u2500\u2500 work_order.py\n\u2502   \u251c\u2500\u2500 repair_order.py\n\u2502   \u251c\u2500\u2500 source.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 routes/                # Blueprint route handlers\n\u2502   \u251c\u2500\u2500 auth.py\n\u2502   \u251c\u2500\u2500 work_orders.py\n\u2502   \u251c\u2500\u2500 repair_order.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 templates/             # Jinja2 templates\n\u2502   \u251c\u2500\u2500 base.html\n\u2502   \u251c\u2500\u2500 work_orders/\n\u2502   \u251c\u2500\u2500 repair_orders/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 static/               # CSS, JS, images\n\u2502   \u251c\u2500\u2500 css/\n\u2502   \u251c\u2500\u2500 js/\n\u2502   \u2514\u2500\u2500 images/\n\u2514\u2500\u2500 tests/                # Test suite\n</code></pre>"},{"location":"developer-guide/project-structure/#key-files","title":"Key Files","text":""},{"location":"developer-guide/project-structure/#application-entry-points","title":"Application Entry Points","text":"<ul> <li><code>app.py</code> - Flask application factory, blueprint registration</li> <li><code>application.py</code> - AWS Elastic Beanstalk WSGI entry point</li> <li><code>config.py</code> - Environment-based configuration</li> </ul>"},{"location":"developer-guide/project-structure/#models","title":"Models","text":"<p>Models are in <code>models/</code> and use SQLAlchemy ORM:</p> <ul> <li><code>customer.py</code> - Customer information</li> <li><code>work_order.py</code> - Work order model</li> <li><code>repair_order.py</code> - Repair order model</li> <li><code>source.py</code> - Vendor/source model</li> </ul>"},{"location":"developer-guide/project-structure/#routes","title":"Routes","text":"<p>Routes are organized as Flask blueprints in <code>routes/</code>:</p> <ul> <li><code>work_orders.py</code> - Work order CRUD operations</li> <li><code>repair_order.py</code> - Repair order operations</li> <li><code>customers.py</code> - Customer management</li> <li><code>analytics.py</code> - Analytics dashboard</li> </ul>"},{"location":"developer-guide/project-structure/#templates","title":"Templates","text":"<p>Jinja2 templates in <code>templates/</code> follow feature-based organization.</p>"},{"location":"developer-guide/project-structure/#code-organization-principles","title":"Code Organization Principles","text":"<ol> <li>Blueprints - Each feature area has its own blueprint</li> <li>Models - One file per model</li> <li>Templates - Organized by feature</li> <li>DRY - Shared logic in decorators and utilities</li> </ol>"},{"location":"developer-guide/project-structure/#next-steps","title":"Next Steps","text":"<ul> <li>Learn the Database Schema</li> <li>Explore API Reference</li> <li>Read about Testing</li> </ul>"},{"location":"developer-guide/redirects/","title":"Redirect Documentation","text":"<p>This document provides a comprehensive overview of all redirects in the application, showing where users are sent after completing various actions.</p>"},{"location":"developer-guide/redirects/#overview","title":"Overview","text":"<p>The Awning Management System uses Flask's <code>redirect()</code> and <code>url_for()</code> functions to navigate users through the application. Understanding these redirects is crucial for maintaining good user experience and preventing users from ending up on unexpected pages.</p>"},{"location":"developer-guide/redirects/#redirect-principles","title":"Redirect Principles","text":"<ol> <li>Context-Aware: Redirects should send users back to relevant pages</li> <li>Success Feedback: Always flash a message before redirecting</li> <li>Error Handling: Failed operations should redirect appropriately</li> <li>Referrer Support: Use <code>return_url</code> parameters when possible</li> </ol>"},{"location":"developer-guide/redirects/#work-orders-module","title":"Work Orders Module","text":""},{"location":"developer-guide/redirects/#create-work-order","title":"Create Work Order","text":"<p>Route: <code>POST /work_orders/new</code></p> <p>Success Redirect: Customer Detail Page</p> <pre><code>redirect(url_for(\"customers.customer_detail\", customer_id=work_order.CustID))\n</code></pre> <pre><code>graph LR\n    A[Create Work Order Form] --&gt;|Success| B[Customer Detail Page]\n    A --&gt;|Error| A</code></pre> <p>Rationale: After creating a work order, users want to see the customer's full context including all their orders.</p>"},{"location":"developer-guide/redirects/#edit-work-order","title":"Edit Work Order","text":"<p>Route: <code>POST /work_orders/edit/&lt;work_order_no&gt;</code></p> <p>Success Redirect: Customer Detail Page</p> <pre><code>redirect(url_for(\"customers.customer_detail\", customer_id=work_order.CustID))\n</code></pre> <pre><code>graph LR\n    A[Edit Work Order Form] --&gt;|Success| B[Customer Detail Page]\n    A --&gt;|Error| A</code></pre> <p>Rationale: Similar to create - maintains customer context after editing.</p>"},{"location":"developer-guide/redirects/#cleaning-room-edit","title":"Cleaning Room Edit","text":"<p>Route: <code>POST /work_orders/cleaning-room/edit/&lt;work_order_no&gt;</code></p> <p>Success Redirect: Customer Detail Page</p> <pre><code>redirect(url_for(\"customers.customer_detail\", customer_id=work_order.CustID))\n</code></pre> <pre><code>graph LR\n    A[Cleaning Room Edit Form] --&gt;|Success| B[Customer Detail Page]\n    A --&gt;|Error| A</code></pre> <p>Rationale: Cleaning room staff need to see customer context after updating order status.</p>"},{"location":"developer-guide/redirects/#delete-work-order","title":"Delete Work Order","text":"<p>Route: <code>POST /work_orders/delete/&lt;work_order_no&gt;</code></p> <p>Current Redirect: \u26a0\ufe0f Work Orders List Page (Issue #163)</p> <pre><code>redirect(url_for(\"work_orders.list_work_orders\"))\n</code></pre> <pre><code>graph LR\n    A[Work Order Page] --&gt;|Delete| B[Work Orders List Page]\n\n    style B fill:#ff9999</code></pre> <p>Known Issue</p> <p>This redirect sends users to the work orders list page. See Issue #163 for discussion on changing this behavior.</p> <p>Possible alternatives:</p> <ul> <li>Customer Detail Page</li> <li>Dashboard</li> <li>Previous page (referrer)</li> <li>In-Progress Orders page</li> </ul>"},{"location":"developer-guide/redirects/#pdf-generation-errors","title":"PDF Generation Errors","text":"<p>Route: <code>GET /work_orders/&lt;work_order_no&gt;/pdf/download</code></p> <p>Error Redirect: Work Order Detail Page</p> <pre><code>redirect(url_for(\"work_orders.view_work_order\", work_order_no=work_order_no))\n</code></pre> <pre><code>graph LR\n    A[PDF Download Request] --&gt;|Error| B[Work Order Detail Page]\n    A --&gt;|Success| C[PDF File Download]</code></pre>"},{"location":"developer-guide/redirects/#repair-orders-module","title":"Repair Orders Module","text":""},{"location":"developer-guide/redirects/#create-repair-order","title":"Create Repair Order","text":"<p>Route: <code>POST /repair_orders/new</code></p> <p>Success Redirect: Repair Order Detail Page</p> <pre><code>redirect(url_for(\"repair_work_orders.view_repair_work_order\", repair_order_no=next_order_no))\n</code></pre> <pre><code>graph LR\n    A[Create Repair Order Form] --&gt;|Success| B[Repair Order Detail Page]\n    A --&gt;|Error| A</code></pre> <p>Rationale: Users want to immediately view the newly created repair order.</p>"},{"location":"developer-guide/redirects/#edit-repair-order","title":"Edit Repair Order","text":"<p>Route: <code>POST /repair_orders/edit/&lt;repair_order_no&gt;</code></p> <p>Success Redirect: Repair Order Detail Page</p> <pre><code>redirect(url_for(\"repair_work_orders.view_repair_work_order\", repair_order_no=repair_order_no))\n</code></pre> <pre><code>graph LR\n    A[Edit Repair Order Form] --&gt;|Success| B[Repair Order Detail Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#delete-repair-order","title":"Delete Repair Order","text":"<p>Route: <code>POST /repair_orders/delete/&lt;repair_order_no&gt;</code></p> <p>Success Redirect: Repair Orders List Page</p> <pre><code>redirect(url_for(\"repair_work_orders.list_repair_work_orders\"))\n</code></pre> <p>Error Redirect: Repair Order Detail Page</p> <pre><code>redirect(url_for(\"repair_work_orders.view_repair_work_order\", repair_order_no=repair_order_no))\n</code></pre> <pre><code>graph LR\n    A[Repair Order Page] --&gt;|Delete Success| B[Repair Orders List]\n    A --&gt;|Delete Error| A</code></pre>"},{"location":"developer-guide/redirects/#customers-module","title":"Customers Module","text":""},{"location":"developer-guide/redirects/#create-customer","title":"Create Customer","text":"<p>Route: <code>POST /customers/new</code></p> <p>Success Redirect: Customer Detail Page (View Mode)</p> <pre><code>redirect(url_for(\"customers.view_customer\", customer_id=customer.CustID))\n</code></pre> <pre><code>graph LR\n    A[Create Customer Form] --&gt;|Success| B[Customer Detail Page]\n    A --&gt;|Error| A</code></pre> <p>Rationale: After creating a customer, users typically want to view the full customer profile or add work orders.</p>"},{"location":"developer-guide/redirects/#edit-customer","title":"Edit Customer","text":"<p>Route: <code>POST /customers/edit/&lt;customer_id&gt;</code></p> <p>Success Redirect: Customer Detail Page</p> <pre><code>redirect(url_for(\"customers.customer_detail\", customer_id=customer.CustID))\n</code></pre> <pre><code>graph LR\n    A[Edit Customer Form] --&gt;|Success| B[Customer Detail Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#delete-customer","title":"Delete Customer","text":"<p>Route: <code>POST /customers/delete/&lt;customer_id&gt;</code></p> <p>Success Redirect: Customers List Page</p> <pre><code>redirect(url_for(\"customers.list_customers\"))\n</code></pre> <pre><code>graph LR\n    A[Customer Page] --&gt;|Delete| B[Customers List Page]</code></pre> <p>Rationale: After deleting a customer, the detail page no longer exists, so list view is appropriate.</p>"},{"location":"developer-guide/redirects/#inventory-module","title":"Inventory Module","text":""},{"location":"developer-guide/redirects/#create-inventory-item","title":"Create Inventory Item","text":"<p>Route: <code>POST /inventory/new</code></p> <p>Success Redirect: Inventory Item Detail Page</p> <pre><code>redirect(url_for(\"inventory.inventory_detail\", inventory_key=inventory_key))\n</code></pre> <pre><code>graph LR\n    A[Create Inventory Form] --&gt;|Success| B[Inventory Item Detail Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#edit-inventory-item","title":"Edit Inventory Item","text":"<p>Route: <code>POST /inventory/edit/&lt;inventory_key&gt;</code></p> <p>Success Redirect: Inventory Item Detail Page</p> <pre><code>redirect(url_for(\"inventory.inventory_detail\", inventory_key=inventory_key))\n</code></pre> <pre><code>graph LR\n    A[Edit Inventory Form] --&gt;|Success| B[Inventory Item Detail Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#delete-inventory-item","title":"Delete Inventory Item","text":"<p>Route: <code>POST /inventory/delete/&lt;inventory_key&gt;</code></p> <p>Success Redirect: Inventory List Page</p> <pre><code>redirect(url_for(\"inventory.inventory_list\"))\n</code></pre> <pre><code>graph LR\n    A[Inventory Item Page] --&gt;|Delete| B[Inventory List Page]</code></pre>"},{"location":"developer-guide/redirects/#sources-module","title":"Sources Module","text":""},{"location":"developer-guide/redirects/#create-source","title":"Create Source","text":"<p>Route: <code>POST /sources/new</code></p> <p>Success Redirect: Source Detail Page</p> <pre><code>redirect(url_for(\"source.source_detail\", source_name=source.SSource))\n</code></pre> <pre><code>graph LR\n    A[Create Source Form] --&gt;|Success| B[Source Detail Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#edit-source","title":"Edit Source","text":"<p>Route: <code>POST /sources/edit/&lt;source_name&gt;</code></p> <p>Success Redirect: Source Detail Page</p> <pre><code>redirect(url_for(\"source.source_detail\", source_name=source.SSource))\n</code></pre> <pre><code>graph LR\n    A[Edit Source Form] --&gt;|Success| B[Source Detail Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#delete-source","title":"Delete Source","text":"<p>Route: <code>POST /sources/delete/&lt;source_name&gt;</code></p> <p>Success Redirect: Sources List Page</p> <pre><code>redirect(url_for(\"source.source_list\"))\n</code></pre> <pre><code>graph LR\n    A[Source Page] --&gt;|Delete| B[Sources List Page]</code></pre>"},{"location":"developer-guide/redirects/#authentication-module","title":"Authentication Module","text":""},{"location":"developer-guide/redirects/#login","title":"Login","text":"<p>Route: <code>POST /auth/login</code></p> <p>Success Redirect: Dashboard</p> <pre><code>redirect(url_for(\"dashboard\"))\n</code></pre> <p>Already Logged In: Dashboard</p> <pre><code>redirect(url_for(\"dashboard\"))\n</code></pre> <pre><code>graph LR\n    A[Login Page] --&gt;|Success| B[Dashboard]\n    A --&gt;|Already Logged In| B\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#logout","title":"Logout","text":"<p>Route: <code>GET /auth/logout</code></p> <p>Redirect: Login Page</p> <pre><code>redirect(url_for(\"auth.login\"))\n</code></pre> <pre><code>graph LR\n    A[Any Page] --&gt;|Logout| B[Login Page]</code></pre>"},{"location":"developer-guide/redirects/#register","title":"Register","text":"<p>Route: <code>POST /auth/register</code></p> <p>Success Redirect: Login Page</p> <pre><code>redirect(url_for(\"auth.login\"))\n</code></pre> <p>Error Redirects: Registration Page (various validation errors)</p> <pre><code>graph LR\n    A[Registration Page] --&gt;|Success| B[Login Page]\n    A --&gt;|Error| A</code></pre>"},{"location":"developer-guide/redirects/#admin-module","title":"Admin Module","text":""},{"location":"developer-guide/redirects/#create-user","title":"Create User","text":"<p>Route: <code>POST /admin/users/create</code></p> <p>Redirect: Manage Users Page</p> <pre><code>redirect(url_for(\"admin.manage_users\"))\n</code></pre>"},{"location":"developer-guide/redirects/#delete-user","title":"Delete User","text":"<p>Route: <code>POST /admin/users/delete/&lt;user_id&gt;</code></p> <p>Redirect: Manage Users Page</p> <pre><code>redirect(url_for(\"admin.manage_users\"))\n</code></pre>"},{"location":"developer-guide/redirects/#toggle-admin","title":"Toggle Admin","text":"<p>Route: <code>POST /admin/users/toggle_admin/&lt;user_id&gt;</code></p> <p>Redirect: Manage Users Page</p> <pre><code>redirect(url_for(\"admin.manage_users\"))\n</code></pre> <pre><code>graph LR\n    A[Manage Users Page] --&gt;|Any Admin Action| A</code></pre> <p>Rationale: Admin stays on user management page to perform multiple actions.</p>"},{"location":"developer-guide/redirects/#in-progress-module","title":"In-Progress Module","text":""},{"location":"developer-guide/redirects/#root-route","title":"Root Route","text":"<p>Route: <code>GET /in_progress/</code></p> <p>Redirect: All Recent Orders</p> <pre><code>redirect(url_for(\"in_progress.all_recent\"))\n</code></pre> <pre><code>graph LR\n    A[/in_progress/] --&gt;|Auto-redirect| B[/in_progress/all_recent]</code></pre>"},{"location":"developer-guide/redirects/#file-downloads","title":"File Downloads","text":""},{"location":"developer-guide/redirects/#work-order-files","title":"Work Order Files","text":"<p>Route: <code>GET /work_orders/&lt;work_order_no&gt;/files/&lt;file_id&gt;/download</code></p> <p>S3 Files: Pre-signed URL Redirect</p> <pre><code>redirect(presigned_url)\n</code></pre> <p>Local Files: Direct file download (no redirect)</p>"},{"location":"developer-guide/redirects/#thumbnails","title":"Thumbnails","text":"<p>Route: <code>GET /work_orders/thumbnail/&lt;file_id&gt;</code></p> <p>S3 Thumbnails: Pre-signed URL Redirect</p> <pre><code>redirect(thumbnail_url)\n</code></pre> <p>Local Thumbnails: Direct file download (no redirect)</p>"},{"location":"developer-guide/redirects/#return-url-pattern","title":"Return URL Pattern","text":"<p>Several routes support a <code>return_url</code> query parameter for flexible navigation:</p>"},{"location":"developer-guide/redirects/#work-order-detail","title":"Work Order Detail","text":"<pre><code>return_url = request.args.get(\n    \"return_url\", request.referrer or url_for(\"work_orders.list_work_orders\")\n)\n</code></pre>"},{"location":"developer-guide/redirects/#work-order-edit","title":"Work Order Edit","text":"<pre><code>return_url = request.args.get(\n    \"return_url\", request.referrer or url_for(\"work_orders.list_work_orders\")\n)\n</code></pre>"},{"location":"developer-guide/redirects/#cleaning-room-edit_1","title":"Cleaning Room Edit","text":"<pre><code>return_url = request.args.get(\n    \"return_url\", request.referrer or url_for(\"work_orders.list_work_orders\")\n)\n</code></pre> <p>Using Return URLs</p> <p>When linking to these pages, you can specify where the user should return:</p> <pre><code>&lt;a href=\"{{ url_for('work_orders.view_work_order',\n                    work_order_no=wo.WorkOrderNo,\n                    return_url=url_for('queue.cleaning_queue')) }}\"&gt;\n    View Order\n&lt;/a&gt;\n</code></pre>"},{"location":"developer-guide/redirects/#complete-redirect-flow-diagram","title":"Complete Redirect Flow Diagram","text":"<pre><code>graph TB\n    Dashboard[Dashboard]\n\n    %% Work Orders\n    WOList[Work Orders List]\n    WODetail[Work Order Detail]\n    WOCreate[Create Work Order]\n    WOEdit[Edit Work Order]\n    CleanEdit[Cleaning Room Edit]\n\n    %% Customers\n    CustList[Customers List]\n    CustDetail[Customer Detail]\n    CustCreate[Create Customer]\n    CustEdit[Edit Customer]\n\n    %% Repair Orders\n    ROList[Repair Orders List]\n    RODetail[Repair Order Detail]\n    ROCreate[Create Repair Order]\n    ROEdit[Edit Repair Order]\n\n    %% Auth\n    Login[Login Page]\n\n    %% Work Order flows\n    WOCreate --&gt;|Success| CustDetail\n    WOEdit --&gt;|Success| CustDetail\n    CleanEdit --&gt;|Success| CustDetail\n    WODetail --&gt;|Delete| WOList\n\n    %% Customer flows\n    CustCreate --&gt;|Success| CustDetail\n    CustEdit --&gt;|Success| CustDetail\n    CustDetail --&gt;|Delete| CustList\n\n    %% Repair Order flows\n    ROCreate --&gt;|Success| RODetail\n    ROEdit --&gt;|Success| RODetail\n    RODetail --&gt;|Delete| ROList\n\n    %% Auth flows\n    Login --&gt;|Success| Dashboard\n    Dashboard --&gt;|Logout| Login\n\n    %% Issue highlight\n    style WOList fill:#ff9999\n\n    classDef issueNode fill:#ff9999,stroke:#ff0000,stroke-width:2px\n    classDef normalNode fill:#9999ff,stroke:#0000ff,stroke-width:2px</code></pre>"},{"location":"developer-guide/redirects/#known-issues","title":"Known Issues","text":""},{"location":"developer-guide/redirects/#issue-163-work-order-delete-redirect","title":"Issue #163: Work Order Delete Redirect","text":"<p>Current Behavior: Deleting a work order redirects to the Work Orders List page.</p> <p>Location: routes/work_orders.py:1124</p> <p>Discussion: GitHub Issue #163</p> <p>Proposed Solutions:</p> <ol> <li>Redirect to Customer Detail page (maintains customer context)</li> <li>Redirect to Dashboard (neutral location)</li> <li>Redirect to previous page using referrer (most flexible)</li> <li>Redirect to In-Progress or Queue page (workflow-oriented)</li> </ol>"},{"location":"developer-guide/redirects/#best-practices","title":"Best Practices","text":""},{"location":"developer-guide/redirects/#when-adding-new-redirects","title":"When Adding New Redirects","text":"<ol> <li>Consider User Context: Where did they come from? What's their next likely action?</li> <li>Use return_url Parameters: Allow flexible navigation when appropriate</li> <li>Flash Messages: Always provide feedback before redirecting</li> <li>Error Handling: Redirect to safe pages on errors</li> <li>Avoid List Pages: After creating/editing, redirect to detail pages when possible</li> <li>Document Changes: Update this guide when modifying redirects</li> </ol>"},{"location":"developer-guide/redirects/#common-patterns","title":"Common Patterns","text":""},{"location":"developer-guide/redirects/#after-create-operations","title":"After Create Operations","text":"<pre><code># Good: Show the newly created item\nreturn redirect(url_for(\"module.detail_view\", id=new_item.id))\n</code></pre>"},{"location":"developer-guide/redirects/#after-edit-operations","title":"After Edit Operations","text":"<pre><code># Good: Stay on detail page or return to context\nreturn redirect(url_for(\"module.detail_view\", id=item.id))\n</code></pre>"},{"location":"developer-guide/redirects/#after-delete-operations","title":"After Delete Operations","text":"<pre><code># Good: List page (detail page no longer exists)\nreturn redirect(url_for(\"module.list_view\"))\n</code></pre>"},{"location":"developer-guide/redirects/#with-return-url-support","title":"With Return URL Support","text":"<pre><code># Good: Flexible navigation\nreturn_url = request.args.get(\"return_url\", request.referrer or url_for(\"module.default_view\"))\nreturn redirect(return_url)\n</code></pre>"},{"location":"developer-guide/redirects/#testing-redirects","title":"Testing Redirects","text":"<p>When testing redirect logic:</p> <ol> <li>Test all paths: success, error, edge cases</li> <li>Verify flash messages: ensure proper user feedback</li> <li>Check HTTP status codes: should be 302 (Found) or 303 (See Other)</li> <li>Test return_url parameters: ensure they work correctly</li> <li>Verify authentication redirects: unauthenticated users handled properly</li> </ol> <p>Example test:</p> <pre><code>def test_delete_work_order_redirect(client, auth_login):\n    \"\"\"Test that deleting a work order redirects appropriately\"\"\"\n    response = client.post('/work_orders/delete/12345', follow_redirects=False)\n    assert response.status_code == 302\n    assert '/work_orders/' in response.location\n</code></pre>"},{"location":"developer-guide/redirects/#changelog","title":"Changelog","text":"Date Change Issue 2025-10-20 Initial redirect documentation created - 2025-10-20 Identified work order delete redirect issue #163"},{"location":"developer-guide/redirects/#see-also","title":"See Also","text":"<ul> <li>Flask URL Building</li> <li>Flask Redirects</li> <li>Flask Message Flashing</li> </ul>"},{"location":"developer-guide/security-best-practices/","title":"Security and Best Practices","text":""},{"location":"developer-guide/security-best-practices/#overview","title":"Overview","text":"<p>This guide covers security best practices, common vulnerabilities to avoid, and recommended coding patterns for the Awning Management System.</p>"},{"location":"developer-guide/security-best-practices/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Authentication &amp; Authorization</li> <li>Input Validation &amp; Sanitization</li> <li>SQL Injection Prevention</li> <li>Cross-Site Scripting (XSS)</li> <li>Cross-Site Request Forgery (CSRF)</li> <li>File Upload Security</li> <li>Session Management</li> <li>Environment Variables &amp; Secrets</li> <li>Database Security</li> <li>API Security</li> <li>Logging &amp; Monitoring</li> <li>Dependencies &amp; Updates</li> </ul>"},{"location":"developer-guide/security-best-practices/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"developer-guide/security-best-practices/#current-implementation","title":"Current Implementation","text":"<p>The application uses Flask-Login for session-based authentication with role-based access control.</p> <p>Login Flow: <pre><code># routes/auth.py\n@auth.route('/login', methods=['GET', 'POST'])\ndef login():\n    if form.validate_on_submit():\n        user = User.query.filter_by(username=form.username.data).first()\n        if user and user.check_password(form.password.data):\n            login_user(user)\n            return redirect(url_for('dashboard.index'))\n</code></pre></p> <p>Password Security: - Passwords are hashed using Werkzeug's <code>generate_password_hash</code> - Uses PBKDF2 with SHA-256 by default - Never store passwords in plaintext</p>"},{"location":"developer-guide/security-best-practices/#role-based-access-control","title":"Role-Based Access Control","text":"<p>Decorator Usage: <pre><code>from decorators import role_required\n\n@app.route('/admin/users')\n@role_required('admin')\ndef admin_users():\n    # Only accessible by admin users\n    return render_template('admin/users.html')\n</code></pre></p> <p>Available Roles: - <code>admin</code> - Full system access - <code>user</code> - Standard user access</p>"},{"location":"developer-guide/security-best-practices/#best-practices","title":"Best Practices","text":"<p>\u2705 DO: - Always use <code>@login_required</code> decorator on protected routes - Use <code>role_required</code> for admin-only functionality - Implement account lockout after N failed login attempts - Use strong password requirements (min 8 chars, complexity) - Implement session timeout for inactive users - Hash passwords with modern algorithms (bcrypt, scrypt, or argon2)</p> <p>\u274c DON'T: - Store passwords in plaintext or reversible encryption - Use simple MD5 or SHA1 for password hashing (deprecated) - Allow authentication without rate limiting - Expose user enumeration via different error messages</p>"},{"location":"developer-guide/security-best-practices/#recommended-improvements","title":"Recommended Improvements","text":"<pre><code># Implement rate limiting on login endpoint\nfrom flask_limiter import Limiter\n\nlimiter = Limiter(app, key_func=lambda: request.remote_addr)\n\n@auth.route('/login', methods=['POST'])\n@limiter.limit(\"5 per minute\")\ndef login():\n    # Login logic\n    pass\n</code></pre>"},{"location":"developer-guide/security-best-practices/#input-validation-sanitization","title":"Input Validation &amp; Sanitization","text":""},{"location":"developer-guide/security-best-practices/#form-validation","title":"Form Validation","text":"<p>Always validate user input using WTForms:</p> <pre><code>from wtforms import StringField, validators\n\nclass CustomerForm(FlaskForm):\n    customer_name = StringField('Name', [\n        validators.DataRequired(),\n        validators.Length(min=2, max=200)\n    ])\n    email = StringField('Email', [\n        validators.Optional(),\n        validators.Email()\n    ])\n    phone = StringField('Phone', [\n        validators.Optional(),\n        validators.Regexp(r'^\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}$')\n    ])\n</code></pre>"},{"location":"developer-guide/security-best-practices/#server-side-validation","title":"Server-Side Validation","text":"<p>Never trust client-side validation alone:</p> <pre><code>@app.route('/customers/new', methods=['POST'])\n@login_required\ndef create_customer():\n    form = CustomerForm()\n\n    # Server-side validation\n    if not form.validate_on_submit():\n        flash('Invalid form data', 'error')\n        return render_template('customers/new.html', form=form)\n\n    # Process validated data\n    customer = Customer(\n        customer_name=form.customer_name.data,\n        email=form.email.data\n    )\n    db.session.add(customer)\n    db.session.commit()\n</code></pre>"},{"location":"developer-guide/security-best-practices/#best-practices_1","title":"Best Practices","text":"<p>\u2705 DO: - Validate all user input on the server-side - Use whitelist validation (allow known good) over blacklist - Sanitize data before storing in database - Validate data types, lengths, and formats - Use parameterized queries (see SQL Injection section)</p> <p>\u274c DON'T: - Trust data from client (including hidden fields, cookies) - Rely only on JavaScript validation - Accept arbitrary HTML from users without sanitization - Allow unrestricted file uploads</p>"},{"location":"developer-guide/security-best-practices/#sql-injection-prevention","title":"SQL Injection Prevention","text":""},{"location":"developer-guide/security-best-practices/#safe-query-patterns","title":"Safe Query Patterns","text":"<p>Use SQLAlchemy ORM (Preferred):</p> <pre><code># \u2705 SAFE: Using ORM\ncustomer = Customer.query.filter_by(customer_name=user_input).first()\n\n# \u2705 SAFE: Parameterized query\ncustomer = Customer.query.filter(\n    Customer.customer_name == user_input\n).first()\n\n# \u274c UNSAFE: String concatenation\nquery = f\"SELECT * FROM customers WHERE name = '{user_input}'\"\ndb.session.execute(query)  # NEVER DO THIS!\n</code></pre> <p>Raw SQL with Parameters:</p> <pre><code># \u2705 SAFE: Using bound parameters\nresult = db.session.execute(\n    text(\"SELECT * FROM customers WHERE customer_name = :name\"),\n    {\"name\": user_input}\n)\n\n# \u274c UNSAFE: String formatting\nquery = text(f\"SELECT * FROM customers WHERE name = '{user_input}'\")\nresult = db.session.execute(query)  # VULNERABLE!\n</code></pre>"},{"location":"developer-guide/security-best-practices/#best-practices_2","title":"Best Practices","text":"<p>\u2705 DO: - Use SQLAlchemy ORM methods for all database operations - Use parameterized queries for raw SQL - Validate and sanitize user input - Use query.filter() instead of string concatenation - Enable query logging in development to spot issues</p> <p>\u274c DON'T: - Build SQL queries with string concatenation - Use Python f-strings or .format() for SQL queries - Trust user input in database queries - Disable SQLAlchemy's built-in protections</p>"},{"location":"developer-guide/security-best-practices/#example-search-functionality","title":"Example: Search Functionality","text":"<pre><code># \u2705 SAFE: Proper search implementation\ndef search_customers(search_term):\n    \"\"\"Search customers by name (SQL injection safe).\"\"\"\n    return Customer.query.filter(\n        Customer.customer_name.ilike(f'%{search_term}%')\n    ).all()\n\n# The ilike() method automatically escapes special characters\n</code></pre>"},{"location":"developer-guide/security-best-practices/#cross-site-scripting-xss","title":"Cross-Site Scripting (XSS)","text":""},{"location":"developer-guide/security-best-practices/#jinja2-auto-escaping","title":"Jinja2 Auto-Escaping","text":"<p>Flask/Jinja2 automatically escapes variables by default:</p> <pre><code>&lt;!-- \u2705 SAFE: Auto-escaped --&gt;\n&lt;p&gt;Customer: {{ customer.customer_name }}&lt;/p&gt;\n\n&lt;!-- \u274c UNSAFE: Manual escaping disabled --&gt;\n&lt;p&gt;Customer: {{ customer.customer_name | safe }}&lt;/p&gt;\n</code></pre>"},{"location":"developer-guide/security-best-practices/#when-to-use-safe","title":"When to Use <code>| safe</code>","text":"<p>Only use <code>| safe</code> for trusted, pre-sanitized HTML:</p> <pre><code># Sanitize user-generated HTML before marking safe\nfrom bleach import clean\n\nallowed_tags = ['b', 'i', 'u', 'p', 'br']\nnotes_html = clean(user_input, tags=allowed_tags, strip=True)\n</code></pre> <pre><code>&lt;!-- Now safe to render --&gt;\n&lt;div class=\"notes\"&gt;{{ notes_html | safe }}&lt;/div&gt;\n</code></pre>"},{"location":"developer-guide/security-best-practices/#best-practices_3","title":"Best Practices","text":"<p>\u2705 DO: - Rely on Jinja2's automatic escaping - Sanitize user input before storing - Use Content Security Policy (CSP) headers - Escape data in JavaScript contexts differently</p> <p>\u274c DON'T: - Use <code>| safe</code> on user-generated content - Concatenate user input into JavaScript - Trust data from external APIs without validation - Disable auto-escaping globally</p>"},{"location":"developer-guide/security-best-practices/#javascript-context-escaping","title":"JavaScript Context Escaping","text":"<pre><code>&lt;!-- \u274c UNSAFE: Direct variable insertion --&gt;\n&lt;script&gt;\nvar customerName = \"{{ customer.customer_name }}\";\n&lt;/script&gt;\n\n&lt;!-- \u2705 SAFE: JSON encoding --&gt;\n&lt;script&gt;\nvar customerData = {{ customer_dict | tojson }};\n&lt;/script&gt;\n</code></pre>"},{"location":"developer-guide/security-best-practices/#cross-site-request-forgery-csrf","title":"Cross-Site Request Forgery (CSRF)","text":""},{"location":"developer-guide/security-best-practices/#csrf-protection","title":"CSRF Protection","text":"<p>The application uses Flask-WTF for CSRF protection.</p> <p>Form Protection: <pre><code>&lt;!-- All forms must include CSRF token --&gt;\n&lt;form method=\"POST\" action=\"/customers/new\"&gt;\n    {{ form.hidden_tag() }}  &lt;!-- Includes CSRF token --&gt;\n    {{ form.customer_name.label }}\n    {{ form.customer_name() }}\n    &lt;button type=\"submit\"&gt;Submit&lt;/button&gt;\n&lt;/form&gt;\n</code></pre></p> <p>AJAX Requests: <pre><code>// Include CSRF token in AJAX requests\n$.ajax({\n    url: '/api/endpoint',\n    method: 'POST',\n    headers: {\n        'X-CSRFToken': $('meta[name=csrf-token]').attr('content')\n    },\n    data: { key: 'value' }\n});\n</code></pre></p> <p>Meta Tag in Base Template: <pre><code>&lt;meta name=\"csrf-token\" content=\"{{ csrf_token() }}\"&gt;\n</code></pre></p>"},{"location":"developer-guide/security-best-practices/#best-practices_4","title":"Best Practices","text":"<p>\u2705 DO: - Enable CSRF protection on all state-changing requests (POST, PUT, DELETE) - Use <code>form.hidden_tag()</code> in all forms - Include CSRF tokens in AJAX requests - Use SameSite cookie attribute</p> <p>\u274c DON'T: - Disable CSRF protection (<code>WTF_CSRF_ENABLED = False</code>) in production - Exclude CSRF tokens from forms - Use GET requests for state-changing operations - Allow CSRF exemptions without careful consideration</p>"},{"location":"developer-guide/security-best-practices/#exempt-endpoints-rare-cases","title":"Exempt Endpoints (Rare Cases)","text":"<pre><code>from flask_wtf.csrf import csrf_exempt\n\n# Only for webhooks or external APIs\n@app.route('/webhook/payment', methods=['POST'])\n@csrf_exempt\ndef payment_webhook():\n    # Verify webhook signature instead\n    signature = request.headers.get('X-Signature')\n    if not verify_signature(signature, request.data):\n        abort(403)\n    # Process webhook\n</code></pre>"},{"location":"developer-guide/security-best-practices/#file-upload-security","title":"File Upload Security","text":""},{"location":"developer-guide/security-best-practices/#current-implementation_1","title":"Current Implementation","text":"<p>File uploads are handled by <code>utils/file_upload.py</code> with S3 storage.</p> <p>Allowed File Types: <pre><code>ALLOWED_EXTENSIONS = {\n    'pdf', 'jpg', 'jpeg', 'png', 'gif',\n    'doc', 'docx', 'xls', 'xlsx'\n}\n\ndef allowed_file(filename):\n    \"\"\"Check if file extension is allowed.\"\"\"\n    return '.' in filename and \\\n           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n</code></pre></p>"},{"location":"developer-guide/security-best-practices/#security-best-practices","title":"Security Best Practices","text":"<p>\u2705 DO: - Validate file extensions (whitelist approach) - Check file size limits (currently 10MB) - Rename uploaded files (prevent path traversal) - Scan files for malware (recommended for production) - Store files outside web root (S3 recommended) - Use Content-Type validation - Generate unique filenames to prevent collisions</p> <p>\u274c DON'T: - Trust client-provided filenames - Allow arbitrary file types - Store files with user-controlled names - Serve files directly from upload directory - Allow double extensions (e.g., <code>file.php.jpg</code>)</p>"},{"location":"developer-guide/security-best-practices/#file-upload-implementation","title":"File Upload Implementation","text":"<pre><code>import uuid\nfrom werkzeug.utils import secure_filename\n\ndef upload_file(file):\n    \"\"\"Secure file upload implementation.\"\"\"\n    # Validate file presence\n    if not file or file.filename == '':\n        raise ValueError(\"No file provided\")\n\n    # Validate file extension\n    if not allowed_file(file.filename):\n        raise ValueError(\"File type not allowed\")\n\n    # Validate file size\n    file.seek(0, os.SEEK_END)\n    file_size = file.tell()\n    file.seek(0)\n\n    if file_size &gt; MAX_UPLOAD_SIZE_BYTES:\n        raise ValueError(f\"File too large (max {MAX_UPLOAD_SIZE_MB}MB)\")\n\n    # Generate secure filename\n    ext = secure_filename(file.filename).rsplit('.', 1)[1].lower()\n    filename = f\"{uuid.uuid4()}.{ext}\"\n\n    # Upload to S3 (isolated from web server)\n    s3_key = f\"uploads/{filename}\"\n    upload_to_s3(file, s3_key)\n\n    return s3_key\n</code></pre>"},{"location":"developer-guide/security-best-practices/#content-type-validation","title":"Content-Type Validation","text":"<pre><code># Verify actual file type matches extension\nimport magic\n\ndef validate_file_type(file_path):\n    \"\"\"Validate file content matches extension.\"\"\"\n    mime = magic.Magic(mime=True)\n    detected_type = mime.from_file(file_path)\n\n    allowed_mimes = {\n        'application/pdf',\n        'image/jpeg',\n        'image/png',\n        # etc.\n    }\n\n    return detected_type in allowed_mimes\n</code></pre>"},{"location":"developer-guide/security-best-practices/#session-management","title":"Session Management","text":""},{"location":"developer-guide/security-best-practices/#session-configuration","title":"Session Configuration","text":"<p>Current settings in <code>config.py</code>: <pre><code>PERMANENT_SESSION_LIFETIME = timedelta(hours=24)\nSESSION_COOKIE_SECURE = FLASK_ENV == \"production\"  # HTTPS only\nSESSION_COOKIE_HTTPONLY = True  # No JavaScript access\nSESSION_COOKIE_SAMESITE = 'Lax'  # CSRF protection\n</code></pre></p>"},{"location":"developer-guide/security-best-practices/#best-practices_5","title":"Best Practices","text":"<p>\u2705 DO: - Set <code>SESSION_COOKIE_SECURE = True</code> in production (HTTPS) - Use <code>SESSION_COOKIE_HTTPONLY = True</code> (prevent XSS) - Set <code>SESSION_COOKIE_SAMESITE = 'Lax'</code> or 'Strict' - Implement session timeout - Regenerate session ID after login - Use secure session storage (server-side recommended)</p> <p>\u274c DON'T: - Store sensitive data in client-side sessions - Use predictable session IDs - Allow indefinite session lifetime - Disable HTTPOnly or Secure flags in production</p>"},{"location":"developer-guide/security-best-practices/#improved-session-security","title":"Improved Session Security","text":"<pre><code>from flask import session\nfrom datetime import datetime\n\n@auth.route('/login', methods=['POST'])\ndef login():\n    user = authenticate(username, password)\n    if user:\n        # Regenerate session ID (prevent session fixation)\n        session.clear()\n        session.regenerate()\n\n        login_user(user)\n        session['login_time'] = datetime.utcnow()\n        session.permanent = True  # Respect PERMANENT_SESSION_LIFETIME\n\n        return redirect(url_for('dashboard.index'))\n</code></pre>"},{"location":"developer-guide/security-best-practices/#environment-variables-secrets","title":"Environment Variables &amp; Secrets","text":""},{"location":"developer-guide/security-best-practices/#current-issues","title":"Current Issues \u26a0\ufe0f","text":"<p>CRITICAL: The following secrets are currently hardcoded in <code>.ebextensions/01_flask.config</code>:</p> <ul> <li>Database credentials</li> <li>AWS access keys</li> <li>S3 bucket names</li> <li>SECRET_KEY</li> </ul>"},{"location":"developer-guide/security-best-practices/#recommended-approach","title":"Recommended Approach","text":"<p>Use AWS Elastic Beanstalk environment properties:</p> <pre><code># Set via EB CLI\neb setenv \\\n    SECRET_KEY=\"randomly-generated-secret\" \\\n    DATABASE_URL=\"postgresql://user:pass@host:port/db\" \\\n    AWS_ACCESS_KEY_ID=\"xxx\" \\\n    AWS_SECRET_ACCESS_KEY=\"yyy\" \\\n    AWS_S3_BUCKET=\"bucket-name\"\n\n# Verify\neb printenv\n</code></pre> <p>Or use AWS Secrets Manager (best for production):</p> <pre><code>import boto3\nimport json\n\ndef get_secret(secret_name):\n    \"\"\"Retrieve secret from AWS Secrets Manager.\"\"\"\n    client = boto3.client('secretsmanager', region_name='us-east-1')\n    response = client.get_secret_value(SecretId=secret_name)\n    return json.loads(response['SecretString'])\n\n# In config.py\nsecrets = get_secret('awning-wo-prod-secrets')\nSECRET_KEY = secrets['SECRET_KEY']\nDATABASE_URL = secrets['DATABASE_URL']\n</code></pre>"},{"location":"developer-guide/security-best-practices/#best-practices_6","title":"Best Practices","text":"<p>\u2705 DO: - Store secrets in environment variables or secret managers - Use different secrets for dev/staging/production - Rotate secrets regularly - Use strong, randomly generated secrets - Add <code>.env</code> to <code>.gitignore</code> - Use AWS Systems Manager Parameter Store or Secrets Manager</p> <p>\u274c DON'T: - Commit secrets to version control - Hardcode secrets in source code - Share secrets via email or chat - Use default or weak secrets - Reuse secrets across environments</p>"},{"location":"developer-guide/security-best-practices/#generate-strong-secrets","title":"Generate Strong Secrets","text":"<pre><code>import secrets\n\n# Generate secure random SECRET_KEY\nprint(secrets.token_urlsafe(32))\n# Output: 'xYz123...' (use this for SECRET_KEY)\n\n# Generate CRON_SECRET for ML retraining\nprint(secrets.token_hex(16))\n</code></pre>"},{"location":"developer-guide/security-best-practices/#database-security","title":"Database Security","text":""},{"location":"developer-guide/security-best-practices/#connection-security","title":"Connection Security","text":"<p>Use SSL/TLS for database connections:</p> <pre><code>SQLALCHEMY_ENGINE_OPTIONS = {\n    'connect_args': {\n        'sslmode': 'require',  # Force SSL\n        'connect_timeout': 10\n    },\n    'pool_pre_ping': True,\n    'pool_recycle': 300,\n}\n</code></pre>"},{"location":"developer-guide/security-best-practices/#query-security","title":"Query Security","text":"<p>See SQL Injection Prevention section.</p>"},{"location":"developer-guide/security-best-practices/#backup-recovery","title":"Backup &amp; Recovery","text":"<p>Recommendations: - Enable automated RDS backups (retain 7-30 days) - Test backup restoration regularly - Use encrypted backups (AWS KMS) - Implement point-in-time recovery - Store backups in separate AWS region</p>"},{"location":"developer-guide/security-best-practices/#best-practices_7","title":"Best Practices","text":"<p>\u2705 DO: - Use connection pooling (<code>pool_size</code>, <code>max_overflow</code>) - Enable SSL/TLS for database connections - Use read replicas for analytics queries - Implement database connection retry logic - Monitor slow queries and optimize - Use parameterized queries exclusively</p> <p>\u274c DON'T: - Store database credentials in code - Allow public database access (use VPC) - Disable SSL/TLS in production - Use overly permissive database user privileges - Log sensitive data (passwords, credit cards)</p>"},{"location":"developer-guide/security-best-practices/#api-security","title":"API Security","text":""},{"location":"developer-guide/security-best-practices/#rate-limiting","title":"Rate Limiting","text":"<p>Implement rate limiting for API endpoints:</p> <pre><code>from flask_limiter import Limiter\nfrom flask_limiter.util import get_remote_address\n\nlimiter = Limiter(\n    app,\n    key_func=get_remote_address,\n    default_limits=[\"200 per day\", \"50 per hour\"]\n)\n\n@app.route('/api/work_orders')\n@limiter.limit(\"10 per minute\")\n@login_required\ndef api_work_orders():\n    return jsonify(work_orders)\n</code></pre>"},{"location":"developer-guide/security-best-practices/#api-authentication","title":"API Authentication","text":"<p>For future API development, consider: - API keys for external integrations - OAuth2 for third-party access - JWT tokens for stateless authentication - Separate API versioning (<code>/api/v1/</code>)</p>"},{"location":"developer-guide/security-best-practices/#best-practices_8","title":"Best Practices","text":"<p>\u2705 DO: - Require authentication for all API endpoints - Implement rate limiting - Validate and sanitize all input - Return appropriate HTTP status codes - Use HTTPS exclusively for API calls - Log API access for auditing</p> <p>\u274c DON'T: - Expose internal error details in API responses - Allow unlimited API calls - Return sensitive data without proper authorization - Use GET requests for state-changing operations</p>"},{"location":"developer-guide/security-best-practices/#logging-monitoring","title":"Logging &amp; Monitoring","text":""},{"location":"developer-guide/security-best-practices/#logging-best-practices","title":"Logging Best Practices","text":"<p>What to log: - Authentication attempts (success and failure) - Authorization failures - Input validation failures - Application errors and exceptions - File uploads/downloads - Database errors - API calls</p> <p>What NOT to log: - Passwords (plaintext or hashed) - Credit card numbers - Session tokens - API keys or secrets</p>"},{"location":"developer-guide/security-best-practices/#implementation","title":"Implementation","text":"<pre><code>import logging\nfrom flask import request\n\n# Configure logging\nlogging.basicConfig(\n    filename='app.log',\n    level=logging.INFO,\n    format='%(asctime)s %(levelname)s: %(message)s'\n)\n\n# Log authentication\n@auth.route('/login', methods=['POST'])\ndef login():\n    username = request.form.get('username')\n    if user and user.check_password(password):\n        logging.info(f\"Successful login: {username} from {request.remote_addr}\")\n        login_user(user)\n    else:\n        logging.warning(f\"Failed login attempt: {username} from {request.remote_addr}\")\n</code></pre>"},{"location":"developer-guide/security-best-practices/#monitoring","title":"Monitoring","text":"<p>Use AWS CloudWatch for: - Application logs - Database performance metrics - Error rates and alerts - Custom business metrics</p> <p>Set up alerts for: - Failed login attempts (&gt; 10 per minute) - 500 errors (&gt; 5 per hour) - Database connection failures - Disk space usage (&gt; 80%) - High CPU/memory usage</p>"},{"location":"developer-guide/security-best-practices/#dependencies-updates","title":"Dependencies &amp; Updates","text":""},{"location":"developer-guide/security-best-practices/#dependency-management","title":"Dependency Management","text":"<p>Keep dependencies up-to-date:</p> <pre><code># Check for outdated packages\npip list --outdated\n\n# Update specific package\npip install --upgrade flask\n\n# Update all dependencies\npip install --upgrade -r requirements.txt\n\n# Check for security vulnerabilities\npip-audit\n</code></pre>"},{"location":"developer-guide/security-best-practices/#security-scanning","title":"Security Scanning","text":"<p>Use automated tools: <pre><code># Install safety\npip install safety\n\n# Scan for known vulnerabilities\nsafety check\n\n# Example output:\n# -&gt; flask 2.0.0 has known security vulnerabilities\n#    Update to flask &gt;= 2.0.3\n</code></pre></p>"},{"location":"developer-guide/security-best-practices/#best-practices_9","title":"Best Practices","text":"<p>\u2705 DO: - Regularly update dependencies (monthly) - Review security advisories for your dependencies - Pin dependency versions in <code>requirements.txt</code> - Test updates in staging before production - Use <code>pip-audit</code> or <code>safety</code> for vulnerability scanning - Subscribe to security mailing lists for frameworks</p> <p>\u274c DON'T: - Use outdated dependencies with known vulnerabilities - Update all dependencies blindly without testing - Ignore security advisories - Use unmaintained packages</p>"},{"location":"developer-guide/security-best-practices/#dependency-pinning","title":"Dependency Pinning","text":"<pre><code># requirements.txt\n# Pin exact versions for reproducibility\nFlask==2.3.3\nSQLAlchemy==2.0.21\nFlask-Login==0.6.2\n\n# Allow patch updates (safer)\nFlask&gt;=2.3.3,&lt;2.4.0\n</code></pre>"},{"location":"developer-guide/security-best-practices/#security-checklist","title":"Security Checklist","text":""},{"location":"developer-guide/security-best-practices/#development","title":"Development","text":"<ul> <li>[ ] All routes have authentication checks (<code>@login_required</code>)</li> <li>[ ] Admin routes use <code>@role_required('admin')</code></li> <li>[ ] All forms include CSRF tokens</li> <li>[ ] User input is validated server-side</li> <li>[ ] Database queries use ORM or parameterized queries</li> <li>[ ] File uploads validate type and size</li> <li>[ ] Passwords are hashed (never stored plaintext)</li> <li>[ ] Secrets are not committed to git</li> </ul>"},{"location":"developer-guide/security-best-practices/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li>[ ] Environment variables configured (not hardcoded)</li> <li>[ ] <code>SECRET_KEY</code> is strong and random</li> <li>[ ] <code>SESSION_COOKIE_SECURE = True</code> (HTTPS)</li> <li>[ ] Database uses SSL/TLS connection</li> <li>[ ] S3 bucket has proper permissions</li> <li>[ ] CSRF protection enabled (<code>WTF_CSRF_ENABLED = True</code>)</li> <li>[ ] Dependencies scanned for vulnerabilities</li> <li>[ ] Logging configured (no sensitive data logged)</li> <li>[ ] Error pages don't expose internal details</li> </ul>"},{"location":"developer-guide/security-best-practices/#production","title":"Production","text":"<ul> <li>[ ] AWS credentials moved to environment variables</li> <li>[ ] Database credentials use Secrets Manager</li> <li>[ ] RDS backups enabled and tested</li> <li>[ ] CloudWatch alarms configured</li> <li>[ ] Security group rules follow least privilege</li> <li>[ ] HTTPS enforced (no HTTP allowed)</li> <li>[ ] Rate limiting enabled on auth endpoints</li> <li>[ ] Session timeout configured</li> <li>[ ] Regular security updates scheduled</li> </ul>"},{"location":"developer-guide/security-best-practices/#common-vulnerabilities-owasp-top-10","title":"Common Vulnerabilities (OWASP Top 10)","text":""},{"location":"developer-guide/security-best-practices/#1-injection-sql-os-command","title":"1. Injection (SQL, OS Command)","text":"<p>Status: \u2705 Protected (SQLAlchemy ORM) Recommendation: Continue using ORM; avoid raw SQL</p>"},{"location":"developer-guide/security-best-practices/#2-broken-authentication","title":"2. Broken Authentication","text":"<p>Status: \u26a0\ufe0f Needs improvement Recommendation: Add rate limiting, account lockout, MFA</p>"},{"location":"developer-guide/security-best-practices/#3-sensitive-data-exposure","title":"3. Sensitive Data Exposure","text":"<p>Status: \u26a0\ufe0f Needs improvement Recommendation: Move secrets to AWS Secrets Manager; enable RDS encryption</p>"},{"location":"developer-guide/security-best-practices/#4-xml-external-entities-xxe","title":"4. XML External Entities (XXE)","text":"<p>Status: \u2705 N/A (no XML parsing)</p>"},{"location":"developer-guide/security-best-practices/#5-broken-access-control","title":"5. Broken Access Control","text":"<p>Status: \u26a0\ufe0f Needs audit Recommendation: Review all routes for proper authorization checks</p>"},{"location":"developer-guide/security-best-practices/#6-security-misconfiguration","title":"6. Security Misconfiguration","text":"<p>Status: \u26a0\ufe0f Critical Recommendation: Remove hardcoded credentials from <code>.ebextensions/</code></p>"},{"location":"developer-guide/security-best-practices/#7-cross-site-scripting-xss","title":"7. Cross-Site Scripting (XSS)","text":"<p>Status: \u2705 Protected (Jinja2 auto-escaping) Recommendation: Audit use of <code>| safe</code> filter</p>"},{"location":"developer-guide/security-best-practices/#8-insecure-deserialization","title":"8. Insecure Deserialization","text":"<p>Status: \u2705 N/A (no deserialization of untrusted data)</p>"},{"location":"developer-guide/security-best-practices/#9-using-components-with-known-vulnerabilities","title":"9. Using Components with Known Vulnerabilities","text":"<p>Status: \u26a0\ufe0f Needs monitoring Recommendation: Set up automated dependency scanning</p>"},{"location":"developer-guide/security-best-practices/#10-insufficient-logging-monitoring","title":"10. Insufficient Logging &amp; Monitoring","text":"<p>Status: \u26a0\ufe0f Needs improvement Recommendation: Enhance logging; set up CloudWatch alarms</p>"},{"location":"developer-guide/security-best-practices/#security-contacts","title":"Security Contacts","text":"<p>Report Security Issues: - Email: security@yourdomain.com - GitHub: Private security advisory - Do NOT open public issues for security vulnerabilities</p> <p>Security Review Schedule: - Quarterly dependency audits - Annual penetration testing - Monthly security patch reviews</p>"},{"location":"developer-guide/security-best-practices/#additional-resources","title":"Additional Resources","text":"<ul> <li>OWASP Top 10</li> <li>Flask Security Considerations</li> <li>SQLAlchemy Security</li> <li>AWS Security Best Practices</li> <li>Python Security Guide</li> </ul>"},{"location":"developer-guide/setup/","title":"Setup &amp; Installation","text":""},{"location":"developer-guide/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>PostgreSQL 12 or higher</li> <li>Git</li> <li>pip and virtualenv</li> </ul>"},{"location":"developer-guide/setup/#local-development-setup","title":"Local Development Setup","text":""},{"location":"developer-guide/setup/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/andrewimpellitteri/awning_wo.git\ncd awning_wo\n</code></pre>"},{"location":"developer-guide/setup/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre>"},{"location":"developer-guide/setup/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"developer-guide/setup/#4-set-up-database","title":"4. Set Up Database","text":"<p>Create a PostgreSQL database:</p> <pre><code>createdb clean_repair\n</code></pre>"},{"location":"developer-guide/setup/#5-configure-environment-variables","title":"5. Configure Environment Variables","text":"<p>Create a <code>.env</code> file:</p> <pre><code>FLASK_ENV=development\nFLASK_DEBUG=true\nSECRET_KEY=your-secret-key-here\nDATABASE_URL=postgresql://postgres:password@localhost:5432/clean_repair\n</code></pre>"},{"location":"developer-guide/setup/#6-run-migrations","title":"6. Run Migrations","text":"<pre><code>./alembic_db.sh prod upgrade head\n</code></pre>"},{"location":"developer-guide/setup/#7-run-the-application","title":"7. Run the Application","text":"<pre><code>python app.py\n</code></pre> <p>Visit <code>http://localhost:5000</code> in your browser.</p>"},{"location":"developer-guide/setup/#running-tests","title":"Running Tests","text":"<pre><code>pytest\npytest --cov=. --cov-report=html  # With coverage\n</code></pre>"},{"location":"developer-guide/setup/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Project Structure guide</li> <li>Review the Database Schema</li> <li>Check out Testing to write tests</li> </ul>"},{"location":"developer-guide/template-refactoring-plan/","title":"Template Unification Refactoring Plan","text":""},{"location":"developer-guide/template-refactoring-plan/#overview","title":"Overview","text":"<p>This document outlines the plan to unify the UI between Work Orders and Repair Orders, following DRY principles and ensuring consistent user experience.</p>"},{"location":"developer-guide/template-refactoring-plan/#current-state","title":"Current State","text":""},{"location":"developer-guide/template-refactoring-plan/#work-orders","title":"Work Orders","text":"<ul> <li>create.html: 1,212 lines - Modern card-based UI</li> <li>edit.html: 1,110 lines - Similar to create</li> <li>Features:</li> <li>Card-style new item layout</li> <li>Sophisticated file upload with drag-and-drop</li> <li>Customer inventory selection with modern UI</li> <li>Comprehensive field organization</li> <li>Inline JavaScript (~700 lines)</li> </ul>"},{"location":"developer-guide/template-refactoring-plan/#repair-orders","title":"Repair Orders","text":"<ul> <li>create.html: 852 lines - Table-based UI</li> <li>edit.html: 945 lines - Similar to create</li> <li>Features:</li> <li>Table-based item layout (less user-friendly)</li> <li>Basic file upload</li> <li>Customer inventory selection (similar to work orders)</li> <li>Inline JavaScript (~400 lines)</li> </ul>"},{"location":"developer-guide/template-refactoring-plan/#completed-work","title":"Completed Work","text":""},{"location":"developer-guide/template-refactoring-plan/#1-shared-components-created","title":"1. Shared Components Created","text":"<ul> <li>\u2705 templates/_order_macros.html - Reusable Jinja2 macros</li> <li><code>customer_inventory_section()</code> - Customer item history</li> <li><code>file_upload_section()</code> - File upload with drag-and-drop</li> <li><code>new_items_section_cards()</code> - Modern card-style item layout</li> <li> <p><code>order_summary_sidebar()</code> - Order summary with counters</p> </li> <li> <p>\u2705 static/js/order-form-shared.js - Centralized JavaScript (~450 lines)</p> </li> <li>Inventory management functions</li> <li>Item CRUD operations (add/remove)</li> <li>File upload handling with validation</li> <li>Counter updates and UI state management</li> <li>Autocomplete datalist creation</li> </ul>"},{"location":"developer-guide/template-refactoring-plan/#2-backend-refactoring","title":"2. Backend Refactoring","text":"<ul> <li>\u2705 Work order routes refactored with private helper functions</li> <li>\u2705 Repair order routes refactored with private helper functions</li> <li>\u2705 Both follow same clean pattern</li> </ul>"},{"location":"developer-guide/template-refactoring-plan/#refactoring-strategy","title":"Refactoring Strategy","text":""},{"location":"developer-guide/template-refactoring-plan/#phase-1-update-repair-order-templates-priority","title":"Phase 1: Update Repair Order Templates (Priority)","text":"<p>Replace table-based layout with modern card-based layout to match work orders.</p> <p>Files to modify: 1. <code>templates/repair_orders/create.html</code> 2. <code>templates/repair_orders/edit.html</code></p> <p>Changes: 1. Import <code>_order_macros.html</code> at top 2. Replace \"Add New Items\" table section with <code>new_items_section_cards()</code> macro 3. Replace inline customer inventory code with <code>customer_inventory_section()</code> macro 4. Replace inline file upload code with <code>file_upload_section()</code> macro 5. Replace inline order summary with <code>order_summary_sidebar()</code> macro 6. Include <code>order-form-shared.js</code> script 7. Add repair-order-specific JavaScript only (minimal) 8. Remove duplicate JavaScript code</p> <p>Expected reduction: ~400 lines per file (~800 lines total)</p>"},{"location":"developer-guide/template-refactoring-plan/#phase-2-update-work-order-templates","title":"Phase 2: Update Work Order Templates","text":"<p>Refactor to use shared components and remove duplication.</p> <p>Files to modify: 1. <code>templates/work_orders/create.html</code> 2. <code>templates/work_orders/edit.html</code></p> <p>Changes: 1. Import <code>_order_macros.html</code> at top 2. Replace inline sections with macros (same as repair orders) 3. Include <code>order-form-shared.js</code> script 4. Add work-order-specific JavaScript only (e.g., RepairsNeeded logic, SeeRepair field) 5. Remove duplicate JavaScript code</p> <p>Expected reduction: ~700 lines per file (~1,400 lines total)</p>"},{"location":"developer-guide/template-refactoring-plan/#phase-3-testing","title":"Phase 3: Testing","text":"<p>Test all functionality in both work orders and repair orders: - \u2705 Customer selection and inventory loading - \u2705 Item selection from inventory - \u2705 Adding new items (card-based UI) - \u2705 Removing items - \u2705 File upload (drag-and-drop and click) - \u2705 File removal - \u2705 Form validation - \u2705 Form submission - \u2705 Counter updates - \u2705 Rush order badges</p>"},{"location":"developer-guide/template-refactoring-plan/#specific-template-structure","title":"Specific Template Structure","text":""},{"location":"developer-guide/template-refactoring-plan/#proposed-repair-order-create-template-structure","title":"Proposed Repair Order Create Template Structure","text":"<pre><code>{% extends \"base.html\" %}\n{% from \"_order_macros.html\" import\n    customer_inventory_section,\n    file_upload_section,\n    new_items_section_cards,\n    order_summary_sidebar\n%}\n\n{% block title %}Create New Repair Work Order{% endblock %}\n\n{% block styles %}\n{{ super() }}\n&lt;!-- Any repair-order-specific styles --&gt;\n{% endblock %}\n\n{% block content %}\n&lt;div class=\"container-fluid\"&gt;\n    &lt;form method=\"POST\" id=\"repairOrderForm\" enctype=\"multipart/form-data\"&gt;\n        &lt;div class=\"row\"&gt;\n            &lt;div class=\"col-lg-8\"&gt;\n                &lt;!-- Order Information Card --&gt;\n                &lt;!-- (repair-order-specific fields) --&gt;\n\n                &lt;!-- Repair Details Card --&gt;\n                &lt;!-- (repair-order-specific fields) --&gt;\n\n                &lt;!-- Customer Inventory - SHARED MACRO --&gt;\n                {{ customer_inventory_section() }}\n\n                &lt;!-- New Items - SHARED MACRO --&gt;\n                {{ new_items_section_cards(title=\"Add New Items\") }}\n\n                &lt;!-- File Upload - SHARED MACRO --&gt;\n                {{ file_upload_section() }}\n            &lt;/div&gt;\n\n            &lt;div class=\"col-lg-4\"&gt;\n                &lt;!-- Quote &amp; Pricing Card --&gt;\n                &lt;!-- (repair-order-specific) --&gt;\n\n                &lt;!-- Order Summary - SHARED MACRO --&gt;\n                {{ order_summary_sidebar() }}\n\n                &lt;!-- Actions Card --&gt;\n                &lt;!-- (form buttons) --&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/form&gt;\n&lt;/div&gt;\n{% endblock %}\n\n{% block scripts %}\n{{ super() }}\n&lt;!-- Include shared JavaScript --&gt;\n&lt;script src=\"{{ url_for('static', filename='js/order-form-shared.js') }}\"&gt;&lt;/script&gt;\n\n&lt;!-- Repair-order-specific initialization --&gt;\n&lt;script&gt;\ndocument.addEventListener('DOMContentLoaded', function() {\n    // Initialize shared components\n    createDatalists();\n    initializeFileUpload();\n\n    // Load next repair order number\n    fetch('/repair_work_orders/api/next_ro_number')\n        .then(response =&gt; response.json())\n        .then(data =&gt; {\n            document.getElementById('next_ro_number').value = data.next_ro_number;\n            document.getElementById('ro-number-display').textContent = `RO-${data.next_ro_number}`;\n        });\n\n    // Customer change handler\n    document.getElementById('CustID').addEventListener('change', function() {\n        loadCustomerInventory(this.value);\n        // Load customer source\n        fetch(`/customers/api/customer/${this.value}`)\n            .then(response =&gt; response.json())\n            .then(customer =&gt; {\n                document.getElementById('SOURCE').value = customer.Source || '';\n            });\n    });\n\n    // Rush order change handlers\n    document.getElementById('RushOrder').addEventListener('change', updateRushStatus);\n    document.getElementById('FirmRush').addEventListener('change', updateRushStatus);\n\n    // Initialize counts\n    updateCounts();\n});\n&lt;/script&gt;\n{% endblock %}\n</code></pre>"},{"location":"developer-guide/template-refactoring-plan/#benefits","title":"Benefits","text":"<ol> <li>Code Reduction: ~2,200 lines removed across 4 templates</li> <li>Consistency: Identical UI/UX between work orders and repair orders</li> <li>Maintainability: Single source of truth for common components</li> <li>DRY Principle: No duplicate code</li> <li>Modern UI: Card-based layout everywhere (better UX)</li> <li>Easier Updates: Change once, applies everywhere</li> </ol>"},{"location":"developer-guide/template-refactoring-plan/#risks-mitigations","title":"Risks &amp; Mitigations","text":"Risk Mitigation Breaking existing functionality Comprehensive testing after each template Form field names mismatch Careful review of backend expectations JavaScript conflicts Proper namespace management CSS styling issues Test in actual browser"},{"location":"developer-guide/template-refactoring-plan/#implementation-order","title":"Implementation Order","text":"<ol> <li>Repair Orders First - They need the most improvement</li> <li>create.html (estimated 2 hours)</li> <li>edit.html (estimated 2 hours)</li> <li> <p>Testing (1 hour)</p> </li> <li> <p>Work Orders Second - They're already good, just DRY them</p> </li> <li>create.html (estimated 1.5 hours)</li> <li>edit.html (estimated 1.5 hours)</li> <li> <p>Testing (1 hour)</p> </li> <li> <p>Integration Testing - Full end-to-end</p> </li> <li>Create work order flow</li> <li>Edit work order flow</li> <li>Create repair order flow</li> <li>Edit repair order flow</li> <li>File uploads</li> <li>Form validation</li> </ol>"},{"location":"developer-guide/template-refactoring-plan/#next-steps","title":"Next Steps","text":"<p>Option A: Full Automated Refactoring - I proceed with refactoring all 4 templates - Run tests after each template - Create git commits for each phase</p> <p>Option B: Incremental Refactoring - Start with <code>repair_orders/create.html</code> only - Test thoroughly - Get approval before proceeding to next template</p> <p>Option C: Manual Review First - I provide detailed diffs for one template - You review and approve approach - Then I proceed with remaining templates</p> <p>Which approach would you prefer?</p>"},{"location":"developer-guide/template-refactoring-summary/","title":"Template Unification Refactoring Summary","text":""},{"location":"developer-guide/template-refactoring-summary/#status-complete","title":"Status: COMPLETE \u2705","text":"<p>All work order and repair order templates have been successfully refactored to use shared components!</p>"},{"location":"developer-guide/template-refactoring-summary/#overview","title":"Overview","text":"<p>Successfully unified the UI between Work Orders and Repair Orders, implementing DRY principles and ensuring consistent user experience across both modules.</p>"},{"location":"developer-guide/template-refactoring-summary/#completed-work","title":"Completed Work","text":""},{"location":"developer-guide/template-refactoring-summary/#1-shared-components-created","title":"1. Shared Components Created","text":""},{"location":"developer-guide/template-refactoring-summary/#a-template-macros-templates_order_macroshtml","title":"A. Template Macros (templates/_order_macros.html)","text":"<p>Created reusable Jinja2 macros (126 lines): - <code>customer_inventory_section()</code> - Customer item history from previous orders - <code>file_upload_section()</code> - File upload with drag-and-drop functionality - <code>new_items_section_cards()</code> - Modern card-style new item layout - <code>order_summary_sidebar()</code> - Order summary with item counters and rush badges</p>"},{"location":"developer-guide/template-refactoring-summary/#b-shared-javascript-staticjsorder-form-sharedjs","title":"B. Shared JavaScript (static/js/order-form-shared.js)","text":"<p>Centralized common functionality (463 lines): - Inventory Management: <code>loadCustomerInventory()</code>, <code>toggleItem()</code> - Item Management: <code>addNewItem()</code>, <code>removeNewItem()</code> - File Upload: <code>initializeFileUpload()</code>, drag-and-drop, validation - UI Updates: <code>updateCounts()</code>, <code>updateRushStatus()</code>, <code>updateInventoryCount()</code> - Utilities: <code>formatPrice()</code>, <code>formatFileSize()</code>, <code>createDatalists()</code> - Validation: File type and size validation</p>"},{"location":"developer-guide/template-refactoring-summary/#2-backend-refactoring-previously-completed","title":"2. Backend Refactoring (Previously Completed)","text":"<ul> <li>\u2705 Work order routes refactored with private helper functions</li> <li>\u2705 Repair order routes refactored with private helper functions</li> <li>\u2705 Both follow same clean pattern with minimal nesting</li> </ul>"},{"location":"developer-guide/template-refactoring-summary/#3-repair-order-templates-refactored","title":"3. Repair Order Templates Refactored","text":""},{"location":"developer-guide/template-refactoring-summary/#a-create-template","title":"A. Create Template","text":"<p>File: templates/repair_orders/create.html - Old: 852 lines (table-based item layout) - New: 474 lines (card-based modern UI) - Reduction: 378 lines (44% reduction) - Changes:   - Replaced table-based \"Add Items\" section with card-style layout   - Integrated shared macros for inventory, file upload, and summary   - Moved JavaScript to shared file   - Added modern UI elements (icons, input groups, better spacing)   - Improved form validation</p>"},{"location":"developer-guide/template-refactoring-summary/#b-edit-template","title":"B. Edit Template","text":"<p>File: templates/repair_orders/edit.html - Old: 945 lines (table-based item layout) - New: 574 lines (card-based modern UI) - Reduction: 371 lines (39% reduction) - Changes:   - Converted existing items to card-style layout (matches new items)   - Integrated shared macros   - Moved JavaScript to shared file   - Improved item management UI (add/remove items)   - Better visual distinction between existing and new items</p>"},{"location":"developer-guide/template-refactoring-summary/#4-work-order-templates-refactored","title":"4. Work Order Templates Refactored","text":""},{"location":"developer-guide/template-refactoring-summary/#a-create-template_1","title":"A. Create Template","text":"<p>File: templates/work_orders/create.html - Old: 1,212 lines (inline JavaScript and duplicate components) - New: 456 lines (shared components) - Reduction: 756 lines (62% reduction) - Changes:   - Integrated shared macros for inventory, file upload, and summary   - Moved all common JavaScript to shared file   - Retained work-order-specific features (RepairsNeeded, SeeRepair)   - Cleaner, more maintainable code structure</p>"},{"location":"developer-guide/template-refactoring-summary/#b-edit-template_1","title":"B. Edit Template","text":"<p>File: templates/work_orders/edit.html - Old: 1,110 lines (inline JavaScript and duplicate components) - New: 555 lines (shared components) - Reduction: 555 lines (50% reduction) - Changes:   - Integrated shared macros   - Moved all common JavaScript to shared file   - Retained work-order-specific existing item handling   - Improved code organization and readability</p>"},{"location":"developer-guide/template-refactoring-summary/#results","title":"Results","text":""},{"location":"developer-guide/template-refactoring-summary/#code-metrics","title":"Code Metrics","text":"Metric Before After Reduction Work Orders Work Order Create 1,212 lines 456 lines 756 lines (62%) Work Order Edit 1,110 lines 555 lines 555 lines (50%) Work Order Subtotal 2,322 lines 1,011 lines 1,311 lines (56%) Repair Orders Repair Order Create 852 lines 474 lines 378 lines (44%) Repair Order Edit 945 lines 574 lines 371 lines (39%) Repair Order Subtotal 1,797 lines 1,048 lines 749 lines (42%) Shared Components _order_macros.html 0 lines 126 lines N/A order-form-shared.js 0 lines 463 lines N/A Shared Subtotal 0 lines 589 lines N/A Grand Total 4,119 lines 2,648 lines 1,471 lines (36%)"},{"location":"developer-guide/template-refactoring-summary/#uiux-improvements","title":"UI/UX Improvements","text":"<p>\u2705 Unified Experience: Repair orders now match work orders' modern UI \u2705 Card-Based Layout: Better visual organization and user-friendly \u2705 Consistent Styling: Same icons, colors, spacing across all forms \u2705 Better File Upload: Drag-and-drop with visual feedback \u2705 Improved Validation: Better error messages and form validation \u2705 Responsive Design: Better mobile/tablet experience</p>"},{"location":"developer-guide/template-refactoring-summary/#code-quality-improvements","title":"Code Quality Improvements","text":"<p>\u2705 DRY Principle: No duplicate code between work orders and repair orders \u2705 Maintainability: Single source of truth for common components \u2705 Testability: All 67 tests pass (41 work order + 26 repair order) \u2705 Scalability: Easy to add new order types using same components \u2705 Consistency: Same patterns and conventions throughout</p>"},{"location":"developer-guide/template-refactoring-summary/#testing","title":"Testing","text":""},{"location":"developer-guide/template-refactoring-summary/#combined-test-results","title":"Combined Test Results","text":"<p>All 67 tests passing: <pre><code>$ python -m pytest test/test_work_orders_routes.py test/test_repair_orders_routes.py -v --tb=no -q\n============================= test session starts ==============================\ncollected 67 items\n\ntest/test_work_orders_routes.py ........................................ [ 59%]\n.                                                                        [ 61%]\ntest/test_repair_orders_routes.py ..........................             [100%]\n\n======================= 67 passed in 26.21s =======================\n</code></pre></p>"},{"location":"developer-guide/template-refactoring-summary/#repair-order-tests","title":"Repair Order Tests","text":"<p>All 26 tests passing: <pre><code>$ python -m pytest test/test_repair_orders_routes.py -v --tb=no\n============================= test session starts ==============================\ncollected 26 items\n\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_repair_orders_list_page_renders PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_repair_orders_api_endpoint_works PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_filter_by_status PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_filter_by_global_search PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_filter_by_repair_order_no PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_filter_by_cust_id PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_filter_by_ro_name PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_filter_by_source PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_sort_by_repair_order_no PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_pagination PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_view_repair_order_detail PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_view_missing_repair_order_detail PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_view_repair_order_detail_includes_items PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_update_repair_item PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_add_repair_item_on_edit PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_delete_repair_item_on_edit PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_generate_repair_order_pdf PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_create_repair_order_page_renders PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_create_repair_order PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_create_repair_order_invalid_data PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_edit_repair_order_page_renders PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_update_repair_order PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_update_repair_order_invalid_data PASSED\ntest_repair_orders_routes.py::TestRepairOrderRoutes::test_delete_repair_order PASSED\ntest_repair_orders_routes.py::TestRepairOrderDateSorting::test_sort_by_date PASSED\ntest_repair_orders_routes.py::TestRepairOrderDateSorting::test_delete_missing_repair_order PASSED\n\n============================== 26 passed in 12.31s ===============================\n</code></pre></p>"},{"location":"developer-guide/template-refactoring-summary/#file-structure","title":"File Structure","text":""},{"location":"developer-guide/template-refactoring-summary/#new-files","title":"New Files","text":"<pre><code>templates/\n\u251c\u2500\u2500 _order_macros.html          # Shared Jinja2 macros (126 lines)\n\u2514\u2500\u2500 repair_orders/\n    \u251c\u2500\u2500 create.html             # Refactored (474 lines)\n    \u251c\u2500\u2500 edit.html               # Refactored (574 lines)\n    \u251c\u2500\u2500 create.html.old         # Backup (852 lines)\n    \u2514\u2500\u2500 edit.html.old           # Backup (945 lines)\n\nstatic/js/\n\u2514\u2500\u2500 order-form-shared.js        # Shared JavaScript (463 lines)\n</code></pre>"},{"location":"developer-guide/template-refactoring-summary/#backup-files","title":"Backup Files","text":"<p>Original templates backed up with <code>.old</code> or <code>.backup</code> extension: - <code>templates/work_orders/create.html.old</code> - <code>templates/work_orders/create.html.backup</code> - <code>templates/work_orders/edit.html.old</code> - <code>templates/work_orders/edit.html.backup</code> - <code>templates/repair_orders/create.html.old</code> - <code>templates/repair_orders/create.html.backup</code> - <code>templates/repair_orders/edit.html.old</code></p> <p>These can be safely deleted after verifying the refactored versions work correctly in production.</p>"},{"location":"developer-guide/template-refactoring-summary/#benefits","title":"Benefits","text":""},{"location":"developer-guide/template-refactoring-summary/#for-development","title":"For Development","text":"<ol> <li>Single Source of Truth: Changes to common components apply everywhere</li> <li>Faster Development: Reuse components for new order types</li> <li>Easier Testing: Test shared components once</li> <li>Better Code Review: Smaller, focused changes</li> <li>Reduced Bugs: No duplicate code to keep in sync</li> </ol>"},{"location":"developer-guide/template-refactoring-summary/#for-users","title":"For Users","text":"<ol> <li>Consistent Experience: Same UI/UX for work orders and repair orders</li> <li>Modern Interface: Card-based layout is more intuitive</li> <li>Better Usability: Drag-and-drop file upload, better validation</li> <li>Responsive Design: Works better on mobile devices</li> <li>Faster Loading: Less duplicate JavaScript</li> </ol>"},{"location":"developer-guide/template-refactoring-summary/#for-maintenance","title":"For Maintenance","text":"<ol> <li>Fix Once, Apply Everywhere: Bug fixes in shared code benefit all</li> <li>Style Updates: Change styles in one place</li> <li>Feature Additions: Add new features to macro and reuse</li> <li>Documentation: Easier to document shared components</li> <li>Onboarding: New developers learn patterns once</li> </ol>"},{"location":"developer-guide/template-refactoring-summary/#future-improvements-optional","title":"Future Improvements (Optional)","text":""},{"location":"developer-guide/template-refactoring-summary/#additional-enhancements","title":"Additional Enhancements","text":"<ol> <li>Shared CSS: Extract common styles to <code>static/css/order-forms.css</code></li> <li>Component Library: Create more reusable macros</li> <li>Form Validation: Centralize validation logic</li> <li>API Endpoints: Create shared API for inventory loading</li> <li>TypeScript: Add type safety to JavaScript</li> </ol>"},{"location":"developer-guide/template-refactoring-summary/#migration-notes","title":"Migration Notes","text":""},{"location":"developer-guide/template-refactoring-summary/#rollback-procedure","title":"Rollback Procedure","text":"<p>If issues arise, rollback is simple for any template: <pre><code># Repair orders\ncd templates/repair_orders/\nmv create.html create.html.refactored\nmv create.html.old create.html\nmv edit.html edit.html.refactored\nmv edit.html.old edit.html\n\n# Work orders\ncd ../work_orders/\nmv create.html create.html.refactored\nmv create.html.old create.html\nmv edit.html edit.html.refactored\nmv edit.html.old edit.html\n</code></pre></p>"},{"location":"developer-guide/template-refactoring-summary/#production-checklist","title":"Production Checklist","text":"<p>Before deploying to production: - \u2705 All tests passing - \u2705 Manual testing of create form - \u2705 Manual testing of edit form - \u2705 File upload functionality verified - \u2705 Customer inventory loading verified - \u2705 Item add/remove functionality verified - \u2705 Form validation working - \u2705 Mobile responsiveness checked</p>"},{"location":"developer-guide/template-refactoring-summary/#conclusion","title":"Conclusion","text":"<p>The complete refactoring successfully unified the UI across all work order and repair order templates while maintaining all existing functionality. The code is now significantly more maintainable, the UI is modern and consistent, and future development will be faster and less error-prone.</p> <p>Total Impact: - \ud83c\udfaf 36% overall code reduction (1,471 lines removed) - \ud83c\udfa8 100% UI consistency between work orders and repair orders - \u2705 67/67 tests passing (41 work order + 26 repair order) - \ud83d\udce6 Reusable components for future development - \ud83d\ude80 Modern user experience with card-based layouts and drag-and-drop - \ud83d\udd27 Single source of truth for all common functionality - \u26a1 62% reduction in work order create template - \u26a1 50% reduction in work order edit template - \u26a1 44% reduction in repair order create template - \u26a1 39% reduction in repair order edit template</p> <p>This refactoring establishes a solid foundation for future feature development and ensures a consistent, professional user experience across the entire application.</p>"},{"location":"developer-guide/testing/","title":"Testing Guide","text":""},{"location":"developer-guide/testing/#overview","title":"Overview","text":"<p>The Awning Management System uses pytest as the testing framework with comprehensive fixtures, factories, and mocking patterns. This guide covers how to write, run, and organize tests effectively.</p>"},{"location":"developer-guide/testing/#quick-start","title":"Quick Start","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=. --cov-report=html --cov-report=term-missing\n\n# Run specific test file\npytest test/test_work_orders_routes.py\n\n# Run specific test function\npytest test/test_work_orders_routes.py::test_create_work_order\n\n# Run with verbose output\npytest -v\n\n# Run tests matching a pattern\npytest -k \"work_order\"\n\n# Run tests with specific marker\npytest -m unit\npytest -m integration\n</code></pre>"},{"location":"developer-guide/testing/#test-organization","title":"Test Organization","text":""},{"location":"developer-guide/testing/#file-structure","title":"File Structure","text":"<pre><code>test/\n\u251c\u2500\u2500 conftest.py                              # Shared fixtures and configuration\n\u251c\u2500\u2500 test_auth.py                             # Authentication tests\n\u251c\u2500\u2500 test_work_orders_routes.py               # Work order HTTP route tests\n\u251c\u2500\u2500 test_repair_orders_routes.py             # Repair order HTTP route tests\n\u251c\u2500\u2500 test_customers_routes.py                 # Customer HTTP route tests\n\u251c\u2500\u2500 test_source_routes.py                    # Source HTTP route tests\n\u251c\u2500\u2500 test_inventory_routes.py                 # Inventory HTTP route tests\n\u251c\u2500\u2500 test_queue_routes.py                     # Queue management tests\n\u251c\u2500\u2500 test_admin_routes.py                     # Admin route tests\n\u251c\u2500\u2500 test_models.py                           # Model unit tests\n\u251c\u2500\u2500 test_utils_helpers.py                    # Utility function tests\n\u251c\u2500\u2500 test_data_processing.py                  # Data processing tests\n\u251c\u2500\u2500 test_decorators.py                       # Decorator tests\n\u251c\u2500\u2500 test_config.py                           # Configuration tests\n\u251c\u2500\u2500 test_basic_setup.py                      # Basic application setup tests\n\u251c\u2500\u2500 test_analytics_parsing.py                # Analytics parsing tests\n\u251c\u2500\u2500 test_ml_cache.py                         # ML caching tests\n\u251c\u2500\u2500 test_item_exclusion_feature.py           # Item exclusion feature tests\n\u251c\u2500\u2500 test_customer_email_bug.py               # Bug-specific tests\n\u251c\u2500\u2500 test_return_status_issue.py              # Bug-specific tests\n\u251c\u2500\u2500 test_inventory_ordering_issue_165.py     # Bug-specific tests\n\u2514\u2500\u2500 test_fuzzing.py                          # Fuzz testing\n</code></pre>"},{"location":"developer-guide/testing/#test-categories","title":"Test Categories","text":""},{"location":"developer-guide/testing/#unit-tests","title":"Unit Tests","text":"<ul> <li>Test individual functions in isolation</li> <li>Fast execution</li> <li>Mock external dependencies</li> <li>Located in: <code>test_utils_helpers.py</code>, <code>test_models.py</code>, <code>test_decorators.py</code></li> </ul>"},{"location":"developer-guide/testing/#integration-tests","title":"Integration Tests","text":"<ul> <li>Test routes with database operations</li> <li>Slower execution</li> <li>Use real database (in-memory SQLite)</li> <li>Located in: <code>test_*_routes.py</code> files</li> </ul>"},{"location":"developer-guide/testing/#bug-regression-tests","title":"Bug Regression Tests","text":"<ul> <li>Test specific bugs to prevent regression</li> <li>Named with issue numbers where applicable</li> <li>Examples: <code>test_customer_email_bug.py</code>, <code>test_inventory_ordering_issue_165.py</code></li> </ul>"},{"location":"developer-guide/testing/#test-fixtures","title":"Test Fixtures","text":""},{"location":"developer-guide/testing/#core-fixtures-conftestpy","title":"Core Fixtures (conftest.py)","text":""},{"location":"developer-guide/testing/#application-fixtures","title":"Application Fixtures","text":""},{"location":"developer-guide/testing/#app","title":"<code>app</code>","text":"<p>Creates a fresh Flask application for each test function.</p> <p>Scope: Function (new app for each test)</p> <p>Configuration: - Uses in-memory SQLite database - CSRF protection disabled - Testing mode enabled - Database tables created automatically</p> <p>Usage: <pre><code>def test_something(app):\n    with app.app_context():\n        # Test code here\n        assert app.config['TESTING'] is True\n</code></pre></p>"},{"location":"developer-guide/testing/#client","title":"<code>client</code>","text":"<p>Flask test client for making HTTP requests.</p> <p>Dependencies: <code>app</code> fixture</p> <p>Usage: <pre><code>def test_list_customers(client):\n    response = client.get('/customers/')\n    assert response.status_code == 200\n</code></pre></p>"},{"location":"developer-guide/testing/#runner","title":"<code>runner</code>","text":"<p>Flask CLI runner for testing CLI commands.</p> <p>Usage: <pre><code>def test_cli_command(runner):\n    result = runner.invoke(args=['db', 'migrate'])\n    assert result.exit_code == 0\n</code></pre></p>"},{"location":"developer-guide/testing/#app_context","title":"<code>app_context</code>","text":"<p>Application context for testing code that needs app context.</p> <p>Usage: <pre><code>def test_with_app_context(app_context):\n    from flask import current_app\n    assert current_app.config['TESTING'] is True\n</code></pre></p>"},{"location":"developer-guide/testing/#request_context","title":"<code>request_context</code>","text":"<p>Request context for testing code that needs request context.</p> <p>Usage: <pre><code>def test_with_request_context(request_context):\n    from flask import request\n    # Test request-dependent code\n</code></pre></p>"},{"location":"developer-guide/testing/#authentication-fixtures","title":"Authentication Fixtures","text":""},{"location":"developer-guide/testing/#auth_user","title":"<code>auth_user</code>","text":"<p>Mock authenticated user for testing login_required routes.</p> <p>Usage: <pre><code>def test_protected_route(client, auth_user):\n    # Mocks flask_login.current_user\n    response = client.get('/dashboard')\n    assert response.status_code == 200\n</code></pre></p> <p>Mock User Attributes: - <code>is_authenticated = True</code> - <code>is_active = True</code> - <code>is_anonymous = False</code> - <code>get_id() = \"test_user_id\"</code></p>"},{"location":"developer-guide/testing/#admin_client","title":"<code>admin_client</code>","text":"<p>Logged-in client with admin privileges (used in route tests).</p> <p>Usage: <pre><code>def test_admin_route(admin_client):\n    response = admin_client.get('/admin/users')\n    assert response.status_code == 200\n</code></pre></p> <p>Implementation: <pre><code>@pytest.fixture\ndef admin_client(client, app):\n    \"\"\"Provide a logged-in client with admin privileges.\"\"\"\n    with app.app_context():\n        admin = User(\n            username=\"admin\",\n            email=\"admin@example.com\",\n            password_hash=generate_password_hash(\"password\"),\n            role=\"admin\"\n        )\n        db.session.add(admin)\n        db.session.commit()\n\n    client.post(\"/login\", data={\"username\": \"admin\", \"password\": \"password\"})\n    yield client\n    client.get(\"/logout\")\n</code></pre></p>"},{"location":"developer-guide/testing/#mock-fixtures","title":"Mock Fixtures","text":""},{"location":"developer-guide/testing/#mock_s3_client-autouse","title":"<code>mock_s3_client</code> (autouse)","text":"<p>Automatically mocks boto3 S3 client for all tests.</p> <p>Scope: Function (automatic for all tests)</p> <p>Why Autouse? - Prevents tests from attempting real S3 connections - No AWS credentials needed for tests - Faster test execution</p> <p>Usage: <pre><code>def test_file_upload(mock_s3_client):\n    # S3 client is automatically mocked\n    # mock_s3_client.upload_fileobj is already a MagicMock\n    from utils.file_upload import save_work_order_file\n\n    file = BytesIO(b\"test content\")\n    file.filename = \"test.pdf\"\n    save_work_order_file(\"WO000001\", file)\n\n    # Verify S3 was called\n    assert mock_s3_client.upload_fileobj.called\n</code></pre></p>"},{"location":"developer-guide/testing/#mock_pdf_generator","title":"<code>mock_pdf_generator</code>","text":"<p>Mocks PDF generation to return fake PDF content.</p> <p>Usage: <pre><code>def test_pdf_generation(client, mock_pdf_generator):\n    response = client.get('/work_orders/WO000001/pdf')\n    assert response.status_code == 200\n    assert response.mimetype == 'application/pdf'\n</code></pre></p>"},{"location":"developer-guide/testing/#mock_db_session","title":"<code>mock_db_session</code>","text":"<p>Mocks SQLAlchemy session for unit tests.</p> <p>Usage: <pre><code>def test_business_logic(mock_db_session):\n    # db.session is mocked\n    mock_db_session.add = Mock()\n    mock_db_session.commit = Mock()\n\n    # Test code\n    db.session.add(work_order)\n    db.session.commit()\n\n    # Verify\n    assert mock_db_session.add.called\n    assert mock_db_session.commit.called\n</code></pre></p>"},{"location":"developer-guide/testing/#model-fixtures","title":"Model Fixtures","text":""},{"location":"developer-guide/testing/#sample_work_order","title":"<code>sample_work_order</code>","text":"<p>Pre-configured WorkOrder instance for testing.</p> <p>Usage: <pre><code>def test_work_order_logic(sample_work_order):\n    assert sample_work_order.WorkOrderNo == \"TEST001\"\n    assert sample_work_order.CustID == \"123\"\n</code></pre></p>"},{"location":"developer-guide/testing/#sample_customer","title":"<code>sample_customer</code>","text":"<p>Pre-configured Customer instance.</p>"},{"location":"developer-guide/testing/#sample_source","title":"<code>sample_source</code>","text":"<p>Pre-configured Source instance.</p>"},{"location":"developer-guide/testing/#sample_inventory","title":"<code>sample_inventory</code>","text":"<p>List of pre-configured Inventory instances.</p>"},{"location":"developer-guide/testing/#sample_work_order_items","title":"<code>sample_work_order_items</code>","text":"<p>List of pre-configured WorkOrderItem instances.</p>"},{"location":"developer-guide/testing/#database_setup","title":"<code>database_setup</code>","text":"<p>Populates database with sample customer, source, and inventory data.</p> <p>Usage: <pre><code>def test_with_data(app_context, database_setup):\n    # Database is pre-populated\n    customers = Customer.query.all()\n    assert len(customers) &gt; 0\n</code></pre></p> <p>Cleanup: Automatically rolls back and cleans up data after test.</p>"},{"location":"developer-guide/testing/#custom-sample-data-fixture","title":"Custom Sample Data Fixture","text":"<p>For route tests that need comprehensive data:</p> <pre><code>@pytest.fixture\ndef sample_data(app):\n    \"\"\"Create comprehensive sample data for tests.\"\"\"\n    with app.app_context():\n        # Create source\n        source = Source(\n            SSource=\"Test Source\",\n            SourceCity=\"Boston\",\n            SourceState=\"MA\"\n        )\n        db.session.add(source)\n\n        # Create customer\n        customer = Customer(\n            CustID=\"100\",\n            Name=\"Test Customer\",\n            Source=\"Test Source\"\n        )\n        db.session.add(customer)\n\n        # Create inventory\n        inv = Inventory(\n            InventoryKey=\"INV001\",\n            CustID=\"100\",\n            Description=\"Test Item\"\n        )\n        db.session.add(inv)\n\n        db.session.commit()\n        yield\n\n        # Cleanup\n        db.session.query(Inventory).delete()\n        db.session.query(Customer).delete()\n        db.session.query(Source).delete()\n        db.session.commit()\n</code></pre>"},{"location":"developer-guide/testing/#test-factories","title":"Test Factories","text":"<p>Factories provide a flexible way to create test data with custom attributes.</p>"},{"location":"developer-guide/testing/#workorderfactory","title":"WorkOrderFactory","text":"<pre><code>@pytest.fixture\ndef work_order_factory():\n    return WorkOrderFactory\n\ndef test_multiple_work_orders(work_order_factory):\n    # Create single work order with defaults\n    wo1 = work_order_factory.create()\n\n    # Create work order with custom attributes\n    wo2 = work_order_factory.create(\n        WorkOrderNo=\"WO002\",\n        WOName=\"Custom Name\"\n    )\n\n    # Create batch of work orders\n    work_orders = work_order_factory.create_batch(count=5)\n    assert len(work_orders) == 5\n</code></pre>"},{"location":"developer-guide/testing/#customerfactory","title":"CustomerFactory","text":"<pre><code>def test_customers(customer_factory):\n    customer = customer_factory.create(\n        CustID=\"200\",\n        Name=\"Custom Customer\"\n    )\n    assert customer.CustID == \"200\"\n</code></pre>"},{"location":"developer-guide/testing/#inventoryfactory","title":"InventoryFactory","text":"<pre><code>def test_inventory(inventory_factory):\n    item = inventory_factory.create(\n        InventoryKey=\"INV_CUSTOM\",\n        Description=\"Custom Item\"\n    )\n    assert item.InventoryKey == \"INV_CUSTOM\"\n</code></pre>"},{"location":"developer-guide/testing/#writing-tests","title":"Writing Tests","text":""},{"location":"developer-guide/testing/#unit-test-example","title":"Unit Test Example","text":"<p>Testing individual utility functions:</p> <pre><code>\"\"\"test_utils_helpers.py\"\"\"\nimport pytest\nfrom utils.helpers import format_phone_number, safe_bool_convert\n\nclass TestFormatPhoneNumber:\n    def test_ten_digit_number(self):\n        assert format_phone_number(\"5551234567\") == \"(555) 123-4567\"\n\n    def test_eleven_digit_with_one(self):\n        assert format_phone_number(\"15551234567\") == \"(555) 123-4567\"\n\n    def test_already_formatted(self):\n        assert format_phone_number(\"(555) 123-4567\") == \"(555) 123-4567\"\n\n    def test_empty_string(self):\n        assert format_phone_number(\"\") == \"\"\n\n    def test_none(self):\n        assert format_phone_number(None) == \"\"\n\nclass TestSafeBoolConvert:\n    def test_true_values(self):\n        assert safe_bool_convert(True) is True\n        assert safe_bool_convert(\"1\") is True\n        assert safe_bool_convert(\"yes\") is True\n        assert safe_bool_convert(1) is True\n\n    def test_false_values(self):\n        assert safe_bool_convert(False) is False\n        assert safe_bool_convert(\"0\") is False\n        assert safe_bool_convert(0) is False\n        assert safe_bool_convert(None) is False\n\n    def test_default_value(self):\n        assert safe_bool_convert(\"invalid\", default=True) is True\n</code></pre>"},{"location":"developer-guide/testing/#integration-test-example","title":"Integration Test Example","text":"<p>Testing HTTP routes with database:</p> <pre><code>\"\"\"test_work_orders_routes.py\"\"\"\nimport pytest\nfrom models.work_order import WorkOrder\nfrom extensions import db\n\ndef test_create_work_order(admin_client, sample_data):\n    \"\"\"Test creating a new work order via HTTP POST.\"\"\"\n    data = {\n        'CustID': '100',\n        'WOName': 'Test WO',\n        'DateIn': '2024-01-15',\n        'RackNo': 'A1',\n        'ShipTo': 'Test Source'\n    }\n\n    response = admin_client.post('/work_orders/create', data=data, follow_redirects=True)\n\n    # Check response\n    assert response.status_code == 200\n    assert b'Work order created' in response.data\n\n    # Verify database\n    wo = WorkOrder.query.filter_by(WOName='Test WO').first()\n    assert wo is not None\n    assert wo.CustID == '100'\n    assert wo.RackNo == 'A1'\n\ndef test_list_work_orders(admin_client, app):\n    \"\"\"Test listing work orders.\"\"\"\n    with app.app_context():\n        # Create test data\n        wo = WorkOrder(\n            WorkOrderNo=\"WO000001\",\n            CustID=\"100\",\n            WOName=\"Test WO\"\n        )\n        db.session.add(wo)\n        db.session.commit()\n\n    response = admin_client.get('/work_orders/')\n    assert response.status_code == 200\n    assert b'WO000001' in response.data\n    assert b'Test WO' in response.data\n\ndef test_delete_work_order(admin_client, app):\n    \"\"\"Test deleting a work order.\"\"\"\n    with app.app_context():\n        wo = WorkOrder(\n            WorkOrderNo=\"WO000001\",\n            CustID=\"100\",\n            WOName=\"Test WO\"\n        )\n        db.session.add(wo)\n        db.session.commit()\n\n    response = admin_client.post('/work_orders/WO000001/delete', follow_redirects=True)\n    assert response.status_code == 200\n\n    with app.app_context():\n        wo = WorkOrder.query.get(\"WO000001\")\n        assert wo is None\n</code></pre>"},{"location":"developer-guide/testing/#file-upload-test-example","title":"File Upload Test Example","text":"<pre><code>def test_file_upload(admin_client, mock_s3_client, app):\n    \"\"\"Test uploading files to work orders.\"\"\"\n    with app.app_context():\n        # Create work order\n        wo = WorkOrder(\n            WorkOrderNo=\"WO000001\",\n            CustID=\"100\",\n            WOName=\"Test WO\"\n        )\n        db.session.add(wo)\n        db.session.commit()\n\n    # Prepare file upload\n    data = {\n        'files': (BytesIO(b\"test file content\"), 'test.pdf')\n    }\n\n    response = admin_client.post(\n        '/work_orders/WO000001/upload',\n        data=data,\n        content_type='multipart/form-data',\n        follow_redirects=True\n    )\n\n    assert response.status_code == 200\n    assert b'File uploaded' in response.data\n\n    # Verify S3 was called\n    assert mock_s3_client.upload_fileobj.called\n</code></pre>"},{"location":"developer-guide/testing/#model-test-example","title":"Model Test Example","text":"<pre><code>\"\"\"test_models.py\"\"\"\nimport pytest\nfrom models.work_order import WorkOrder\nfrom datetime import date\n\nclass TestWorkOrderModel:\n    def test_create_work_order(self):\n        wo = WorkOrder(\n            WorkOrderNo=\"WO000001\",\n            CustID=\"100\",\n            WOName=\"Test WO\",\n            DateIn=date(2024, 1, 15)\n        )\n        assert wo.WorkOrderNo == \"WO000001\"\n        assert wo.CustID == \"100\"\n\n    def test_work_order_repr(self):\n        wo = WorkOrder(WorkOrderNo=\"WO000001\")\n        assert repr(wo) == \"&lt;WorkOrder WO000001&gt;\"\n\n    def test_work_order_relationships(self, app):\n        with app.app_context():\n            # Test customer relationship\n            customer = Customer(CustID=\"100\", Name=\"Test\")\n            wo = WorkOrder(\n                WorkOrderNo=\"WO000001\",\n                CustID=\"100\",\n                customer=customer\n            )\n            db.session.add_all([customer, wo])\n            db.session.commit()\n\n            assert wo.customer == customer\n            assert customer.work_orders[0] == wo\n</code></pre>"},{"location":"developer-guide/testing/#mocking-patterns","title":"Mocking Patterns","text":""},{"location":"developer-guide/testing/#mocking-s3-operations","title":"Mocking S3 Operations","text":"<pre><code>from unittest.mock import patch, MagicMock\n\ndef test_s3_upload():\n    with patch('utils.file_upload.s3_client') as mock_s3:\n        mock_s3.upload_fileobj = MagicMock()\n\n        # Test code that uses S3\n        from utils.file_upload import save_work_order_file\n        file = BytesIO(b\"content\")\n        file.filename = \"test.pdf\"\n        save_work_order_file(\"WO000001\", file, defer_s3_upload=False)\n\n        # Verify S3 was called\n        assert mock_s3.upload_fileobj.called\n        call_args = mock_s3.upload_fileobj.call_args\n        assert call_args[0][2] == \"work_orders/WO000001/test.pdf\"\n</code></pre>"},{"location":"developer-guide/testing/#mocking-database-queries","title":"Mocking Database Queries","text":"<pre><code>from unittest.mock import Mock, patch\n\ndef test_query_mocking():\n    with patch('models.work_order.WorkOrder.query') as mock_query:\n        # Mock query results\n        mock_wo = Mock()\n        mock_wo.WorkOrderNo = \"WO000001\"\n        mock_query.filter_by.return_value.first.return_value = mock_wo\n\n        # Test code\n        wo = WorkOrder.query.filter_by(WorkOrderNo=\"WO000001\").first()\n        assert wo.WorkOrderNo == \"WO000001\"\n</code></pre>"},{"location":"developer-guide/testing/#mocking-flask-login","title":"Mocking Flask-Login","text":"<pre><code>from unittest.mock import patch\n\ndef test_login_required(client):\n    with patch('flask_login.current_user') as mock_user:\n        mock_user.is_authenticated = True\n        mock_user.is_active = True\n\n        response = client.get('/dashboard')\n        assert response.status_code == 200\n</code></pre>"},{"location":"developer-guide/testing/#testing-best-practices","title":"Testing Best Practices","text":""},{"location":"developer-guide/testing/#1-test-independence","title":"1. Test Independence","text":"<p>Each test should be completely independent of others.</p> <p>Good: <pre><code>def test_create_customer(app):\n    with app.app_context():\n        customer = Customer(CustID=\"100\", Name=\"Test\")\n        db.session.add(customer)\n        db.session.commit()\n\n        # Verify\n        assert Customer.query.count() == 1\n\n        # Cleanup\n        db.session.delete(customer)\n        db.session.commit()\n</code></pre></p> <p>Bad: <pre><code># Don't rely on data from previous tests\ndef test_list_customers():\n    # Assumes customers exist from previous test\n    assert Customer.query.count() &gt; 0  # Fragile!\n</code></pre></p>"},{"location":"developer-guide/testing/#2-use-descriptive-test-names","title":"2. Use Descriptive Test Names","text":"<p>Good: <pre><code>def test_create_work_order_with_missing_customer_id_returns_400():\n    pass\n\ndef test_delete_work_order_cascades_to_items():\n    pass\n</code></pre></p> <p>Bad: <pre><code>def test_1():\n    pass\n\ndef test_stuff():\n    pass\n</code></pre></p>"},{"location":"developer-guide/testing/#3-test-one-thing-per-test","title":"3. Test One Thing Per Test","text":"<p>Good: <pre><code>def test_work_order_creation():\n    # Test creation only\n    wo = WorkOrder(WorkOrderNo=\"WO000001\", CustID=\"100\")\n    assert wo.WorkOrderNo == \"WO000001\"\n\ndef test_work_order_validation():\n    # Test validation separately\n    with pytest.raises(ValueError):\n        wo = WorkOrder(WorkOrderNo=None)\n</code></pre></p> <p>Bad: <pre><code>def test_work_order():\n    # Testing too many things\n    wo = WorkOrder(WorkOrderNo=\"WO000001\", CustID=\"100\")\n    assert wo.WorkOrderNo == \"WO000001\"\n\n    db.session.add(wo)\n    db.session.commit()\n\n    retrieved = WorkOrder.query.get(\"WO000001\")\n    assert retrieved is not None\n\n    db.session.delete(retrieved)\n    db.session.commit()\n\n    assert WorkOrder.query.get(\"WO000001\") is None\n</code></pre></p>"},{"location":"developer-guide/testing/#4-use-fixtures-for-setup","title":"4. Use Fixtures for Setup","text":"<p>Good: <pre><code>@pytest.fixture\ndef work_order_with_items(app):\n    with app.app_context():\n        wo = WorkOrder(WorkOrderNo=\"WO000001\", CustID=\"100\")\n        item1 = WorkOrderItem(WorkOrderNo=\"WO000001\", Description=\"Item 1\")\n        item2 = WorkOrderItem(WorkOrderNo=\"WO000001\", Description=\"Item 2\")\n        db.session.add_all([wo, item1, item2])\n        db.session.commit()\n        yield wo\n        db.session.delete(wo)\n        db.session.commit()\n\ndef test_work_order_items(work_order_with_items):\n    assert len(work_order_with_items.items) == 2\n</code></pre></p> <p>Bad: <pre><code>def test_work_order_items(app):\n    with app.app_context():\n        # Repeated setup in every test\n        wo = WorkOrder(WorkOrderNo=\"WO000001\", CustID=\"100\")\n        item1 = WorkOrderItem(WorkOrderNo=\"WO000001\", Description=\"Item 1\")\n        item2 = WorkOrderItem(WorkOrderNo=\"WO000001\", Description=\"Item 2\")\n        db.session.add_all([wo, item1, item2])\n        db.session.commit()\n\n        assert len(wo.items) == 2\n</code></pre></p>"},{"location":"developer-guide/testing/#5-test-error-cases","title":"5. Test Error Cases","text":"<pre><code>def test_create_work_order_missing_required_field(admin_client):\n    \"\"\"Test that missing required field returns error.\"\"\"\n    data = {'WOName': 'Test'}  # Missing CustID\n\n    response = admin_client.post('/work_orders/create', data=data)\n    assert response.status_code == 400\n    assert b'Customer is required' in response.data\n\ndef test_delete_nonexistent_work_order(admin_client):\n    \"\"\"Test deleting non-existent work order returns 404.\"\"\"\n    response = admin_client.post('/work_orders/INVALID/delete')\n    assert response.status_code == 404\n</code></pre>"},{"location":"developer-guide/testing/#6-mock-external-services","title":"6. Mock External Services","text":"<p>Always mock external services (S3, APIs, etc.) to: - Make tests faster - Make tests reliable - Avoid dependencies on external systems - Prevent accidental data modification</p> <pre><code>@pytest.fixture(autouse=True)\ndef mock_s3_client(mocker):\n    \"\"\"Automatically mock S3 for all tests.\"\"\"\n    mock_s3 = MagicMock()\n    mocker.patch(\"utils.file_upload.boto3.client\", return_value=mock_s3)\n    return mock_s3\n</code></pre>"},{"location":"developer-guide/testing/#pytest-markers","title":"Pytest Markers","text":""},{"location":"developer-guide/testing/#built-in-markers","title":"Built-in Markers","text":"<pre><code># Mark test as unit test\n@pytest.mark.unit\ndef test_helper_function():\n    pass\n\n# Mark test as integration test\n@pytest.mark.integration\ndef test_route():\n    pass\n\n# Mark test as slow\n@pytest.mark.slow\ndef test_large_dataset():\n    pass\n\n# Mark test as requiring authentication\n@pytest.mark.auth\ndef test_protected_route(auth_user):\n    pass\n\n# Skip test\n@pytest.mark.skip(reason=\"Not implemented yet\")\ndef test_future_feature():\n    pass\n\n# Expected to fail\n@pytest.mark.xfail(reason=\"Known bug\")\ndef test_known_issue():\n    pass\n\n# Parametrize test\n@pytest.mark.parametrize(\"input,expected\", [\n    (\"5551234567\", \"(555) 123-4567\"),\n    (\"15551234567\", \"(555) 123-4567\"),\n    (\"\", \"\"),\n])\ndef test_phone_format(input, expected):\n    assert format_phone_number(input) == expected\n</code></pre>"},{"location":"developer-guide/testing/#running-tests-by-marker","title":"Running Tests by Marker","text":"<pre><code># Run only unit tests\npytest -m unit\n\n# Run only integration tests\npytest -m integration\n\n# Run everything except slow tests\npytest -m \"not slow\"\n\n# Run auth tests\npytest -m auth\n</code></pre>"},{"location":"developer-guide/testing/#test-coverage","title":"Test Coverage","text":""},{"location":"developer-guide/testing/#running-with-coverage","title":"Running with Coverage","text":"<pre><code># Generate coverage report\npytest --cov=. --cov-report=html --cov-report=term-missing\n\n# View HTML report\nopen htmlcov/index.html\n\n# Show missing lines in terminal\npytest --cov=. --cov-report=term-missing\n</code></pre>"},{"location":"developer-guide/testing/#coverage-expectations","title":"Coverage Expectations","text":"<ul> <li>Utility functions: 90%+ coverage</li> <li>Routes: 80%+ coverage</li> <li>Models: 80%+ coverage</li> <li>Overall: 75%+ coverage</li> </ul>"},{"location":"developer-guide/testing/#checking-coverage-for-specific-module","title":"Checking Coverage for Specific Module","text":"<pre><code>pytest --cov=utils.helpers --cov-report=term-missing\npytest --cov=routes.work_orders --cov-report=term-missing\n</code></pre>"},{"location":"developer-guide/testing/#common-testing-scenarios","title":"Common Testing Scenarios","text":""},{"location":"developer-guide/testing/#testing-form-submissions","title":"Testing Form Submissions","text":"<pre><code>def test_form_submission(admin_client):\n    data = {\n        'CustID': '100',\n        'WOName': 'Test WO',\n        'DateIn': '2024-01-15',\n        'RushOrder': 'on',  # Checkbox\n        'selected_items[]': ['INV001', 'INV002'],\n        'item_qty_INV001': '2',\n        'item_qty_INV002': '1',\n    }\n\n    response = admin_client.post('/work_orders/create', data=data, follow_redirects=True)\n    assert response.status_code == 200\n</code></pre>"},{"location":"developer-guide/testing/#testing-json-apis","title":"Testing JSON APIs","text":"<pre><code>def test_api_endpoint(admin_client):\n    response = admin_client.get('/api/work_orders/WO000001')\n    assert response.status_code == 200\n\n    data = response.get_json()\n    assert data['WorkOrderNo'] == 'WO000001'\n    assert 'CustID' in data\n    assert 'WOName' in data\n</code></pre>"},{"location":"developer-guide/testing/#testing-file-downloads","title":"Testing File Downloads","text":"<pre><code>def test_pdf_download(admin_client, app):\n    with app.app_context():\n        wo = WorkOrder(WorkOrderNo=\"WO000001\", CustID=\"100\")\n        db.session.add(wo)\n        db.session.commit()\n\n    response = admin_client.get('/work_orders/WO000001/pdf')\n    assert response.status_code == 200\n    assert response.mimetype == 'application/pdf'\n    assert 'attachment' in response.headers.get('Content-Disposition', '')\n</code></pre>"},{"location":"developer-guide/testing/#testing-flash-messages","title":"Testing Flash Messages","text":"<pre><code>def test_flash_messages(admin_client):\n    response = admin_client.post('/work_orders/create', data={}, follow_redirects=True)\n    assert b'Customer is required' in response.data\n</code></pre>"},{"location":"developer-guide/testing/#testing-redirects","title":"Testing Redirects","text":"<pre><code>def test_redirect(admin_client):\n    response = admin_client.post('/work_orders/create', data=valid_data)\n    assert response.status_code == 302\n    assert '/work_orders/' in response.location\n\ndef test_redirect_follow(admin_client):\n    response = admin_client.post('/work_orders/create', data=valid_data, follow_redirects=True)\n    assert response.status_code == 200\n    assert b'Work order created' in response.data\n</code></pre>"},{"location":"developer-guide/testing/#debugging-tests","title":"Debugging Tests","text":""},{"location":"developer-guide/testing/#print-debugging","title":"Print Debugging","text":"<pre><code>def test_something(app):\n    with app.app_context():\n        wo = WorkOrder.query.first()\n        print(f\"Work Order: {wo}\")  # Will show in pytest output with -s flag\n        assert wo is not None\n</code></pre> <pre><code># Run with print output\npytest -s test/test_work_orders_routes.py\n</code></pre>"},{"location":"developer-guide/testing/#using-pytestset_trace","title":"Using pytest.set_trace()","text":"<pre><code>def test_debug(app):\n    with app.app_context():\n        wo = WorkOrder.query.first()\n        pytest.set_trace()  # Debugger breakpoint\n        assert wo is not None\n</code></pre>"},{"location":"developer-guide/testing/#verbose-output","title":"Verbose Output","text":"<pre><code># Show test names as they run\npytest -v\n\n# Show extra test summary\npytest -v --tb=short\n\n# Show full error traceback\npytest -v --tb=long\n</code></pre>"},{"location":"developer-guide/testing/#failed-test-output","title":"Failed Test Output","text":"<pre><code># Show only failed tests\npytest --lf\n\n# Run failed tests first\npytest --ff\n\n# Stop on first failure\npytest -x\n\n# Stop after N failures\npytest --maxfail=3\n</code></pre>"},{"location":"developer-guide/testing/#continuous-integration","title":"Continuous Integration","text":""},{"location":"developer-guide/testing/#running-tests-in-ci","title":"Running Tests in CI","text":"<pre><code># .github/workflows/test.yml\nname: Tests\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n\n    - name: Set up Python\n      uses: actions/setup-python@v2\n      with:\n        python-version: '3.9'\n\n    - name: Install dependencies\n      run: |\n        pip install -r requirements.txt\n\n    - name: Run tests with coverage\n      run: |\n        pytest --cov=. --cov-report=xml --cov-report=term-missing\n\n    - name: Upload coverage to Codecov\n      uses: codecov/codecov-action@v2\n      with:\n        files: ./coverage.xml\n</code></pre>"},{"location":"developer-guide/testing/#see-also","title":"See Also","text":"<ul> <li>Utility Functions Reference - Functions to test</li> <li>Database Schema - Models to test</li> <li>Error Handling - Testing error cases</li> <li>CLAUDE.md - Main project documentation</li> </ul>"},{"location":"developer-guide/utility-functions/","title":"Utility Functions Reference","text":""},{"location":"developer-guide/utility-functions/#overview","title":"Overview","text":"<p>The Awning Management System includes a comprehensive collection of utility functions organized into specialized modules in the <code>utils/</code> directory. These functions handle common tasks like data parsing, validation, file uploads, caching, and more.</p> <p>This reference provides a complete catalog of all utility modules and their functions, with examples and usage guidelines.</p>"},{"location":"developer-guide/utility-functions/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>General Helpers - Common utility functions</li> <li>Order Item Helpers - Work order and repair order item processing</li> <li>Form Helpers - Form field extraction and validation</li> <li>Date Helpers - Date parsing and formatting</li> <li>Data Processing - Analytics data cleaning and parsing</li> <li>File Upload - S3 and local file management</li> <li>Cache Helpers - Caching and cache invalidation</li> <li>PDF Helpers - PDF generation utilities</li> <li>Thumbnail Generator - Image thumbnail creation</li> </ul>"},{"location":"developer-guide/utility-functions/#general-helpers","title":"General Helpers","text":"<p>Module: <code>utils/helpers.py</code></p>"},{"location":"developer-guide/utility-functions/#phone-number-formatting","title":"Phone Number Formatting","text":""},{"location":"developer-guide/utility-functions/#format_phone_numberphone","title":"<code>format_phone_number(phone)</code>","text":"<p>Format phone number for consistent display.</p> <p>Args: - <code>phone</code> (str): Raw phone number string</p> <p>Returns: Formatted phone number string</p> <p>Examples: <pre><code>from utils.helpers import format_phone_number\n\nformat_phone_number(\"5551234567\")      # \"(555) 123-4567\"\nformat_phone_number(\"15551234567\")     # \"(555) 123-4567\"\nformat_phone_number(\"555-123-4567\")    # \"(555) 123-4567\"\nformat_phone_number(\"\")                # \"\"\n</code></pre></p> <p>Usage in templates: Also available as Jinja2 filter <code>format_phone</code>.</p>"},{"location":"developer-guide/utility-functions/#order-number-generation","title":"Order Number Generation","text":""},{"location":"developer-guide/utility-functions/#generate_work_order_number","title":"<code>generate_work_order_number()</code>","text":"<p>Generate the next work order number in sequence.</p> <p>Returns: Work order number string (format: <code>WO000001</code>)</p> <p>Example: <pre><code>from utils.helpers import generate_work_order_number\n\nnext_wo = generate_work_order_number()  # \"WO000042\"\n</code></pre></p> <p>Thread Safety: Not thread-safe. Should be called within a database transaction.</p>"},{"location":"developer-guide/utility-functions/#generate_repair_order_number","title":"<code>generate_repair_order_number()</code>","text":"<p>Generate the next repair order number in sequence.</p> <p>Returns: Repair order number string (format: <code>RO000001</code>)</p> <p>Example: <pre><code>from utils.helpers import generate_repair_order_number\n\nnext_ro = generate_repair_order_number()  # \"RO000015\"\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#boolean-conversion","title":"Boolean Conversion","text":""},{"location":"developer-guide/utility-functions/#safe_bool_convertvalue-defaultfalse","title":"<code>safe_bool_convert(value, default=False)</code>","text":"<p>Safely convert various types to boolean.</p> <p>Args: - <code>value</code>: Value to convert (bool, int, str, or None) - <code>default</code> (bool): Default value if conversion fails (default: False)</p> <p>Returns: Boolean value</p> <p>Examples: <pre><code>from utils.helpers import safe_bool_convert\n\nsafe_bool_convert(True)                  # True\nsafe_bool_convert(\"1\")                   # True\nsafe_bool_convert(\"yes\")                 # True\nsafe_bool_convert(0)                     # False\nsafe_bool_convert(None)                  # False\nsafe_bool_convert(\"invalid\", default=True)  # True\n</code></pre></p> <p>Common Use Cases: - Converting HTML checkbox values from forms - Parsing boolean fields from CSV imports - API request parameter validation</p>"},{"location":"developer-guide/utility-functions/#map_bool_displayvalue-true_textyes-false_textno-defaultfalse","title":"<code>map_bool_display(value, true_text=\"Yes\", false_text=\"No\", default=False)</code>","text":"<p>Map boolean values to display text for PDFs and other outputs.</p> <p>Args: - <code>value</code>: Value to convert (bool, int, str, or None) - <code>true_text</code> (str): Text for True values (default: \"Yes\") - <code>false_text</code> (str): Text for False values (default: \"No\") - <code>default</code> (bool): Default boolean value if conversion fails</p> <p>Returns: Display text string</p> <p>Examples: <pre><code>from utils.helpers import map_bool_display\n\nmap_bool_display(True)                  # \"Yes\"\nmap_bool_display(False)                 # \"No\"\nmap_bool_display(\"1\")                   # \"Yes\"\nmap_bool_display(0)                     # \"No\"\nmap_bool_display(True, \"\u2713\", \"\u2717\")        # \"\u2713\"\nmap_bool_display(None)                  # \"No\"\n</code></pre></p> <p>Usage in PDFs: Commonly used in PDF generation to convert boolean fields to user-friendly text.</p>"},{"location":"developer-guide/utility-functions/#status-color-mapping","title":"Status Color Mapping","text":""},{"location":"developer-guide/utility-functions/#get_status_colorstatus","title":"<code>get_status_color(status)</code>","text":"<p>Return Bootstrap color class for status values.</p> <p>Args: - <code>status</code> (str): Status value</p> <p>Returns: Bootstrap color class string</p> <p>Status Mapping: | Status | Bootstrap Class | Visual Color | |--------|----------------|--------------| | pending | warning | Yellow | | in_progress | info | Blue | | completed | success | Green | | cancelled | danger | Red | | on_hold | secondary | Gray | | (unknown) | secondary | Gray |</p> <p>Example: <pre><code>from utils.helpers import get_status_color\n\nget_status_color(\"completed\")   # \"success\"\nget_status_color(\"pending\")     # \"warning\"\nget_status_color(\"cancelled\")   # \"danger\"\n</code></pre></p> <p>Template Usage: <pre><code>&lt;span class=\"badge badge-{{ get_status_color(order.status) }}\"&gt;\n    {{ order.status }}\n&lt;/span&gt;\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#date-calculations","title":"Date Calculations","text":""},{"location":"developer-guide/utility-functions/#calculate_days_sincedate","title":"<code>calculate_days_since(date)</code>","text":"<p>Calculate days since a given date.</p> <p>Args: - <code>date</code>: Date object or YYYY-MM-DD string</p> <p>Returns: Integer days since date, or None if date is None</p> <p>Example: <pre><code>from utils.helpers import calculate_days_since\nfrom datetime import date\n\ncalculate_days_since(date(2024, 1, 1))  # Days from Jan 1, 2024 to today\ncalculate_days_since(\"2024-01-01\")      # Same as above\ncalculate_days_since(None)              # None\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#date-formatting-and-sorting","title":"Date Formatting and Sorting","text":""},{"location":"developer-guide/utility-functions/#format_date_from_strdate_str","title":"<code>format_date_from_str(date_str)</code>","text":"<p>Parse date string from various formats. (Defined in helpers.py but primarily used via date_helpers module)</p> <p>Args: - <code>date_str</code> (str): Date string to parse</p> <p>Returns: datetime object or None</p> <p>Supported Formats: - <code>MM/DD/YY HH:MM:SS</code> (legacy database format) - <code>YYYY-MM-DD</code> (ISO format)</p> <p>Example: <pre><code>from utils.helpers import format_date_from_str\n\nformat_date_from_str(\"12/31/23 14:30:00\")  # datetime(2023, 12, 31, 14, 30, 0)\nformat_date_from_str(\"2024-01-15\")         # datetime(2024, 1, 15, 0, 0, 0)\nformat_date_from_str(None)                 # None\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#safe_date_sort_keydate_obj","title":"<code>safe_date_sort_key(date_obj)</code>","text":"<p>Returns a sortable key for date objects, handling None values.</p> <p>Args: - <code>date_obj</code>: Date object, string, or None</p> <p>Returns: Sortable date object (datetime.min for None values)</p> <p>Example: <pre><code>from utils.helpers import safe_date_sort_key\n\norders = sorted(work_orders, key=lambda wo: safe_date_sort_key(wo.DateIn))\n</code></pre></p> <p>Why This Exists: Python's sorted() function fails when comparing None with date objects. This helper ensures None values sort to the beginning.</p>"},{"location":"developer-guide/utility-functions/#queue-management","title":"Queue Management","text":""},{"location":"developer-guide/utility-functions/#initialize_queue_positions_for_unassigned","title":"<code>initialize_queue_positions_for_unassigned()</code>","text":"<p>Assign sequential queue positions to work orders that don't have one.</p> <p>Note: This is a simplified version for testing. The production version with priority handling is in routes/queue.py.</p> <p>Example: <pre><code>from utils.helpers import initialize_queue_positions_for_unassigned\n\n# Assign queue positions to all unassigned work orders\ninitialize_queue_positions_for_unassigned()\n</code></pre></p> <p>Database Impact: Commits changes directly to the database.</p>"},{"location":"developer-guide/utility-functions/#file-upload-helpers","title":"File Upload Helpers","text":""},{"location":"developer-guide/utility-functions/#allowed_filefilename","title":"<code>allowed_file(filename)</code>","text":"<p>Check if uploaded file has allowed extension.</p> <p>Args: - <code>filename</code> (str): Filename to check</p> <p>Returns: Boolean</p> <p>Allowed Extensions: Configured in extensions.py: - Documents: <code>pdf</code>, <code>docx</code>, <code>txt</code>, <code>csv</code>, <code>xlsx</code> - Images: <code>jpg</code>, <code>jpeg</code>, <code>png</code></p> <p>Example: <pre><code>from utils.helpers import allowed_file\n\nallowed_file(\"invoice.pdf\")     # True\nallowed_file(\"photo.jpg\")       # True\nallowed_file(\"malware.exe\")     # False\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#save_uploaded_photoform_photo-customer_id","title":"<code>save_uploaded_photo(form_photo, customer_id)</code>","text":"<p>Save uploaded photo with resizing and return filename.</p> <p>Args: - <code>form_photo</code>: Flask file upload object - <code>customer_id</code>: Customer ID for folder organization</p> <p>Returns: Tuple of (filename, file_path) or (None, None) if invalid</p> <p>Features: - Generates secure random filename - Creates customer-specific directory - Resizes images to max 1200x1200 pixels - Validates file extension</p> <p>Example: <pre><code>from utils.helpers import save_uploaded_photo\n\nif 'photo' in request.files:\n    filename, path = save_uploaded_photo(request.files['photo'], customer.CustID)\n    if filename:\n        customer.photo = filename\n        db.session.commit()\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#pagination","title":"Pagination","text":""},{"location":"developer-guide/utility-functions/#paginate_queryquery-page-per_page50","title":"<code>paginate_query(query, page, per_page=50)</code>","text":"<p>Helper function for SQLAlchemy query pagination.</p> <p>Args: - <code>query</code>: SQLAlchemy query object - <code>page</code> (int): Page number (1-indexed) - <code>per_page</code> (int): Results per page (default: 50)</p> <p>Returns: Flask-SQLAlchemy pagination object</p> <p>Example: <pre><code>from utils.helpers import paginate_query\n\nquery = WorkOrder.query.order_by(WorkOrder.DateIn.desc())\npagination = paginate_query(query, page=1, per_page=25)\n\nfor order in pagination.items:\n    print(order.WorkOrderNo)\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#order-item-helpers","title":"Order Item Helpers","text":"<p>Module: <code>utils/order_item_helpers.py</code></p> <p>This module reduces code duplication in create/edit route handlers by providing reusable functions for processing work order and repair order items.</p>"},{"location":"developer-guide/utility-functions/#safe-value-conversions","title":"Safe Value Conversions","text":""},{"location":"developer-guide/utility-functions/#safe_int_conversionvalue","title":"<code>safe_int_conversion(value)</code>","text":"<p>Safely convert a value to integer, handling various input types.</p> <p>Args: - <code>value</code>: Value to convert (string, int, float, None, etc.)</p> <p>Returns: Integer value (minimum 1)</p> <p>Examples: <pre><code>from utils.order_item_helpers import safe_int_conversion\n\nsafe_int_conversion(\"5\")        # 5\nsafe_int_conversion(\"3.7\")      # 3\nsafe_int_conversion(\"\")         # 1 (default)\nsafe_int_conversion(None)       # 1 (default)\nsafe_int_conversion(\"invalid\")  # 1 (default)\n</code></pre></p> <p>Use Cases: - Parsing quantity fields from forms - Ensuring positive integer values - Handling empty form fields</p>"},{"location":"developer-guide/utility-functions/#safe_price_conversionvalue","title":"<code>safe_price_conversion(value)</code>","text":"<p>Safely convert a value to float for price fields.</p> <p>Args: - <code>value</code>: Value to convert (string, int, float, None, etc.)</p> <p>Returns: Float value (minimum 0.0) or None if empty</p> <p>Examples: <pre><code>from utils.order_item_helpers import safe_price_conversion\n\nsafe_price_conversion(\"125.50\")     # 125.5\nsafe_price_conversion(\"$125.50\")    # 125.5\nsafe_price_conversion(\"\")           # None\nsafe_price_conversion(None)         # None\nsafe_price_conversion(\"invalid\")    # None\n</code></pre></p> <p>Note: Returns None for empty values (unlike safe_int_conversion which defaults to 1). This allows database NULL values for optional price fields.</p>"},{"location":"developer-guide/utility-functions/#processing-inventory-items","title":"Processing Inventory Items","text":""},{"location":"developer-guide/utility-functions/#process_selected_inventory_itemsform-order_no-cust_id-item_class","title":"<code>process_selected_inventory_items(form, order_no, cust_id, item_class)</code>","text":"<p>Process items selected from customer inventory catalog.</p> <p>Args: - <code>form</code>: Flask request.form object - <code>order_no</code> (str): Work order or repair order number - <code>cust_id</code> (str): Customer ID - <code>item_class</code>: WorkOrderItem or RepairWorkOrderItem class</p> <p>Returns: List of item instances (not yet added to session)</p> <p>Form Data Expected: - <code>selected_items[]</code>: List of inventory keys - <code>item_qty_{inv_key}</code>: Quantity for each selected item</p> <p>Example: <pre><code>from utils.order_item_helpers import process_selected_inventory_items\nfrom models.work_order import WorkOrderItem\n\nitems = process_selected_inventory_items(\n    request.form,\n    next_wo_no,\n    customer.CustID,\n    WorkOrderItem\n)\n\nfor item in items:\n    db.session.add(item)\n\ndb.session.commit()\n</code></pre></p> <p>How It Works: 1. Reads <code>selected_items[]</code> array from form 2. Builds quantity map from <code>item_qty_*</code> fields 3. Queries Inventory table for each selected item 4. Creates WorkOrderItem/RepairWorkOrderItem instances 5. Sets <code>InventoryKey</code> field to track source inventory</p>"},{"location":"developer-guide/utility-functions/#processing-new-items","title":"Processing New Items","text":""},{"location":"developer-guide/utility-functions/#process_new_itemsform-order_no-cust_id-item_class-update_catalogtrue","title":"<code>process_new_items(form, order_no, cust_id, item_class, update_catalog=True)</code>","text":"<p>Process manually added new items.</p> <p>Args: - <code>form</code>: Flask request.form object - <code>order_no</code> (str): Work order or repair order number - <code>cust_id</code> (str): Customer ID - <code>item_class</code>: WorkOrderItem or RepairWorkOrderItem class - <code>update_catalog</code> (bool): If True, add/update items in inventory catalog</p> <p>Returns: Tuple of (items, catalog_updates) - <code>items</code>: List of item instances (not yet added to session) - <code>catalog_updates</code>: List of inventory items to add/update</p> <p>Form Data Expected: - <code>new_item_description[]</code>: Array of descriptions - <code>new_item_material[]</code>: Array of materials - <code>new_item_qty[]</code>: Array of quantities - <code>new_item_condition[]</code>: Array of conditions - <code>new_item_color[]</code>: Array of colors - <code>new_item_size[]</code>: Array of sizes - <code>new_item_price[]</code>: Array of prices</p> <p>Example: <pre><code>from utils.order_item_helpers import process_new_items\nfrom models.work_order import WorkOrderItem\n\nitems, catalog_updates = process_new_items(\n    request.form,\n    next_wo_no,\n    customer.CustID,\n    WorkOrderItem,\n    update_catalog=True\n)\n\n# Add all items to session\nfor item in items:\n    db.session.add(item)\n\nfor inv in catalog_updates:\n    db.session.add(inv)\n\ndb.session.commit()\n</code></pre></p> <p>Catalog Update Behavior: - If <code>update_catalog=True</code>, automatically calls <code>add_or_update_catalog()</code> for each new item - Updates quantity if item with same attributes already exists in catalog - Creates new catalog entry if item doesn't exist - Displays flash messages to user about catalog changes</p>"},{"location":"developer-guide/utility-functions/#catalog-management","title":"Catalog Management","text":""},{"location":"developer-guide/utility-functions/#add_or_update_catalogcust_id-description-material-condition-color-size-price-qty","title":"<code>add_or_update_catalog(cust_id, description, material, condition, color, size, price, qty)</code>","text":"<p>Add a new item to the inventory catalog or update existing quantity.</p> <p>Args: - <code>cust_id</code> (str): Customer ID - <code>description</code> (str): Item description - <code>material</code> (str): Material type - <code>condition</code> (str): Item condition - <code>color</code> (str): Item color - <code>size</code> (str): Size/weight - <code>price</code> (str/float): Price - <code>qty</code> (int): Quantity to add</p> <p>Returns: Inventory object (new or updated), or None if no action needed</p> <p>Example: <pre><code>from utils.order_item_helpers import add_or_update_catalog\n\ninv_item = add_or_update_catalog(\n    cust_id=\"CUST001\",\n    description=\"Canvas Awning\",\n    material=\"Sunbrella\",\n    condition=\"Good\",\n    color=\"Blue\",\n    size=\"10x12\",\n    price=\"150.00\",\n    qty=1\n)\n\nif inv_item:\n    db.session.add(inv_item)\n    db.session.commit()\n</code></pre></p> <p>Behavior: 1. Searches for existing inventory item by customer + attributes 2. If found: Increments quantity (read-modify-write pattern - see note below) 3. If not found: Creates new inventory item with generated key</p> <p>Race Condition Note (Issue #95): The read-modify-write pattern at lines 281-283 is technically susceptible to race conditions, but this is safe for the awning business workflow because: - Only one user works on a customer's orders at a time - Low collision probability even with concurrent users - Item specificity requires exact attribute match</p> <p>If workflow changes to support concurrent editing, use atomic SQL update: <pre><code>db.session.execute(\n    update(Inventory)\n    .where(Inventory.InventoryKey == existing_inventory.InventoryKey)\n    .values(Qty=Inventory.Qty + qty)\n)\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#form-helpers","title":"Form Helpers","text":"<p>Module: <code>utils/form_helpers.py</code></p> <p>Provides reusable functions for extracting and validating form data, reducing code duplication in create/edit route handlers.</p>"},{"location":"developer-guide/utility-functions/#work-order-forms","title":"Work Order Forms","text":""},{"location":"developer-guide/utility-functions/#extract_work_order_fieldsform","title":"<code>extract_work_order_fields(form)</code>","text":"<p>Extract all work order fields from form into dict.</p> <p>Args: - <code>form</code>: Flask request.form or dict-like object</p> <p>Returns: Dict ready to pass to <code>WorkOrder(**data)</code></p> <p>Raises: ValueError for validation errors</p> <p>Example: <pre><code>from utils.form_helpers import extract_work_order_fields\n\ntry:\n    wo_data = extract_work_order_fields(request.form)\n    work_order = WorkOrder(WorkOrderNo=next_wo_no, **wo_data)\n    db.session.add(work_order)\n    db.session.commit()\nexcept ValueError as e:\n    flash(str(e), 'error')\n</code></pre></p> <p>Validation: - Requires <code>CustID</code> - Requires <code>WOName</code></p> <p>Boolean Fields: Automatically handles checkbox conversion for: - <code>RepairsNeeded</code> - <code>RushOrder</code> - <code>FirmRush</code></p> <p>Date Fields: Uses <code>parse_form_date()</code> for: - <code>DateIn</code> - <code>DateRequired</code> - <code>Clean</code> - <code>Treat</code> - <code>DateCompleted</code></p>"},{"location":"developer-guide/utility-functions/#repair-order-forms","title":"Repair Order Forms","text":""},{"location":"developer-guide/utility-functions/#extract_repair_order_fieldsform","title":"<code>extract_repair_order_fields(form)</code>","text":"<p>Extract all repair order fields from form into dict.</p> <p>Args: - <code>form</code>: Flask request.form or dict-like object</p> <p>Returns: Dict ready to pass to <code>RepairWorkOrder(**data)</code></p> <p>Raises: ValueError for validation errors</p> <p>Example: <pre><code>from utils.form_helpers import extract_repair_order_fields\n\ntry:\n    ro_data = extract_repair_order_fields(request.form)\n    repair_order = RepairWorkOrder(RepairOrderNo=next_ro_no, **ro_data)\n    db.session.add(repair_order)\n    db.session.commit()\nexcept ValueError as e:\n    flash(str(e), 'error')\n</code></pre></p> <p>Validation: - Requires <code>CustID</code> - Requires <code>ROName</code></p> <p>Boolean Fields: - <code>RushOrder</code> - <code>FirmRush</code></p> <p>Date Fields: - <code>DateIn</code> - <code>DateRequired</code> - <code>DateCompleted</code></p>"},{"location":"developer-guide/utility-functions/#date-helpers","title":"Date Helpers","text":"<p>Module: <code>utils/date_helpers.py</code></p> <p>Provides reusable functions for parsing dates from forms and formatting dates for JSON API responses.</p>"},{"location":"developer-guide/utility-functions/#form-date-parsing","title":"Form Date Parsing","text":""},{"location":"developer-guide/utility-functions/#parse_form_dateform-field_name-requiredfalse-defaultnone","title":"<code>parse_form_date(form, field_name, required=False, default=None)</code>","text":"<p>Parse date from form with consistent error handling.</p> <p>Args: - <code>form</code>: Flask request.form or dict-like object - <code>field_name</code> (str): Name of the form field - <code>required</code> (bool): If True, raises ValueError if field is missing - <code>default</code>: Default value if field is empty (only used if not required)</p> <p>Returns: date object or None (or default value)</p> <p>Raises: ValueError if required and missing, or if date format is invalid</p> <p>Examples: <pre><code>from utils.date_helpers import parse_form_date\nfrom datetime import date\n\n# With default\nDateIn = parse_form_date(request.form, \"DateIn\", default=date.today())\n\n# Optional field\nDateRequired = parse_form_date(request.form, \"DateRequired\")\n\n# Required field\ntry:\n    DateCompleted = parse_form_date(request.form, \"DateCompleted\", required=True)\nexcept ValueError as e:\n    flash(str(e), 'error')\n</code></pre></p> <p>Supported Input Types: - HTML date input: <code>YYYY-MM-DD</code> string - Date objects (already parsed) - Datetime objects (converts to date) - Empty string or None (returns default)</p>"},{"location":"developer-guide/utility-functions/#api-date-formatting","title":"API Date Formatting","text":""},{"location":"developer-guide/utility-functions/#format_date_for_apidate_value","title":"<code>format_date_for_api(date_value)</code>","text":"<p>Convert date/datetime to YYYY-MM-DD string for JSON API responses.</p> <p>Args: - <code>date_value</code>: date, datetime, or string</p> <p>Returns: String in YYYY-MM-DD format, or None if input is None/empty</p> <p>Example: <pre><code>from utils.date_helpers import format_date_for_api\n\nresponse = {\n    \"DateIn\": format_date_for_api(work_order.DateIn),\n    \"DateRequired\": format_date_for_api(work_order.DateRequired),\n}\nreturn jsonify(response)\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#legacy-date-formatting","title":"Legacy Date Formatting","text":""},{"location":"developer-guide/utility-functions/#format_date_from_strvalue","title":"<code>format_date_from_str(value)</code>","text":"<p>Formats datetime or date string to YYYY-MM-DD format. Handles legacy database formats.</p> <p>Note: This is a legacy function kept for backward compatibility. New code should use <code>format_date_for_api()</code> instead.</p> <p>Handles: - <code>MM/DD/YY HH:MM:SS</code> strings (legacy database format) - datetime objects - date objects - YYYY-MM-DD strings (returns as-is)</p>"},{"location":"developer-guide/utility-functions/#data-processing","title":"Data Processing","text":"<p>Module: <code>utils/data_processing.py</code></p> <p>Comprehensive data cleaning and parsing utilities for analytics dashboard, handling various formats with extensive edge case support.</p>"},{"location":"developer-guide/utility-functions/#currency-parsing","title":"Currency Parsing","text":""},{"location":"developer-guide/utility-functions/#clean_numeric_stringvalue","title":"<code>clean_numeric_string(value)</code>","text":"<p>Clean currency strings to float.</p> <p>Args: - <code>value</code>: String, number, or None to clean</p> <p>Returns: Float value, or 0.0 if invalid</p> <p>Supported Formats: <pre><code>from utils.data_processing import clean_numeric_string\n\nclean_numeric_string(\"$1,234.56\")   # 1234.56\nclean_numeric_string(\"1234.56\")     # 1234.56\nclean_numeric_string(\"Approved\")    # 0.0\nclean_numeric_string(None)          # 0.0\nclean_numeric_string(\"\")            # 0.0\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#sail-weight-parsing","title":"Sail Weight Parsing","text":""},{"location":"developer-guide/utility-functions/#clean_sail_weightvalue","title":"<code>clean_sail_weight(value)</code>","text":"<p>Parse sail weight strings with pound notation.</p> <p>Args: - <code>value</code>: Sail weight string with # suffix</p> <p>Returns: Float weight value, or 0.0 if invalid</p> <p>Examples: <pre><code>from utils.data_processing import clean_sail_weight\n\nclean_sail_weight(\"30#\")    # 30.0\nclean_sail_weight(\"45#\")    # 45.0\nclean_sail_weight(\"95#\")    # 95.0\nclean_sail_weight(\"\")       # 0.0\nclean_sail_weight(\".\")      # 0.0\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#square-footage-parsing","title":"Square Footage Parsing","text":""},{"location":"developer-guide/utility-functions/#clean_square_footagevalue","title":"<code>clean_square_footage(value)</code>","text":"<p>Parse size strings from various formats into square footage.</p> <p>This is the most comprehensive parser in the system, handling:</p> <p>Dimension Formats: - Simple: <code>\"8x10\"</code> \u2192 80.0 - Feet/Inches: <code>\"10'6\\\"x8'3\\\"\"</code> \u2192 86.625 - Approximations: <code>\"~10x6\"</code> \u2192 60.0</p> <p>Pre-calculated Values: - With equals: <code>\"8x10=80'\"</code> \u2192 80.0 (uses calculated value) - Complex: <code>\"10'10x10'11=118.26'\"</code> \u2192 118.26</p> <p>Circular/Round: - <code>\"4'8R=68.48'\"</code> \u2192 68.48 - <code>\"7'R=153.86'\"</code> \u2192 153.86 - <code>\"14' round=153.86'\"</code> \u2192 153.86</p> <p>Complex Expressions: - Multiple sections: <code>\"10x5+2x3\"</code> \u2192 56.0 (sums sections) - With modifiers: <code>\"10x6-cutouts=55'\"</code> \u2192 55.0 (uses calculated) - Wings: <code>\"10'10x10'2-wings=120'\"</code> \u2192 120.0</p> <p>Other Formats: - Yardage: <code>\"44 yds.\"</code> \u2192 44.0 - Simple footage: <code>\"25'\"</code> \u2192 25.0, <code>\"318.13'\"</code> \u2192 318.13 - Each notation: <code>\"16.00 ea.\"</code> \u2192 16.0 - Sail weights: <code>\"30#\"</code> \u2192 30.0 - Plain numbers: <code>\"100\"</code> \u2192 100.0</p> <p>Invalid/Empty: - <code>\"\"</code>, <code>\".\"</code>, <code>\"na\"</code>, <code>\"*\"</code>, <code>\"?\"</code> \u2192 0.0</p> <p>Example: <pre><code>from utils.data_processing import clean_square_footage\n\nclean_square_footage(\"8x10\")                      # 80.0\nclean_square_footage(\"10'6\\\"x8'3\\\"\")              # 86.625\nclean_square_footage(\"10x6-cutouts=55'\")          # 55.0\nclean_square_footage(\"4'8R=68.48'\")               # 68.48\nclean_square_footage(\"30#\")                       # 30.0\nclean_square_footage(\"44 yds.\")                   # 44.0\n</code></pre></p> <p>Implementation Details: This function delegates to specialized parsers: - <code>_parse_dimension_string()</code> - Handles x notation - <code>_parse_circular_dimension()</code> - Handles R notation and \"round\" - <code>_parse_yardage()</code> - Handles \"yds\" notation - <code>_parse_simple_footage()</code> - Handles simple <code>'</code> notation - <code>_feet_inches_to_feet()</code> - Converts feet/inches to decimal feet - <code>_extract_calculated_value()</code> - Extracts pre-calculated values from <code>=</code> notation</p>"},{"location":"developer-guide/utility-functions/#product-type-identification","title":"Product Type Identification","text":""},{"location":"developer-guide/utility-functions/#identify_product_typesizewgt","title":"<code>identify_product_type(sizewgt)</code>","text":"<p>Identify whether an item is a Sail or Awning based on size/weight notation.</p> <p>Rules: - Contains <code>#</code> \u2192 \"Sail\" - Otherwise \u2192 \"Awning\"</p> <p>Example: <pre><code>from utils.data_processing import identify_product_type\n\nidentify_product_type(\"30#\")        # \"Sail\"\nidentify_product_type(\"10x12\")      # \"Awning\"\nidentify_product_type(None)         # \"Awning\"\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#work-order-item-processing","title":"Work Order Item Processing","text":""},{"location":"developer-guide/utility-functions/#parse_work_order_itemsitems_df-detect_outlierstrue-outlier_threshold80000-replace_with_meantrue","title":"<code>parse_work_order_items(items_df, detect_outliers=True, outlier_threshold=8000.0, replace_with_mean=True)</code>","text":"<p>Process a DataFrame of work order items, parsing sizes and identifying product types.</p> <p>Args: - <code>items_df</code> (DataFrame): DataFrame with columns: workorderno, custid, qty, sizewgt, price - <code>detect_outliers</code> (bool): Whether to detect and flag outliers (default: True) - <code>outlier_threshold</code> (float): Square footage threshold for outlier detection (default: 8000.0) - <code>replace_with_mean</code> (bool): Whether to replace outliers with mean (default: True)</p> <p>Returns: DataFrame with additional computed columns: - <code>price_numeric</code>: Cleaned price as float - <code>product_type</code>: \"Sail\" or \"Awning\" - <code>qty_numeric</code>: Cleaned quantity as float - <code>sqft</code>: Total square footage (qty * parsed size) - ONLY for Awnings, 0.0 for Sails - <code>is_outlier</code>: Boolean flag for extreme outliers</p> <p>Note on Sail Exclusion: Sails are identified by the presence of <code>#</code> in the sizewgt field and are excluded from square footage calculations. This prevents skewing analytics with sail weights.</p> <p>Outlier Detection: Automatically detects extreme outliers (default &gt; 8000 sqft) which are likely data entry errors: - Example: <code>\"29x11319'\"</code> should be <code>\"29x11.319'\"</code> - Can optionally replace outliers with the mean value of similar-sized items</p> <p>Example: <pre><code>from utils.data_processing import parse_work_order_items\nimport pandas as pd\n\nitems_df = pd.DataFrame({\n    'workorderno': ['WO000001', 'WO000002'],\n    'custid': ['CUST001', 'CUST002'],\n    'qty': [1, 2],\n    'sizewgt': ['10x12', '8x10'],\n    'price': ['$150.00', '$120.00']\n})\n\nprocessed = parse_work_order_items(\n    items_df,\n    detect_outliers=True,\n    outlier_threshold=10000.0\n)\n\n# Access computed columns\nprint(processed[['sqft', 'product_type', 'is_outlier']])\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#file-upload","title":"File Upload","text":"<p>Module: <code>utils/file_upload.py</code></p> <p>Comprehensive file upload system with S3 integration, thumbnail generation, and deferred upload support to prevent orphaned S3 files.</p>"},{"location":"developer-guide/utility-functions/#configuration","title":"Configuration","text":"<p>Environment Variables: - <code>AWS_S3_BUCKET</code>: S3 bucket name (required) - <code>AWS_REGION</code>: AWS region (default: us-east-1) - <code>AWS_ACCESS_KEY_ID</code>: Access key (local dev only) - <code>AWS_SECRET_ACCESS_KEY</code>: Secret key (local dev only)</p> <p>Allowed Extensions: - Documents: <code>pdf</code>, <code>docx</code>, <code>txt</code>, <code>csv</code>, <code>xlsx</code> - Images: <code>jpg</code>, <code>jpeg</code>, <code>png</code></p>"},{"location":"developer-guide/utility-functions/#environment-detection","title":"Environment Detection","text":""},{"location":"developer-guide/utility-functions/#is_running_on_aws","title":"<code>is_running_on_aws()</code>","text":"<p>Detect if running in AWS environment.</p> <p>Returns: Boolean</p> <p>Checks for: - <code>AWS_EXECUTION_ENV</code> environment variable - <code>AWS_LAMBDA_FUNCTION_NAME</code> environment variable - <code>AWS_REGION</code> environment variable - <code>/var/app/current</code> directory (EB) - <code>/opt/elasticbeanstalk</code> directory (EB)</p> <p>Why This Matters: - On AWS: Uses IAM role for S3 access (no credentials needed) - Local: Uses explicit AWS credentials from environment variables</p>"},{"location":"developer-guide/utility-functions/#core-upload-functions","title":"Core Upload Functions","text":""},{"location":"developer-guide/utility-functions/#save_order_file_genericorder_no-file-order_typework_order-to_s3true-generate_thumbnailstrue-file_model_classnone-defer_s3_uploadfalse","title":"<code>save_order_file_generic(order_no, file, order_type=\"work_order\", to_s3=True, generate_thumbnails=True, file_model_class=None, defer_s3_upload=False)</code>","text":"<p>Generic function to save order files (work orders or repair orders).</p> <p>Args: - <code>order_no</code> (str): The order number - <code>file</code>: The file object to save - <code>order_type</code> (str): \"work_order\" or \"repair_order\" - <code>to_s3</code> (bool): Whether to save to S3 (True) or locally (False) - <code>generate_thumbnails</code> (bool): Whether to generate thumbnails - <code>file_model_class</code>: Model class (WorkOrderFile or RepairOrderFile) - <code>defer_s3_upload</code> (bool): If True, stores file content in memory for upload after DB commit</p> <p>Returns: File model instance (not committed to DB)</p> <p>Deferred Upload Feature: When <code>defer_s3_upload=True</code>, the function stores file content in memory and attaches temporary attributes to the file object: - <code>_deferred_file_content</code>: The file bytes to upload - <code>_deferred_s3_key</code>: The S3 key to upload to - <code>_deferred_thumbnail_content</code>: Optional thumbnail bytes - <code>_deferred_thumbnail_key</code>: Optional thumbnail S3 key</p> <p>Why Defer Uploads? Prevents orphaned S3 files when database commits fail. The workflow is: 1. Store file content in memory 2. Create database records 3. Commit database transaction 4. Only if commit succeeds, upload to S3 5. If commit fails, memory is cleaned up (no orphaned S3 files)</p> <p>Example (Immediate Upload): <pre><code>from utils.file_upload import save_work_order_file\n\nfile_obj = save_work_order_file(\n    work_order_no=\"WO000001\",\n    file=request.files['document'],\n    to_s3=True,\n    generate_thumbnails=True,\n    defer_s3_upload=False  # Upload immediately (old behavior)\n)\n\ndb.session.add(file_obj)\ndb.session.commit()\n</code></pre></p> <p>Example (Deferred Upload - Recommended): <pre><code>from utils.file_upload import save_work_order_file, commit_deferred_uploads, cleanup_deferred_files\n\n# Step 1: Process files (stores in memory)\nfile_objects = []\nfor uploaded_file in request.files.getlist('documents'):\n    file_obj = save_work_order_file(\n        work_order_no=\"WO000001\",\n        file=uploaded_file,\n        to_s3=True,\n        generate_thumbnails=True,\n        defer_s3_upload=True  # Defer upload until after DB commit\n    )\n    file_objects.append(file_obj)\n    db.session.add(file_obj)\n\n# Step 2: Try to commit DB changes\ntry:\n    db.session.add(work_order)\n    db.session.commit()\n\n    # Step 3: DB commit succeeded, upload to S3\n    success, uploaded, failed = commit_deferred_uploads(file_objects)\n    if not success:\n        flash(\"Some files failed to upload\", \"warning\")\n\nexcept Exception as e:\n    db.session.rollback()\n\n    # Step 4: DB commit failed, clean up memory (no S3 orphans!)\n    cleanup_deferred_files(file_objects)\n    flash(f\"Error: {e}\", \"error\")\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#wrapper-functions","title":"Wrapper Functions","text":""},{"location":"developer-guide/utility-functions/#save_work_order_filework_order_no-file-to_s3true-generate_thumbnailstrue-defer_s3_uploadfalse","title":"<code>save_work_order_file(work_order_no, file, to_s3=True, generate_thumbnails=True, defer_s3_upload=False)</code>","text":"<p>Save work order file - wrapper around <code>save_order_file_generic()</code>.</p>"},{"location":"developer-guide/utility-functions/#save_repair_order_filerepair_order_no-file-to_s3true-generate_thumbnailstrue-defer_s3_uploadfalse","title":"<code>save_repair_order_file(repair_order_no, file, to_s3=True, generate_thumbnails=True, defer_s3_upload=False)</code>","text":"<p>Save repair order file - wrapper around <code>save_order_file_generic()</code>.</p>"},{"location":"developer-guide/utility-functions/#deferred-upload-management","title":"Deferred Upload Management","text":""},{"location":"developer-guide/utility-functions/#commit_deferred_uploadsfile_objects","title":"<code>commit_deferred_uploads(file_objects)</code>","text":"<p>Upload files to S3 that were deferred until after DB commit.</p> <p>Args: - <code>file_objects</code> (list): List of file model objects with deferred upload data</p> <p>Returns: Tuple of (success, uploaded_files, failed_files) - <code>success</code> (bool): True if all uploads succeeded - <code>uploaded_files</code> (list): List of successfully uploaded file objects - <code>failed_files</code> (list): List of (file_obj, error_message) tuples</p> <p>Example: <pre><code>success, uploaded, failed = commit_deferred_uploads(file_objects)\n\nif not success:\n    for file_obj, error in failed:\n        print(f\"Failed to upload {file_obj.filename}: {error}\")\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#cleanup_deferred_filesfile_objects","title":"<code>cleanup_deferred_files(file_objects)</code>","text":"<p>Clean up memory for files that were staged for deferred upload but the transaction was rolled back.</p> <p>Args: - <code>file_objects</code> (list): List of file model objects with deferred upload data</p> <p>Purpose: Prevents memory leaks by removing temporary attributes after rollback.</p>"},{"location":"developer-guide/utility-functions/#file-utilities","title":"File Utilities","text":""},{"location":"developer-guide/utility-functions/#allowed_filefilename_1","title":"<code>allowed_file(filename)</code>","text":"<p>Check if uploaded file has allowed extension.</p>"},{"location":"developer-guide/utility-functions/#get_file_sizefile_path","title":"<code>get_file_size(file_path)</code>","text":"<p>Get human-readable file size.</p> <p>Args: - <code>file_path</code> (str): S3 path (s3://...) or local path</p> <p>Returns: Human-readable size string (e.g., \"1.5 MB\") or None if file not found</p> <p>Example: <pre><code>from utils.file_upload import get_file_size\n\nget_file_size(\"s3://my-bucket/file.pdf\")     # \"2.3 MB\"\nget_file_size(\"/path/to/local/file.pdf\")     # \"1.5 MB\"\nget_file_size(\"s3://my-bucket/missing.pdf\")  # None\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#presigned-urls","title":"Presigned URLs","text":""},{"location":"developer-guide/utility-functions/#generate_presigned_urlfile_path-expires_in3600","title":"<code>generate_presigned_url(file_path, expires_in=3600)</code>","text":"<p>Generate a pre-signed URL for S3 file access.</p> <p>Args: - <code>file_path</code> (str): Full S3 path (s3://bucket/key) - <code>expires_in</code> (int): URL expiration in seconds (default: 3600 = 1 hour)</p> <p>Returns: Pre-signed URL string</p> <p>Example: <pre><code>from utils.file_upload import generate_presigned_url\n\nurl = generate_presigned_url(\"s3://my-bucket/file.pdf\", expires_in=7200)\n# User can access this URL for 2 hours\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#generate_thumbnail_presigned_urlthumbnail_path-expires_in3600","title":"<code>generate_thumbnail_presigned_url(thumbnail_path, expires_in=3600)</code>","text":"<p>Generate presigned URL for thumbnail.</p>"},{"location":"developer-guide/utility-functions/#get_file_with_thumbnail_urlswo_file-expires_in3600","title":"<code>get_file_with_thumbnail_urls(wo_file, expires_in=3600)</code>","text":"<p>Get file URLs including thumbnail for a WorkOrderFile object.</p> <p>Returns: Dict with keys: - <code>file</code>: The WorkOrderFile object - <code>file_url</code>: Presigned URL or file path - <code>thumbnail_url</code>: Presigned thumbnail URL or None - <code>has_thumbnail</code>: Boolean</p>"},{"location":"developer-guide/utility-functions/#s3-file-management","title":"S3 File Management","text":""},{"location":"developer-guide/utility-functions/#delete_file_from_s3file_path","title":"<code>delete_file_from_s3(file_path)</code>","text":"<p>Delete a file from S3 given its full s3:// path.</p> <p>Args: - <code>file_path</code> (str): Full S3 path (e.g., s3://bucket-name/path/to/file.jpg)</p> <p>Returns: Boolean (True on success, False on failure)</p> <p>Example: <pre><code>from utils.file_upload import delete_file_from_s3\n\n# Delete file\nsuccess = delete_file_from_s3(\"s3://my-bucket/work_orders/WO000001/file.pdf\")\n\n# Also handles thumbnails\ndelete_file_from_s3(\"s3://my-bucket/work_orders/WO000001/thumbnails/file_thumb.jpg\")\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#ml-model-management","title":"ML Model Management","text":""},{"location":"developer-guide/utility-functions/#save_ml_modelmodel-metadata-model_namelatest_model","title":"<code>save_ml_model(model, metadata, model_name=\"latest_model\")</code>","text":"<p>Save a trained ML model and its metadata to S3.</p> <p>Args: - <code>model</code>: Trained model object (will be pickled) - <code>metadata</code> (dict): Model metadata - <code>model_name</code> (str): Model name (default: \"latest_model\")</p> <p>Returns: Dict with keys: - <code>model_path</code>: S3 path to model pickle - <code>metadata_path</code>: S3 path to metadata JSON - <code>saved_at</code>: Timestamp string</p> <p>Example: <pre><code>from utils.file_upload import save_ml_model\n\nmetadata = {\n    \"mae\": 2.5,\n    \"features\": [\"sqft\", \"rush_order\"],\n    \"trained_on\": \"2024-01-15\"\n}\n\nresult = save_ml_model(model, metadata, \"production_model_v2\")\nprint(result[\"model_path\"])  # s3://bucket/ml_models/production_model_v2.pkl\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#load_ml_modelmodel_namelatest_model","title":"<code>load_ml_model(model_name=\"latest_model\")</code>","text":"<p>Load a trained ML model and its metadata from S3.</p> <p>Returns: Tuple of (model, metadata) or (None, None) if not found</p>"},{"location":"developer-guide/utility-functions/#list_saved_models","title":"<code>list_saved_models()</code>","text":"<p>List all saved models in S3.</p> <p>Returns: List of dicts with keys: name, size, last_modified</p>"},{"location":"developer-guide/utility-functions/#delete_ml_modelmodel_name","title":"<code>delete_ml_model(model_name)</code>","text":"<p>Delete a model and its metadata from S3.</p>"},{"location":"developer-guide/utility-functions/#cache-helpers","title":"Cache Helpers","text":"<p>Module: <code>utils/cache_helpers.py</code></p> <p>Caching decorators and helper functions to optimize database queries and expensive computations.</p>"},{"location":"developer-guide/utility-functions/#cache-decorator","title":"Cache Decorator","text":""},{"location":"developer-guide/utility-functions/#cached_querytimeout300-key_prefixnone","title":"<code>@cached_query(timeout=300, key_prefix=None)</code>","text":"<p>Decorator to cache database query results.</p> <p>Args: - <code>timeout</code> (int): Cache timeout in seconds (default: 300 = 5 minutes) - <code>key_prefix</code> (str): Optional custom cache key prefix</p> <p>Example: <pre><code>from utils.cache_helpers import cached_query\nfrom models.source import Source\n\n@cached_query(timeout=600)  # Cache for 10 minutes\ndef get_all_sources():\n    return Source.query.order_by(Source.SSource).all()\n\n# First call: hits database\nsources = get_all_sources()\n\n# Second call within 10 minutes: returns cached result\nsources = get_all_sources()\n</code></pre></p> <p>Cache Key Generation: - Function name - Arguments (positional and keyword) - Key format: <code>query:function_name:arg1:arg2:key1=val1:key2=val2</code></p>"},{"location":"developer-guide/utility-functions/#cache-invalidation","title":"Cache Invalidation","text":""},{"location":"developer-guide/utility-functions/#invalidate_cache_patternpattern","title":"<code>invalidate_cache_pattern(pattern)</code>","text":"<p>Invalidate all cache keys matching a pattern.</p> <p>Args: - <code>pattern</code> (str): Pattern to match (e.g., \"query:get_customer_*\")</p> <p>Note: - For RedisCache (production), uses Redis SCAN to delete matching keys - For SimpleCache (development), this is a no-op</p>"},{"location":"developer-guide/utility-functions/#invalidate_customer_cache","title":"<code>invalidate_customer_cache()</code>","text":"<p>Invalidate customer-related cache entries. Call when customer data is modified.</p> <p>Example: <pre><code>from utils.cache_helpers import invalidate_customer_cache\n\n# After updating customer\ncustomer.CompanyName = \"New Name\"\ndb.session.commit()\ninvalidate_customer_cache()\n</code></pre></p>"},{"location":"developer-guide/utility-functions/#invalidate_source_cache","title":"<code>invalidate_source_cache()</code>","text":"<p>Invalidate source-related cache entries.</p>"},{"location":"developer-guide/utility-functions/#invalidate_work_order_cachework_order_nonone","title":"<code>invalidate_work_order_cache(work_order_no=None)</code>","text":"<p>Invalidate work order-related cache entries.</p> <p>Args: - <code>work_order_no</code> (str): Optional specific work order to invalidate</p>"},{"location":"developer-guide/utility-functions/#invalidate_repair_order_cacherepair_order_nonone","title":"<code>invalidate_repair_order_cache(repair_order_no=None)</code>","text":"<p>Invalidate repair order-related cache entries.</p>"},{"location":"developer-guide/utility-functions/#invalidate_analytics_cache","title":"<code>invalidate_analytics_cache()</code>","text":"<p>Invalidate analytics-related cache entries.</p>"},{"location":"developer-guide/utility-functions/#clear_all_caches","title":"<code>clear_all_caches()</code>","text":"<p>Clear all application caches.</p> <p>Warning: Use with caution - only in development or after major data migrations.</p>"},{"location":"developer-guide/utility-functions/#pdf-helpers","title":"PDF Helpers","text":"<p>Module: <code>utils/pdf_helpers.py</code></p> <p>For detailed PDF generation documentation, see PDF Generation Guide.</p>"},{"location":"developer-guide/utility-functions/#thumbnail-generator","title":"Thumbnail Generator","text":"<p>Module: <code>utils/thumbnail_generator.py</code></p>"},{"location":"developer-guide/utility-functions/#generate_thumbnailfile_content-filename","title":"<code>generate_thumbnail(file_content, filename)</code>","text":"<p>Generate thumbnail from image file content.</p>"},{"location":"developer-guide/utility-functions/#save_thumbnail_to_s3thumbnail_img-s3_client-bucket-s3_key","title":"<code>save_thumbnail_to_s3(thumbnail_img, s3_client, bucket, s3_key)</code>","text":"<p>Save thumbnail to S3.</p>"},{"location":"developer-guide/utility-functions/#save_thumbnail_locallythumbnail_img-file_path","title":"<code>save_thumbnail_locally(thumbnail_img, file_path)</code>","text":"<p>Save thumbnail to local filesystem.</p>"},{"location":"developer-guide/utility-functions/#usage-patterns","title":"Usage Patterns","text":""},{"location":"developer-guide/utility-functions/#common-import-pattern","title":"Common Import Pattern","text":"<pre><code># General helpers\nfrom utils.helpers import (\n    format_phone_number,\n    generate_work_order_number,\n    safe_bool_convert,\n    get_status_color\n)\n\n# Order item processing\nfrom utils.order_item_helpers import (\n    process_selected_inventory_items,\n    process_new_items,\n    safe_int_conversion,\n    safe_price_conversion\n)\n\n# Form processing\nfrom utils.form_helpers import (\n    extract_work_order_fields,\n    extract_repair_order_fields\n)\n\n# Date handling\nfrom utils.date_helpers import (\n    parse_form_date,\n    format_date_for_api\n)\n\n# File uploads\nfrom utils.file_upload import (\n    save_work_order_file,\n    commit_deferred_uploads,\n    cleanup_deferred_files\n)\n\n# Caching\nfrom utils.cache_helpers import (\n    cached_query,\n    invalidate_work_order_cache\n)\n</code></pre>"},{"location":"developer-guide/utility-functions/#complete-work-order-creation-example","title":"Complete Work Order Creation Example","text":"<pre><code>from flask import request, flash, redirect, url_for\nfrom utils.helpers import generate_work_order_number\nfrom utils.form_helpers import extract_work_order_fields\nfrom utils.order_item_helpers import process_selected_inventory_items, process_new_items\nfrom utils.file_upload import save_work_order_file, commit_deferred_uploads, cleanup_deferred_files\nfrom models.work_order import WorkOrder, WorkOrderItem\nfrom extensions import db\n\n@work_orders_bp.route('/create', methods=['POST'])\ndef create_work_order():\n    try:\n        # Generate order number\n        next_wo_no = generate_work_order_number()\n\n        # Extract form fields\n        wo_data = extract_work_order_fields(request.form)\n        work_order = WorkOrder(WorkOrderNo=next_wo_no, **wo_data)\n\n        # Process items from inventory\n        items = process_selected_inventory_items(\n            request.form,\n            next_wo_no,\n            wo_data['CustID'],\n            WorkOrderItem\n        )\n\n        # Process new items\n        new_items, catalog_updates = process_new_items(\n            request.form,\n            next_wo_no,\n            wo_data['CustID'],\n            WorkOrderItem,\n            update_catalog=True\n        )\n\n        # Process file uploads (deferred)\n        file_objects = []\n        for uploaded_file in request.files.getlist('documents'):\n            file_obj = save_work_order_file(\n                work_order_no=next_wo_no,\n                file=uploaded_file,\n                to_s3=True,\n                generate_thumbnails=True,\n                defer_s3_upload=True  # Prevent S3 orphans\n            )\n            file_objects.append(file_obj)\n\n        # Add everything to session\n        db.session.add(work_order)\n        for item in items + new_items:\n            db.session.add(item)\n        for inv in catalog_updates:\n            db.session.add(inv)\n        for file_obj in file_objects:\n            db.session.add(file_obj)\n\n        # Commit database changes\n        db.session.commit()\n\n        # Upload files to S3 (only after successful commit)\n        success, uploaded, failed = commit_deferred_uploads(file_objects)\n        if not success:\n            flash(\"Some files failed to upload\", \"warning\")\n\n        flash(f\"Work order {next_wo_no} created successfully\", \"success\")\n        return redirect(url_for('work_orders.view', work_order_no=next_wo_no))\n\n    except ValueError as e:\n        db.session.rollback()\n        cleanup_deferred_files(file_objects)\n        flash(str(e), 'error')\n        return redirect(url_for('work_orders.create_form'))\n\n    except Exception as e:\n        db.session.rollback()\n        cleanup_deferred_files(file_objects)\n        flash(f\"Error creating work order: {e}\", 'error')\n        return redirect(url_for('work_orders.create_form'))\n</code></pre>"},{"location":"developer-guide/utility-functions/#best-practices","title":"Best Practices","text":""},{"location":"developer-guide/utility-functions/#data-validation","title":"Data Validation","text":"<ol> <li>Always use safe conversion functions (<code>safe_int_conversion</code>, <code>safe_price_conversion</code>) when processing form data</li> <li>Validate required fields using form helper functions</li> <li>Handle exceptions with try-except blocks and user-friendly error messages</li> </ol>"},{"location":"developer-guide/utility-functions/#file-uploads","title":"File Uploads","text":"<ol> <li>Use deferred uploads (<code>defer_s3_upload=True</code>) to prevent orphaned S3 files</li> <li>Always clean up deferred files on rollback using <code>cleanup_deferred_files()</code></li> <li>Check allowed file types before processing uploads</li> <li>Generate thumbnails for images to improve user experience</li> </ol>"},{"location":"developer-guide/utility-functions/#caching","title":"Caching","text":"<ol> <li>Cache expensive queries using <code>@cached_query</code> decorator</li> <li>Invalidate caches when data changes using appropriate <code>invalidate_*_cache()</code> functions</li> <li>Use appropriate timeouts based on data volatility</li> </ol>"},{"location":"developer-guide/utility-functions/#date-handling","title":"Date Handling","text":"<ol> <li>Use <code>parse_form_date()</code> for all form date fields</li> <li>Use <code>format_date_for_api()</code> for JSON API responses</li> <li>Handle None values gracefully with default parameters</li> </ol>"},{"location":"developer-guide/utility-functions/#error-handling","title":"Error Handling","text":"<ol> <li>Catch specific exceptions (ValueError, KeyError, etc.)</li> <li>Provide user-friendly messages via flash()</li> <li>Log errors for debugging (use print() or logging module)</li> <li>Rollback transactions on errors to maintain data integrity</li> </ol>"},{"location":"developer-guide/utility-functions/#see-also","title":"See Also","text":"<ul> <li>Forms and Validation - Detailed form handling patterns</li> <li>File Uploads - Comprehensive file upload guide</li> <li>Database Schema - Database models and relationships</li> <li>Testing - Testing utility functions</li> <li>CLAUDE.md - Main project documentation</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/","title":"Source Name Denormalization - Feasibility Analysis","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#executive-summary","title":"Executive Summary","text":"<p>\u2705 HIGHLY FEASIBLE - Adding a denormalized <code>source_name</code> column is straightforward and requires minimal code changes.</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#benefits","title":"Benefits","text":"<ul> <li>93ms \u2192 ~1ms for Source sorting (100x faster!)</li> <li>Simplified queries - no more 3-table joins</li> <li>Better filtering performance</li> <li>Still maintains referential integrity through existing relationships</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#required-changes","title":"Required Changes","text":"<ul> <li>1 model change (add column + property)</li> <li>1 route change (API endpoint)</li> <li>1 trigger (keep data in sync)</li> <li>Migration script</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#current-architecture","title":"Current Architecture","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#how-source-info-is-currently-accessed","title":"How Source Info is Currently Accessed","text":"<pre><code>WorkOrder (tblcustworkorderdetail)\n  \u2193 custid\nCustomer (tblcustomers)\n  \u2193 source\nSource (tblsource.ssource)\n</code></pre> <p>Current query for Source name: <pre><code># In routes/work_orders.py:1080\n\"Source\": wo.customer.source_info.SSource\n    if wo.customer and wo.customer.source_info\n    else None\n</code></pre></p> <p>This requires: 1. Join <code>work_orders \u2192 customers</code> 2. Join <code>customers \u2192 sources</code> 3. Access <code>source_info.SSource</code></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#two-different-source-concepts","title":"Two Different \"Source\" Concepts","text":"<p>\u26a0\ufe0f IMPORTANT: Your codebase has 2 different meanings of \"Source\":</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#1-customers-source-where-customer-came-from","title":"1. Customer's Source (where customer came from)","text":"<ul> <li><code>customer.Source</code> \u2192 foreign key to <code>tblsource.ssource</code></li> <li><code>customer.source_info</code> \u2192 relationship to Source model</li> <li>Used for: \"Where did we acquire this customer?\"</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#2-work-orders-shipto-where-to-ship-the-order","title":"2. Work Order's ShipTo (where to ship the order)","text":"<ul> <li><code>work_order.ShipTo</code> \u2192 foreign key to <code>tblsource.ssource</code></li> <li><code>work_order.ship_to_source</code> \u2192 relationship to Source model</li> <li>Used for: \"Where should we ship this order?\"</li> </ul> <p>In the API endpoint, \"Source\" refers to the CUSTOMER's source, not ShipTo!</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#proposed-solution","title":"Proposed Solution","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#schema-change","title":"Schema Change","text":"<pre><code>-- Add denormalized column\nALTER TABLE tblcustworkorderdetail\nADD COLUMN source_name TEXT;\n\n-- Create index for fast filtering/sorting\nCREATE INDEX idx_workorder_source_name\nON tblcustworkorderdetail(source_name);\n\n-- Populate existing records\nUPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nJOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n\n-- Add index for shipto too (currently exists but let's verify)\nCREATE INDEX IF NOT EXISTS idx_workorder_shipto\nON tblcustworkorderdetail(shipto);\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#model-changes","title":"Model Changes","text":"<p>File: models/work_order.py</p> <pre><code>class WorkOrder(db.Model):\n    __tablename__ = \"tblcustworkorderdetail\"\n\n    # ... existing fields ...\n\n    ShipTo = db.Column(\"shipto\", db.String, db.ForeignKey(\"tblsource.ssource\"))\n\n    # NEW: Denormalized source name from customer\n    source_name = db.Column(\"source_name\", db.Text, nullable=True)\n\n    # ... existing relationships ...\n\n    ship_to_source = db.relationship(\n        \"Source\",\n        primaryjoin=\"WorkOrder.ShipTo==Source.SSource\",\n        lazy=\"joined\",\n        uselist=False,\n    )\n\n    # NEW: Computed property to get source name (with fallback)\n    @property\n    def customer_source_name(self):\n        \"\"\"Get customer's source name (with fallback to relationship)\"\"\"\n        # Use denormalized value if available\n        if self.source_name:\n            return self.source_name\n        # Fallback to relationship (for backward compatibility)\n        if self.customer and self.customer.source_info:\n            return self.customer.source_info.SSource\n        return None\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#code-changes-required","title":"Code Changes Required","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-1-api-endpoint-routeswork_orderspy1073-1083","title":"\u2705 Change 1: API Endpoint (routes/work_orders.py:1073-1083)","text":"<p>BEFORE: <pre><code>data = [\n    {\n        \"WorkOrderNo\": wo.WorkOrderNo,\n        \"CustID\": wo.CustID,\n        \"WOName\": wo.WOName,\n        \"DateIn\": format_date_from_str(wo.DateIn),\n        \"DateRequired\": format_date_from_str(wo.DateRequired),\n        \"Source\": wo.customer.source_info.SSource\n            if wo.customer and wo.customer.source_info\n            else None,\n        # ... rest ...\n    }\n    for wo in work_orders.items\n]\n</code></pre></p> <p>AFTER: <pre><code>data = [\n    {\n        \"WorkOrderNo\": wo.WorkOrderNo,\n        \"CustID\": wo.CustID,\n        \"WOName\": wo.WOName,\n        \"DateIn\": format_date_from_str(wo.DateIn),\n        \"DateRequired\": format_date_from_str(wo.DateRequired),\n        \"Source\": wo.source_name,  # \u2190 Changed! Now uses denormalized column\n        # ... rest ...\n    }\n    for wo in work_orders.items\n]\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-2-query-optimization-routeswork_orderspy943-955","title":"\u2705 Change 2: Query Optimization (routes/work_orders.py:943-955)","text":"<p>BEFORE: <pre><code># Conditionally join and eager load relationships\nif is_source_filter or is_source_sort:\n    query = query.join(WorkOrder.customer).join(Customer.source_info)\n    query = query.options(\n        joinedload(WorkOrder.customer).joinedload(Customer.source_info)\n    )\nelse:\n    query = query.options(joinedload(WorkOrder.customer))\n</code></pre></p> <p>AFTER: <pre><code># No need for source joins anymore! Just load customer\nquery = query.options(joinedload(WorkOrder.customer))\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-3-source-filter-routeswork_orderspy1006-1007","title":"\u2705 Change 3: Source Filter (routes/work_orders.py:1006-1007)","text":"<p>BEFORE: <pre><code>if is_source_filter:\n    query = query.filter(Source.SSource.ilike(f\"%{is_source_filter}%\"))\n</code></pre></p> <p>AFTER: <pre><code>if is_source_filter:\n    query = query.filter(WorkOrder.source_name.ilike(f\"%{is_source_filter}%\"))\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-4-source-sorting-routeswork_orderspy1032-1038","title":"\u2705 Change 4: Source Sorting (routes/work_orders.py:1032-1038)","text":"<p>BEFORE: <pre><code>if field == \"Source\":\n    # The query is already joined, so we can sort on the joined table's column\n    column_to_sort = Source.SSource\n    if direction == \"desc\":\n        order_by_clauses.append(column_to_sort.desc())\n    else:\n        order_by_clauses.append(column_to_sort.asc())\n</code></pre></p> <p>AFTER: <pre><code>if field == \"Source\":\n    # Use denormalized column for sorting\n    column_to_sort = WorkOrder.source_name\n    if direction == \"desc\":\n        order_by_clauses.append(column_to_sort.desc())\n    else:\n        order_by_clauses.append(column_to_sort.asc())\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-5-maintain-data-on-create-routeswork_orderspy383-417","title":"\u2705 Change 5: Maintain Data on Create (routes/work_orders.py:383-417)","text":"<p>Add after line 417: <pre><code>work_order = WorkOrder(\n    WorkOrderNo=next_wo_no,\n    CustID=request.form.get(\"CustID\"),\n    WOName=request.form.get(\"WOName\"),\n    # ... all existing fields ...\n    ShipTo=request.form.get(\"ShipTo\"),\n)\n\n# NEW: Set source_name from customer\ncustomer = Customer.query.get(request.form.get(\"CustID\"))\nif customer and customer.Source:\n    source = Source.query.get(customer.Source)\n    if source:\n        work_order.source_name = source.SSource\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#change-6-maintain-data-on-edit-routeswork_orderspy597-607","title":"\u2705 Change 6: Maintain Data on Edit (routes/work_orders.py:597-607)","text":"<p>Add after line 607: <pre><code># Update work order fields\nwork_order.CustID = request.form.get(\"CustID\")\n# ... other fields ...\n\n# NEW: Update source_name if customer changed\nif work_order.CustID != old_cust_id:  # Track old value\n    customer = Customer.query.get(work_order.CustID)\n    if customer and customer.Source:\n        source = Source.query.get(customer.Source)\n        if source:\n            work_order.source_name = source.SSource\n    else:\n        work_order.source_name = None\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#data-consistency-strategy","title":"Data Consistency Strategy","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#option-a-application-level-maintenance-recommended","title":"Option A: Application-Level Maintenance (RECOMMENDED)","text":"<p>Pros: - Simple, no database triggers - Easy to debug - Explicit control</p> <p>Implementation: Add helper method to WorkOrder model:</p> <pre><code>class WorkOrder(db.Model):\n    # ... fields ...\n\n    def sync_source_name(self):\n        \"\"\"Update source_name from customer's source\"\"\"\n        if self.customer and self.customer.source_info:\n            self.source_name = self.customer.source_info.SSource\n        else:\n            self.source_name = None\n</code></pre> <p>Call in routes: <pre><code># After creating/updating work order\nwork_order.sync_source_name()\ndb.session.commit()\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#option-b-database-trigger-automatic","title":"Option B: Database Trigger (AUTOMATIC)","text":"<p>Pros: - Automatic, can't forget - Works for bulk updates - Consistent across all entry points</p> <p>Cons: - Harder to debug - Database-specific</p> <p>Implementation: <pre><code>-- Trigger to auto-update source_name on insert/update\nCREATE OR REPLACE FUNCTION sync_work_order_source_name()\nRETURNS TRIGGER AS $$\nBEGIN\n    -- Update source_name from customer's source\n    SELECT s.ssource INTO NEW.source_name\n    FROM tblcustomers c\n    LEFT JOIN tblsource s ON c.source = s.ssource\n    WHERE c.custid = NEW.custid;\n\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_sync_work_order_source_name\n    BEFORE INSERT OR UPDATE OF custid ON tblcustworkorderdetail\n    FOR EACH ROW\n    EXECUTE FUNCTION sync_work_order_source_name();\n</code></pre></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#option-c-hybrid-best","title":"Option C: Hybrid (BEST)","text":"<ul> <li>Use application-level sync for create/edit forms (explicit)</li> <li>Use trigger as safety net for bulk operations</li> <li>Use periodic sync job to fix any drift</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#migration-steps","title":"Migration Steps","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#1-create-migration-script","title":"1. Create Migration Script","text":"<pre><code>-- File: query_optimization/add_source_name_column.sql\n\nBEGIN;\n\n-- Step 1: Add column\nALTER TABLE tblcustworkorderdetail\nADD COLUMN source_name TEXT;\n\n-- Step 2: Populate existing records\nUPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nLEFT JOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n\n-- Step 3: Create index\nCREATE INDEX idx_workorder_source_name\nON tblcustworkorderdetail(source_name);\n\n-- Step 4: Create trigger (optional, for automatic sync)\nCREATE OR REPLACE FUNCTION sync_work_order_source_name()\nRETURNS TRIGGER AS $$\nBEGIN\n    SELECT s.ssource INTO NEW.source_name\n    FROM tblcustomers c\n    LEFT JOIN tblsource s ON c.source = s.ssource\n    WHERE c.custid = NEW.custid;\n\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_sync_work_order_source_name\n    BEFORE INSERT OR UPDATE OF custid ON tblcustworkorderdetail\n    FOR EACH ROW\n    EXECUTE FUNCTION sync_work_order_source_name();\n\n-- Step 5: Analyze table\nANALYZE tblcustworkorderdetail;\n\nCOMMIT;\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#2-apply-code-changes","title":"2. Apply Code Changes","text":"<pre><code># File: routes/work_orders.py\n\n# Remove conditional joins (lines 943-955)\nquery = query.options(joinedload(WorkOrder.customer))\n\n# Update Source filter (line 1006)\nif is_source_filter:\n    query = query.filter(WorkOrder.source_name.ilike(f\"%{is_source_filter}%\"))\n\n# Update Source sorting (lines 1032-1038)\nif field == \"Source\":\n    column_to_sort = WorkOrder.source_name\n    if direction == \"desc\":\n        order_by_clauses.append(column_to_sort.desc())\n    else:\n        order_by_clauses.append(column_to_sort.asc())\n\n# Update API response (line 1080)\n\"Source\": wo.source_name,\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#3-test","title":"3. Test","text":"<pre><code># Run migration\npsql \"postgresql://...\" -f query_optimization/add_source_name_column.sql\n\n# Run tests\npytest test/test_work_orders_routes.py -v\n\n# Test API endpoint\ncurl http://localhost:5000/api/work_orders?sort[0][field]=Source&amp;sort[0][dir]=asc\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#4-verify-performance","title":"4. Verify Performance","text":"<pre><code># Re-run performance analysis\npsql \"postgresql://...\" -f query_optimization/analyze_work_orders.sql\n</code></pre> <p>Expected result for Source sorting: - BEFORE: 93ms with Hash Join + 3 Seq Scans - AFTER: ~1ms with Index Scan on <code>idx_workorder_source_name</code></p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#edge-cases-to-handle","title":"Edge Cases to Handle","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#1-work-order-with-no-customer","title":"1. Work Order with No Customer","text":"<pre><code>if wo.source_name:\n    source = wo.source_name\nelse:\n    source = None\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#2-customer-with-no-source","title":"2. Customer with No Source","text":"<pre><code>customer = Customer.query.get(custid)\nif customer and customer.Source:\n    work_order.source_name = customer.source_info.SSource\nelse:\n    work_order.source_name = None\n</code></pre>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#3-customer-source-changes","title":"3. Customer Source Changes","text":"<ul> <li>If using trigger: Automatic update</li> <li>If application-level: Add to customer edit route <pre><code># In routes/customers.py after updating customer.Source\naffected_work_orders = WorkOrder.query.filter_by(CustID=customer.CustID).all()\nfor wo in affected_work_orders:\n    wo.sync_source_name()\n</code></pre></li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#4-source-name-changes","title":"4. Source Name Changes","text":"<ul> <li>Rare: Source names don't typically change</li> <li>If it happens: Run bulk update script <pre><code>UPDATE tblcustworkorderdetail wo\nSET source_name = s.ssource\nFROM tblcustomers c\nJOIN tblsource s ON c.source = s.ssource\nWHERE wo.custid = c.custid;\n</code></pre></li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#backward-compatibility","title":"Backward Compatibility","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#keep-old-relationships-working","title":"Keep Old Relationships Working","text":"<pre><code>class WorkOrder(db.Model):\n    # ... fields ...\n\n    # NEW: Denormalized column\n    source_name = db.Column(\"source_name\", db.Text, nullable=True)\n\n    # OLD: Relationships still work!\n    customer = db.relationship(\"Customer\", back_populates=\"work_orders\")\n    ship_to_source = db.relationship(\n        \"Source\",\n        primaryjoin=\"WorkOrder.ShipTo==Source.SSource\",\n        lazy=\"joined\",\n        uselist=False,\n    )\n\n    @property\n    def customer_source_name(self):\n        \"\"\"Get customer's source name (with fallback)\"\"\"\n        # Prefer denormalized value\n        if self.source_name:\n            return self.source_name\n        # Fallback to relationship (for backward compatibility)\n        if self.customer and self.customer.source_info:\n            return self.customer.source_info.SSource\n        return None\n</code></pre> <p>This means: - Old code using <code>wo.customer.source_info.SSource</code> still works - New code using <code>wo.source_name</code> is faster - Gradual migration is possible</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#testing-checklist","title":"Testing Checklist","text":"<ul> <li>[ ] Work order list loads with Source column</li> <li>[ ] Source column sorting works (asc/desc)</li> <li>[ ] Source filtering works</li> <li>[ ] Creating work order sets source_name correctly</li> <li>[ ] Editing work order updates source_name if customer changes</li> <li>[ ] Work orders without customers show None for source</li> <li>[ ] Customers without sources show None for work order source</li> <li>[ ] PDF generation still works (uses relationships)</li> <li>[ ] All existing tests pass</li> </ul>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#performance-impact-summary","title":"Performance Impact Summary","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#before-denormalization","title":"Before Denormalization","text":"Query Time Method Source sort 93ms Hash Join + 3 Seq Scans Source filter ~1ms Nested joins (but complex) Default list (no joins) 0.8ms Index scan"},{"location":"planning/DENORMALIZATION_ANALYSIS/#after-denormalization","title":"After Denormalization","text":"Query Time Method Source sort ~1ms \u26a1 Index Scan on source_name Source filter ~0.1ms \u26a1 Index Scan on source_name Default list 0.04ms \u26a1\u26a1 Index scan (no joins!) <p>Overall improvement: - Source sorting: 93x faster - Eliminates all 3-table joins - Simpler, more maintainable code</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#risks-mitigation","title":"Risks &amp; Mitigation","text":""},{"location":"planning/DENORMALIZATION_ANALYSIS/#risk-1-data-drift","title":"Risk 1: Data Drift","text":"<p>Problem: source_name gets out of sync with customer.Source</p> <p>Mitigation: - Database trigger (automatic sync) - Periodic sync job (cron) - Validation in tests</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#risk-2-storage-overhead","title":"Risk 2: Storage Overhead","text":"<p>Problem: Denormalization uses more disk space</p> <p>Impact: - ~18 bytes per row average source name - 49,074 rows \u00d7 18 bytes = ~880 KB - Negligible for a 17 MB table</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#risk-3-breaking-existing-code","title":"Risk 3: Breaking Existing Code","text":"<p>Problem: Code expecting relationships breaks</p> <p>Mitigation: - Keep all relationships intact - Add <code>customer_source_name</code> property with fallback - Gradual migration</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#recommendation","title":"Recommendation","text":"<p>\u2705 PROCEED WITH DENORMALIZATION</p> <p>Rationale: 1. Minimal code changes (5 small edits) 2. 100x performance improvement for Source sorting 3. Maintains all existing relationships (backward compatible) 4. Easy to implement (1-2 hours) 5. Low risk (can roll back easily)</p> <p>Implementation order: 1. Test database: Apply migration + code changes 2. Test thoroughly: Run all tests, manual testing 3. Production database: Apply migration during low-traffic period 4. Monitor: Check logs, query performance 5. Optimize: Remove old conditional joins after confirming</p>"},{"location":"planning/DENORMALIZATION_ANALYSIS/#next-steps","title":"Next Steps","text":"<ol> <li>Review this analysis</li> <li>Decide on trigger vs. application-level sync</li> <li>Create migration script</li> <li>Apply to test database</li> <li>Update code</li> <li>Test</li> <li>Deploy to production</li> </ol> <p>Would you like me to: - Create the migration script? - Update the model and routes? - Write tests for the new functionality?</p>"},{"location":"planning/IMPROVEMENTS/","title":"Analytics Dashboard Improvement Plan","text":"<p>This document outlines a roadmap for enhancing the analytics dashboard. The goal is to provide deeper insights into the business performance, moving beyond the current order-centric view.</p>"},{"location":"planning/IMPROVEMENTS/#eda-findings","title":"EDA Findings","text":"<p>Based on an analysis of the database, here are some key findings that should inform the analytics improvements:</p> <ul> <li>Revenue Calculation: The <code>quote</code> column in the <code>tblcustworkorderdetail</code> table is not a reliable source for revenue figures, as it often contains non-numeric values like \"Approved\". The <code>price</code> column in the <code>tblorddetcustawngs</code> table, which represents the price of individual order items, is a much more accurate source for revenue calculation. The existing \"Total Revenue\" KPI should be updated to sum the <code>price</code> of all items in completed work orders.</li> <li>Product Types: The <code>sizewgt</code> column in <code>tblorddetcustawngs</code> contains complex strings that describe the size and weight of order items. The existing logic to differentiate between \"awnings\" and \"sails\" (based on the presence of a \"#\" symbol) appears to be correct. This provides a good foundation for product-level analysis.</li> <li>Rush Orders: The <code>rushorder</code> and <code>firmrush</code> boolean columns in <code>tblcustworkorderdetail</code> are well-populated and can be used to analyze the frequency and impact of rush orders.</li> </ul>"},{"location":"planning/IMPROVEMENTS/#review-of-square-footage-parsing-code","title":"Review of Square Footage Parsing Code","text":"<p>The <code>clean_square_footage</code> and <code>clean_sail_weight</code> functions, along with their usage in <code>load_work_orders</code>, have been reviewed for accuracy and robustness.</p> <p>Findings:</p> <ul> <li><code>clean_square_footage</code>: This function is highly robust and accurate. It effectively handles a wide variety of complex input formats for awning sizes, including dimensions with feet and inches (e.g., <code>8'9\"x10'2\"</code>), simple <code>XxY</code> dimensions, and values with an <code>=</code> sign indicating a pre-calculated area. It also correctly strips currency and unit markers. Error handling for malformed strings is graceful, returning <code>0.0</code>.</li> <li><code>clean_sail_weight</code>: This function accurately parses sail weights in the format <code>95#</code>. It correctly extracts the numeric value and handles potential conversion errors.</li> <li><code>load_work_orders</code> Integration: The logic within <code>load_work_orders</code> to determine <code>product_type</code> (Awning vs. Sail based on <code>#</code> in <code>sizewgt</code>) and then apply the appropriate cleaning function (<code>clean_square_footage</code> or <code>clean_sail_weight</code>) is correct and efficient.</li> </ul> <p>Conclusion:</p> <p>The existing square footage parsing code is accurate, robust, and well-implemented for the identified data patterns. No major improvements are immediately necessary for its core functionality. The current implementation is well-suited for the task of calculating square footage from diverse input strings.</p>"},{"location":"planning/IMPROVEMENTS/#review-of-cleaning-throughput-calculation-code","title":"Review of Cleaning Throughput Calculation Code","text":"<p>The code responsible for calculating cleaning throughput, primarily within <code>load_work_orders</code> and <code>get_daily_throughput</code>, has been reviewed for correctness.</p> <p>Findings:</p> <ul> <li><code>load_work_orders</code>: This function accurately calculates the <code>sqft</code> for individual items by multiplying <code>qty_numeric</code> with the results from <code>clean_sail_weight</code> or <code>clean_square_footage</code> (which were previously reviewed and found to be robust). It then correctly aggregates these <code>sqft</code> values to derive <code>totalsize</code> for each work order.</li> <li><code>get_daily_throughput</code>: This function correctly filters for completed work orders using <code>datecompleted</code>. It then accurately groups these completed orders by their completion date and sums their <code>totalsize</code> to determine the <code>daily_sqft</code>. The rolling average calculation is also correctly implemented, providing a smoothed trend of throughput.</li> </ul> <p>Conclusion:</p> <p>The cleaning throughput calculation code is correct and accurate. It effectively processes raw data into meaningful daily and rolling average metrics. The recent change to remove the <code>.tail(90)</code> limit will ensure that the dashboard now displays the full historical data for daily cleaning throughput, providing a comprehensive view over time.</p>"},{"location":"planning/IMPROVEMENTS/#outlier-analysis-in-daily-throughput","title":"Outlier Analysis in Daily Throughput","text":"<p>An initial outlier detection using the IQR method on daily throughput data revealed several dates with extremely high square footage values. These outliers are highly suggestive of data entry errors rather than legitimate production spikes. For example, some single work orders are recorded with millions of square feet, which is physically improbable.</p> <p>Examples of extreme outliers: *   <code>2011-04-27</code>: 1.679114e+07 sq ft *   <code>2010-08-12</code>: 7.204018e+06 sq ft *   <code>2011-02-18</code>: 6.003085e+06 sq ft</p> <p>Recommendations for Outlier Handling: 1.  Data Validation: Investigate the raw <code>sizewgt</code> entries for the work orders contributing to these extreme outliers. This will help confirm if they are indeed data entry errors. 2.  Data Cleaning Strategy: Implement a strategy to handle such outliers. This could involve:     *   Correction: If possible, correct the erroneous entries in the source data.     *   Exclusion: Exclude extreme outliers from calculations, perhaps by setting a reasonable upper bound for <code>totalsize</code> per work order or per day.     *   Transformation: Apply data transformation techniques (e.g., winsorization) to cap extreme values. 3.  Robustness of Parsing: While <code>clean_square_footage</code> is robust, review if specific malformed patterns in <code>sizewgt</code> are consistently leading to these extreme values, and if so, enhance the parsing logic to better handle or flag them.</p>"},{"location":"planning/IMPROVEMENTS/#1-customer-centric-kpis","title":"1. Customer-Centric KPIs","text":"<p>The current dashboard focuses heavily on work orders. To better understand customer behavior and value, we should add the following KPIs:</p> <ul> <li>New vs. Returning Customers: Track the number of new customers acquired over time versus the number of returning customers. This will help measure customer loyalty and business growth.</li> <li>Customer Lifetime Value (CLV): Calculate the total revenue generated per customer. This will help identify high-value customers.</li> <li>Top Customers: A list of top customers by revenue or number of orders.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Modify the <code>load_work_orders</code> function to also return customer data.</li> <li>Create a new function <code>calculate_customer_kpis</code> to compute the new metrics.</li> <li>Add new KPI cards to the <code>dashboard.html</code> template.</li> <li>Add a new chart to visualize new vs. returning customers over time.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#2-productservice-analysis","title":"2. Product/Service Analysis","text":"<p>The current <code>sizewgt</code> column processing differentiates between \"awnings\" and \"sails\". We can leverage this to provide a more granular analysis of the business.</p> <ul> <li>Revenue by Product Type: Break down total revenue by \"awning\" and \"sail\".</li> <li>Throughput by Product Type: Analyze the square footage cleaned for each product type.</li> <li>Order Volume by Product Type: Show the number of orders for each product type.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Modify the <code>load_work_orders</code> function to categorize each order item as \"awning\" or \"sail\".</li> <li>Update the KPI calculation functions to aggregate by product type.</li> <li>Add new charts or update existing ones to show the product type breakdown. A stacked bar chart for monthly trends could work well.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#3-rush-order-analysis","title":"3. Rush Order Analysis","text":"<p>The <code>rushorder</code> and <code>firmrush</code> columns indicate the urgency of an order. We should analyze the impact of these orders.</p> <ul> <li>Rush Order Frequency: What percentage of orders are rush orders?</li> <li>Rush Order Revenue: Do rush orders generate more revenue on average?</li> <li>Impact on Lead Time: Do rush orders get completed faster?</li> </ul> <p>Implementation Steps:</p> <ol> <li>Incorporate the <code>rushorder</code> and <code>firmrush</code> columns into the <code>load_work_orders</code> function.</li> <li>Calculate KPIs related to rush orders.</li> <li>Add a section to the dashboard to display these insights.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#4-lead-time-analysis","title":"4. Lead Time Analysis","text":"<p>Understanding how long it takes to complete an order is a crucial operational metric.</p> <ul> <li>Average Lead Time: Calculate the average time between <code>datein</code> and <code>datecompleted</code>.</li> <li>Lead Time Distribution: Show a histogram of lead times to identify outliers.</li> <li>Lead Time by Product Type: Analyze if certain products take longer to complete.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Calculate the lead time for each completed order in the <code>load_work_orders</code> function.</li> <li>Create a new function to calculate lead time metrics.</li> <li>Add a new chart to the dashboard to visualize the lead time distribution.</li> </ol>"},{"location":"planning/IMPROVEMENTS/#5-interactive-filtering","title":"5. Interactive Filtering","text":"<p>To make the dashboard more useful, we should add interactive filtering capabilities.</p> <ul> <li>Date Range Filter: Allow users to select a date range to view analytics for a specific period.</li> <li>Product Type Filter: Allow users to filter the data for \"awnings\" or \"sails\".</li> <li>Customer Filter: Allow users to search for a specific customer and see their history.</li> </ul> <p>Implementation Steps:</p> <ol> <li>Add filter controls to the <code>dashboard.html</code> template.</li> <li>Modify the <code>/api/data</code> endpoint to accept filter parameters.</li> <li>Update the backend functions to apply the filters to the data.</li> </ol>"},{"location":"planning/REFACTORING_PLAN/","title":"Route Refactoring Plan","text":""},{"location":"planning/REFACTORING_PLAN/#priority-1-query-helpers-biggest-impact-low-risk","title":"Priority 1: Query Helpers (Biggest Impact, Low Risk)","text":"<p>Impact: Reduces ~300 lines across all route files Complexity: Low - Pure utility functions Files affected: <code>work_orders.py</code>, <code>repair_order.py</code>, <code>customers.py</code>, <code>queue.py</code></p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsquery_helperspy","title":"Create <code>utils/query_helpers.py</code>","text":"<pre><code>def apply_search_filter(query, model, search_term, searchable_fields):\n    \"\"\"\n    Apply OR-based search across multiple model fields.\n\n    Args:\n        query: SQLAlchemy query object\n        model: SQLAlchemy model class (WorkOrder, RepairWorkOrder, etc.)\n        search_term: Search string from request.args\n        searchable_fields: List of field names to search\n\n    Returns:\n        Modified query with search filters applied\n\n    Example:\n        query = apply_search_filter(\n            query,\n            WorkOrder,\n            \"ABC123\",\n            [\"WorkOrderNo\", \"CustID\", \"WOName\", \"ShipTo\"]\n        )\n    \"\"\"\n\ndef apply_column_filters(query, model, request_args, filter_config):\n    \"\"\"\n    Apply individual column filters from Tabulator.\n\n    Args:\n        filter_config: Dict mapping filter names to columns\n            {\n                \"filter_CustID\": {\"column\": Customer.CustID, \"type\": \"exact\"},\n                \"filter_Name\": {\"column\": Customer.Name, \"type\": \"like\"}\n            }\n    \"\"\"\n\ndef apply_tabulator_sorting(query, model, request_args, type_config=None):\n    \"\"\"\n    Parse and apply Tabulator multi-column sorting.\n\n    Args:\n        type_config: Dict of field types for casting\n            {\n                \"WorkOrderNo\": \"integer\",\n                \"DateIn\": \"date\",\n                \"CustID\": \"integer\"\n            }\n\n    Handles: sort[0][field], sort[0][dir], etc.\n    Auto-casts numeric/date fields with nulls_last()\n    \"\"\"\n\ndef optimize_relationship_loading(query, model, request_args, relationship_map):\n    \"\"\"\n    Conditionally eager-load relationships based on filters/sorts.\n\n    Args:\n        relationship_map: Dict of relationships to check for\n            {\n                \"Source\": {\n                    \"join_path\": [WorkOrder.customer, Customer.source_info],\n                    \"load_path\": [WorkOrder.customer, Customer.source_info]\n                }\n            }\n\n    Checks if Source is in filter_* or sort[*][field] params.\n    Only joins/loads if needed (avoids N+1 and unnecessary joins).\n    \"\"\"\n</code></pre>"},{"location":"planning/REFACTORING_PLAN/#refactor-examples","title":"Refactor Examples","text":"<p>Before (work_orders.py lines 909-1043): <pre><code># 135 lines of complex filtering and sorting\n</code></pre></p> <p>After: <pre><code>@work_orders_bp.route(\"/api/work_orders\")\n@login_required\ndef api_work_orders():\n    page = request.args.get(\"page\", 1, type=int)\n    size = request.args.get(\"size\", 25, type=int)\n    status = request.args.get(\"status\", \"\").lower()\n\n    query = WorkOrder.query\n\n    # Optimize relationship loading\n    query = optimize_relationship_loading(\n        query, WorkOrder, request.args,\n        {\"Source\": {\n            \"join_path\": [WorkOrder.customer, Customer.source_info],\n            \"load_path\": [WorkOrder.customer, Customer.source_info]\n        }}\n    )\n\n    # Apply filters\n    if status == \"pending\":\n        query = query.filter(WorkOrder.DateCompleted.is_(None))\n    elif status == \"completed\":\n        query = query.filter(WorkOrder.DateCompleted.isnot(None))\n    elif status == \"rush\":\n        query = query.filter(\n            or_(WorkOrder.RushOrder == True, WorkOrder.FirmRush == True),\n            WorkOrder.DateCompleted.is_(None)\n        )\n\n    # Column-specific filters\n    query = apply_column_filters(query, WorkOrder, request.args, {\n        \"filter_WorkOrderNo\": {\"column\": WorkOrder.WorkOrderNo, \"type\": \"range_or_exact\"},\n        \"filter_CustID\": {\"column\": WorkOrder.CustID, \"type\": \"exact\"},\n        \"filter_WOName\": {\"column\": WorkOrder.WOName, \"type\": \"like\"},\n        \"filter_DateIn\": {\"column\": WorkOrder.DateIn, \"type\": \"like\"},\n        \"filter_DateRequired\": {\"column\": WorkOrder.DateRequired, \"type\": \"like\"},\n        \"filter_Source\": {\"column\": Source.SSource, \"type\": \"like\"}\n    })\n\n    # Sorting\n    query = apply_tabulator_sorting(query, WorkOrder, request.args, {\n        \"WorkOrderNo\": \"integer\",\n        \"CustID\": \"integer\",\n        \"DateIn\": \"date\",\n        \"DateRequired\": \"date\",\n        \"Source\": Source.SSource\n    })\n\n    total = query.count()\n    items = query.paginate(page=page, per_page=size, error_out=False)\n\n    return build_tabulator_response(\n        items.items,\n        total,\n        page,\n        items.pages,\n        row_builder=build_work_order_row\n    )\n</code></pre></p> <p>Lines saved: ~100 lines per API route \u00d7 4 routes = 400 lines</p>"},{"location":"planning/REFACTORING_PLAN/#priority-2-date-helpers-high-impact-zero-risk","title":"Priority 2: Date Helpers (High Impact, Zero Risk)","text":"<p>Impact: Reduces ~150 lines, eliminates bugs Complexity: Trivial Files affected: All route files</p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsdate_helperspy","title":"Create <code>utils/date_helpers.py</code>","text":"<pre><code>def parse_form_date(form, field_name, required=False, default=None):\n    \"\"\"\n    Parse date from form with consistent error handling.\n\n    Returns: date object or None\n    Raises: ValueError if required and missing\n    \"\"\"\n    value = form.get(field_name)\n    if not value:\n        if required:\n            raise ValueError(f\"{field_name} is required\")\n        return default\n\n    try:\n        return datetime.strptime(value, \"%Y-%m-%d\").date()\n    except ValueError:\n        raise ValueError(f\"Invalid date format for {field_name}\")\n\ndef format_date_for_api(date_value):\n    \"\"\"Convert date/datetime to YYYY-MM-DD string for JSON.\"\"\"\n    if not date_value:\n        return None\n    if isinstance(date_value, str):\n        return date_value\n    return date_value.strftime(\"%Y-%m-%d\")\n</code></pre>"},{"location":"planning/REFACTORING_PLAN/#refactor-examples_1","title":"Refactor Examples","text":"<p>Before (work_orders.py lines 397-410): <pre><code>DateIn=datetime.strptime(request.form.get(\"DateIn\"), \"%Y-%m-%d\").date()\nif request.form.get(\"DateIn\")\nelse date.today(),\nDateRequired=datetime.strptime(\n    request.form.get(\"DateRequired\"), \"%Y-%m-%d\"\n).date()\nif request.form.get(\"DateRequired\")\nelse None,\nClean=datetime.strptime(request.form.get(\"Clean\"), \"%Y-%m-%d\").date()\nif request.form.get(\"Clean\")\nelse None,\n# ... repeated 5 more times\n</code></pre></p> <p>After: <pre><code>from utils.date_helpers import parse_form_date\n\nDateIn=parse_form_date(request.form, \"DateIn\", default=date.today()),\nDateRequired=parse_form_date(request.form, \"DateRequired\"),\nClean=parse_form_date(request.form, \"Clean\"),\nTreat=parse_form_date(request.form, \"Treat\"),\n</code></pre></p> <p>Lines saved: ~10 lines per route \u00d7 15 routes = 150 lines</p>"},{"location":"planning/REFACTORING_PLAN/#priority-3-api-response-builders-medium-impact-low-risk","title":"Priority 3: API Response Builders (Medium Impact, Low Risk)","text":"<p>Impact: Reduces ~100 lines, standardizes responses Complexity: Low Files affected: All API routes</p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsapi_helperspy","title":"Create <code>utils/api_helpers.py</code>","text":"<pre><code>def build_tabulator_response(items, total, page, pages, row_builder=None):\n    \"\"\"\n    Standard Tabulator pagination response.\n\n    Args:\n        row_builder: Function to convert model instance to dict\n    \"\"\"\n    if row_builder:\n        data = [row_builder(item) for item in items]\n    else:\n        data = [item.__dict__ for item in items]\n\n    return jsonify({\n        \"data\": data,\n        \"total\": total,\n        \"page\": page,\n        \"last_page\": pages\n    })\n\ndef build_work_order_row(work_order, include_source=True):\n    \"\"\"Convert WorkOrder model to API dict.\"\"\"\n    row = {\n        \"WorkOrderNo\": work_order.WorkOrderNo,\n        \"CustID\": work_order.CustID,\n        \"WOName\": work_order.WOName,\n        \"DateIn\": format_date_for_api(work_order.DateIn),\n        \"DateRequired\": format_date_for_api(work_order.DateRequired),\n        \"detail_url\": url_for(\"work_orders.view_work_order\", work_order_no=work_order.WorkOrderNo),\n        \"edit_url\": url_for(\"work_orders.edit_work_order\", work_order_no=work_order.WorkOrderNo),\n        \"delete_url\": url_for(\"work_orders.delete_work_order\", work_order_no=work_order.WorkOrderNo),\n    }\n\n    if include_source and work_order.customer and work_order.customer.source_info:\n        row[\"Source\"] = work_order.customer.source_info.SSource\n\n    if work_order.customer:\n        row[\"customer_url\"] = url_for(\"customers.customer_detail\", customer_id=work_order.CustID)\n\n    return row\n</code></pre>"},{"location":"planning/REFACTORING_PLAN/#priority-4-form-data-extraction-high-impact-medium-risk","title":"Priority 4: Form Data Extraction (High Impact, Medium Risk)","text":"<p>Impact: Reduces ~200 lines, makes validation easier Complexity: Medium - requires careful testing Files affected: <code>work_orders.py</code>, <code>repair_order.py</code></p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsform_helperspy","title":"Create <code>utils/form_helpers.py</code>","text":"<pre><code>def extract_work_order_fields(form):\n    \"\"\"\n    Extract all work order fields from form into dict.\n\n    Returns: Dict ready to pass to WorkOrder(**data)\n    Raises: ValueError for validation errors\n    \"\"\"\n    from utils.date_helpers import parse_form_date\n\n    if not form.get(\"CustID\"):\n        raise ValueError(\"Customer is required\")\n    if not form.get(\"WOName\"):\n        raise ValueError(\"Name is required\")\n\n    return {\n        \"CustID\": form.get(\"CustID\"),\n        \"WOName\": form.get(\"WOName\"),\n        \"StorageTime\": form.get(\"StorageTime\"),\n        \"RackNo\": form.get(\"RackNo\"),\n        \"SpecialInstructions\": form.get(\"SpecialInstructions\"),\n        \"RepairsNeeded\": \"RepairsNeeded\" in form,\n        \"SeeRepair\": form.get(\"SeeRepair\"),\n        \"Quote\": form.get(\"Quote\"),\n        \"RushOrder\": \"RushOrder\" in form,\n        \"FirmRush\": \"FirmRush\" in form,\n        \"DateIn\": parse_form_date(form, \"DateIn\", default=date.today()),\n        \"DateRequired\": parse_form_date(form, \"DateRequired\"),\n        \"Clean\": parse_form_date(form, \"Clean\"),\n        \"Treat\": parse_form_date(form, \"Treat\"),\n        \"ReturnStatus\": form.get(\"ReturnStatus\"),\n        \"ShipTo\": form.get(\"ShipTo\"),\n    }\n</code></pre> <p>Before (work_orders.py lines 383-414): 31 lines After: 2 lines <pre><code>wo_data = extract_work_order_fields(request.form)\nwork_order = WorkOrder(WorkOrderNo=next_wo_no, **wo_data)\n</code></pre></p>"},{"location":"planning/REFACTORING_PLAN/#priority-5-order-item-processing-highest-complexity-high-impact","title":"Priority 5: Order Item Processing (Highest Complexity, High Impact)","text":"<p>Impact: Reduces ~400 lines, biggest code smell Complexity: High - complex business logic Files affected: <code>work_orders.py</code>, <code>repair_order.py</code></p>"},{"location":"planning/REFACTORING_PLAN/#create-utilsorder_item_helperspy","title":"Create <code>utils/order_item_helpers.py</code>","text":"<pre><code>def process_selected_inventory_items(form, order_no, cust_id, item_class):\n    \"\"\"\n    Process items selected from customer inventory.\n\n    Args:\n        item_class: WorkOrderItem or RepairWorkOrderItem\n\n    Returns: List of item instances (not yet added to session)\n    \"\"\"\n    items = []\n    selected_ids = form.getlist(\"selected_items[]\")\n\n    for inv_key in selected_ids:\n        inventory_item = Inventory.query.get(inv_key)\n        if not inventory_item:\n            continue\n\n        qty_key = f\"item_qty_{inv_key}\"\n        qty = safe_int_conversion(form.get(qty_key, 1))\n\n        item = item_class(\n            WorkOrderNo=order_no,\n            CustID=cust_id,\n            Description=inventory_item.Description,\n            Material=inventory_item.Material,\n            Qty=str(qty),\n            Condition=inventory_item.Condition,\n            Color=inventory_item.Color,\n            SizeWgt=inventory_item.SizeWgt,\n            Price=inventory_item.Price,\n        )\n        items.append(item)\n\n    return items\n\ndef process_new_items(form, order_no, cust_id, item_class, update_catalog=True):\n    \"\"\"\n    Process manually added new items.\n\n    Returns: (items, catalog_updates)\n        items: List of item instances\n        catalog_updates: List of inventory updates if update_catalog=True\n    \"\"\"\n    items = []\n    catalog_updates = []\n\n    descriptions = form.getlist(\"new_item_description[]\")\n    materials = form.getlist(\"new_item_material[]\")\n    quantities = form.getlist(\"new_item_qty[]\")\n    # ... etc\n\n    for i, description in enumerate(descriptions):\n        if not description:\n            continue\n\n        # Create order item\n        item = item_class(...)\n        items.append(item)\n\n        # Catalog update logic\n        if update_catalog:\n            catalog_update = add_or_update_catalog(cust_id, item_data)\n            if catalog_update:\n                catalog_updates.append(catalog_update)\n\n    return items, catalog_updates\n</code></pre> <p>Before (work_orders.py create_work_order): 225 lines After: ~60 lines</p>"},{"location":"planning/REFACTORING_PLAN/#implementation-order","title":"Implementation Order","text":""},{"location":"planning/REFACTORING_PLAN/#week-1-foundation-low-risk","title":"Week 1: Foundation (Low Risk)","text":"<ol> <li>\u2705 Create <code>utils/date_helpers.py</code></li> <li>\u2705 Refactor all date parsing (test thoroughly)</li> <li>\u2705 Create <code>utils/query_helpers.py</code></li> <li>\u2705 Refactor one API route as proof of concept</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#week-2-api-layer-medium-risk","title":"Week 2: API Layer (Medium Risk)","text":"<ol> <li>\u2705 Create <code>utils/api_helpers.py</code></li> <li>\u2705 Refactor all API routes</li> <li>\u2705 Test Tabulator functionality</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#week-3-forms-higher-risk","title":"Week 3: Forms (Higher Risk)","text":"<ol> <li>\u2705 Create <code>utils/form_helpers.py</code></li> <li>\u2705 Refactor work_orders create/edit</li> <li>\u2705 Refactor repair_orders create/edit</li> <li>\u2705 Extensive testing</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#week-4-items-highest-risk","title":"Week 4: Items (Highest Risk)","text":"<ol> <li>\u2705 Create <code>utils/order_item_helpers.py</code></li> <li>\u2705 Refactor item processing</li> <li>\u2705 Test inventory catalog updates</li> <li>\u2705 Regression testing</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#testing-strategy","title":"Testing Strategy","text":""},{"location":"planning/REFACTORING_PLAN/#unit-tests-new","title":"Unit Tests (New)","text":"<ul> <li>Test each helper function in isolation</li> <li>Mock database calls</li> <li>Test edge cases (None, empty, invalid dates)</li> </ul>"},{"location":"planning/REFACTORING_PLAN/#integration-tests-existing","title":"Integration Tests (Existing)","text":"<ul> <li>Run full test suite after each refactor</li> <li>Pay special attention to:</li> <li>Date parsing edge cases</li> <li>Inventory quantity tracking</li> <li>API response formats</li> </ul>"},{"location":"planning/REFACTORING_PLAN/#manual-testing-checklist","title":"Manual Testing Checklist","text":"<ul> <li>[ ] Create work order with selected items</li> <li>[ ] Create work order with new items</li> <li>[ ] Edit work order and remove items</li> <li>[ ] API filtering works (all columns)</li> <li>[ ] API sorting works (all columns)</li> <li>[ ] Date fields handle None correctly</li> <li>[ ] Rush orders filter correctly</li> <li>[ ] Pagination works on all views</li> </ul>"},{"location":"planning/REFACTORING_PLAN/#metrics","title":"Metrics","text":"Metric Before After Change Total route LOC 3,685 2,150 -42% Longest function 225 lines 60 lines -73% Code duplication High Low \u2705 Test coverage 60% 85% +25% Helper functions 5 25 +400%"},{"location":"planning/REFACTORING_PLAN/#risk-mitigation","title":"Risk Mitigation","text":""},{"location":"planning/REFACTORING_PLAN/#high-risk-areas","title":"High-Risk Areas","text":"<ol> <li>Inventory catalog updates - Complex business logic, easy to break</li> <li>Solution: Unit test helpers thoroughly</li> <li> <p>Solution: Compare before/after catalog state in tests</p> </li> <li> <p>Date parsing - Used everywhere, silent failures possible</p> </li> <li>Solution: Explicit error handling in helpers</li> <li> <p>Solution: Return None vs raise exception (document clearly)</p> </li> <li> <p>Query optimization - Could break N+1 or add unnecessary joins</p> </li> <li>Solution: Log SQL queries in dev</li> <li>Solution: Benchmark before/after</li> </ol>"},{"location":"planning/REFACTORING_PLAN/#rollback-plan","title":"Rollback Plan","text":"<ul> <li>Keep old code commented out for 1 sprint</li> <li>Feature flag for new helpers (if needed)</li> <li>Git tags for each refactor phase</li> </ul>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/","title":"Optimizing Thumbnail Generation with WebAssembly (WASM)","text":"<p>This guide details how to refactor the file upload process to generate thumbnails on the client-side using WebAssembly, significantly reducing server load and improving user experience.</p> <p>The current workflow executes all thumbnail generation (a CPU-intensive task) on the server. The new workflow offloads this to the user's browser.</p>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#step-1-update-backend-to-receive-pre-processed-thumbnails","title":"Step 1: Update Backend to Receive Pre-Processed Thumbnails","text":"<p>First, we'll simplify the backend. It will no longer generate thumbnails; it will only receive and save the original file and the thumbnail file created by the client.</p>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#11-simplify-utilsfile_uploadpy","title":"1.1. Simplify <code>utils/file_upload.py</code>","text":"<p>The <code>save_work_order_file</code> function will be simplified to just save two files. The complex <code>generate_thumbnail</code> logic is no longer needed here.</p> <p>Replace the contents of <code>utils/file_upload.py</code> with the following. We are keeping the S3 logic but removing all thumbnail generation calls.</p> <pre><code>import os\nfrom werkzeug.utils import secure_filename\nfrom models.work_order_file import WorkOrderFile\nfrom extensions import db\nimport boto3\nfrom io import BytesIO\nfrom datetime import datetime\n\n# --- S3 Configuration ---\nUPLOAD_FOLDER = \"uploads/work_orders\"  # local fallback\nALLOWED_EXTENSIONS = {\"pdf\", \"jpg\", \"jpeg\", \"png\", \"docx\", \"xlsx\", \"txt\", \"csv\"}\n\nAWS_S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\")\nAWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n\nif not AWS_S3_BUCKET:\n    raise ValueError(\"AWS_S3_BUCKET environment variable is required\")\n\ndef is_running_on_aws():\n    return any([\n        os.getenv(\"AWS_EXECUTION_ENV\"),\n        os.getenv(\"AWS_LAMBDA_FUNCTION_NAME\"),\n        os.getenv(\"AWS_REGION\"),\n    ])\n\nis_aws_environment = is_running_on_aws()\n\nif is_aws_environment:\n    print(\"Detected AWS environment - using IAM role for S3 access\")\n    s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\nelse:\n    print(\"Detected local environment - using explicit AWS credentials\")\n    AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n    AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n        raise ValueError(\"Local dev requires AWS credentials\")\n    s3_client = boto3.client(\n        \"s3\",\n        aws_access_key_id=AWS_ACCESS_KEY_ID,\n        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n        region_name=AWS_REGION,\n    )\n\ndef save_uploaded_files(work_order_no, original_file, thumbnail_file, to_s3=True):\n    \"\"\"\n    Saves an original file and its pre-generated thumbnail.\n    This function no longer generates thumbnails.\n    \"\"\"\n    original_filename = secure_filename(original_file.filename)\n    thumbnail_filename = secure_filename(thumbnail_file.filename)\n\n    if to_s3:\n        # Save Original File\n        original_s3_key = f\"work_orders/{work_order_no}/{original_filename}\"\n        s3_client.upload_fileobj(original_file, AWS_S3_BUCKET, original_s3_key)\n        file_path = f\"s3://{AWS_S3_BUCKET}/{original_s3_key}\"\n\n        # Save Thumbnail File\n        thumbnail_s3_key = f\"work_orders/{work_order_no}/{thumbnail_filename}\"\n        s3_client.upload_fileobj(thumbnail_file, AWS_S3_BUCKET, thumbnail_s3_key)\n        thumbnail_path = f\"s3://{AWS_S3_BUCKET}/{thumbnail_s3_key}\"\n    else:\n        # Save locally (fallback)\n        wo_folder = os.path.join(UPLOAD_FOLDER, str(work_order_no))\n        os.makedirs(wo_folder, exist_ok=True)\n\n        file_path = os.path.join(wo_folder, original_filename)\n        original_file.save(file_path)\n\n        thumbnail_path = os.path.join(wo_folder, thumbnail_filename)\n        thumbnail_file.save(thumbnail_path)\n\n    # Create WorkOrderFile object to be committed later\n    wo_file = WorkOrderFile(\n        WorkOrderNo=work_order_no,\n        filename=original_filename,\n        file_path=file_path,\n        thumbnail_path=thumbnail_path,\n    )\n    return wo_file\n\n# Other utility functions like generate_presigned_url can remain unchanged.\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#12-update-routeswork_orderspy","title":"1.2. Update <code>routes/work_orders.py</code>","text":"<p>Modify the <code>create_work_order</code> route (and any other upload routes) to handle the two incoming files (<code>original</code> and <code>thumbnail</code>).</p> <pre><code># Inside routes/work_orders.py\n\n# IMPORTANT: Change the import from `save_work_order_file` to `save_uploaded_files`\nfrom utils.file_upload import save_uploaded_files\n\n# ... inside the create_work_order function, find the file handling block ...\n\n# --- This block replaces the old file handling logic ---\nif 'original_files[]' in request.files:\n    original_files = request.files.getlist('original_files[]')\n    thumbnail_files = request.files.getlist('thumbnail_files[]')\n\n    if len(original_files) != len(thumbnail_files):\n        raise Exception(\"Mismatch between original files and thumbnails.\")\n\n    for i, original_file in enumerate(original_files):\n        if original_file and original_file.filename:\n            thumbnail_file = thumbnail_files[i]\n\n            wo_file = save_uploaded_files(\n                work_order_no=next_wo_no,\n                original_file=original_file,\n                thumbnail_file=thumbnail_file,\n                to_s3=True \n            )\n\n            if not wo_file:\n                raise Exception(f\"Failed to save file: {original_file.filename}\")\n\n            db.session.add(wo_file)\n            print(f\"Saved {wo_file.filename} and its thumbnail {thumbnail_file.filename}\")\n# --- End of replacement block ---\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#step-2-implement-client-side-thumbnail-generation","title":"Step 2: Implement Client-Side Thumbnail Generation","text":"<p>This involves adding JavaScript to your frontend templates. We will use <code>pdf.js</code> for PDFs and <code>libsquoosh</code> for images, as they are robust, well-supported libraries that use WebAssembly.</p>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#21-update-your-html-template","title":"2.1. Update Your HTML Template","text":"<p>In your <code>work_orders/create.html</code> and <code>work_orders/edit.html</code> (or any template with a file upload), add a file input and a preview area.</p> <pre><code>&lt;!-- Add a unique ID to your file input --&gt;\n&lt;input type=\"file\" id=\"file-uploader\" name=\"files[]\" multiple&gt;\n\n&lt;!-- Add a container to display thumbnail previews --&gt;\n&lt;div id=\"thumbnail-preview-area\" style=\"display:flex; flex-wrap:wrap; gap:10px; margin-top:15px;\"&gt;&lt;/div&gt;\n\n&lt;!-- Include pdf.js and libsquosh from a CDN --&gt;\n&lt;!-- Place these in your base.html or at the bottom of the page --&gt;\n&lt;script src=\"https://unpkg.com/pdfjs-dist@3.4.120/build/pdf.min.js\"&gt;&lt;/script&gt;\n&lt;script&gt;\n    // Required for pdf.js\n    pdfjsLib.GlobalWorkerOptions.workerSrc = `https://unpkg.com/pdfjs-dist@3.4.120/build/pdf.worker.min.js`;\n&lt;/script&gt;\n&lt;script type=\"module\" src=\"https://unpkg.com/@jsquash/jpeg@1.3.0/meta.js\"&gt;&lt;/script&gt;\n&lt;script type=\"module\" src=\"https://unpkg.com/@jsquash/resize@1.2.1/meta.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#22-add-the-client-side-processing-javascript","title":"2.2. Add the Client-Side Processing JavaScript","text":"<p>Add this script to your page. It will listen for file selections, process them, and prepare them for upload.</p> <pre><code>document.addEventListener('DOMContentLoaded', () =&gt; {\n    const fileUploader = document.getElementById('file-uploader');\n    const previewArea = document.getElementById('thumbnail-preview-area');\n\n    // This will store our processed files, ready for upload\n    const processedFiles = {\n        originals: [],\n        thumbnails: []\n    };\n\n    fileUploader.addEventListener('change', async (event) =&gt; {\n        const files = event.target.files;\n        if (!files.length) return;\n\n        // Clear previous previews and stored files\n        previewArea.innerHTML = '';\n        processedFiles.originals = [];\n        processedFiles.thumbnails = [];\n\n        for (const file of files) {\n            let thumbnailBlob;\n            const originalFileName = file.name;\n\n            // Show a placeholder\n            const placeholder = document.createElement('div');\n            placeholder.textContent = `Processing ${originalFileName}...`;\n            previewArea.appendChild(placeholder);\n\n            try {\n                if (file.type.startsWith('image/')) {\n                    thumbnailBlob = await processImage(file);\n                } else if (file.type === 'application/pdf') {\n                    thumbnailBlob = await processPdf(file);\n                } else {\n                    // For other files, you might create a default icon or skip a thumbnail\n                    console.log(`Skipping thumbnail for ${originalFileName}`);\n                    placeholder.textContent = `No preview for ${originalFileName}`;\n                    continue; // Or create a default thumbnail\n                }\n\n                const thumbnailFile = new File([thumbnailBlob], `thumb_${originalFileName.split('.')[0]}.jpeg`, { type: 'image/jpeg' });\n\n                // Store the files\n                processedFiles.originals.push(file);\n                processedFiles.thumbnails.push(thumbnailFile);\n\n                // Create and display the thumbnail preview\n                const reader = new FileReader();\n                reader.onload = (e) =&gt; {\n                    const img = document.createElement('img');\n                    img.src = e.target.result;\n                    img.style.width = '150px';\n                    img.style.height = '150px';\n                    img.style.objectFit = 'cover';\n                    img.title = `Thumbnail for ${originalFileName}`;\n                    placeholder.replaceWith(img); // Replace placeholder with the actual thumbnail\n                };\n                reader.readAsDataURL(thumbnailBlob);\n\n            } catch (error) {\n                console.error(`Failed to process ${originalFileName}:`, error);\n                placeholder.textContent = `Error processing ${originalFileName}`;\n            }\n        }\n    });\n\n    // --- Image Processing Function (uses libsquosh) ---\n    async function processImage(file) {\n        const imageBuffer = await file.arrayBuffer();\n\n        // Resize the image\n        const resizeOptions = {\n            width: 200,\n            height: 200,\n            method: 'lanczos3',\n        };\n        const resizedImage = await resize(imageBuffer, resizeOptions);\n\n        // Encode the resized image to JPEG\n        const jpegBlob = await encode(resizedImage, { quality: 85 });\n        return jpegBlob;\n    }\n\n    // --- PDF Processing Function (uses pdf.js) ---\n    async function processPdf(file) {\n        const fileBuffer = await file.arrayBuffer();\n        const pdf = await pdfjsLib.getDocument({ data: fileBuffer }).promise;\n        const page = await pdf.getPage(1); // Get the first page\n\n        const viewport = page.getViewport({ scale: 1 });\n        const canvas = document.createElement('canvas');\n        const context = canvas.getContext('2d');\n\n        // Set canvas dimensions to match PDF page aspect ratio\n        const scale = 200 / viewport.height;\n        const scaledViewport = page.getViewport({ scale });\n        canvas.height = scaledViewport.height;\n        canvas.width = scaledViewport.width;\n\n        // Render PDF page to canvas\n        await page.render({ canvasContext: context, viewport: scaledViewport }).promise;\n\n        // Convert canvas to JPEG blob\n        return new Promise(resolve =&gt; {\n            canvas.toBlob(resolve, 'image/jpeg', 0.85);\n        });\n    }\n\n    // --- Modify Form Submission ---\n    // You need to intercept the form submission to append the processed files.\n    const form = fileUploader.closest('form');\n    form.addEventListener('submit', function(event) {\n        event.preventDefault(); // Stop the default submission\n\n        const formData = new FormData(form);\n\n        // Remove the original placeholder file list\n        formData.delete('files[]');\n\n        // Append the processed files\n        processedFiles.originals.forEach(file =&gt; {\n            formData.append('original_files[]', file);\n        });\n        processedFiles.thumbnails.forEach(file =&gt; {\n            formData.append('thumbnail_files[]', file);\n        });\n\n        // Submit the form with the new FormData\n        fetch(form.action, {\n            method: 'POST',\n            body: formData,\n            // headers: { 'X-CSRF-TOKEN': 'your_csrf_token' } // If you use CSRF tokens\n        })\n        .then(response =&gt; {\n            if (response.ok) {\n                // Redirect on success, e.g., to the work order detail page\n                window.location.href = response.url; \n            } else {\n                // Handle errors\n                console.error('Upload failed');\n                alert('Upload failed!');\n            }\n        })\n        .catch(error =&gt; {\n            console.error('Error submitting form:', error);\n            alert('An error occurred.');\n        });\n    });\n});\n</code></pre>"},{"location":"planning/WASM_THUMBNAIL_OPTIMIZATION/#step-3-clean-up-old-code","title":"Step 3: Clean Up Old Code","text":"<p>Once the new implementation is verified and working, you can safely remove the old server-side generation code.</p> <ol> <li>Delete <code>utils/thumbnail_generator.py</code>: This file is no longer needed.</li> <li>Clean up <code>utils/file_upload.py</code>: Ensure the old <code>save_work_order_file</code> and any related helper functions for generation are removed, as shown in Step 1.1.</li> <li>Remove old libraries: If <code>Pillow</code>, <code>PyMuPDF</code>, <code>python-docx</code>, etc., were only used for thumbnailing, you can remove them from your <code>requirements.txt</code> to slim down your application dependencies.</li> </ol> <p>This refactoring moves the performance-critical task of thumbnail generation to the client, resulting in a faster, more scalable, and more responsive application.</p>"},{"location":"reference/faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"reference/faq/#table-of-contents","title":"Table of Contents","text":"<ul> <li>General Questions</li> <li>Account &amp; Access</li> <li>Work Orders</li> <li>Repair Orders</li> <li>Customers</li> <li>File Uploads</li> <li>PDF Generation</li> <li>Analytics &amp; Reports</li> <li>Technical Questions</li> <li>Billing &amp; Pricing</li> </ul>"},{"location":"reference/faq/#general-questions","title":"General Questions","text":""},{"location":"reference/faq/#what-is-the-awning-management-system","title":"What is the Awning Management System?","text":"<p>The Awning Management System is a web-based application designed to manage awning cleaning and repair operations. It handles work orders, repair orders, customer information, inventory tracking, and business analytics.</p>"},{"location":"reference/faq/#who-can-use-the-application","title":"Who can use the application?","text":"<p>The application is designed for: - Office staff - Create and manage orders, handle customer interactions - Cleaning crew - View queue, update order status - Managers - Access analytics, manage inventory - Administrators - Full system access, user management</p>"},{"location":"reference/faq/#can-i-use-the-app-on-mobile-devices","title":"Can I use the app on mobile devices?","text":"<p>Yes, the application is responsive and works on mobile devices (phones and tablets). However, some features work best on desktop computers: - Works well on mobile: Viewing orders, checking queue, basic edits - Better on desktop: Creating complex orders, analytics dashboards, PDF generation</p> <p>Recommended: - Use mobile for quick tasks and viewing information - Use desktop for data entry and detailed work</p>"},{"location":"reference/faq/#how-do-i-get-started","title":"How do I get started?","text":"<ol> <li>Receive login credentials from your administrator</li> <li>Navigate to the application URL</li> <li>Log in with your username and password</li> <li>Start with the Getting Started Guide</li> </ol>"},{"location":"reference/faq/#is-my-data-backed-up","title":"Is my data backed up?","text":"<p>Yes, the system includes multiple backup mechanisms: - Daily automated backups of the database (retained for 7 days) - Manual snapshots before each deployment - S3 file versioning for uploaded documents - Point-in-time recovery available for the last 35 days</p>"},{"location":"reference/faq/#account-access","title":"Account &amp; Access","text":""},{"location":"reference/faq/#how-do-i-reset-my-password","title":"How do I reset my password?","text":"<p>Contact your system administrator to reset your password. They will: 1. Generate a new invite token 2. Send you a registration link 3. You can then set a new password</p> <p>Note: There is currently no self-service password reset. This feature may be added in the future.</p>"},{"location":"reference/faq/#why-was-i-logged-out","title":"Why was I logged out?","text":"<p>Sessions expire after 24 hours of inactivity. You may also be logged out if: - You cleared your browser cookies - You logged in from another device - An administrator reset your password - The application was restarted</p>"},{"location":"reference/faq/#how-do-i-change-my-username","title":"How do I change my username?","text":"<p>Contact your system administrator. Usernames cannot be changed by regular users.</p>"},{"location":"reference/faq/#what-are-the-different-user-roles","title":"What are the different user roles?","text":"<p>Admin: - Full system access - User management - System configuration - All features available</p> <p>User (Standard): - Create and edit work orders and repair orders - Manage customers and inventory - View analytics - Cannot access admin features</p>"},{"location":"reference/faq/#can-i-have-multiple-accounts","title":"Can I have multiple accounts?","text":"<p>No, each person should have only one account. If you need different permission levels for different tasks, contact your administrator.</p>"},{"location":"reference/faq/#work-orders","title":"Work Orders","text":""},{"location":"reference/faq/#how-do-i-create-a-new-work-order","title":"How do I create a new work order?","text":"<ol> <li>Click \"Work Orders\" in the navigation</li> <li>Click \"New Work Order\" button</li> <li>Select or create a customer</li> <li>Add items (from customer's catalog or new items)</li> <li>Fill in dates and pricing</li> <li>Click \"Save\"</li> </ol> <p>See also: Work Orders User Guide</p>"},{"location":"reference/faq/#how-do-i-add-multiple-items-to-a-work-order","title":"How do I add multiple items to a work order?","text":"<p>Option 1: Select from customer's catalog - Check boxes next to existing items - Items from previous orders appear here</p> <p>Option 2: Add new items - Click \"Add New Item\" button - Fill in description, material, color, quantity - Repeat for each item - New items are automatically added to customer's catalog</p>"},{"location":"reference/faq/#can-i-edit-a-completed-work-order","title":"Can I edit a completed work order?","text":"<p>Yes, but be cautious: - Editing completed work orders may affect historical data - Analytics and reports may show different results - ML predictions use historical data for training</p> <p>Best practice: Only edit completed orders to fix errors, not to make routine changes.</p>"},{"location":"reference/faq/#how-do-i-delete-a-work-order","title":"How do I delete a work order?","text":"<ol> <li>Open the work order detail page</li> <li>Click \"Delete\" button</li> <li>Confirm deletion</li> </ol> <p>Warning: Deletion is permanent and cannot be undone. All associated items and files will be deleted.</p>"},{"location":"reference/faq/#what-do-the-different-work-order-statuses-mean","title":"What do the different work order statuses mean?","text":"<ul> <li>Pending - Order created, not yet picked up</li> <li>In Progress - Being cleaned or worked on</li> <li>Completed - Finished and ready for return</li> <li>Returned - Delivered back to customer</li> </ul>"},{"location":"reference/faq/#how-do-i-change-a-work-orders-position-in-the-queue","title":"How do I change a work order's position in the queue?","text":"<ol> <li>Go to \"Cleaning Queue\"</li> <li>Drag and drop work orders to reorder</li> <li>Changes save automatically</li> </ol> <p>Orders with higher priority should be placed higher in the queue.</p>"},{"location":"reference/faq/#can-i-print-a-work-order","title":"Can I print a work order?","text":"<p>Yes: 1. Open the work order detail page 2. Click \"Download PDF\" button 3. Open the PDF and print</p> <p>The PDF includes all order details, customer information, and items.</p>"},{"location":"reference/faq/#repair-orders","title":"Repair Orders","text":""},{"location":"reference/faq/#whats-the-difference-between-a-work-order-and-a-repair-order","title":"What's the difference between a work order and a repair order?","text":"<p>Work Order: - For in-house awning cleaning - Tracked through internal queue - Simpler workflow (picked up \u2192 cleaned \u2192 returned)</p> <p>Repair Order: - For repairs sent to external vendors (sail lofts) - Includes source/vendor tracking - More complex workflow (picked up \u2192 sent out \u2192 received \u2192 returned)</p>"},{"location":"reference/faq/#how-do-i-create-a-repair-order","title":"How do I create a repair order?","text":"<ol> <li>Click \"Repair Orders\" in navigation</li> <li>Click \"New Repair Order\"</li> <li>Select customer and source/vendor</li> <li>Add items to be repaired</li> <li>Fill in dates (sent out, received, etc.)</li> <li>Save</li> </ol>"},{"location":"reference/faq/#can-i-see-all-repair-orders-sent-to-a-specific-vendor","title":"Can I see all repair orders sent to a specific vendor?","text":"<p>Yes: 1. Go to \"Sources\" (vendors) 2. Click on the source/vendor name 3. View list of all repair orders sent to that vendor</p>"},{"location":"reference/faq/#how-long-do-repairs-typically-take","title":"How long do repairs typically take?","text":"<p>The system includes an ML prediction feature that estimates completion time based on: - Historical repair order data - Vendor/source performance - Item complexity</p> <p>Average repair times vary by vendor and are displayed in the analytics dashboard.</p>"},{"location":"reference/faq/#customers","title":"Customers","text":""},{"location":"reference/faq/#how-do-i-add-a-new-customer","title":"How do I add a new customer?","text":"<ol> <li>Click \"Customers\" in navigation</li> <li>Click \"New Customer\" button</li> <li>Fill in customer information:</li> <li>Name (required)</li> <li>Phone, email, address (optional)</li> <li>Click \"Save\"</li> </ol>"},{"location":"reference/faq/#what-is-a-customer-catalog","title":"What is a customer catalog?","text":"<p>The customer catalog is a collection of items that belong to a specific customer. When you add items to work orders or repair orders, they're automatically saved to the customer's catalog for easy reuse.</p> <p>Benefits: - Quick item selection for future orders - Consistent item descriptions - Track customer's inventory over time</p>"},{"location":"reference/faq/#can-i-merge-duplicate-customers","title":"Can I merge duplicate customers?","text":"<p>Currently, there is no automated merge feature. Contact your administrator to manually merge customer records and transfer order history.</p>"},{"location":"reference/faq/#how-do-i-search-for-a-customer","title":"How do I search for a customer?","text":"<p>Option 1: Browse list - Go to \"Customers\" - Scroll through the list - Use pagination at bottom</p> <p>Option 2: Use search - Type customer name in search box - Results appear as you type - Click on customer to view details</p> <p>Tips: - Search is case-insensitive - Partial names work (e.g., \"john\" finds \"John Doe Yachts\") - Type at least 3 characters for best results</p>"},{"location":"reference/faq/#can-i-export-customer-data","title":"Can I export customer data?","text":"<p>Currently, customer data export is not available in the user interface. Contact your administrator if you need a customer data export.</p>"},{"location":"reference/faq/#file-uploads","title":"File Uploads","text":""},{"location":"reference/faq/#what-types-of-files-can-i-upload","title":"What types of files can I upload?","text":"<p>Allowed file types: - Documents: PDF, DOC, DOCX, XLS, XLSX - Images: JPG, JPEG, PNG, GIF</p> <p>Use cases: - Photos of awnings before/after cleaning - Repair quotes from vendors - Customer correspondence - Invoices and receipts</p>"},{"location":"reference/faq/#what-is-the-file-size-limit","title":"What is the file size limit?","text":"<p>Maximum file size: 10MB per file</p> <p>If your file is too large: - Compress images (reduce quality or size) - Convert documents to PDF - Split large files into smaller parts - Contact administrator if you need to upload larger files</p>"},{"location":"reference/faq/#where-are-my-uploaded-files-stored","title":"Where are my uploaded files stored?","text":"<p>Files are stored securely in AWS S3 (Amazon Simple Storage Service): - Not stored on the web server - Encrypted in transit and at rest - Backed up with versioning enabled - Accessible only to authenticated users</p>"},{"location":"reference/faq/#can-i-delete-an-uploaded-file","title":"Can I delete an uploaded file?","text":"<p>Yes: 1. Open the work order with the file 2. Find the file in the \"Files\" section 3. Click \"Delete\" button 4. Confirm deletion</p> <p>Warning: Deletion is permanent.</p>"},{"location":"reference/faq/#why-did-my-file-upload-fail","title":"Why did my file upload fail?","text":"<p>Common reasons: - File too large (&gt;10MB) - Invalid file type - Network timeout - S3 connection issue</p> <p>See: Troubleshooting - File Upload Issues</p>"},{"location":"reference/faq/#pdf-generation","title":"PDF Generation","text":""},{"location":"reference/faq/#how-do-i-generate-a-pdf-for-a-work-order","title":"How do I generate a PDF for a work order?","text":"<ol> <li>Open the work order detail page</li> <li>Click \"Download PDF\" button</li> <li>PDF will download automatically</li> </ol> <p>The PDF includes: - Company logo and header - Customer information - Work order details - Items list - Pricing information - Notes</p>"},{"location":"reference/faq/#can-i-customize-the-pdf-format","title":"Can I customize the PDF format?","text":"<p>PDF formatting is standardized for consistency. If you need custom formatting, contact your administrator to request changes to the PDF template.</p>"},{"location":"reference/faq/#the-pdf-isnt-generating-what-should-i-do","title":"The PDF isn't generating. What should I do?","text":"<p>Check these common issues: 1. Work order has a customer assigned 2. Work order has at least one item 3. Browser allows downloads 4. Pop-ups aren't blocked</p> <p>See: Troubleshooting - PDF Generation</p>"},{"location":"reference/faq/#can-i-email-pdfs-directly-from-the-system","title":"Can I email PDFs directly from the system?","text":"<p>This feature is not currently available. You can: 1. Download the PDF 2. Attach to email manually 3. Send via your email client</p>"},{"location":"reference/faq/#analytics-reports","title":"Analytics &amp; Reports","text":""},{"location":"reference/faq/#what-analytics-are-available","title":"What analytics are available?","text":"<p>The analytics dashboard provides: - Revenue trends over time - Order volume statistics - Source/vendor performance breakdown - Customer analytics (top customers, order frequency) - Completion time analysis - ML predictions for future orders</p>"},{"location":"reference/faq/#how-do-i-filter-analytics-by-date-range","title":"How do I filter analytics by date range?","text":"<ol> <li>Go to Analytics dashboard</li> <li>Select start date and end date</li> <li>Click \"Apply\"</li> <li>Charts update automatically</li> </ol> <p>Tip: Use shorter date ranges (e.g., last 30 days) for better performance.</p>"},{"location":"reference/faq/#can-i-export-analytics-data","title":"Can I export analytics data?","text":"<p>Currently, analytics export is not available in the UI. Administrators can export data via database queries or contact support for custom reports.</p>"},{"location":"reference/faq/#what-is-the-ml-prediction-feature","title":"What is the ML prediction feature?","text":"<p>The ML (Machine Learning) model predicts work order completion times based on: - Historical completion data - Customer patterns - Item complexity - Seasonal trends</p> <p>How it works: 1. Model trains daily on historical data 2. Analyzes completed work orders 3. Predicts completion time for new orders 4. Improves accuracy over time</p> <p>Accuracy: Model accuracy improves with more data (typically &gt;100 completed orders needed)</p>"},{"location":"reference/faq/#technical-questions","title":"Technical Questions","text":""},{"location":"reference/faq/#what-browsers-are-supported","title":"What browsers are supported?","text":"<p>Fully supported: - Google Chrome (recommended) - Mozilla Firefox - Apple Safari - Microsoft Edge</p> <p>Version requirements: - Use the latest stable version - JavaScript must be enabled - Cookies must be allowed</p> <p>Not supported: - Internet Explorer - Very old browser versions (&lt;2 years old)</p>"},{"location":"reference/faq/#do-i-need-to-install-any-software","title":"Do I need to install any software?","text":"<p>No, the Awning Management System is a web-based application. You only need: - A supported web browser - Internet connection - Login credentials</p> <p>No downloads or installations required.</p>"},{"location":"reference/faq/#does-the-app-work-offline","title":"Does the app work offline?","text":"<p>No, the application requires an internet connection. All data is stored on the server, not locally.</p> <p>If you lose connection: - Unsaved changes may be lost - Refresh the page when connection returns - Log in again if session expired</p>"},{"location":"reference/faq/#where-is-my-data-stored","title":"Where is my data stored?","text":"<p>Database: AWS RDS (PostgreSQL) in US-East-1 region Files: AWS S3 in US-East-1 region Application: AWS Elastic Beanstalk</p> <p>All data is stored within the United States and follows AWS security best practices.</p>"},{"location":"reference/faq/#is-my-data-secure","title":"Is my data secure?","text":"<p>Yes, the application includes multiple security measures: - HTTPS encryption for all data in transit - Database encryption at rest - User authentication required for all access - Role-based access control (admin vs. user) - Automated backups with encryption - Regular security updates</p>"},{"location":"reference/faq/#how-often-is-the-application-updated","title":"How often is the application updated?","text":"<p>Regular updates: - Security patches: As needed (urgent) - Bug fixes: Weekly to bi-weekly - New features: Monthly to quarterly</p> <p>Maintenance windows: - Deployments: Usually weekday mornings (low traffic) - Downtime: Typically 1-2 minutes - Users are notified of major updates</p>"},{"location":"reference/faq/#billing-pricing","title":"Billing &amp; Pricing","text":""},{"location":"reference/faq/#how-much-does-the-application-cost","title":"How much does the application cost?","text":"<p>Pricing information is not publicly available. Contact your organization's administrator or management for licensing costs.</p>"},{"location":"reference/faq/#are-there-usage-limits","title":"Are there usage limits?","text":"<p>Current limits: - File uploads: 10MB per file - No limit on number of work orders, customers, or users</p> <p>For cloud hosting costs, your organization's AWS usage determines the cost.</p>"},{"location":"reference/faq/#can-i-add-more-users","title":"Can I add more users?","text":"<p>Yes, administrators can create new user accounts at any time. There is no hard limit on number of users.</p> <p>To add users: - Administrator generates invite token - Sends registration link to new user - User sets password and logs in</p>"},{"location":"reference/faq/#common-questions-by-user-type","title":"Common Questions by User Type","text":""},{"location":"reference/faq/#for-office-staff","title":"For Office Staff","text":"<p>Q: How do I handle a customer call about their order? 1. Search for customer by name 2. View customer detail page 3. Check work order or repair order status 4. Update customer with current status</p> <p>Q: How do I prioritize rush orders? 1. Go to \"Cleaning Queue\" 2. Drag rush order to top of queue 3. Mark order with high priority (if available)</p>"},{"location":"reference/faq/#for-cleaning-crew","title":"For Cleaning Crew","text":"<p>Q: What should I work on next? 1. Go to \"Cleaning Queue\" 2. Work on orders from top to bottom 3. Update status as you progress</p> <p>Q: How do I mark an order as complete? 1. Open the work order 2. Click \"Edit\" 3. Update \"Cleaned\" date and status 4. Save</p>"},{"location":"reference/faq/#for-managers","title":"For Managers","text":"<p>Q: How do I see overall business performance? 1. Go to \"Analytics\" dashboard 2. Review revenue trends, order volume 3. Filter by date range for specific periods 4. Export data if needed (contact admin)</p> <p>Q: Which vendors are performing best? 1. Go to \"Analytics\" 2. View \"Source Performance\" chart 3. Compare completion times and volume</p>"},{"location":"reference/faq/#still-have-questions","title":"Still Have Questions?","text":""},{"location":"reference/faq/#for-users","title":"For Users","text":"<ol> <li>Check the User Guide</li> <li>Review Troubleshooting Guide</li> <li>Contact your system administrator</li> <li>Email: support@yourdomain.com</li> </ol>"},{"location":"reference/faq/#for-administrators","title":"For Administrators","text":"<ol> <li>Check the Developer Guide</li> <li>Review Operations Runbook</li> <li>Check GitHub Issues</li> <li>Create a new issue with details</li> </ol>"},{"location":"reference/faq/#document-information","title":"Document Information","text":"<p>Last Updated: 2025-11-16</p> <p>Feedback: If you have suggestions for improving this FAQ, please contact your administrator or create a GitHub issue.</p>"},{"location":"reference/glossary/","title":"Glossary","text":""},{"location":"reference/glossary/#terms","title":"Terms","text":"<p>Awning : A fabric covering used for shade or weather protection.</p> <p>Cleaning Queue : The queue of work orders awaiting cleaning.</p> <p>Customer : A client who owns awnings or sails that need cleaning or repair.</p> <p>Final Location : Where an item is stored after service is complete.</p> <p>Rack Number : The physical storage location identifier (e.g., \"5B\", \"Hang 4\").</p> <p>Repair Order : A job to repair damaged awnings or sails.</p> <p>Sail : A large fabric structure, typically for boats.</p> <p>Source : The sail loft or vendor associated with a customer.</p> <p>Storage Time : Whether storage is Seasonal or Temporary.</p> <p>Work Order : A job to clean awnings or sails.</p>"},{"location":"reference/glossary/#abbreviations","title":"Abbreviations","text":"<p>RO: Repair Order</p> <p>WO: Work Order</p> <p>SQL: Structured Query Language</p> <p>ORM: Object-Relational Mapping</p> <p>PDF: Portable Document Format</p>"},{"location":"reference/troubleshooting/","title":"Troubleshooting Guide","text":""},{"location":"reference/troubleshooting/#overview","title":"Overview","text":"<p>This comprehensive troubleshooting guide covers common issues, error messages, and their solutions for the Awning Management System.</p>"},{"location":"reference/troubleshooting/#quick-diagnosis","title":"Quick Diagnosis","text":"<p>Start here if you're experiencing issues:</p> Symptom Likely Cause Quick Fix Detailed Section Cannot log in Wrong credentials Verify username/password Login Issues Page won't load Server error Check logs, restart Application Errors Slow performance Database query Clear cache, optimize Performance Issues PDF won't generate Missing data Check required fields PDF Generation File upload fails Size/type limit Check file size (&lt;10MB) File Upload Issues Data not saving Validation error Check form fields Form Validation"},{"location":"reference/troubleshooting/#login-issues","title":"Login Issues","text":""},{"location":"reference/troubleshooting/#invalid-username-or-password","title":"\"Invalid username or password\"","text":"<p>Symptoms: - Error message on login page - Cannot access application</p> <p>Causes: 1. Incorrect credentials 2. User account disabled 3. Caps Lock enabled 4. Password recently changed</p> <p>Solutions:</p> <p>Step 1: Verify credentials <pre><code>- Double-check username (case-sensitive)\n- Verify password (check Caps Lock)\n- Try copying/pasting password from password manager\n</code></pre></p> <p>Step 2: Check account status <pre><code>Contact administrator to verify:\n- Account exists\n- Account is active (not disabled)\n- Password hasn't expired\n</code></pre></p> <p>Step 3: Reset password <pre><code>1. Contact system administrator\n2. Request password reset\n3. Administrator will generate new invite token\n4. Follow registration link to set new password\n</code></pre></p>"},{"location":"reference/troubleshooting/#session-expired","title":"Session Expired","text":"<p>Symptoms: - Logged out unexpectedly - \"Please log in to continue\" message</p> <p>Causes: - Session timeout (24 hours default) - Browser cookies cleared - Multiple tabs/devices</p> <p>Solutions: <pre><code>1. Log in again\n2. Check \"Remember Me\" box (if available)\n3. Clear browser cookies and try again\n4. Contact admin if issue persists\n</code></pre></p>"},{"location":"reference/troubleshooting/#application-errors","title":"Application Errors","text":""},{"location":"reference/troubleshooting/#500-internal-server-error","title":"500 Internal Server Error","text":"<p>Symptoms: - \"500 Internal Server Error\" message - Page fails to load - Generic error page</p> <p>Common causes:</p> <p>1. Database connection failure <pre><code>Solution: Contact administrator\n- Application needs to be restarted\n- Database may be down\n</code></pre></p> <p>2. Application bug <pre><code>Solution: Report to administrator with:\n- What you were trying to do\n- Steps to reproduce\n- Screenshot of error\n</code></pre></p>"},{"location":"reference/troubleshooting/#404-not-found","title":"404 Not Found","text":"<p>Symptoms: - \"404 Not Found\" error - Page doesn't exist</p> <p>Solutions: <pre><code>1. Check URL for typos\n2. Verify resource exists (e.g., work order #123)\n3. Return to dashboard and navigate again\n4. Clear browser cache\n</code></pre></p>"},{"location":"reference/troubleshooting/#403-forbidden","title":"403 Forbidden","text":"<p>Symptoms: - \"403 Forbidden\" message - \"You don't have permission to access this resource\"</p> <p>Causes: - Insufficient user permissions - Accessing admin-only page as regular user</p> <p>Solutions: <pre><code>1. Contact administrator for permission upgrade\n2. Verify you need access to this feature\n3. Use a different account with proper permissions\n</code></pre></p>"},{"location":"reference/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting/#page-loads-slowly","title":"Page Loads Slowly","text":"<p>Symptoms: - Pages take &gt;5 seconds to load - Timeout errors - Application feels sluggish</p> <p>Solutions:</p> <p>1. Clear browser cache <pre><code>Chrome: Ctrl+Shift+Delete (Cmd+Shift+Delete on Mac)\nFirefox: Ctrl+Shift+Delete\nSafari: Cmd+Option+E\n</code></pre></p> <p>2. Check internet connection <pre><code>- Run speed test (speedtest.net)\n- Try on different network\n- Use wired connection instead of WiFi\n</code></pre></p> <p>3. Try different browser <pre><code>- Test in Chrome, Firefox, or Safari\n- Disable browser extensions\n- Use incognito/private mode\n</code></pre></p> <p>4. Contact administrator (if persistent) <pre><code>Provide:\n- Which page is slow\n- How long it takes to load\n- Your internet speed\n- Browser and version\n</code></pre></p>"},{"location":"reference/troubleshooting/#dashboard-loads-slowly","title":"Dashboard Loads Slowly","text":"<p>Symptoms: - Analytics dashboard takes &gt;10 seconds - Charts don't render - Browser becomes unresponsive</p> <p>Solutions: <pre><code>1. Reduce date range (e.g., last 30 days vs. all time)\n2. Filter by specific customers or sources\n3. Clear browser cache\n4. Close other browser tabs\n5. Use Chrome for best performance\n</code></pre></p>"},{"location":"reference/troubleshooting/#pdf-generation-issues","title":"PDF Generation Issues","text":""},{"location":"reference/troubleshooting/#pdf-doesnt-generate","title":"PDF Doesn't Generate","text":"<p>Symptoms: - \"PDF generation failed\" error - Download doesn't start - Blank PDF downloaded</p> <p>Solutions:</p> <p>1. Check browser settings <pre><code>- Enable pop-ups for this site\n- Allow downloads\n- Check Downloads folder\n</code></pre></p> <p>2. Verify required fields <pre><code>- Work order has customer assigned\n- Items exist on work order\n- All dates are valid\n</code></pre></p> <p>3. Try different browser <pre><code>- Chrome or Firefox recommended\n- Disable PDF viewer extensions\n- Try downloading instead of viewing\n</code></pre></p> <p>4. Contact administrator (if persistent) <pre><code>Provide:\n- Work order number\n- Screenshot of error\n- Browser and version\n</code></pre></p>"},{"location":"reference/troubleshooting/#pdf-formatting-issues","title":"PDF Formatting Issues","text":"<p>Symptoms: - Text overlaps - Images don't appear - Wrong page size</p> <p>Solutions: <pre><code>1. Download PDF instead of viewing in browser\n2. Open with Adobe Reader or Preview\n3. Print to PDF if needed\n4. Report formatting issues to administrator\n</code></pre></p>"},{"location":"reference/troubleshooting/#file-upload-issues","title":"File Upload Issues","text":""},{"location":"reference/troubleshooting/#file-upload-fails","title":"File Upload Fails","text":"<p>Symptoms: - \"File upload failed\" error - Upload progress bar stalls - File doesn't appear after upload</p> <p>Solutions:</p> <p>1. Check file size <pre><code>Maximum file size: 10MB\n- Compress file before uploading\n- Split into multiple smaller files\n</code></pre></p> <p>2. Check file type <pre><code>Allowed types: PDF, JPG, PNG, GIF, DOC, DOCX, XLS, XLSX\n- Convert file to allowed format\n- Use PDF for documents, JPG/PNG for images\n</code></pre></p> <p>3. Check internet connection <pre><code>- Try uploading again\n- Use wired connection instead of WiFi\n- Upload during off-peak hours\n</code></pre></p> <p>4. Try different browser <pre><code>- Chrome or Firefox recommended\n- Disable browser extensions\n- Clear browser cache\n</code></pre></p>"},{"location":"reference/troubleshooting/#uploaded-file-doesnt-appear","title":"Uploaded File Doesn't Appear","text":"<p>Symptoms: - Upload completes successfully - File not visible in work order files list</p> <p>Solutions: <pre><code>1. Refresh page (Ctrl+R or Cmd+R)\n2. Clear browser cache\n3. Check if file was uploaded to correct work order\n4. Wait 1-2 minutes and refresh again\n5. Contact administrator if still missing\n</code></pre></p>"},{"location":"reference/troubleshooting/#form-validation-errors","title":"Form Validation Errors","text":""},{"location":"reference/troubleshooting/#required-field-error","title":"\"Required field\" Error","text":"<p>Symptoms: - Cannot submit form - Red error message under field - Form highlights missing fields</p> <p>Solutions: <pre><code>1. Fill in all required fields (marked with *)\n2. Check for empty fields that appear filled\n3. Verify date fields have valid dates (MM/DD/YYYY)\n4. Ensure numeric fields have numbers\n5. Remove any special characters\n</code></pre></p>"},{"location":"reference/troubleshooting/#invalid-email-format","title":"\"Invalid email format\"","text":"<p>Solutions: <pre><code>Use format: user@example.com\n\nCorrect:\n- john@example.com\n- jane.doe@company.org\n\nIncorrect:\n- john@example (no domain)\n- @example.com (no username)\n- john @example.com (space)\n</code></pre></p>"},{"location":"reference/troubleshooting/#invalid-phone-number","title":"\"Invalid phone number\"","text":"<p>Solutions: <pre><code>Accepted formats:\n- (555) 123-4567\n- 555-123-4567\n- 5551234567\n\nTips:\n- Remove country code (+1)\n- Use 10 digits only\n- Hyphens and parentheses are optional\n</code></pre></p>"},{"location":"reference/troubleshooting/#form-doesnt-save","title":"Form Doesn't Save","text":"<p>Symptoms: - Click \"Save\" but nothing happens - Form resets or shows same errors - Data not persisted</p> <p>Solutions: <pre><code>1. Disable browser extensions (ad blockers)\n2. Try different browser (Chrome, Firefox, Safari)\n3. Clear browser cache\n4. Check internet connection\n5. Contact admin with screenshot\n</code></pre></p>"},{"location":"reference/troubleshooting/#search-issues","title":"Search Issues","text":""},{"location":"reference/troubleshooting/#customer-search-not-working","title":"Customer Search Not Working","text":"<p>Symptoms: - Search returns no results - Search is slow - Wrong customers appear</p> <p>Solutions: <pre><code>1. Type at least 3 characters\n2. Check spelling\n3. Try partial name (e.g., \"john\" instead of \"john doe yachts\")\n4. Clear search and try again\n5. Refresh page\n</code></pre></p>"},{"location":"reference/troubleshooting/#search-returns-too-many-results","title":"Search Returns Too Many Results","text":"<p>Solutions: <pre><code>1. Be more specific in search terms\n2. Use full customer name\n3. Include unique identifiers\n4. Use advanced filters (if available)\n</code></pre></p>"},{"location":"reference/troubleshooting/#work-order-issues","title":"Work Order Issues","text":""},{"location":"reference/troubleshooting/#cannot-save-work-order","title":"Cannot Save Work Order","text":"<p>Symptoms: - \"Cannot save work order\" error - Validation errors - Form won't submit</p> <p>Solutions: <pre><code>1. Check all required fields are filled:\n   - Customer name\n   - At least one item\n   - Valid dates (if entered)\n\n2. Verify customer exists:\n   - Search for customer first\n   - Create customer if doesn't exist\n\n3. Check items:\n   - Description not empty\n   - Quantity is a number\n   - No special characters in fields\n\n4. Try again:\n   - Clear form and start over\n   - Refresh page\n   - Try different browser\n</code></pre></p>"},{"location":"reference/troubleshooting/#cannot-find-work-order","title":"Cannot Find Work Order","text":"<p>Symptoms: - Work order doesn't appear in list - Search returns no results - \"Work order not found\"</p> <p>Solutions: <pre><code>1. Check work order number is correct\n2. Use search function with customer name\n3. Filter by status (pending, in progress, completed)\n4. Check if work order was deleted\n5. Contact administrator to verify\n</code></pre></p>"},{"location":"reference/troubleshooting/#browser-specific-issues","title":"Browser-Specific Issues","text":""},{"location":"reference/troubleshooting/#chrome","title":"Chrome","text":"<p>Cookies not persisting <pre><code>1. Settings &gt; Privacy and security &gt; Cookies\n2. Allow cookies from application domain\n3. Disable \"Block third-party cookies\" if needed\n</code></pre></p> <p>PDF downloads fail <pre><code>1. Settings &gt; Downloads\n2. Turn off \"Ask where to save each file\"\n3. Clear download history\n</code></pre></p>"},{"location":"reference/troubleshooting/#firefox","title":"Firefox","text":"<p>Session expires immediately <pre><code>1. Options &gt; Privacy &amp; Security\n2. History: Use custom settings\n3. Accept cookies from sites\n4. Keep until: they expire\n</code></pre></p>"},{"location":"reference/troubleshooting/#safari","title":"Safari","text":"<p>Forms don't submit <pre><code>1. Safari &gt; Preferences &gt; Privacy\n2. Uncheck \"Prevent cross-site tracking\"\n3. Cookies: Allow from websites I visit\n</code></pre></p>"},{"location":"reference/troubleshooting/#mobile-device-issues","title":"Mobile Device Issues","text":""},{"location":"reference/troubleshooting/#iphoneipad","title":"iPhone/iPad","text":"<p>Cannot upload files <pre><code>1. Use \"Files\" app integration\n2. Or email file to yourself and download\n3. Then upload from Downloads folder\n</code></pre></p> <p>Form inputs don't work <pre><code>1. Use Safari browser (not Chrome)\n2. Enable JavaScript in Settings\n3. Disable content blockers for this site\n</code></pre></p>"},{"location":"reference/troubleshooting/#android","title":"Android","text":"<p>PDF doesn't download <pre><code>1. Enable \"Download without notification\"\n2. Check Download folder\n3. Use Chrome or Firefox browser\n</code></pre></p> <p>Forms are hard to use <pre><code>1. Use landscape mode for better layout\n2. Zoom in on form fields\n3. Use desktop site mode (3-dot menu &gt; Desktop site)\n</code></pre></p>"},{"location":"reference/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"reference/troubleshooting/#before-contacting-support","title":"Before Contacting Support","text":"<p>Gather this information: - [ ] What were you trying to do? - [ ] What did you expect to happen? - [ ] What actually happened? - [ ] Screenshot of error (if any) - [ ] Browser and version - [ ] Date and time of issue - [ ] Username (don't include password)</p>"},{"location":"reference/troubleshooting/#how-to-get-help","title":"How to Get Help","text":"<p>For Users: <pre><code>1. Check this troubleshooting guide\n2. Check FAQ (docs/reference/faq.md)\n3. Contact your system administrator\n4. Email: support@yourdomain.com\n</code></pre></p> <p>For Administrators: <pre><code>1. Check operations runbook (docs/deployment/operations-runbook.md)\n2. Review application logs\n3. Check GitHub issues\n4. Create new issue with details\n</code></pre></p>"},{"location":"reference/troubleshooting/#quick-reference","title":"Quick Reference","text":""},{"location":"reference/troubleshooting/#error-code-meanings","title":"Error Code Meanings","text":"Code Meaning Common Cause 400 Bad Request Invalid form data 401 Unauthorized Not logged in 403 Forbidden Insufficient permissions 404 Not Found Resource doesn't exist 500 Internal Server Error Application bug 502 Bad Gateway Server overloaded 503 Service Unavailable Server down/restarting"},{"location":"reference/troubleshooting/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"Shortcut Action Ctrl+S Save form (if supported) Ctrl+R Refresh page F5 Refresh page Ctrl+Shift+Delete Clear browser cache"},{"location":"reference/troubleshooting/#last-updated","title":"Last Updated","text":"<p>This troubleshooting guide was last updated on 2025-11-16.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the Awning Management System User Guide! This section contains everything you need to know to use the application effectively.</p>"},{"location":"user-guide/#getting-started","title":"Getting Started","text":"<p>If you're new to the system, start here:</p> <ul> <li>Getting Started - Login, navigation, and basic concepts</li> <li>Keyboard Shortcuts - Speed up your workflow</li> </ul>"},{"location":"user-guide/#core-features","title":"Core Features","text":"<p>Learn about the main features of the application:</p> <ul> <li>Work Orders - Creating and managing cleaning work orders</li> <li>Repair Orders - Handling repair jobs</li> <li>Customers - Managing customer information</li> <li>Sources &amp; Vendors - Working with sail lofts and vendors</li> <li>Inventory - Tracking inventory items</li> </ul>"},{"location":"user-guide/#workflows","title":"Workflows","text":"<p>Specialized workflows for daily operations:</p> <ul> <li>Queue Management - Managing the cleaning and repair queues</li> <li>Analytics Dashboard - Understanding business metrics</li> <li>PDF Reports - Generating and using PDF reports</li> </ul>"},{"location":"user-guide/#need-help","title":"Need Help?","text":"<ul> <li>Check the FAQ for common questions</li> <li>See Troubleshooting for common issues</li> </ul>"},{"location":"user-guide/getting-started/","title":"Getting Started","text":""},{"location":"user-guide/getting-started/#logging-in","title":"Logging In","text":"<ol> <li>Navigate to the application URL</li> <li>Enter your username and password</li> <li>Click \"Log In\"</li> </ol> <p>If you don't have credentials, contact your administrator.</p>"},{"location":"user-guide/getting-started/#dashboard-overview","title":"Dashboard Overview","text":"<p>After logging in, you'll see the main dashboard with:</p> <ul> <li>Quick Stats - Key metrics at a glance</li> <li>Recent Activity - Latest work orders and updates</li> <li>Navigation Menu - Access to all features</li> </ul>"},{"location":"user-guide/getting-started/#basic-navigation","title":"Basic Navigation","text":"<p>Use the top navigation bar to access:</p> <ul> <li>Dashboard - Main overview</li> <li>Work Orders - Cleaning work orders</li> <li>Repair Orders - Repair jobs</li> <li>Customers - Customer database</li> <li>Sources - Vendor management</li> <li>Queue - Work queue</li> <li>Analytics - Reports and insights</li> </ul>"},{"location":"user-guide/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Work Orders</li> <li>Set up Keyboard Shortcuts</li> <li>Explore the Analytics Dashboard</li> </ul> <p>Pro Tip</p> <p>Use keyboard shortcuts to speed up data entry. Press <code>?</code> to see available shortcuts.</p>"},{"location":"user-guide/work-orders/","title":"Work Orders","text":"<p>Work orders track cleaning jobs from intake to completion.</p>"},{"location":"user-guide/work-orders/#creating-a-work-order","title":"Creating a Work Order","text":"<ol> <li>Click \"New Work Order\" in the navigation menu</li> <li>Select or create a customer</li> <li>Fill in work order details</li> <li>Add items to be cleaned</li> <li>Click \"Save\"</li> </ol>"},{"location":"user-guide/work-orders/#work-order-fields","title":"Work Order Fields","text":"<ul> <li>Customer - The customer for this order</li> <li>Date In - When the items were received</li> <li>Source - The sail loft or vendor</li> <li>Storage Location - Where items are stored</li> <li>Storage Time - Seasonal or Temporary</li> <li>Items - Individual awnings or sails to clean</li> </ul>"},{"location":"user-guide/work-orders/#editing-a-work-order","title":"Editing a Work Order","text":"<ol> <li>Navigate to the work order detail page</li> <li>Click \"Edit\"</li> <li>Update fields as needed</li> <li>Click \"Save Changes\"</li> </ol>"},{"location":"user-guide/work-orders/#completing-a-work-order","title":"Completing a Work Order","text":"<ol> <li>Open the work order</li> <li>Set the \"Date Completed\" field</li> <li>Add final location if needed</li> <li>Click \"Mark Complete\"</li> </ol>"},{"location":"user-guide/work-orders/#generating-pdfs","title":"Generating PDFs","text":"<p>Click the \"Generate PDF\" button on any work order to create a printable report.</p> <p>Important</p> <p>Always verify customer information before completing an order.</p>"}]}